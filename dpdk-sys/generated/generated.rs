/* automatically generated by rust-bindgen 0.72.1 */

#[repr(C)]
#[derive(Copy, Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct __BindgenBitfieldUnit<Storage> {
    storage: Storage,
}
impl<Storage> __BindgenBitfieldUnit<Storage> {
    #[inline]
    pub const fn new(storage: Storage) -> Self {
        Self { storage }
    }
}
impl<Storage> __BindgenBitfieldUnit<Storage>
where
    Storage: AsRef<[u8]> + AsMut<[u8]>,
{
    #[inline]
    fn extract_bit(byte: u8, index: usize) -> bool {
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        byte & mask == mask
    }
    #[inline]
    pub fn get_bit(&self, index: usize) -> bool {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = self.storage.as_ref()[byte_index];
        Self::extract_bit(byte, index)
    }
    #[inline]
    pub unsafe fn raw_get_bit(this: *const Self, index: usize) -> bool {
        debug_assert!(index / 8 < core::mem::size_of::<Storage>());
        let byte_index = index / 8;
        let byte = unsafe {
            *(core::ptr::addr_of!((*this).storage) as *const u8).offset(byte_index as isize)
        };
        Self::extract_bit(byte, index)
    }
    #[inline]
    fn change_bit(byte: u8, index: usize, val: bool) -> u8 {
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        if val { byte | mask } else { byte & !mask }
    }
    #[inline]
    pub fn set_bit(&mut self, index: usize, val: bool) {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = &mut self.storage.as_mut()[byte_index];
        *byte = Self::change_bit(*byte, index, val);
    }
    #[inline]
    pub unsafe fn raw_set_bit(this: *mut Self, index: usize, val: bool) {
        debug_assert!(index / 8 < core::mem::size_of::<Storage>());
        let byte_index = index / 8;
        let byte = unsafe {
            (core::ptr::addr_of_mut!((*this).storage) as *mut u8).offset(byte_index as isize)
        };
        unsafe { *byte = Self::change_bit(*byte, index, val) };
    }
    #[inline]
    pub fn get(&self, bit_offset: usize, bit_width: u8) -> u64 {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        let mut val = 0;
        for i in 0..(bit_width as usize) {
            if self.get_bit(i + bit_offset) {
                let index = if cfg!(target_endian = "big") {
                    bit_width as usize - 1 - i
                } else {
                    i
                };
                val |= 1 << index;
            }
        }
        val
    }
    #[inline]
    pub unsafe fn raw_get(this: *const Self, bit_offset: usize, bit_width: u8) -> u64 {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < core::mem::size_of::<Storage>());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= core::mem::size_of::<Storage>());
        let mut val = 0;
        for i in 0..(bit_width as usize) {
            if unsafe { Self::raw_get_bit(this, i + bit_offset) } {
                let index = if cfg!(target_endian = "big") {
                    bit_width as usize - 1 - i
                } else {
                    i
                };
                val |= 1 << index;
            }
        }
        val
    }
    #[inline]
    pub fn set(&mut self, bit_offset: usize, bit_width: u8, val: u64) {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        for i in 0..(bit_width as usize) {
            let mask = 1 << i;
            let val_bit_is_set = val & mask == mask;
            let index = if cfg!(target_endian = "big") {
                bit_width as usize - 1 - i
            } else {
                i
            };
            self.set_bit(index + bit_offset, val_bit_is_set);
        }
    }
    #[inline]
    pub unsafe fn raw_set(this: *mut Self, bit_offset: usize, bit_width: u8, val: u64) {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < core::mem::size_of::<Storage>());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= core::mem::size_of::<Storage>());
        for i in 0..(bit_width as usize) {
            let mask = 1 << i;
            let val_bit_is_set = val & mask == mask;
            let index = if cfg!(target_endian = "big") {
                bit_width as usize - 1 - i
            } else {
                i
            };
            unsafe { Self::raw_set_bit(this, index + bit_offset, val_bit_is_set) };
        }
    }
}
#[repr(C)]
#[derive(Default)]
pub struct __IncompleteArrayField<T>(::core::marker::PhantomData<T>, [T; 0]);
impl<T> __IncompleteArrayField<T> {
    #[inline]
    pub const fn new() -> Self {
        __IncompleteArrayField(::core::marker::PhantomData, [])
    }
    #[inline]
    pub fn as_ptr(&self) -> *const T {
        self as *const _ as *const T
    }
    #[inline]
    pub fn as_mut_ptr(&mut self) -> *mut T {
        self as *mut _ as *mut T
    }
    #[inline]
    pub unsafe fn as_slice(&self, len: usize) -> &[T] {
        unsafe { ::core::slice::from_raw_parts(self.as_ptr(), len) }
    }
    #[inline]
    pub unsafe fn as_mut_slice(&mut self, len: usize) -> &mut [T] {
        unsafe { ::core::slice::from_raw_parts_mut(self.as_mut_ptr(), len) }
    }
}
impl<T> ::core::fmt::Debug for __IncompleteArrayField<T> {
    fn fmt(&self, fmt: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
        fmt.write_str("__IncompleteArrayField")
    }
}
#[repr(C)]
pub struct __BindgenUnionField<T>(::core::marker::PhantomData<T>);
impl<T> __BindgenUnionField<T> {
    #[inline]
    pub const fn new() -> Self {
        __BindgenUnionField(::core::marker::PhantomData)
    }
    #[inline]
    pub unsafe fn as_ref(&self) -> &T {
        unsafe { ::core::mem::transmute(self) }
    }
    #[inline]
    pub unsafe fn as_mut(&mut self) -> &mut T {
        unsafe { ::core::mem::transmute(self) }
    }
}
impl<T> ::core::default::Default for __BindgenUnionField<T> {
    #[inline]
    fn default() -> Self {
        Self::new()
    }
}
impl<T> ::core::clone::Clone for __BindgenUnionField<T> {
    #[inline]
    fn clone(&self) -> Self {
        *self
    }
}
impl<T> ::core::marker::Copy for __BindgenUnionField<T> {}
impl<T> ::core::fmt::Debug for __BindgenUnionField<T> {
    fn fmt(&self, fmt: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
        fmt.write_str("__BindgenUnionField")
    }
}
impl<T> ::core::hash::Hash for __BindgenUnionField<T> {
    fn hash<H: ::core::hash::Hasher>(&self, _state: &mut H) {}
}
impl<T> ::core::cmp::PartialEq for __BindgenUnionField<T> {
    fn eq(&self, _other: &__BindgenUnionField<T>) -> bool {
        true
    }
}
impl<T> ::core::cmp::Eq for __BindgenUnionField<T> {}
pub const RTE_ARCH_X86: u32 = 1;
pub const RTE_ARCH_X86_64: u32 = 1;
pub const RTE_BUS_AUXILIARY: u32 = 1;
pub const RTE_BUS_PCI: u32 = 1;
pub const RTE_BUS_VDEV: u32 = 1;
pub const RTE_CACHE_LINE_SIZE: u32 = 64;
pub const RTE_COMMON_MLX5: u32 = 1;
pub const RTE_COMPILE_TIME_CPUFLAGS: u32 = 71;
pub const RTE_DRIVER_MEMPOOL_BUCKET_SIZE_KB: u32 = 64;
pub const RTE_EAL_NUMA_AWARE_HUGEPAGES: u32 = 1;
pub const RTE_EAL_PMD_PATH: &::core::ffi::CStr =
    c"/nix/store/7vif4n35j8a4ckf3bkiq0czkyyxl3hfr-dpdk-25.03/lib/dpdk/pmds-25.1";
pub const RTE_ENV_FREEBSD: u32 = 0;
pub const RTE_ENV_LINUX: u32 = 1;
pub const RTE_ENV_WINDOWS: u32 = 2;
pub const RTE_EXEC_ENV: u32 = 1;
pub const RTE_EXEC_ENV_IS_FREEBSD: u32 = 0;
pub const RTE_EXEC_ENV_IS_LINUX: u32 = 1;
pub const RTE_EXEC_ENV_IS_WINDOWS: u32 = 0;
pub const RTE_EXEC_ENV_LINUX: u32 = 1;
pub const RTE_HAS_LIBNUMA: u32 = 1;
pub const RTE_IOVA_IN_MBUF: u32 = 1;
pub const RTE_LIBRTE_VHOST_NUMA: u32 = 1;
pub const RTE_LIB_CMDLINE: u32 = 1;
pub const RTE_LIB_CRYPTODEV: u32 = 1;
pub const RTE_LIB_DMADEV: u32 = 1;
pub const RTE_LIB_EAL: u32 = 1;
pub const RTE_LIB_ETHDEV: u32 = 1;
pub const RTE_LIB_HASH: u32 = 1;
pub const RTE_LIB_KVARGS: u32 = 1;
pub const RTE_LIB_LOG: u32 = 1;
pub const RTE_LIB_MBUF: u32 = 1;
pub const RTE_LIB_MEMPOOL: u32 = 1;
pub const RTE_LIB_METER: u32 = 1;
pub const RTE_LIB_NET: u32 = 1;
pub const RTE_LIB_PCI: u32 = 1;
pub const RTE_LIB_RCU: u32 = 1;
pub const RTE_LIB_RING: u32 = 1;
pub const RTE_LIB_STACK: u32 = 1;
pub const RTE_LIB_TELEMETRY: u32 = 1;
pub const RTE_LIB_VHOST: u32 = 1;
pub const RTE_MAX_ETHPORTS: u32 = 32;
pub const RTE_MAX_LCORE: u32 = 128;
pub const RTE_MAX_MEM_MB: u32 = 524288;
pub const RTE_MAX_NUMA_NODES: u32 = 4;
pub const RTE_MAX_VFIO_GROUPS: u32 = 64;
pub const RTE_MEMPOOL_BUCKET: u32 = 1;
pub const RTE_MEMPOOL_RING: u32 = 1;
pub const RTE_MEMPOOL_STACK: u32 = 1;
pub const RTE_NET_E1000: u32 = 1;
pub const RTE_NET_MLX5: u32 = 1;
pub const RTE_NET_RING: u32 = 1;
pub const RTE_NET_VHOST: u32 = 1;
pub const RTE_NET_VIRTIO: u32 = 1;
pub const RTE_PKTMBUF_HEADROOM: u32 = 128;
pub const RTE_USE_LIBBSD: u32 = 1;
pub const RTE_VER_MINOR: u32 = 0;
pub const RTE_VER_MONTH: u32 = 3;
pub const RTE_VER_RELEASE: u32 = 99;
pub const RTE_VER_SUFFIX: &::core::ffi::CStr = c"";
pub const RTE_VER_YEAR: u32 = 25;
pub const RTE_TOOLCHAIN: &::core::ffi::CStr = c"clang";
pub const RTE_TOOLCHAIN_CLANG: u32 = 1;
pub const RTE_EXEC_ENV_LINUXAPP: u32 = 1;
pub const RTE_VER_PREFIX: &::core::ffi::CStr = c"DPDK";
pub const RTE_CACHE_GUARD_LINES: u32 = 1;
pub const RTE_MAX_HEAPS: u32 = 32;
pub const RTE_MAX_LCORE_VAR: u32 = 131072;
pub const RTE_MAX_MEMSEG_LISTS: u32 = 128;
pub const RTE_MAX_MEMSEG_PER_LIST: u32 = 8192;
pub const RTE_MAX_MEM_MB_PER_LIST: u32 = 32768;
pub const RTE_MAX_MEMSEG_PER_TYPE: u32 = 32768;
pub const RTE_MAX_MEM_MB_PER_TYPE: u32 = 65536;
pub const RTE_MAX_TAILQ: u32 = 32;
pub const RTE_LOG_DP_LEVEL: u32 = 7;
pub const RTE_MAX_VFIO_CONTAINERS: u32 = 64;
pub const RTE_CONTIGMEM_MAX_NUM_BUFS: u32 = 64;
pub const RTE_CONTIGMEM_DEFAULT_NUM_BUFS: u32 = 1;
pub const RTE_CONTIGMEM_DEFAULT_BUF_SIZE: u32 = 536870912;
pub const RTE_MEMPOOL_CACHE_MAX_SIZE: u32 = 512;
pub const RTE_MBUF_DEFAULT_MEMPOOL_OPS: &::core::ffi::CStr = c"ring_mp_mc";
pub const RTE_MAX_QUEUES_PER_PORT: u32 = 1024;
pub const RTE_ETHDEV_QUEUE_STAT_CNTRS: u32 = 16;
pub const RTE_MAX_MULTI_HOST_CTRLS: u32 = 4;
pub const RTE_CRYPTO_MAX_DEVS: u32 = 64;
pub const RTE_CRYPTODEV_NAME_LEN: u32 = 64;
pub const RTE_CRYPTO_CALLBACKS: u32 = 1;
pub const RTE_COMPRESS_MAX_DEVS: u32 = 64;
pub const RTE_MAX_REGEXDEV_DEVS: u32 = 32;
pub const RTE_EVENT_MAX_DEVS: u32 = 16;
pub const RTE_EVENT_MAX_PORTS_PER_DEV: u32 = 255;
pub const RTE_EVENT_MAX_QUEUES_PER_DEV: u32 = 255;
pub const RTE_EVENT_MAX_PROFILES_PER_PORT: u32 = 8;
pub const RTE_EVENT_TIMER_ADAPTER_NUM_MAX: u32 = 32;
pub const RTE_EVENT_ETH_INTR_RING_SIZE: u32 = 1024;
pub const RTE_EVENT_CRYPTO_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_EVENT_ETH_TX_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_EVENT_DMA_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_RAWDEV_MAX_DEVS: u32 = 64;
pub const RTE_LIBRTE_IP_FRAG_MAX_FRAG: u32 = 8;
pub const RTE_MAX_LCORE_FREQS: u32 = 64;
pub const RTE_MAX_UNCORE_FREQS: u32 = 64;
pub const RTE_GRAPH_BURST_SIZE: u32 = 256;
pub const RTE_LIBRTE_GRAPH_STATS: u32 = 1;
pub const RTE_PMD_PACKET_PREFETCH: u32 = 1;
pub const RTE_PMD_QAT_MAX_PCI_DEVICES: u32 = 48;
pub const RTE_PMD_QAT_COMP_SGL_MAX_SEGMENTS: u32 = 16;
pub const RTE_PMD_QAT_COMP_IM_BUFFER_SIZE: u32 = 65536;
pub const RTE_PMD_ZSDA_MAX_PCI_DEVICES: u32 = 256;
pub const RTE_MAX_VIRTIO_CRYPTO: u32 = 32;
pub const RTE_LIBRTE_DPAA_MAX_CRYPTODEV: u32 = 4;
pub const RTE_LIBRTE_FM10K_RX_OLFLAGS_ENABLE: u32 = 1;
pub const RTE_LIBRTE_HNS3_MAX_TQP_NUM_PER_PF: u32 = 256;
pub const RTE_LIBRTE_I40E_RX_ALLOW_BULK_ALLOC: u32 = 1;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_PF: u32 = 64;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_VF: u32 = 4;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_VM: u32 = 4;
pub const RTE_PMD_RING_MAX_RX_RINGS: u32 = 16;
pub const RTE_PMD_RING_MAX_TX_RINGS: u32 = 16;
pub const RTE_LIBRTE_QEDE_FW: &::core::ffi::CStr = c"";
pub const RTE_CC_IS_GNU: u32 = 0;
pub const RTE_PRIORITY_LOG: u32 = 101;
pub const RTE_PRIORITY_BUS: u32 = 110;
pub const RTE_PRIORITY_CLASS: u32 = 120;
pub const RTE_PRIORITY_LAST: u32 = 65535;
pub const RTE_CACHE_LINE_MASK: u32 = 63;
pub const RTE_CACHE_LINE_SIZE_LOG2: u32 = 6;
pub const RTE_CACHE_LINE_MIN_SIZE: u32 = 64;
pub const RTE_UUID_STRLEN: u32 = 37;
pub const RTE_MAGIC: u32 = 19820526;
pub const RTE_MP_MAX_FD_NUM: u32 = 253;
pub const RTE_MP_MAX_NAME_LEN: u32 = 64;
pub const RTE_MP_MAX_PARAM_LEN: u32 = 256;
pub const RTE_THREAD_NAME_SIZE: u32 = 16;
pub const RTE_MAX_THREAD_NAME_LEN: u32 = 16;
pub const RTE_THREAD_INTERNAL_PREFIX: &::core::ffi::CStr = c"dpdk-";
pub const RTE_THREAD_INTERNAL_NAME_SIZE: u32 = 11;
pub const rte_memory_order_relaxed: u32 = 0;
pub const rte_memory_order_consume: u32 = 1;
pub const rte_memory_order_acquire: u32 = 2;
pub const rte_memory_order_release: u32 = 3;
pub const rte_memory_order_acq_rel: u32 = 4;
pub const rte_memory_order_seq_cst: u32 = 5;
pub const RTE_SPINLOCK_INITIALIZER: u32 = 0;
pub const RTE_XBEGIN_STARTED: i32 = -1;
pub const RTE_XABORT_EXPLICIT: u32 = 1;
pub const RTE_XABORT_RETRY: u32 = 2;
pub const RTE_XABORT_CONFLICT: u32 = 4;
pub const RTE_XABORT_CAPACITY: u32 = 8;
pub const RTE_XABORT_DEBUG: u32 = 16;
pub const RTE_XABORT_NESTED: u32 = 32;
pub const RTE_LOGTYPE_EAL: u32 = 0;
pub const RTE_LOGTYPE_USER1: u32 = 24;
pub const RTE_LOGTYPE_USER2: u32 = 25;
pub const RTE_LOGTYPE_USER3: u32 = 26;
pub const RTE_LOGTYPE_USER4: u32 = 27;
pub const RTE_LOGTYPE_USER5: u32 = 28;
pub const RTE_LOGTYPE_USER6: u32 = 29;
pub const RTE_LOGTYPE_USER7: u32 = 30;
pub const RTE_LOGTYPE_USER8: u32 = 31;
pub const RTE_LOGTYPE_FIRST_EXT_ID: u32 = 32;
pub const RTE_LOG_EMERG: u32 = 1;
pub const RTE_LOG_ALERT: u32 = 2;
pub const RTE_LOG_CRIT: u32 = 3;
pub const RTE_LOG_ERR: u32 = 4;
pub const RTE_LOG_WARNING: u32 = 5;
pub const RTE_LOG_NOTICE: u32 = 6;
pub const RTE_LOG_INFO: u32 = 7;
pub const RTE_LOG_DEBUG: u32 = 8;
pub const RTE_LOG_MAX: u32 = 8;
pub const RTE_RTM_MAX_RETRIES: u32 = 20;
pub const RTE_XABORT_LOCK_BUSY: u32 = 255;
pub const RTE_RWLOCK_WAIT: u32 = 1;
pub const RTE_RWLOCK_WRITE: u32 = 2;
pub const RTE_RWLOCK_MASK: u32 = 3;
pub const RTE_RWLOCK_READ: u32 = 4;
pub const RTE_RWLOCK_INITIALIZER: u32 = 0;
pub const RTE_FBARRAY_NAME_LEN: u32 = 64;
pub const RTE_PGSIZE_4K: u32 = 4096;
pub const RTE_PGSIZE_64K: u32 = 65536;
pub const RTE_PGSIZE_256K: u32 = 262144;
pub const RTE_PGSIZE_2M: u32 = 2097152;
pub const RTE_PGSIZE_16M: u32 = 16777216;
pub const RTE_PGSIZE_256M: u32 = 268435456;
pub const RTE_PGSIZE_512M: u32 = 536870912;
pub const RTE_PGSIZE_1G: u32 = 1073741824;
pub const RTE_PGSIZE_4G: u64 = 4294967296;
pub const RTE_PGSIZE_16G: u64 = 17179869184;
pub const RTE_MEMSEG_FLAG_DO_NOT_FREE: u32 = 1;
pub const RTE_MEMSEG_FLAG_DIRTY: u32 = 2;
pub const RTE_MEM_EVENT_CALLBACK_NAME_LEN: u32 = 64;
pub const RTE_MEM_ALLOC_VALIDATOR_NAME_LEN: u32 = 64;
pub const RTE_MEMZONE_2MB: u32 = 1;
pub const RTE_MEMZONE_1GB: u32 = 2;
pub const RTE_MEMZONE_16MB: u32 = 256;
pub const RTE_MEMZONE_16GB: u32 = 512;
pub const RTE_MEMZONE_256KB: u32 = 65536;
pub const RTE_MEMZONE_256MB: u32 = 131072;
pub const RTE_MEMZONE_512MB: u32 = 262144;
pub const RTE_MEMZONE_4GB: u32 = 524288;
pub const RTE_MEMZONE_SIZE_HINT_ONLY: u32 = 4;
pub const RTE_MEMZONE_IOVA_CONTIG: u32 = 1048576;
pub const RTE_MEMZONE_NAMESIZE: u32 = 32;
pub const RTE_TAILQ_RING_NAME: &::core::ffi::CStr = c"RTE_RING";
pub const RTE_RING_MZ_PREFIX: &::core::ffi::CStr = c"RG_";
pub const RTE_RING_NAMESIZE: u32 = 29;
pub const RTE_RING_SZ_MASK: u32 = 2147483647;
pub const RTE_VECT_DEFAULT_SIMD_BITWIDTH: u32 = 256;
pub const RTE_TRACE_BLOB_LEN_MAX: u32 = 64;
pub const RTE_MEMPOOL_HEADER_COOKIE1: i64 = -4982197544707871147;
pub const RTE_MEMPOOL_HEADER_COOKIE2: i64 = -941548164385788331;
pub const RTE_MEMPOOL_TRAILER_COOKIE: i64 = -5921418378119291987;
pub const RTE_MEMPOOL_NAMESIZE: u32 = 26;
pub const RTE_MEMPOOL_MZ_PREFIX: &::core::ffi::CStr = c"MP_";
pub const RTE_MEMPOOL_MZ_FORMAT: &::core::ffi::CStr = c"MP_%s";
pub const RTE_MEMPOOL_ALIGN: u32 = 64;
pub const RTE_MEMPOOL_ALIGN_MASK: u32 = 63;
pub const RTE_MEMPOOL_F_NO_SPREAD: u32 = 1;
pub const RTE_MEMPOOL_F_NO_CACHE_ALIGN: u32 = 2;
pub const RTE_MEMPOOL_F_SP_PUT: u32 = 4;
pub const RTE_MEMPOOL_F_SC_GET: u32 = 8;
pub const RTE_MEMPOOL_F_POOL_CREATED: u32 = 16;
pub const RTE_MEMPOOL_F_NO_IOVA_CONTIG: u32 = 32;
pub const RTE_MEMPOOL_F_NON_IO: u32 = 64;
pub const RTE_MEMPOOL_VALID_USER_FLAGS: u32 = 47;
pub const RTE_MEMPOOL_OPS_NAMESIZE: u32 = 32;
pub const RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ: u32 = 1;
pub const RTE_MEMPOOL_MAX_OPS_IDX: u32 = 16;
pub const RTE_PTYPE_UNKNOWN: u32 = 0;
pub const RTE_PTYPE_L2_ETHER: u32 = 1;
pub const RTE_PTYPE_L2_ETHER_TIMESYNC: u32 = 2;
pub const RTE_PTYPE_L2_ETHER_ARP: u32 = 3;
pub const RTE_PTYPE_L2_ETHER_LLDP: u32 = 4;
pub const RTE_PTYPE_L2_ETHER_NSH: u32 = 5;
pub const RTE_PTYPE_L2_ETHER_VLAN: u32 = 6;
pub const RTE_PTYPE_L2_ETHER_QINQ: u32 = 7;
pub const RTE_PTYPE_L2_ETHER_PPPOE: u32 = 8;
pub const RTE_PTYPE_L2_ETHER_FCOE: u32 = 9;
pub const RTE_PTYPE_L2_ETHER_MPLS: u32 = 10;
pub const RTE_PTYPE_L2_MASK: u32 = 15;
pub const RTE_PTYPE_L3_IPV4: u32 = 16;
pub const RTE_PTYPE_L3_IPV4_EXT: u32 = 48;
pub const RTE_PTYPE_L3_IPV6: u32 = 64;
pub const RTE_PTYPE_L3_IPV4_EXT_UNKNOWN: u32 = 144;
pub const RTE_PTYPE_L3_IPV6_EXT: u32 = 192;
pub const RTE_PTYPE_L3_IPV6_EXT_UNKNOWN: u32 = 224;
pub const RTE_PTYPE_L3_MASK: u32 = 240;
pub const RTE_PTYPE_L4_TCP: u32 = 256;
pub const RTE_PTYPE_L4_UDP: u32 = 512;
pub const RTE_PTYPE_L4_FRAG: u32 = 768;
pub const RTE_PTYPE_L4_SCTP: u32 = 1024;
pub const RTE_PTYPE_L4_ICMP: u32 = 1280;
pub const RTE_PTYPE_L4_NONFRAG: u32 = 1536;
pub const RTE_PTYPE_L4_IGMP: u32 = 1792;
pub const RTE_PTYPE_L4_ESP: u32 = 2048;
pub const RTE_PTYPE_L4_MASK: u32 = 3840;
pub const RTE_PTYPE_TUNNEL_IP: u32 = 4096;
pub const RTE_PTYPE_TUNNEL_GRE: u32 = 8192;
pub const RTE_PTYPE_TUNNEL_VXLAN: u32 = 12288;
pub const RTE_PTYPE_TUNNEL_NVGRE: u32 = 16384;
pub const RTE_PTYPE_TUNNEL_GENEVE: u32 = 20480;
pub const RTE_PTYPE_TUNNEL_GRENAT: u32 = 24576;
pub const RTE_PTYPE_TUNNEL_GTPC: u32 = 28672;
pub const RTE_PTYPE_TUNNEL_GTPU: u32 = 32768;
pub const RTE_PTYPE_TUNNEL_ESP: u32 = 36864;
pub const RTE_PTYPE_TUNNEL_L2TP: u32 = 40960;
pub const RTE_PTYPE_TUNNEL_VXLAN_GPE: u32 = 45056;
pub const RTE_PTYPE_TUNNEL_MPLS_IN_GRE: u32 = 49152;
pub const RTE_PTYPE_TUNNEL_MPLS_IN_UDP: u32 = 53248;
pub const RTE_PTYPE_TUNNEL_MASK: u32 = 61440;
pub const RTE_PTYPE_INNER_L2_ETHER: u32 = 65536;
pub const RTE_PTYPE_INNER_L2_ETHER_VLAN: u32 = 131072;
pub const RTE_PTYPE_INNER_L2_ETHER_QINQ: u32 = 196608;
pub const RTE_PTYPE_INNER_L2_MASK: u32 = 983040;
pub const RTE_PTYPE_INNER_L3_IPV4: u32 = 1048576;
pub const RTE_PTYPE_INNER_L3_IPV4_EXT: u32 = 2097152;
pub const RTE_PTYPE_INNER_L3_IPV6: u32 = 3145728;
pub const RTE_PTYPE_INNER_L3_IPV4_EXT_UNKNOWN: u32 = 4194304;
pub const RTE_PTYPE_INNER_L3_IPV6_EXT: u32 = 5242880;
pub const RTE_PTYPE_INNER_L3_IPV6_EXT_UNKNOWN: u32 = 6291456;
pub const RTE_PTYPE_INNER_L3_MASK: u32 = 15728640;
pub const RTE_PTYPE_INNER_L4_TCP: u32 = 16777216;
pub const RTE_PTYPE_INNER_L4_UDP: u32 = 33554432;
pub const RTE_PTYPE_INNER_L4_FRAG: u32 = 50331648;
pub const RTE_PTYPE_INNER_L4_SCTP: u32 = 67108864;
pub const RTE_PTYPE_INNER_L4_ICMP: u32 = 83886080;
pub const RTE_PTYPE_INNER_L4_NONFRAG: u32 = 100663296;
pub const RTE_PTYPE_INNER_L4_ESP: u32 = 134217728;
pub const RTE_PTYPE_INNER_L4_MASK: u32 = 251658240;
pub const RTE_PTYPE_ALL_MASK: u32 = 268435455;
pub const RTE_BIG_ENDIAN: u32 = 1;
pub const RTE_LITTLE_ENDIAN: u32 = 2;
pub const RTE_BYTE_ORDER: u32 = 2;
pub const RTE_MBUF_F_RX_VLAN: u32 = 1;
pub const RTE_MBUF_F_RX_RSS_HASH: u32 = 2;
pub const RTE_MBUF_F_RX_FDIR: u32 = 4;
pub const RTE_MBUF_F_RX_OUTER_IP_CKSUM_BAD: u32 = 32;
pub const RTE_MBUF_F_RX_VLAN_STRIPPED: u32 = 64;
pub const RTE_MBUF_F_RX_IP_CKSUM_MASK: u32 = 144;
pub const RTE_MBUF_F_RX_IP_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_IP_CKSUM_BAD: u32 = 16;
pub const RTE_MBUF_F_RX_IP_CKSUM_GOOD: u32 = 128;
pub const RTE_MBUF_F_RX_IP_CKSUM_NONE: u32 = 144;
pub const RTE_MBUF_F_RX_L4_CKSUM_MASK: u32 = 264;
pub const RTE_MBUF_F_RX_L4_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_L4_CKSUM_BAD: u32 = 8;
pub const RTE_MBUF_F_RX_L4_CKSUM_GOOD: u32 = 256;
pub const RTE_MBUF_F_RX_L4_CKSUM_NONE: u32 = 264;
pub const RTE_MBUF_F_RX_IEEE1588_PTP: u32 = 512;
pub const RTE_MBUF_F_RX_IEEE1588_TMST: u32 = 1024;
pub const RTE_MBUF_F_RX_FDIR_ID: u32 = 8192;
pub const RTE_MBUF_F_RX_FDIR_FLX: u32 = 16384;
pub const RTE_MBUF_F_RX_QINQ_STRIPPED: u32 = 32768;
pub const RTE_MBUF_F_RX_LRO: u32 = 65536;
pub const RTE_MBUF_F_RX_SEC_OFFLOAD: u32 = 262144;
pub const RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED: u32 = 524288;
pub const RTE_MBUF_F_RX_QINQ: u32 = 1048576;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_MASK: u32 = 6291456;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_BAD: u32 = 2097152;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_GOOD: u32 = 4194304;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_INVALID: u32 = 6291456;
pub const RTE_MBUF_F_FIRST_FREE: u32 = 8388608;
pub const RTE_MBUF_F_LAST_FREE: u64 = 1099511627776;
pub const RTE_MBUF_F_TX_OUTER_UDP_CKSUM: u64 = 2199023255552;
pub const RTE_MBUF_F_TX_UDP_SEG: u64 = 4398046511104;
pub const RTE_MBUF_F_TX_SEC_OFFLOAD: u64 = 8796093022208;
pub const RTE_MBUF_F_TX_MACSEC: u64 = 17592186044416;
pub const RTE_MBUF_F_TX_TUNNEL_VXLAN: u64 = 35184372088832;
pub const RTE_MBUF_F_TX_TUNNEL_GRE: u64 = 70368744177664;
pub const RTE_MBUF_F_TX_TUNNEL_IPIP: u64 = 105553116266496;
pub const RTE_MBUF_F_TX_TUNNEL_GENEVE: u64 = 140737488355328;
pub const RTE_MBUF_F_TX_TUNNEL_MPLSINUDP: u64 = 175921860444160;
pub const RTE_MBUF_F_TX_TUNNEL_VXLAN_GPE: u64 = 211106232532992;
pub const RTE_MBUF_F_TX_TUNNEL_GTP: u64 = 246290604621824;
pub const RTE_MBUF_F_TX_TUNNEL_ESP: u64 = 281474976710656;
pub const RTE_MBUF_F_TX_TUNNEL_IP: u64 = 457396837154816;
pub const RTE_MBUF_F_TX_TUNNEL_UDP: u64 = 492581209243648;
pub const RTE_MBUF_F_TX_TUNNEL_MASK: u64 = 527765581332480;
pub const RTE_MBUF_F_TX_QINQ: u64 = 562949953421312;
pub const RTE_MBUF_F_TX_TCP_SEG: u64 = 1125899906842624;
pub const RTE_MBUF_F_TX_IEEE1588_TMST: u64 = 2251799813685248;
pub const RTE_MBUF_F_TX_L4_NO_CKSUM: u32 = 0;
pub const RTE_MBUF_F_TX_TCP_CKSUM: u64 = 4503599627370496;
pub const RTE_MBUF_F_TX_SCTP_CKSUM: u64 = 9007199254740992;
pub const RTE_MBUF_F_TX_UDP_CKSUM: u64 = 13510798882111488;
pub const RTE_MBUF_F_TX_L4_MASK: u64 = 13510798882111488;
pub const RTE_MBUF_F_TX_IP_CKSUM: u64 = 18014398509481984;
pub const RTE_MBUF_F_TX_IPV4: u64 = 36028797018963968;
pub const RTE_MBUF_F_TX_IPV6: u64 = 72057594037927936;
pub const RTE_MBUF_F_TX_VLAN: u64 = 144115188075855872;
pub const RTE_MBUF_F_TX_OUTER_IP_CKSUM: u64 = 288230376151711744;
pub const RTE_MBUF_F_TX_OUTER_IPV4: u64 = 576460752303423488;
pub const RTE_MBUF_F_TX_OUTER_IPV6: u64 = 1152921504606846976;
pub const RTE_MBUF_F_TX_OFFLOAD_MASK: u64 = 2305840810190438400;
pub const RTE_MBUF_F_EXTERNAL: u64 = 2305843009213693952;
pub const RTE_MBUF_F_INDIRECT: u64 = 4611686018427387904;
pub const RTE_MBUF_PRIV_ALIGN: u32 = 8;
pub const RTE_MBUF_DEFAULT_DATAROOM: u32 = 2048;
pub const RTE_MBUF_DEFAULT_BUF_SIZE: u32 = 2176;
pub const RTE_MBUF_MAX_NB_SEGS: u32 = 65535;
pub const RTE_MBUF_PORT_INVALID: u32 = 65535;
pub const RTE_PKTMBUF_POOL_F_PINNED_EXT_BUF: u32 = 1;
pub const RTE_ETHER_ADDR_LEN: u32 = 6;
pub const RTE_ETHER_TYPE_LEN: u32 = 2;
pub const RTE_ETHER_CRC_LEN: u32 = 4;
pub const RTE_ETHER_HDR_LEN: u32 = 14;
pub const RTE_ETHER_MIN_LEN: u32 = 64;
pub const RTE_ETHER_MAX_LEN: u32 = 1518;
pub const RTE_ETHER_MTU: u32 = 1500;
pub const RTE_VLAN_HLEN: u32 = 4;
pub const RTE_ETHER_MAX_VLAN_FRAME_LEN: u32 = 1522;
pub const RTE_ETHER_MAX_JUMBO_FRAME_LEN: u32 = 16128;
pub const RTE_ETHER_MAX_VLAN_ID: u32 = 4095;
pub const RTE_ETHER_MIN_MTU: u32 = 68;
pub const RTE_VLAN_DEI_SHIFT: u32 = 12;
pub const RTE_VLAN_PRI_SHIFT: u32 = 13;
pub const RTE_VLAN_PRI_MASK: u32 = 57344;
pub const RTE_VLAN_DEI_MASK: u32 = 4096;
pub const RTE_VLAN_ID_MASK: u32 = 4095;
pub const RTE_ETHER_LOCAL_ADMIN_ADDR: u32 = 2;
pub const RTE_ETHER_GROUP_ADDR: u32 = 1;
pub const RTE_ETHER_ADDR_PRT_FMT: &::core::ffi::CStr = c"%02X:%02X:%02X:%02X:%02X:%02X";
pub const RTE_ETHER_ADDR_FMT_SIZE: u32 = 18;
pub const RTE_ETHER_TYPE_IPV4: u32 = 2048;
pub const RTE_ETHER_TYPE_IPV6: u32 = 34525;
pub const RTE_ETHER_TYPE_ARP: u32 = 2054;
pub const RTE_ETHER_TYPE_RARP: u32 = 32821;
pub const RTE_ETHER_TYPE_VLAN: u32 = 33024;
pub const RTE_ETHER_TYPE_QINQ: u32 = 34984;
pub const RTE_ETHER_TYPE_QINQ1: u32 = 37120;
pub const RTE_ETHER_TYPE_QINQ2: u32 = 37376;
pub const RTE_ETHER_TYPE_QINQ3: u32 = 37632;
pub const RTE_ETHER_TYPE_PPPOE_DISCOVERY: u32 = 34915;
pub const RTE_ETHER_TYPE_PPPOE_SESSION: u32 = 34916;
pub const RTE_ETHER_TYPE_ETAG: u32 = 35135;
pub const RTE_ETHER_TYPE_1588: u32 = 35063;
pub const RTE_ETHER_TYPE_SLOW: u32 = 34825;
pub const RTE_ETHER_TYPE_TEB: u32 = 25944;
pub const RTE_ETHER_TYPE_LLDP: u32 = 35020;
pub const RTE_ETHER_TYPE_MPLS: u32 = 34887;
pub const RTE_ETHER_TYPE_MPLSM: u32 = 34888;
pub const RTE_ETHER_TYPE_ECPRI: u32 = 44798;
pub const RTE_ARP_HRD_ETHER: u32 = 1;
pub const RTE_ARP_OP_REQUEST: u32 = 1;
pub const RTE_ARP_OP_REPLY: u32 = 2;
pub const RTE_ARP_OP_REVREQUEST: u32 = 3;
pub const RTE_ARP_OP_REVREPLY: u32 = 4;
pub const RTE_ARP_OP_INVREQUEST: u32 = 8;
pub const RTE_ARP_OP_INVREPLY: u32 = 9;
pub const RTE_BITMAP_SLAB_BIT_SIZE: u32 = 64;
pub const RTE_BITMAP_SLAB_BIT_SIZE_LOG2: u32 = 6;
pub const RTE_BITMAP_SLAB_BIT_MASK: u32 = 63;
pub const RTE_BITMAP_CL_BIT_SIZE: u32 = 512;
pub const RTE_BITMAP_CL_BIT_SIZE_LOG2: u32 = 9;
pub const RTE_BITMAP_CL_BIT_MASK: u32 = 511;
pub const RTE_BITMAP_CL_SLAB_SIZE: u32 = 8;
pub const RTE_BITMAP_CL_SLAB_SIZE_LOG2: u32 = 3;
pub const RTE_BITMAP_CL_SLAB_MASK: u32 = 7;
pub const RTE_INTR_EVENT_ADD: u32 = 1;
pub const RTE_INTR_EVENT_DEL: u32 = 2;
pub const RTE_EPOLL_PER_THREAD: i32 = -1;
pub const RTE_INTR_INSTANCE_F_PRIVATE: u32 = 0;
pub const RTE_INTR_INSTANCE_F_SHARED: u32 = 1;
pub const RTE_MAX_RXTX_INTR_VEC_ID: u32 = 512;
pub const RTE_INTR_VEC_ZERO_OFFSET: u32 = 0;
pub const RTE_INTR_VEC_RXTX_OFFSET: u32 = 1;
pub const RTE_PCI_CFG_SPACE_SIZE: u32 = 256;
pub const RTE_PCI_CFG_SPACE_EXP_SIZE: u32 = 4096;
pub const RTE_PCI_STD_HEADER_SIZEOF: u32 = 64;
pub const RTE_PCI_VENDOR_ID: u32 = 0;
pub const RTE_PCI_DEVICE_ID: u32 = 2;
pub const RTE_PCI_COMMAND: u32 = 4;
pub const RTE_PCI_STATUS: u32 = 6;
pub const RTE_PCI_BASE_ADDRESS_0: u32 = 16;
pub const RTE_PCI_CAPABILITY_LIST: u32 = 52;
pub const RTE_PCI_COMMAND_MEMORY: u32 = 2;
pub const RTE_PCI_COMMAND_MASTER: u32 = 4;
pub const RTE_PCI_COMMAND_INTX_DISABLE: u32 = 1024;
pub const RTE_PCI_STATUS_CAP_LIST: u32 = 16;
pub const RTE_PCI_BASE_ADDRESS_SPACE_IO: u32 = 1;
pub const RTE_PCI_CAP_ID_PM: u32 = 1;
pub const RTE_PCI_CAP_ID_MSI: u32 = 5;
pub const RTE_PCI_CAP_ID_VNDR: u32 = 9;
pub const RTE_PCI_CAP_ID_EXP: u32 = 16;
pub const RTE_PCI_CAP_ID_MSIX: u32 = 17;
pub const RTE_PCI_CAP_SIZEOF: u32 = 4;
pub const RTE_PCI_CAP_NEXT: u32 = 1;
pub const RTE_PCI_PM_CTRL: u32 = 4;
pub const RTE_PCI_PM_CTRL_STATE_MASK: u32 = 3;
pub const RTE_PCI_PM_CTRL_PME_ENABLE: u32 = 256;
pub const RTE_PCI_PM_CTRL_PME_STATUS: u32 = 32768;
pub const RTE_PCI_EXP_TYPE_RC_EC: u32 = 10;
pub const RTE_PCI_EXP_DEVCTL: u32 = 8;
pub const RTE_PCI_EXP_DEVCTL_PAYLOAD: u32 = 224;
pub const RTE_PCI_EXP_DEVCTL_READRQ: u32 = 28672;
pub const RTE_PCI_EXP_DEVCTL_BCR_FLR: u32 = 32768;
pub const RTE_PCI_EXP_DEVSTA: u32 = 10;
pub const RTE_PCI_EXP_DEVSTA_TRPND: u32 = 32;
pub const RTE_PCI_EXP_LNKCTL: u32 = 16;
pub const RTE_PCI_EXP_LNKSTA: u32 = 18;
pub const RTE_PCI_EXP_LNKSTA_CLS: u32 = 15;
pub const RTE_PCI_EXP_LNKSTA_NLW: u32 = 1008;
pub const RTE_PCI_EXP_SLTCTL: u32 = 24;
pub const RTE_PCI_EXP_RTCTL: u32 = 28;
pub const RTE_PCI_EXP_DEVCTL2: u32 = 40;
pub const RTE_PCI_EXP_LNKCTL2: u32 = 48;
pub const RTE_PCI_EXP_SLTCTL2: u32 = 56;
pub const RTE_PCI_MSIX_FLAGS: u32 = 2;
pub const RTE_PCI_MSIX_FLAGS_QSIZE: u32 = 2047;
pub const RTE_PCI_MSIX_FLAGS_MASKALL: u32 = 16384;
pub const RTE_PCI_MSIX_FLAGS_ENABLE: u32 = 32768;
pub const RTE_PCI_MSIX_TABLE: u32 = 4;
pub const RTE_PCI_MSIX_TABLE_BIR: u32 = 7;
pub const RTE_PCI_MSIX_TABLE_OFFSET: u32 = 4294967288;
pub const RTE_PCI_EXT_CAP_ID_ERR: u32 = 1;
pub const RTE_PCI_EXT_CAP_ID_DSN: u32 = 3;
pub const RTE_PCI_EXT_CAP_ID_ACS: u32 = 13;
pub const RTE_PCI_EXT_CAP_ID_SRIOV: u32 = 16;
pub const RTE_PCI_EXT_CAP_ID_PRI: u32 = 19;
pub const RTE_PCI_EXT_CAP_ID_PASID: u32 = 27;
pub const RTE_PCI_ERR_UNCOR_STATUS: u32 = 4;
pub const RTE_PCI_ERR_COR_STATUS: u32 = 16;
pub const RTE_PCI_ERR_ROOT_STATUS: u32 = 48;
pub const RTE_PCI_ACS_CAP: u32 = 4;
pub const RTE_PCI_ACS_CTRL: u32 = 6;
pub const RTE_PCI_ACS_SV: u32 = 1;
pub const RTE_PCI_ACS_RR: u32 = 4;
pub const RTE_PCI_ACS_CR: u32 = 8;
pub const RTE_PCI_ACS_UF: u32 = 16;
pub const RTE_PCI_ACS_EC: u32 = 32;
pub const RTE_PCI_SRIOV_CAP: u32 = 4;
pub const RTE_PCI_SRIOV_CTRL: u32 = 8;
pub const RTE_PCI_SRIOV_INITIAL_VF: u32 = 12;
pub const RTE_PCI_SRIOV_TOTAL_VF: u32 = 14;
pub const RTE_PCI_SRIOV_NUM_VF: u32 = 16;
pub const RTE_PCI_SRIOV_FUNC_LINK: u32 = 18;
pub const RTE_PCI_SRIOV_VF_OFFSET: u32 = 20;
pub const RTE_PCI_SRIOV_VF_STRIDE: u32 = 22;
pub const RTE_PCI_SRIOV_VF_DID: u32 = 26;
pub const RTE_PCI_SRIOV_SUP_PGSIZE: u32 = 28;
pub const RTE_PCI_PRI_CTRL: u32 = 4;
pub const RTE_PCI_PRI_CTRL_ENABLE: u32 = 1;
pub const RTE_PCI_PRI_ALLOC_REQ: u32 = 12;
pub const RTE_PCI_PASID_CTRL: u32 = 6;
pub const RTE_PCI_ANY_ID: u32 = 65535;
pub const RTE_CLASS_ANY_ID: u32 = 16777215;
pub const RTE_DEV_NAME_MAX_LEN: u32 = 64;
pub const RTE_ETH_REG_NAME_SIZE: u32 = 64;
pub const RTE_ETH_MODULE_SFF_8079: u32 = 1;
pub const RTE_ETH_MODULE_SFF_8079_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8472: u32 = 2;
pub const RTE_ETH_MODULE_SFF_8472_LEN: u32 = 512;
pub const RTE_ETH_MODULE_SFF_8636: u32 = 3;
pub const RTE_ETH_MODULE_SFF_8636_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8636_MAX_LEN: u32 = 640;
pub const RTE_ETH_MODULE_SFF_8436: u32 = 4;
pub const RTE_ETH_MODULE_SFF_8436_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8436_MAX_LEN: u32 = 640;
pub const RTE_DEVARGS_KEY_BUS: &::core::ffi::CStr = c"bus";
pub const RTE_DEVARGS_KEY_CLASS: &::core::ffi::CStr = c"class";
pub const RTE_DEVARGS_KEY_DRIVER: &::core::ffi::CStr = c"driver";
pub const RTE_DTLS_TYPE_INVALID: u32 = 0;
pub const RTE_DTLS_TYPE_CHANGE_CIPHER_SPEC: u32 = 20;
pub const RTE_DTLS_TYPE_ALERT: u32 = 21;
pub const RTE_DTLS_TYPE_HANDSHAKE: u32 = 22;
pub const RTE_DTLS_TYPE_APPDATA: u32 = 23;
pub const RTE_DTLS_TYPE_HEARTBEAT: u32 = 24;
pub const RTE_DTLS_TYPE_CIPHERTEXT_WITH_CID: u32 = 25;
pub const RTE_DTLS_TYPE_ACK: u32 = 26;
pub const RTE_DTLS_TYPE_MAX: u32 = 255;
pub const RTE_DTLS_VERSION_1_2: u32 = 65277;
pub const RTE_DTLS_VERSION_1_3: u32 = 65276;
pub const RTE_ECPRI_REV_UP_TO_20: u32 = 1;
pub const RTE_ECPRI_MSG_TYPE_IQ_DATA: u32 = 0;
pub const RTE_ECPRI_MSG_TYPE_BIT_SEQ: u32 = 1;
pub const RTE_ECPRI_MSG_TYPE_RTC_CTRL: u32 = 2;
pub const RTE_ECPRI_MSG_TYPE_GEN_DATA: u32 = 3;
pub const RTE_ECPRI_MSG_TYPE_RM_ACC: u32 = 4;
pub const RTE_ECPRI_MSG_TYPE_DLY_MSR: u32 = 5;
pub const RTE_ECPRI_MSG_TYPE_RMT_RST: u32 = 6;
pub const RTE_ECPRI_MSG_TYPE_EVT_IND: u32 = 7;
pub const RTE_ECPRI_MSG_TYPE_IWF_UP: u32 = 8;
pub const RTE_ECPRI_MSG_TYPE_IWF_OPT: u32 = 9;
pub const RTE_ECPRI_MSG_TYPE_IWF_MAP: u32 = 10;
pub const RTE_ECPRI_MSG_TYPE_IWF_DCTRL: u32 = 11;
pub const RTE_ECPRI_EVT_IND_FAULT_IND: u32 = 0;
pub const RTE_ECPRI_EVT_IND_FAULT_ACK: u32 = 1;
pub const RTE_ECPRI_EVT_IND_NTFY_IND: u32 = 2;
pub const RTE_ECPRI_EVT_IND_SYNC_REQ: u32 = 3;
pub const RTE_ECPRI_EVT_IND_SYNC_ACK: u32 = 4;
pub const RTE_ECPRI_EVT_IND_SYNC_END: u32 = 5;
pub const RTE_ICMP_TYPE_ECHO_REPLY: u32 = 0;
pub const RTE_IP_ICMP_ECHO_REPLY: u32 = 0;
pub const RTE_ICMP_TYPE_DEST_UNREACHABLE: u32 = 3;
pub const RTE_ICMP_TYPE_REDIRECT: u32 = 5;
pub const RTE_ICMP_TYPE_ECHO_REQUEST: u32 = 8;
pub const RTE_IP_ICMP_ECHO_REQUEST: u32 = 8;
pub const RTE_ICMP_TYPE_TTL_EXCEEDED: u32 = 11;
pub const RTE_ICMP_TYPE_PARAM_PROBLEM: u32 = 12;
pub const RTE_ICMP_TYPE_TIMESTAMP_REQUEST: u32 = 13;
pub const RTE_ICMP_TYPE_TIMESTAMP_REPLY: u32 = 14;
pub const RTE_ICMP_CODE_UNREACH_NET: u32 = 0;
pub const RTE_ICMP_CODE_UNREACH_HOST: u32 = 1;
pub const RTE_ICMP_CODE_UNREACH_PROTO: u32 = 2;
pub const RTE_ICMP_CODE_UNREACH_PORT: u32 = 3;
pub const RTE_ICMP_CODE_UNREACH_FRAG: u32 = 4;
pub const RTE_ICMP_CODE_UNREACH_SRC: u32 = 5;
pub const RTE_ICMP_CODE_TTL_EXCEEDED: u32 = 0;
pub const RTE_ICMP_CODE_TTL_FRAG: u32 = 1;
pub const RTE_ICMP_CODE_REDIRECT_NET: u32 = 0;
pub const RTE_ICMP_CODE_REDIRECT_HOST: u32 = 1;
pub const RTE_ICMP_CODE_REDIRECT_TOS_NET: u32 = 2;
pub const RTE_ICMP_CODE_REDIRECT_TOS_HOST: u32 = 3;
pub const RTE_ICMP6_ECHO_REQUEST: u32 = 128;
pub const RTE_ICMP6_ECHO_REPLY: u32 = 129;
pub const RTE_IPV4_MAX_PKT_LEN: u32 = 65535;
pub const RTE_IPV4_HDR_IHL_MASK: u32 = 15;
pub const RTE_IPV4_IHL_MULTIPLIER: u32 = 4;
pub const RTE_IPV4_HDR_DSCP_MASK: u32 = 252;
pub const RTE_IPV4_HDR_ECN_MASK: u32 = 3;
pub const RTE_IPV4_HDR_ECN_CE: u32 = 3;
pub const RTE_IPV4_HDR_DF_SHIFT: u32 = 14;
pub const RTE_IPV4_HDR_MF_SHIFT: u32 = 13;
pub const RTE_IPV4_HDR_FO_SHIFT: u32 = 3;
pub const RTE_IPV4_HDR_DF_FLAG: u32 = 16384;
pub const RTE_IPV4_HDR_MF_FLAG: u32 = 8192;
pub const RTE_IPV4_HDR_OFFSET_MASK: u32 = 8191;
pub const RTE_IPV4_HDR_OFFSET_UNITS: u32 = 8;
pub const RTE_IPV4_HDR_OPT_EOL: u32 = 0;
pub const RTE_IPV4_HDR_OPT_NOP: u32 = 1;
pub const RTE_IPV4_HDR_OPT_MAX_LEN: u32 = 40;
pub const RTE_IPV4_ANY: u32 = 0;
pub const RTE_IPV4_LOOPBACK: u32 = 2130706433;
pub const RTE_IPV4_BROADCAST: u32 = 3758096384;
pub const RTE_IPV4_ALLHOSTS_GROUP: u32 = 3758096385;
pub const RTE_IPV4_ALLRTRS_GROUP: u32 = 3758096386;
pub const RTE_IPV4_MAX_LOCAL_GROUP: u32 = 3758096639;
pub const RTE_IPV4_MIN_MCAST: u32 = 3758096384;
pub const RTE_IPV4_MAX_MCAST: u32 = 4026531839;
pub const RTE_IPV4_MIN_IHL: u32 = 5;
pub const RTE_IPV4_VHL_DEF: u32 = 69;
pub const RTE_IPV6_ADDR_SIZE: u32 = 16;
pub const RTE_IPV6_ADDR_FMT: &::core::ffi::CStr =
    c"%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x:%02x%02x";
pub const RTE_IPV6_SRCRT_TYPE_4: u32 = 4;
pub const RTE_IPV6_HDR_FL_SHIFT: u32 = 0;
pub const RTE_IPV6_HDR_TC_SHIFT: u32 = 20;
pub const RTE_IPV6_HDR_FL_MASK: u32 = 1048575;
pub const RTE_IPV6_HDR_TC_MASK: u32 = 267386880;
pub const RTE_IPV6_HDR_DSCP_MASK: u32 = 264241152;
pub const RTE_IPV6_HDR_ECN_MASK: u32 = 3145728;
pub const RTE_IPV6_HDR_ECN_CE: u32 = 3145728;
pub const RTE_IPV6_MIN_MTU: u32 = 1280;
pub const RTE_IPV6_EHDR_MF_SHIFT: u32 = 0;
pub const RTE_IPV6_EHDR_MF_MASK: u32 = 1;
pub const RTE_IPV6_EHDR_FO_SHIFT: u32 = 3;
pub const RTE_IPV6_EHDR_FO_MASK: i32 = -8;
pub const RTE_IPV6_EHDR_FO_ALIGN: u32 = 8;
pub const RTE_IPV6_FRAG_USED_MASK: i32 = -7;
pub const RTE_IPV6_FRAG_HDR_SIZE: u32 = 8;
pub const RTE_TCP_CWR_FLAG: u32 = 128;
pub const RTE_TCP_ECE_FLAG: u32 = 64;
pub const RTE_TCP_URG_FLAG: u32 = 32;
pub const RTE_TCP_ACK_FLAG: u32 = 16;
pub const RTE_TCP_PSH_FLAG: u32 = 8;
pub const RTE_TCP_RST_FLAG: u32 = 4;
pub const RTE_TCP_SYN_FLAG: u32 = 2;
pub const RTE_TCP_FIN_FLAG: u32 = 1;
pub const RTE_VXLAN_DEFAULT_PORT: u32 = 4789;
pub const RTE_VXLAN_GPE_DEFAULT_PORT: u32 = 4790;
pub const RTE_ETHER_VXLAN_HLEN: u32 = 16;
pub const RTE_ETHER_VXLAN_GPE_HLEN: u32 = 16;
pub const RTE_VXLAN_GPE_TYPE_IPV4: u32 = 1;
pub const RTE_VXLAN_GPE_TYPE_IPV6: u32 = 2;
pub const RTE_VXLAN_GPE_TYPE_ETH: u32 = 3;
pub const RTE_VXLAN_GPE_TYPE_NSH: u32 = 4;
pub const RTE_VXLAN_GPE_TYPE_MPLS: u32 = 5;
pub const RTE_VXLAN_GPE_TYPE_GBP: u32 = 6;
pub const RTE_VXLAN_GPE_TYPE_VBNG: u32 = 7;
pub const RTE_MBUF_DYN_NAMESIZE: u32 = 64;
pub const RTE_MBUF_DYNFIELD_METADATA_NAME: &::core::ffi::CStr = c"rte_flow_dynfield_metadata";
pub const RTE_MBUF_DYNFLAG_METADATA_NAME: &::core::ffi::CStr = c"rte_flow_dynflag_metadata";
pub const RTE_MBUF_DYNFIELD_TIMESTAMP_NAME: &::core::ffi::CStr = c"rte_dynfield_timestamp";
pub const RTE_MBUF_DYNFLAG_RX_TIMESTAMP_NAME: &::core::ffi::CStr = c"rte_dynflag_rx_timestamp";
pub const RTE_MBUF_DYNFLAG_TX_TIMESTAMP_NAME: &::core::ffi::CStr = c"rte_dynflag_tx_timestamp";
pub const RTE_MBUF_DYNFIELD_IP_REASSEMBLY_NAME: &::core::ffi::CStr = c"rte_dynfield_ip_reassembly";
pub const RTE_MBUF_DYNFLAG_IP_REASSEMBLY_INCOMPLETE_NAME: &::core::ffi::CStr =
    c"rte_dynflag_ip_reassembly_incomplete";
pub const RTE_ETHER_GTP_HLEN: u32 = 16;
pub const RTE_GTP_TYPE_IPV4: u32 = 64;
pub const RTE_GTP_TYPE_IPV6: u32 = 96;
pub const RTE_GTPC_UDP_PORT: u32 = 2123;
pub const RTE_GTPU_UDP_PORT: u32 = 2152;
pub const RTE_L2TPV2_MSG_TYPE_CONTROL: u32 = 51202;
pub const RTE_L2TPV2_MSG_TYPE_DATA: u32 = 2;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L: u32 = 16386;
pub const RTE_L2TPV2_MSG_TYPE_DATA_S: u32 = 2050;
pub const RTE_L2TPV2_MSG_TYPE_DATA_O: u32 = 514;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_S: u32 = 18434;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_O: u32 = 16898;
pub const RTE_L2TPV2_MSG_TYPE_DATA_S_O: u32 = 2562;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_S_O: u32 = 18946;
pub const RTE_MACSEC_TCI_VER_MASK: u32 = 128;
pub const RTE_MACSEC_TCI_ES: u32 = 64;
pub const RTE_MACSEC_TCI_SC: u32 = 32;
pub const RTE_MACSEC_TCI_SCB: u32 = 16;
pub const RTE_MACSEC_TCI_E: u32 = 8;
pub const RTE_MACSEC_TCI_C: u32 = 4;
pub const RTE_MACSEC_AN_MASK: u32 = 3;
pub const RTE_MACSEC_SCI_LEN: u32 = 8;
pub const RTE_ROCEV2_DEFAULT_PORT: u32 = 4791;
pub const RTE_POWER_MONITOR_OPAQUE_SZ: u32 = 4;
pub const RTE_ETH_LINK_SPEED_AUTONEG: u32 = 0;
pub const RTE_ETH_LINK_SPEED_FIXED: u32 = 1;
pub const RTE_ETH_LINK_SPEED_10M_HD: u32 = 2;
pub const RTE_ETH_LINK_SPEED_10M: u32 = 4;
pub const RTE_ETH_LINK_SPEED_100M_HD: u32 = 8;
pub const RTE_ETH_LINK_SPEED_100M: u32 = 16;
pub const RTE_ETH_LINK_SPEED_1G: u32 = 32;
pub const RTE_ETH_LINK_SPEED_2_5G: u32 = 64;
pub const RTE_ETH_LINK_SPEED_5G: u32 = 128;
pub const RTE_ETH_LINK_SPEED_10G: u32 = 256;
pub const RTE_ETH_LINK_SPEED_20G: u32 = 512;
pub const RTE_ETH_LINK_SPEED_25G: u32 = 1024;
pub const RTE_ETH_LINK_SPEED_40G: u32 = 2048;
pub const RTE_ETH_LINK_SPEED_50G: u32 = 4096;
pub const RTE_ETH_LINK_SPEED_56G: u32 = 8192;
pub const RTE_ETH_LINK_SPEED_100G: u32 = 16384;
pub const RTE_ETH_LINK_SPEED_200G: u32 = 32768;
pub const RTE_ETH_LINK_SPEED_400G: u32 = 65536;
pub const RTE_ETH_SPEED_NUM_NONE: u32 = 0;
pub const RTE_ETH_SPEED_NUM_10M: u32 = 10;
pub const RTE_ETH_SPEED_NUM_100M: u32 = 100;
pub const RTE_ETH_SPEED_NUM_1G: u32 = 1000;
pub const RTE_ETH_SPEED_NUM_2_5G: u32 = 2500;
pub const RTE_ETH_SPEED_NUM_5G: u32 = 5000;
pub const RTE_ETH_SPEED_NUM_10G: u32 = 10000;
pub const RTE_ETH_SPEED_NUM_20G: u32 = 20000;
pub const RTE_ETH_SPEED_NUM_25G: u32 = 25000;
pub const RTE_ETH_SPEED_NUM_40G: u32 = 40000;
pub const RTE_ETH_SPEED_NUM_50G: u32 = 50000;
pub const RTE_ETH_SPEED_NUM_56G: u32 = 56000;
pub const RTE_ETH_SPEED_NUM_100G: u32 = 100000;
pub const RTE_ETH_SPEED_NUM_200G: u32 = 200000;
pub const RTE_ETH_SPEED_NUM_400G: u32 = 400000;
pub const RTE_ETH_SPEED_NUM_UNKNOWN: u32 = 4294967295;
pub const RTE_ETH_LINK_HALF_DUPLEX: u32 = 0;
pub const RTE_ETH_LINK_FULL_DUPLEX: u32 = 1;
pub const RTE_ETH_LINK_DOWN: u32 = 0;
pub const RTE_ETH_LINK_UP: u32 = 1;
pub const RTE_ETH_LINK_FIXED: u32 = 0;
pub const RTE_ETH_LINK_AUTONEG: u32 = 1;
pub const RTE_ETH_LINK_MAX_STR_LEN: u32 = 40;
pub const RTE_ETH_MQ_RX_RSS_FLAG: u32 = 1;
pub const RTE_ETH_MQ_RX_DCB_FLAG: u32 = 2;
pub const RTE_ETH_MQ_RX_VMDQ_FLAG: u32 = 4;
pub const RTE_ETH_FLOW_UNKNOWN: u32 = 0;
pub const RTE_ETH_FLOW_RAW: u32 = 1;
pub const RTE_ETH_FLOW_IPV4: u32 = 2;
pub const RTE_ETH_FLOW_FRAG_IPV4: u32 = 3;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_TCP: u32 = 4;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_UDP: u32 = 5;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_SCTP: u32 = 6;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_OTHER: u32 = 7;
pub const RTE_ETH_FLOW_IPV6: u32 = 8;
pub const RTE_ETH_FLOW_FRAG_IPV6: u32 = 9;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_TCP: u32 = 10;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_UDP: u32 = 11;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_SCTP: u32 = 12;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_OTHER: u32 = 13;
pub const RTE_ETH_FLOW_L2_PAYLOAD: u32 = 14;
pub const RTE_ETH_FLOW_IPV6_EX: u32 = 15;
pub const RTE_ETH_FLOW_IPV6_TCP_EX: u32 = 16;
pub const RTE_ETH_FLOW_IPV6_UDP_EX: u32 = 17;
pub const RTE_ETH_FLOW_PORT: u32 = 18;
pub const RTE_ETH_FLOW_VXLAN: u32 = 19;
pub const RTE_ETH_FLOW_GENEVE: u32 = 20;
pub const RTE_ETH_FLOW_NVGRE: u32 = 21;
pub const RTE_ETH_FLOW_VXLAN_GPE: u32 = 22;
pub const RTE_ETH_FLOW_GTPU: u32 = 23;
pub const RTE_ETH_FLOW_MAX: u32 = 24;
pub const RTE_ETH_RSS_IPV4: u32 = 4;
pub const RTE_ETH_RSS_FRAG_IPV4: u32 = 8;
pub const RTE_ETH_RSS_NONFRAG_IPV4_TCP: u32 = 16;
pub const RTE_ETH_RSS_NONFRAG_IPV4_UDP: u32 = 32;
pub const RTE_ETH_RSS_NONFRAG_IPV4_SCTP: u32 = 64;
pub const RTE_ETH_RSS_NONFRAG_IPV4_OTHER: u32 = 128;
pub const RTE_ETH_RSS_IPV6: u32 = 256;
pub const RTE_ETH_RSS_FRAG_IPV6: u32 = 512;
pub const RTE_ETH_RSS_NONFRAG_IPV6_TCP: u32 = 1024;
pub const RTE_ETH_RSS_NONFRAG_IPV6_UDP: u32 = 2048;
pub const RTE_ETH_RSS_NONFRAG_IPV6_SCTP: u32 = 4096;
pub const RTE_ETH_RSS_NONFRAG_IPV6_OTHER: u32 = 8192;
pub const RTE_ETH_RSS_L2_PAYLOAD: u32 = 16384;
pub const RTE_ETH_RSS_IPV6_EX: u32 = 32768;
pub const RTE_ETH_RSS_IPV6_TCP_EX: u32 = 65536;
pub const RTE_ETH_RSS_IPV6_UDP_EX: u32 = 131072;
pub const RTE_ETH_RSS_PORT: u32 = 262144;
pub const RTE_ETH_RSS_VXLAN: u32 = 524288;
pub const RTE_ETH_RSS_GENEVE: u32 = 1048576;
pub const RTE_ETH_RSS_NVGRE: u32 = 2097152;
pub const RTE_ETH_RSS_GTPU: u32 = 8388608;
pub const RTE_ETH_RSS_ETH: u32 = 16777216;
pub const RTE_ETH_RSS_S_VLAN: u32 = 33554432;
pub const RTE_ETH_RSS_C_VLAN: u32 = 67108864;
pub const RTE_ETH_RSS_ESP: u32 = 134217728;
pub const RTE_ETH_RSS_AH: u32 = 268435456;
pub const RTE_ETH_RSS_L2TPV3: u32 = 536870912;
pub const RTE_ETH_RSS_PFCP: u32 = 1073741824;
pub const RTE_ETH_RSS_PPPOE: u32 = 2147483648;
pub const RTE_ETH_RSS_ECPRI: u64 = 4294967296;
pub const RTE_ETH_RSS_MPLS: u64 = 8589934592;
pub const RTE_ETH_RSS_IPV4_CHKSUM: u64 = 17179869184;
pub const RTE_ETH_RSS_L4_CHKSUM: u64 = 34359738368;
pub const RTE_ETH_RSS_L2TPV2: u64 = 68719476736;
pub const RTE_ETH_RSS_IPV6_FLOW_LABEL: u64 = 137438953472;
pub const RTE_ETH_RSS_L3_DST_ONLY: u64 = 4611686018427387904;
pub const RTE_ETH_RSS_L4_SRC_ONLY: u64 = 2305843009213693952;
pub const RTE_ETH_RSS_L4_DST_ONLY: u64 = 1152921504606846976;
pub const RTE_ETH_RSS_L2_SRC_ONLY: u64 = 576460752303423488;
pub const RTE_ETH_RSS_L2_DST_ONLY: u64 = 288230376151711744;
pub const RTE_ETH_RSS_L3_PRE32: u64 = 144115188075855872;
pub const RTE_ETH_RSS_L3_PRE40: u64 = 72057594037927936;
pub const RTE_ETH_RSS_L3_PRE48: u64 = 36028797018963968;
pub const RTE_ETH_RSS_L3_PRE56: u64 = 18014398509481984;
pub const RTE_ETH_RSS_L3_PRE64: u64 = 9007199254740992;
pub const RTE_ETH_RSS_L3_PRE96: u64 = 4503599627370496;
pub const RTE_ETH_RSS_LEVEL_PMD_DEFAULT: u32 = 0;
pub const RTE_ETH_RSS_LEVEL_OUTERMOST: u64 = 1125899906842624;
pub const RTE_ETH_RSS_LEVEL_INNERMOST: u64 = 2251799813685248;
pub const RTE_ETH_RSS_LEVEL_MASK: u64 = 3377699720527872;
pub const RTE_ETH_RSS_IPV6_PRE32: u64 = 144115188075856128;
pub const RTE_ETH_RSS_IPV6_PRE40: u64 = 72057594037928192;
pub const RTE_ETH_RSS_IPV6_PRE48: u64 = 36028797018964224;
pub const RTE_ETH_RSS_IPV6_PRE56: u64 = 18014398509482240;
pub const RTE_ETH_RSS_IPV6_PRE64: u64 = 9007199254741248;
pub const RTE_ETH_RSS_IPV6_PRE96: u64 = 4503599627370752;
pub const RTE_ETH_RSS_IPV6_PRE32_UDP: u64 = 144115188075857920;
pub const RTE_ETH_RSS_IPV6_PRE40_UDP: u64 = 72057594037929984;
pub const RTE_ETH_RSS_IPV6_PRE48_UDP: u64 = 36028797018966016;
pub const RTE_ETH_RSS_IPV6_PRE56_UDP: u64 = 18014398509484032;
pub const RTE_ETH_RSS_IPV6_PRE64_UDP: u64 = 9007199254743040;
pub const RTE_ETH_RSS_IPV6_PRE96_UDP: u64 = 4503599627372544;
pub const RTE_ETH_RSS_IPV6_PRE32_TCP: u64 = 144115188075856896;
pub const RTE_ETH_RSS_IPV6_PRE40_TCP: u64 = 72057594037928960;
pub const RTE_ETH_RSS_IPV6_PRE48_TCP: u64 = 36028797018964992;
pub const RTE_ETH_RSS_IPV6_PRE56_TCP: u64 = 18014398509483008;
pub const RTE_ETH_RSS_IPV6_PRE64_TCP: u64 = 9007199254742016;
pub const RTE_ETH_RSS_IPV6_PRE96_TCP: u64 = 4503599627371520;
pub const RTE_ETH_RSS_IPV6_PRE32_SCTP: u64 = 144115188075859968;
pub const RTE_ETH_RSS_IPV6_PRE40_SCTP: u64 = 72057594037932032;
pub const RTE_ETH_RSS_IPV6_PRE48_SCTP: u64 = 36028797018968064;
pub const RTE_ETH_RSS_IPV6_PRE56_SCTP: u64 = 18014398509486080;
pub const RTE_ETH_RSS_IPV6_PRE64_SCTP: u64 = 9007199254745088;
pub const RTE_ETH_RSS_IPV6_PRE96_SCTP: u64 = 4503599627374592;
pub const RTE_ETH_RSS_IP: u32 = 41868;
pub const RTE_ETH_RSS_UDP: u32 = 133152;
pub const RTE_ETH_RSS_TCP: u32 = 66576;
pub const RTE_ETH_RSS_SCTP: u32 = 4160;
pub const RTE_ETH_RSS_TUNNEL: u32 = 3670016;
pub const RTE_ETH_RSS_VLAN: u32 = 100663296;
pub const RTE_ETH_RSS_PROTO_MASK: u64 = 8594128892;
pub const RTE_ETH_RSS_RETA_SIZE_64: u32 = 64;
pub const RTE_ETH_RSS_RETA_SIZE_128: u32 = 128;
pub const RTE_ETH_RSS_RETA_SIZE_256: u32 = 256;
pub const RTE_ETH_RSS_RETA_SIZE_512: u32 = 512;
pub const RTE_ETH_RETA_GROUP_SIZE: u32 = 64;
pub const RTE_ETH_VMDQ_MAX_VLAN_FILTERS: u32 = 64;
pub const RTE_ETH_DCB_NUM_USER_PRIORITIES: u32 = 8;
pub const RTE_ETH_VMDQ_DCB_NUM_QUEUES: u32 = 128;
pub const RTE_ETH_DCB_NUM_QUEUES: u32 = 128;
pub const RTE_ETH_DCB_PG_SUPPORT: u32 = 1;
pub const RTE_ETH_DCB_PFC_SUPPORT: u32 = 2;
pub const RTE_ETH_VLAN_STRIP_OFFLOAD: u32 = 1;
pub const RTE_ETH_VLAN_FILTER_OFFLOAD: u32 = 2;
pub const RTE_ETH_VLAN_EXTEND_OFFLOAD: u32 = 4;
pub const RTE_ETH_QINQ_STRIP_OFFLOAD: u32 = 8;
pub const RTE_ETH_VLAN_STRIP_MASK: u32 = 1;
pub const RTE_ETH_VLAN_FILTER_MASK: u32 = 2;
pub const RTE_ETH_VLAN_EXTEND_MASK: u32 = 4;
pub const RTE_ETH_QINQ_STRIP_MASK: u32 = 8;
pub const RTE_ETH_VLAN_ID_MAX: u32 = 4095;
pub const RTE_ETH_NUM_RECEIVE_MAC_ADDR: u32 = 128;
pub const RTE_ETH_VMDQ_NUM_UC_HASH_ARRAY: u32 = 128;
pub const RTE_ETH_VMDQ_ACCEPT_UNTAG: u32 = 1;
pub const RTE_ETH_VMDQ_ACCEPT_HASH_MC: u32 = 2;
pub const RTE_ETH_VMDQ_ACCEPT_HASH_UC: u32 = 4;
pub const RTE_ETH_VMDQ_ACCEPT_BROADCAST: u32 = 8;
pub const RTE_ETH_VMDQ_ACCEPT_MULTICAST: u32 = 16;
pub const RTE_ETH_MAX_HAIRPIN_PEERS: u32 = 32;
pub const RTE_ETH_RX_OFFLOAD_VLAN_STRIP: u32 = 1;
pub const RTE_ETH_RX_OFFLOAD_IPV4_CKSUM: u32 = 2;
pub const RTE_ETH_RX_OFFLOAD_UDP_CKSUM: u32 = 4;
pub const RTE_ETH_RX_OFFLOAD_TCP_CKSUM: u32 = 8;
pub const RTE_ETH_RX_OFFLOAD_TCP_LRO: u32 = 16;
pub const RTE_ETH_RX_OFFLOAD_QINQ_STRIP: u32 = 32;
pub const RTE_ETH_RX_OFFLOAD_OUTER_IPV4_CKSUM: u32 = 64;
pub const RTE_ETH_RX_OFFLOAD_MACSEC_STRIP: u32 = 128;
pub const RTE_ETH_RX_OFFLOAD_VLAN_FILTER: u32 = 512;
pub const RTE_ETH_RX_OFFLOAD_VLAN_EXTEND: u32 = 1024;
pub const RTE_ETH_RX_OFFLOAD_SCATTER: u32 = 8192;
pub const RTE_ETH_RX_OFFLOAD_TIMESTAMP: u32 = 16384;
pub const RTE_ETH_RX_OFFLOAD_SECURITY: u32 = 32768;
pub const RTE_ETH_RX_OFFLOAD_KEEP_CRC: u32 = 65536;
pub const RTE_ETH_RX_OFFLOAD_SCTP_CKSUM: u32 = 131072;
pub const RTE_ETH_RX_OFFLOAD_OUTER_UDP_CKSUM: u32 = 262144;
pub const RTE_ETH_RX_OFFLOAD_RSS_HASH: u32 = 524288;
pub const RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT: u32 = 1048576;
pub const RTE_ETH_RX_OFFLOAD_CHECKSUM: u32 = 14;
pub const RTE_ETH_RX_OFFLOAD_VLAN: u32 = 1569;
pub const RTE_ETH_TX_OFFLOAD_VLAN_INSERT: u32 = 1;
pub const RTE_ETH_TX_OFFLOAD_IPV4_CKSUM: u32 = 2;
pub const RTE_ETH_TX_OFFLOAD_UDP_CKSUM: u32 = 4;
pub const RTE_ETH_TX_OFFLOAD_TCP_CKSUM: u32 = 8;
pub const RTE_ETH_TX_OFFLOAD_SCTP_CKSUM: u32 = 16;
pub const RTE_ETH_TX_OFFLOAD_TCP_TSO: u32 = 32;
pub const RTE_ETH_TX_OFFLOAD_UDP_TSO: u32 = 64;
pub const RTE_ETH_TX_OFFLOAD_OUTER_IPV4_CKSUM: u32 = 128;
pub const RTE_ETH_TX_OFFLOAD_QINQ_INSERT: u32 = 256;
pub const RTE_ETH_TX_OFFLOAD_VXLAN_TNL_TSO: u32 = 512;
pub const RTE_ETH_TX_OFFLOAD_GRE_TNL_TSO: u32 = 1024;
pub const RTE_ETH_TX_OFFLOAD_IPIP_TNL_TSO: u32 = 2048;
pub const RTE_ETH_TX_OFFLOAD_GENEVE_TNL_TSO: u32 = 4096;
pub const RTE_ETH_TX_OFFLOAD_MACSEC_INSERT: u32 = 8192;
pub const RTE_ETH_TX_OFFLOAD_MT_LOCKFREE: u32 = 16384;
pub const RTE_ETH_TX_OFFLOAD_MULTI_SEGS: u32 = 32768;
pub const RTE_ETH_TX_OFFLOAD_MBUF_FAST_FREE: u32 = 65536;
pub const RTE_ETH_TX_OFFLOAD_SECURITY: u32 = 131072;
pub const RTE_ETH_TX_OFFLOAD_UDP_TNL_TSO: u32 = 262144;
pub const RTE_ETH_TX_OFFLOAD_IP_TNL_TSO: u32 = 524288;
pub const RTE_ETH_TX_OFFLOAD_OUTER_UDP_CKSUM: u32 = 1048576;
pub const RTE_ETH_TX_OFFLOAD_SEND_ON_TIMESTAMP: u32 = 2097152;
pub const RTE_ETH_DEV_CAPA_RUNTIME_RX_QUEUE_SETUP: u32 = 1;
pub const RTE_ETH_DEV_CAPA_RUNTIME_TX_QUEUE_SETUP: u32 = 2;
pub const RTE_ETH_DEV_CAPA_RXQ_SHARE: u32 = 4;
pub const RTE_ETH_DEV_CAPA_FLOW_RULE_KEEP: u32 = 8;
pub const RTE_ETH_DEV_CAPA_FLOW_SHARED_OBJECT_KEEP: u32 = 16;
pub const RTE_ETH_DEV_FALLBACK_RX_RINGSIZE: u32 = 512;
pub const RTE_ETH_DEV_FALLBACK_TX_RINGSIZE: u32 = 512;
pub const RTE_ETH_DEV_FALLBACK_RX_NBQUEUES: u32 = 1;
pub const RTE_ETH_DEV_FALLBACK_TX_NBQUEUES: u32 = 1;
pub const RTE_ETH_DEV_SWITCH_DOMAIN_ID_INVALID: u32 = 65535;
pub const RTE_ETH_QUEUE_STATE_STOPPED: u32 = 0;
pub const RTE_ETH_QUEUE_STATE_STARTED: u32 = 1;
pub const RTE_ETH_QUEUE_STATE_HAIRPIN: u32 = 2;
pub const RTE_ETH_BURST_FLAG_PER_QUEUE: u32 = 1;
pub const RTE_ETH_BURST_MODE_INFO_SIZE: u32 = 1024;
pub const RTE_ETH_XSTATS_NAME_SIZE: u32 = 64;
pub const RTE_ETH_DCB_NUM_TCS: u32 = 8;
pub const RTE_ETH_MAX_VMDQ_POOL: u32 = 64;
pub const RTE_ETH_ALL: u32 = 32;
pub const RTE_ETH_NAME_MAX_LEN: u32 = 64;
pub const RTE_ETH_DEV_NO_OWNER: u32 = 0;
pub const RTE_ETH_MAX_OWNER_NAME_LEN: u32 = 64;
pub const RTE_ETH_DEV_FLOW_OPS_THREAD_SAFE: u32 = 1;
pub const RTE_ETH_DEV_INTR_LSC: u32 = 2;
pub const RTE_ETH_DEV_BONDING_MEMBER: u32 = 4;
pub const RTE_ETH_DEV_INTR_RMV: u32 = 8;
pub const RTE_ETH_DEV_REPRESENTOR: u32 = 16;
pub const RTE_ETH_DEV_NOLIVE_MAC_ADDR: u32 = 32;
pub const RTE_ETH_DEV_AUTOFILL_QUEUE_XSTATS: u32 = 64;
pub const RTE_ETH_RX_METADATA_USER_FLAG: u32 = 1;
pub const RTE_ETH_RX_METADATA_USER_MARK: u32 = 2;
pub const RTE_ETH_RX_METADATA_TUNNEL_ID: u32 = 4;
pub const RTE_ETH_DEV_REASSEMBLY_F_IPV4: u32 = 1;
pub const RTE_ETH_DEV_REASSEMBLY_F_IPV6: u32 = 2;
pub const RTE_ETH_RX_DESC_AVAIL: u32 = 0;
pub const RTE_ETH_RX_DESC_DONE: u32 = 1;
pub const RTE_ETH_RX_DESC_UNAVAIL: u32 = 2;
pub const RTE_ETH_TX_DESC_FULL: u32 = 0;
pub const RTE_ETH_TX_DESC_DONE: u32 = 1;
pub const RTE_ETH_TX_DESC_UNAVAIL: u32 = 2;
pub const RTE_FLOW_CONNTRACK_PKT_STATE_VALID: u32 = 1;
pub const RTE_FLOW_CONNTRACK_PKT_STATE_CHANGED: u32 = 2;
pub const RTE_FLOW_CONNTRACK_PKT_STATE_INVALID: u32 = 4;
pub const RTE_FLOW_CONNTRACK_PKT_STATE_DISABLED: u32 = 8;
pub const RTE_FLOW_CONNTRACK_PKT_STATE_BAD: u32 = 16;
pub const RTE_FLOW_RESTORE_INFO_TUNNEL: u32 = 1;
pub const RTE_FLOW_RESTORE_INFO_ENCAPSULATED: u32 = 2;
pub const RTE_FLOW_RESTORE_INFO_GROUP_ID: u32 = 4;
pub const RTE_FLOW_PORT_FLAG_STRICT_QUEUE: u32 = 1;
pub const RTE_FLOW_PORT_FLAG_SHARE_INDIRECT: u32 = 2;
pub const RTE_FLOW_TABLE_SPECIALIZE_TRANSFER_WIRE_ORIG: u32 = 1;
pub const RTE_FLOW_TABLE_SPECIALIZE_TRANSFER_VPORT_ORIG: u32 = 2;
pub const RTE_FLOW_TABLE_SPECIALIZE_RESIZABLE: u32 = 4;
pub const RTE_NTUPLE_FLAGS_DST_IP: u32 = 1;
pub const RTE_NTUPLE_FLAGS_SRC_IP: u32 = 2;
pub const RTE_NTUPLE_FLAGS_DST_PORT: u32 = 4;
pub const RTE_NTUPLE_FLAGS_SRC_PORT: u32 = 8;
pub const RTE_NTUPLE_FLAGS_PROTO: u32 = 16;
pub const RTE_NTUPLE_FLAGS_TCP_FLAG: u32 = 32;
pub const RTE_5TUPLE_FLAGS: u32 = 31;
pub const RTE_2TUPLE_FLAGS: u32 = 20;
pub const RTE_NTUPLE_TCP_FLAGS_MASK: u32 = 63;
pub const RTE_ETH_FDIR_MAX_FLEXLEN: u32 = 16;
pub const RTE_ETH_INSET_SIZE_MAX: u32 = 128;
pub const RTE_JHASH_GOLDEN_RATIO: u32 = 3735928559;
pub const RTE_FBK_HASH_INIT_VAL_DEFAULT: u32 = 4294967295;
pub const RTE_FBK_HASH_ENTRIES_MAX: u32 = 1048576;
pub const RTE_FBK_HASH_ENTRIES_PER_BUCKET_MAX: u32 = 256;
pub const RTE_FBK_HASH_NAMESIZE: u32 = 32;
pub const RTE_GENEVE_DEFAULT_PORT: u32 = 6081;
pub const RTE_GENEVE_TYPE_ETH: u32 = 25944;
pub const RTE_QSBR_THRID_INVALID: u32 = 4294967295;
pub const RTE_RCU_QSBR_DQ_NAMESIZE: u32 = 29;
pub const RTE_RCU_QSBR_DQ_MT_UNSAFE: u32 = 1;
pub const RTE_HASH_ENTRIES_MAX: u32 = 1073741824;
pub const RTE_HASH_NAMESIZE: u32 = 32;
pub const RTE_HASH_LOOKUP_BULK_MAX: u32 = 64;
pub const RTE_HASH_LOOKUP_MULTI_MAX: u32 = 64;
pub const RTE_HASH_EXTRA_FLAGS_TRANS_MEM_SUPPORT: u32 = 1;
pub const RTE_HASH_EXTRA_FLAGS_MULTI_WRITER_ADD: u32 = 2;
pub const RTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY: u32 = 4;
pub const RTE_HASH_EXTRA_FLAGS_EXT_TABLE: u32 = 8;
pub const RTE_HASH_EXTRA_FLAGS_NO_FREE_ON_DEL: u32 = 16;
pub const RTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY_LF: u32 = 32;
pub const RTE_KEEPALIVE_MAXCORES: u32 = 128;
pub const RTE_KVARGS_MAX: u32 = 32;
pub const RTE_KVARGS_PAIRS_DELIM: &::core::ffi::CStr = c",";
pub const RTE_KVARGS_KV_DELIM: &::core::ffi::CStr = c"=";
pub const RTE_INTR_MODE_NONE_NAME: &::core::ffi::CStr = c"none";
pub const RTE_INTR_MODE_LEGACY_NAME: &::core::ffi::CStr = c"legacy";
pub const RTE_INTR_MODE_MSI_NAME: &::core::ffi::CStr = c"msi";
pub const RTE_INTR_MODE_MSIX_NAME: &::core::ffi::CStr = c"msix";
pub const RTE_PDCP_CTRL_PDU_SIZE_MAX: u32 = 9000;
pub const RTE_PDCP_MAC_I_LEN: u32 = 4;
pub const RTE_PFLOCK_WBITS: u32 = 3;
pub const RTE_PFLOCK_PRES: u32 = 2;
pub const RTE_PFLOCK_PHID: u32 = 1;
pub const RTE_PFLOCK_LSB: u32 = 65520;
pub const RTE_PFLOCK_RINC: u32 = 16;
pub const RTE_PMD_MLX5_FINE_GRANULARITY_INLINE: &::core::ffi::CStr =
    c"mlx5_fine_granularity_inline";
pub const RTE_PMD_MLX5_DOMAIN_BIT_NIC_RX: u32 = 1;
pub const RTE_PMD_MLX5_DOMAIN_BIT_NIC_TX: u32 = 2;
pub const RTE_PMD_MLX5_DOMAIN_BIT_FDB: u32 = 4;
pub const RTE_PMD_MLX5_EXTERNAL_RX_QUEUE_ID_MIN: u32 = 64536;
pub const RTE_PMD_MLX5_LINEAR_HASH_TAG_INDEX: u32 = 255;
pub const RTE_PMD_MLX5_HOST_SHAPER_FLAG_AVAIL_THRESH_TRIGGERED: u32 = 0;
pub const RTE_PMD_MLX5_FLOW_ENGINE_FLAG_STANDBY_DUP_INGRESS: u32 = 1;
pub const RTE_SERVICE_NAME_MAX: u32 = 32;
pub const RTE_SERVICE_CAP_MT_SAFE: u32 = 1;
pub const RTE_SERVICE_ATTR_CYCLES: u32 = 0;
pub const RTE_SERVICE_ATTR_CALL_COUNT: u32 = 1;
pub const RTE_SERVICE_ATTR_IDLE_CALL_COUNT: u32 = 2;
pub const RTE_SERVICE_ATTR_ERROR_CALL_COUNT: u32 = 3;
pub const RTE_SERVICE_LCORE_ATTR_LOOPS: u32 = 0;
pub const RTE_SERVICE_LCORE_ATTR_CYCLES: u32 = 1;
pub const RTE_TAILQ_STACK_NAME: &::core::ffi::CStr = c"RTE_STACK";
pub const RTE_STACK_MZ_PREFIX: &::core::ffi::CStr = c"STK_";
pub const RTE_STACK_NAMESIZE: u32 = 28;
pub const RTE_STACK_F_LF: u32 = 1;
pub const RTE_TAILQ_NAMESIZE: u32 = 32;
pub const RTE_TEL_MAX_STRING_LEN: u32 = 128;
pub const RTE_TEL_MAX_SINGLE_STRING_LEN: u32 = 8192;
pub const RTE_TEL_MAX_DICT_ENTRIES: u32 = 256;
pub const RTE_TEL_MAX_ARRAY_ENTRIES: u32 = 512;
pub const RTE_TEL_U64_VAL: u32 = 2;
pub const RTE_THASH_V4_L3_LEN: u32 = 2;
pub const RTE_THASH_V4_L4_LEN: u32 = 3;
pub const RTE_THASH_V6_L3_LEN: u32 = 8;
pub const RTE_THASH_V6_L4_LEN: u32 = 9;
pub const RTE_THASH_KEY_LEN_MAX: u32 = 52;
pub const RTE_THASH_TUPLE_LEN_MAX: u32 = 48;
pub const RTE_THASH_RETA_SZ_MIN: u32 = 2;
pub const RTE_THASH_RETA_SZ_MAX: u32 = 16;
pub const RTE_THASH_IGNORE_PERIOD_OVERFLOW: u32 = 1;
pub const RTE_THASH_MINIMAL_SEQ: u32 = 2;
pub const RTE_TICKETLOCK_INITIALIZER: u32 = 0;
pub const RTE_TLS_TYPE_INVALID: u32 = 0;
pub const RTE_TLS_TYPE_CHANGE_CIPHER_SPEC: u32 = 20;
pub const RTE_TLS_TYPE_ALERT: u32 = 21;
pub const RTE_TLS_TYPE_HANDSHAKE: u32 = 22;
pub const RTE_TLS_TYPE_APPDATA: u32 = 23;
pub const RTE_TLS_TYPE_HEARTBEAT: u32 = 24;
pub const RTE_TLS_TYPE_MAX: u32 = 255;
pub const RTE_TLS_VERSION_1_2: u32 = 771;
pub const RTE_TLS_VERSION_1_3: u32 = 772;
pub const RTE_TM_ETH_FRAMING_OVERHEAD: u32 = 20;
pub const RTE_TM_ETH_FRAMING_OVERHEAD_FCS: u32 = 24;
pub const RTE_TM_WRED_PROFILE_ID_NONE: u32 = 4294967295;
pub const RTE_TM_SHAPER_PROFILE_ID_NONE: u32 = 4294967295;
pub const RTE_TM_NODE_ID_NULL: u32 = 4294967295;
pub const RTE_TM_NODE_LEVEL_ID_ANY: u32 = 4294967295;
pub const RTE_VERSION: u32 = 419627107;
pub const RTE_VFIO_NOIOMMU: u32 = 8;
pub const RTE_VFIO_INFO_FLAG_CAPS: u32 = 8;
pub const RTE_VFIO_CAP_MSIX_MAPPABLE: u32 = 3;
pub const RTE_VFIO_DEVICE_FEATURE: u32 = 15221;
pub const RTE_VFIO_DEVICE_FEATURE_BUS_MASTER: u32 = 10;
pub const RTE_VFIO_DEFAULT_CONTAINER_FD: i32 = -1;
pub type __off_t = ::core::ffi::c_long;
pub type __off64_t = ::core::ffi::c_long;
pub type __time_t = ::core::ffi::c_long;
pub type __syscall_slong_t = ::core::ffi::c_long;
#[doc = "Signature of callback back function called when an alarm goes off."]
pub type rte_eal_alarm_callback =
    ::core::option::Option<unsafe extern "C" fn(arg: *mut ::core::ffi::c_void)>;
unsafe extern "C" {
    #[doc = "Function to set a callback to be triggered when us microseconds\nhave expired. Accuracy of timing to the microsecond is not guaranteed. The\nalarm function will not be called *before* the requested time, but may\nbe called a short period of time afterwards.\nThe alarm handler will be called only once. There is no need to call\n\"rte_eal_alarm_cancel\" from within the callback function.\n\n# Arguments\n\n* `us` -\nThe time in microseconds before the callback is called\n* `cb` -\nThe function to be called when the alarm expires\n* `cb_arg` -\nPointer parameter to be passed to the callback function\n\n# Returns\n\nOn success, zero.\nOn failure, a negative error number"]
    pub fn rte_eal_alarm_set(
        us: u64,
        cb: rte_eal_alarm_callback,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Function to cancel an alarm callback which has been registered before. If\nused outside alarm callback it wait for all callbacks to finish execution.\n\n# Arguments\n\n* `cb_fn` -\nalarm callback\n* `cb_arg` -\nPointer parameter to be passed to the callback function. To remove all\ncopies of a given callback function, irrespective of parameter, (void *)-1\ncan be used here.\n\n# Returns\n\n- value greater than 0 and rte_errno not changed - returned value is\nthe number of canceled alarm callback functions\n- value greater or equal 0 and rte_errno set to EINPROGRESS, at least one\nalarm could not be canceled because cancellation was requested from alarm\ncallback context. Returned value is the number of successfully canceled\nalarm callbacks\n-  0 and rte_errno set to ENOENT - no alarm found\n- -1 and rte_errno set to EINVAL - invalid parameter (NULL callback)"]
    pub fn rte_eal_alarm_cancel(
        cb_fn: rte_eal_alarm_callback,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
pub type __gnuc_va_list = __builtin_va_list;
#[doc = "The opaque type of streams.  This is the definition used elsewhere."]
pub type FILE = _IO_FILE;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_marker {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_codecvt {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_wide_data {
    _unused: [u8; 0],
}
pub type _IO_lock_t = ::core::ffi::c_void;
#[doc = "The tag name of this struct is _IO_FILE to preserve historic\nC++ mangled names for functions taking FILE* arguments.\nThat name should not be used in new code."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct _IO_FILE {
    #[doc = "High-order word is _IO_MAGIC; rest is flags."]
    pub _flags: ::core::ffi::c_int,
    #[doc = "Current read pointer"]
    pub _IO_read_ptr: *mut ::core::ffi::c_char,
    #[doc = "End of get area."]
    pub _IO_read_end: *mut ::core::ffi::c_char,
    #[doc = "Start of putback+get area."]
    pub _IO_read_base: *mut ::core::ffi::c_char,
    #[doc = "Start of put area."]
    pub _IO_write_base: *mut ::core::ffi::c_char,
    #[doc = "Current put pointer."]
    pub _IO_write_ptr: *mut ::core::ffi::c_char,
    #[doc = "End of put area."]
    pub _IO_write_end: *mut ::core::ffi::c_char,
    #[doc = "Start of reserve area."]
    pub _IO_buf_base: *mut ::core::ffi::c_char,
    #[doc = "End of reserve area."]
    pub _IO_buf_end: *mut ::core::ffi::c_char,
    #[doc = "Pointer to start of non-current get area."]
    pub _IO_save_base: *mut ::core::ffi::c_char,
    #[doc = "Pointer to first valid character of backup area"]
    pub _IO_backup_base: *mut ::core::ffi::c_char,
    #[doc = "Pointer to end of non-current get area."]
    pub _IO_save_end: *mut ::core::ffi::c_char,
    pub _markers: *mut _IO_marker,
    pub _chain: *mut _IO_FILE,
    pub _fileno: ::core::ffi::c_int,
    pub _flags2: ::core::ffi::c_int,
    #[doc = "This used to be _offset but it's too small."]
    pub _old_offset: __off_t,
    #[doc = "1+column number of pbase(); 0 is unknown."]
    pub _cur_column: ::core::ffi::c_ushort,
    pub _vtable_offset: ::core::ffi::c_schar,
    pub _shortbuf: [::core::ffi::c_char; 1usize],
    pub _lock: *mut _IO_lock_t,
    pub _offset: __off64_t,
    #[doc = "Wide character stream stuff."]
    pub _codecvt: *mut _IO_codecvt,
    pub _wide_data: *mut _IO_wide_data,
    pub _freeres_list: *mut _IO_FILE,
    pub _freeres_buf: *mut ::core::ffi::c_void,
    pub _prevchain: *mut *mut _IO_FILE,
    pub _mode: ::core::ffi::c_int,
    #[doc = "Make sure we don't get into trouble again."]
    pub _unused2: [::core::ffi::c_char; 20usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of _IO_FILE"][::core::mem::size_of::<_IO_FILE>() - 216usize];
    ["Alignment of _IO_FILE"][::core::mem::align_of::<_IO_FILE>() - 8usize];
    ["Offset of field: _IO_FILE::_flags"][::core::mem::offset_of!(_IO_FILE, _flags) - 0usize];
    ["Offset of field: _IO_FILE::_IO_read_ptr"]
        [::core::mem::offset_of!(_IO_FILE, _IO_read_ptr) - 8usize];
    ["Offset of field: _IO_FILE::_IO_read_end"]
        [::core::mem::offset_of!(_IO_FILE, _IO_read_end) - 16usize];
    ["Offset of field: _IO_FILE::_IO_read_base"]
        [::core::mem::offset_of!(_IO_FILE, _IO_read_base) - 24usize];
    ["Offset of field: _IO_FILE::_IO_write_base"]
        [::core::mem::offset_of!(_IO_FILE, _IO_write_base) - 32usize];
    ["Offset of field: _IO_FILE::_IO_write_ptr"]
        [::core::mem::offset_of!(_IO_FILE, _IO_write_ptr) - 40usize];
    ["Offset of field: _IO_FILE::_IO_write_end"]
        [::core::mem::offset_of!(_IO_FILE, _IO_write_end) - 48usize];
    ["Offset of field: _IO_FILE::_IO_buf_base"]
        [::core::mem::offset_of!(_IO_FILE, _IO_buf_base) - 56usize];
    ["Offset of field: _IO_FILE::_IO_buf_end"]
        [::core::mem::offset_of!(_IO_FILE, _IO_buf_end) - 64usize];
    ["Offset of field: _IO_FILE::_IO_save_base"]
        [::core::mem::offset_of!(_IO_FILE, _IO_save_base) - 72usize];
    ["Offset of field: _IO_FILE::_IO_backup_base"]
        [::core::mem::offset_of!(_IO_FILE, _IO_backup_base) - 80usize];
    ["Offset of field: _IO_FILE::_IO_save_end"]
        [::core::mem::offset_of!(_IO_FILE, _IO_save_end) - 88usize];
    ["Offset of field: _IO_FILE::_markers"][::core::mem::offset_of!(_IO_FILE, _markers) - 96usize];
    ["Offset of field: _IO_FILE::_chain"][::core::mem::offset_of!(_IO_FILE, _chain) - 104usize];
    ["Offset of field: _IO_FILE::_fileno"][::core::mem::offset_of!(_IO_FILE, _fileno) - 112usize];
    ["Offset of field: _IO_FILE::_flags2"][::core::mem::offset_of!(_IO_FILE, _flags2) - 116usize];
    ["Offset of field: _IO_FILE::_old_offset"]
        [::core::mem::offset_of!(_IO_FILE, _old_offset) - 120usize];
    ["Offset of field: _IO_FILE::_cur_column"]
        [::core::mem::offset_of!(_IO_FILE, _cur_column) - 128usize];
    ["Offset of field: _IO_FILE::_vtable_offset"]
        [::core::mem::offset_of!(_IO_FILE, _vtable_offset) - 130usize];
    ["Offset of field: _IO_FILE::_shortbuf"]
        [::core::mem::offset_of!(_IO_FILE, _shortbuf) - 131usize];
    ["Offset of field: _IO_FILE::_lock"][::core::mem::offset_of!(_IO_FILE, _lock) - 136usize];
    ["Offset of field: _IO_FILE::_offset"][::core::mem::offset_of!(_IO_FILE, _offset) - 144usize];
    ["Offset of field: _IO_FILE::_codecvt"][::core::mem::offset_of!(_IO_FILE, _codecvt) - 152usize];
    ["Offset of field: _IO_FILE::_wide_data"]
        [::core::mem::offset_of!(_IO_FILE, _wide_data) - 160usize];
    ["Offset of field: _IO_FILE::_freeres_list"]
        [::core::mem::offset_of!(_IO_FILE, _freeres_list) - 168usize];
    ["Offset of field: _IO_FILE::_freeres_buf"]
        [::core::mem::offset_of!(_IO_FILE, _freeres_buf) - 176usize];
    ["Offset of field: _IO_FILE::_prevchain"]
        [::core::mem::offset_of!(_IO_FILE, _prevchain) - 184usize];
    ["Offset of field: _IO_FILE::_mode"][::core::mem::offset_of!(_IO_FILE, _mode) - 192usize];
    ["Offset of field: _IO_FILE::_unused2"][::core::mem::offset_of!(_IO_FILE, _unused2) - 196usize];
};
impl Default for _IO_FILE {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub type va_list = __gnuc_va_list;
pub type off_t = __off_t;
unsafe extern "C" {
    #[doc = "Seed the pseudo-random generator.\nThe generator is automatically seeded by the EAL init with a timer\nvalue. It may need to be re-seeded by the user with a real random\nvalue.\nThis function is not multi-thread safe in regards to other\nrte_srand() calls, nor is it in relation to concurrent rte_rand(),\nrte_rand_max() or rte_drand() calls.\n\n# Arguments\n\n* `seedval` -\nThe value of the seed."]
    pub fn rte_srand(seedval: u64);
}
unsafe extern "C" {
    #[doc = "Get a pseudo-random value.\nThe generator is not cryptographically secure.\nrte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\nwith the exception that they may not be called by multiple\n_unregistered_ non-EAL threads in parallel.\n\n# Returns\n\nA pseudo-random value between 0 and (1<<64)-1."]
    pub fn rte_rand() -> u64;
}
unsafe extern "C" {
    #[doc = "Generates a pseudo-random number with an upper bound.\nThis function returns an uniformly distributed (unbiased) random\nnumber less than a user-specified maximum value.\nrte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\nwith the exception that they may not be called by multiple\n_unregistered_ non-EAL threads in parallel.\n\n# Arguments\n\n* `upper_bound` -\nThe upper bound of the generated number.\n\n# Returns\n\nA pseudo-random value between 0 and (upper_bound-1)."]
    pub fn rte_rand_max(upper_bound: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Generates a pseudo-random floating point number.\nThis function returns a non-negative double-precision floating random\nnumber uniformly distributed over the interval [0.0, 1.0).\nThe generator is not cryptographically secure.\nrte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\nwith the exception that they may not be called by multiple\n_unregistered_ non-EAL threads in parallel.\n\n# Returns\n\nA pseudo-random value between 0 and 1.0."]
    pub fn rte_drand() -> f64;
}
#[doc = "POSIX.1b structure for a time value.  This is like a `struct timeval' but\nhas nanoseconds instead of microseconds."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct timespec {
    #[doc = "Seconds."]
    pub tv_sec: __time_t,
    #[doc = "Nanoseconds."]
    pub tv_nsec: __syscall_slong_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of timespec"][::core::mem::size_of::<timespec>() - 16usize];
    ["Alignment of timespec"][::core::mem::align_of::<timespec>() - 8usize];
    ["Offset of field: timespec::tv_sec"][::core::mem::offset_of!(timespec, tv_sec) - 0usize];
    ["Offset of field: timespec::tv_nsec"][::core::mem::offset_of!(timespec, tv_nsec) - 8usize];
};
unsafe extern "C" {
    #[doc = "Checks if a pointer is aligned to a given power-of-two value\n\n# Arguments\n\n* `ptr` -\nThe pointer whose alignment is to be checked\n* `align` -\nThe power-of-two value to which the ptr should be aligned\n\n# Returns\n\nTrue(1) where the pointer is correctly aligned, false(0) otherwise"]
    #[link_name = "rte_is_aligned_w"]
    pub fn rte_is_aligned(
        ptr: *const ::core::ffi::c_void,
        align: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
#[doc = "Physical address"]
pub type phys_addr_t = u64;
#[doc = "IO virtual address type.\nWhen the physical addressing mode (IOVA as PA) is in use,\nthe translation from an IO virtual address (IOVA) to a physical address\nis a direct mapping, i.e. the same value.\nOtherwise, in virtual mode (IOVA as VA), an IOMMU may do the translation."]
pub type rte_iova_t = u64;
#[doc = "Generic marker for any place in a structure."]
pub type RTE_MARKER = [*mut ::core::ffi::c_void; 0usize];
#[doc = "Marker for 1B alignment in a structure."]
pub type RTE_MARKER8 = [u8; 0usize];
#[doc = "Marker for 2B alignment in a structure."]
pub type RTE_MARKER16 = [u16; 0usize];
#[doc = "Marker for 4B alignment in a structure."]
pub type RTE_MARKER32 = [u32; 0usize];
#[doc = "Marker for 8B alignment in a structure."]
pub type RTE_MARKER64 = [u64; 0usize];
unsafe extern "C" {
    #[doc = "Converts a numeric string to the equivalent uint64_t value.\nAs well as straight number conversion, also recognises the suffixes\nk, m and g for kilobytes, megabytes and gigabytes respectively.\nIf a negative number is passed in  i.e. a string with the first non-black\ncharacter being \"-\", zero is returned. Zero is also returned in the case of\nan error with the strtoull call in the function.\n\n# Arguments\n\n* `str` -\nString containing number to convert.\n\n# Returns\n\nNumber."]
    pub fn rte_str_to_size(str_: *const ::core::ffi::c_char) -> u64;
}
unsafe extern "C" {
    #[doc = "Function to terminate the application immediately, printing an error\nmessage and returning the exit_code back to the shell.\nThis function never returns\n\n# Arguments\n\n* `exit_code` -\nThe exit code to be returned by the application\n* `format` -\nThe format string to be used for printing the message. This can include\nprintf format characters which will be expanded using any further parameters\nto the function."]
    pub fn rte_exit(exit_code: ::core::ffi::c_int, format: *const ::core::ffi::c_char, ...) -> !;
}
#[doc = "Struct describing a Universal Unique Identifier"]
pub type rte_uuid_t = [::core::ffi::c_uchar; 16usize];
unsafe extern "C" {
    #[doc = "Test if UUID is all zeros.\n\n# Arguments\n\n* `uu` -\nThe uuid to check.\n\n# Returns\n\ntrue if uuid is NULL value, false otherwise"]
    pub fn rte_uuid_is_null(uu: *const ::core::ffi::c_uchar) -> bool;
}
unsafe extern "C" {
    #[doc = "Copy uuid.\n\n# Arguments\n\n* `dst` -\nDestination uuid\n* `src` -\nSource uuid"]
    #[link_name = "rte_uuid_copy_w"]
    pub fn rte_uuid_copy(dst: *mut ::core::ffi::c_uchar, src: *const ::core::ffi::c_uchar);
}
unsafe extern "C" {
    #[doc = "Compare two UUID's\n\n# Arguments\n\n* `a` -\nA UUID to compare\n* `b` -\nA UUID to compare\n\n# Returns\n\nreturns an integer less than, equal to, or greater than zero if UUID a is\nis less than, equal, or greater than UUID b."]
    pub fn rte_uuid_compare(
        a: *const ::core::ffi::c_uchar,
        b: *const ::core::ffi::c_uchar,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Extract UUID from string\n\n# Arguments\n\n* `in` -\nPointer to string of characters to convert\n* `uu` -\nDestination UUID\n\n# Returns\n\nReturns 0 on success, and -1 if string is not a valid UUID."]
    pub fn rte_uuid_parse(
        in_: *const ::core::ffi::c_char,
        uu: *mut ::core::ffi::c_uchar,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Convert UUID to string\n\n# Arguments\n\n* `uu` -\nUUID to format\n* `out` -\nResulting string buffer\n* `len` -\nSizeof the available string buffer"]
    pub fn rte_uuid_unparse(
        uu: *const ::core::ffi::c_uchar,
        out: *mut ::core::ffi::c_char,
        len: usize,
    );
}
pub mod rte_intr_mode {
    #[doc = "interrupt mode"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_INTR_MODE_NONE: Type = 0;
    pub const RTE_INTR_MODE_LEGACY: Type = 1;
    pub const RTE_INTR_MODE_MSI: Type = 2;
    pub const RTE_INTR_MODE_MSIX: Type = 3;
}
pub mod rte_proc_type_t {
    #[doc = "The type of process in a linux, multi-process setup"]
    pub type Type = ::core::ffi::c_int;
    #[doc = "allow auto-detection of primary/secondary"]
    pub const RTE_PROC_AUTO: Type = -1;
    #[doc = "set to zero, so primary is the default"]
    pub const RTE_PROC_PRIMARY: Type = 0;
    pub const RTE_PROC_SECONDARY: Type = 1;
    pub const RTE_PROC_INVALID: Type = 2;
}
unsafe extern "C" {
    #[doc = "Get the process type in a multi-process setup\n\n# Returns\n\nThe process type"]
    pub fn rte_eal_process_type() -> rte_proc_type_t::Type;
}
unsafe extern "C" {
    #[doc = "Request iopl privilege for all RPL.\nThis function should be called by pmds which need access to ioports.\n\n# Returns\n\n- On success, returns 0.\n- On failure, returns -1."]
    pub fn rte_eal_iopl_init() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize the Environment Abstraction Layer (EAL).\nThis function is to be executed on the MAIN lcore only, as soon\nas possible in the application's main() function.\nIt puts the WORKER lcores in the WAIT state.\n\n# Arguments\n\n* `argc` -\nA non-negative value.  If it is greater than 0, the array members\nfor argv[0] through argv[argc] (non-inclusive) shall contain pointers\nto strings.\n* `argv` -\nAn array of strings.  The contents of the array, as well as the strings\nwhich are pointed to by the array, may be modified by this function.\nThe program name pointer argv[0] is copied into the last parsed argv\nso that argv[0] is still the same after deducing the parsed arguments.\n\n# Returns\n\n- On success, the number of parsed arguments, which is greater or\nequal to zero. After the call to rte_eal_init(),\nall arguments argv[x] with x < ret may have been modified by this\nfunction call and should not be further interpreted by the\napplication.  The EAL does not take any ownership of the memory used\nfor either the argv array, or its members.\n- On failure, -1 and rte_errno is set to a value indicating the cause\nfor failure.  In some instances, the application will need to be\nrestarted as part of clearing the issue.\nError codes returned via rte_errno:\nEACCES indicates a permissions issue.\nEAGAIN indicates either a bus or system resource was not available,\nsetup may be attempted again.\nEALREADY indicates that the rte_eal_init function has already been\ncalled, and cannot be called again.\nEFAULT indicates the tailq configuration name was not found in\nmemory configuration.\nEINVAL indicates invalid parameters were passed as argv/argc.\nENOMEM indicates failure likely caused by an out-of-memory condition.\nENODEV indicates memory setup issues.\nENOTSUP indicates that the EAL cannot initialize on this system.\nEPROTO indicates that the PCI bus is either not present, or is not\nreadable by the eal.\nENOEXEC indicates that a service core failed to launch successfully."]
    pub fn rte_eal_init(
        argc: ::core::ffi::c_int,
        argv: *mut *mut ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Clean up the Environment Abstraction Layer (EAL)\nThis function must be called to release any internal resources that EAL has\nallocated during rte_eal_init(). After this call, no DPDK function calls may\nbe made. It is expected that common usage of this function is to call it\njust before terminating the process.\n\n# Returns\n\n- 0 Successfully released all internal EAL resources.\n- -EFAULT There was an error in releasing all resources."]
    pub fn rte_eal_cleanup() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if a primary process is currently alive\nThis function returns true when a primary process is currently\nactive.\n\n# Arguments\n\n* `config_file_path` -\nThe config_file_path argument provided should point at the location\nthat the primary process will create its config file. If NULL, the default\nconfig file path is used.\n\n# Returns\n\n- If alive, returns 1.\n- If dead, returns 0."]
    pub fn rte_eal_primary_proc_alive(
        config_file_path: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable multiprocess.\nThis function can be called to indicate that multiprocess won't be used for\nthe rest of the application life.\n\n# Returns\n\n- true if called from a primary process that had no secondary processes\nattached,\n- false, otherwise."]
    pub fn rte_mp_disable() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_msg {
    pub name: [::core::ffi::c_char; 64usize],
    pub len_param: ::core::ffi::c_int,
    pub num_fds: ::core::ffi::c_int,
    pub param: [u8; 256usize],
    pub fds: [::core::ffi::c_int; 253usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mp_msg"][::core::mem::size_of::<rte_mp_msg>() - 1340usize];
    ["Alignment of rte_mp_msg"][::core::mem::align_of::<rte_mp_msg>() - 4usize];
    ["Offset of field: rte_mp_msg::name"][::core::mem::offset_of!(rte_mp_msg, name) - 0usize];
    ["Offset of field: rte_mp_msg::len_param"]
        [::core::mem::offset_of!(rte_mp_msg, len_param) - 64usize];
    ["Offset of field: rte_mp_msg::num_fds"]
        [::core::mem::offset_of!(rte_mp_msg, num_fds) - 68usize];
    ["Offset of field: rte_mp_msg::param"][::core::mem::offset_of!(rte_mp_msg, param) - 72usize];
    ["Offset of field: rte_mp_msg::fds"][::core::mem::offset_of!(rte_mp_msg, fds) - 328usize];
};
impl Default for rte_mp_msg {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_reply {
    pub nb_sent: ::core::ffi::c_int,
    pub nb_received: ::core::ffi::c_int,
    #[doc = "caller to free"]
    pub msgs: *mut rte_mp_msg,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mp_reply"][::core::mem::size_of::<rte_mp_reply>() - 16usize];
    ["Alignment of rte_mp_reply"][::core::mem::align_of::<rte_mp_reply>() - 8usize];
    ["Offset of field: rte_mp_reply::nb_sent"]
        [::core::mem::offset_of!(rte_mp_reply, nb_sent) - 0usize];
    ["Offset of field: rte_mp_reply::nb_received"]
        [::core::mem::offset_of!(rte_mp_reply, nb_received) - 4usize];
    ["Offset of field: rte_mp_reply::msgs"][::core::mem::offset_of!(rte_mp_reply, msgs) - 8usize];
};
impl Default for rte_mp_reply {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Action function typedef used by other components.\nAs we create  socket channel for primary/secondary communication, use\nthis function typedef to register action for coming messages.\n> **Note** When handling IPC request callbacks, the reply must be sent even in\ncases of error handling. Simply returning success or failure will *not*\nsend a response to the requestor.\nImplementation of error signalling mechanism is up to the application.\n> **Note** No memory allocations should take place inside the callback."]
pub type rte_mp_t = ::core::option::Option<
    unsafe extern "C" fn(
        msg: *const rte_mp_msg,
        peer: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Asynchronous reply function typedef used by other components.\nAs we create socket channel for primary/secondary communication, use\nthis function typedef to register action for coming responses to asynchronous\nrequests.\n> **Note** When handling IPC request callbacks, the reply must be sent even in\ncases of error handling. Simply returning success or failure will *not*\nsend a response to the requestor.\nImplementation of error signalling mechanism is up to the application.\n> **Note** No memory allocations should take place inside the callback."]
pub type rte_mp_async_reply_t = ::core::option::Option<
    unsafe extern "C" fn(
        request: *const rte_mp_msg,
        reply: *const rte_mp_reply,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Register an action function for primary/secondary communication.\nCall this function to register an action, if the calling component wants\nto response the messages from the corresponding component in its primary\nprocess or secondary processes.\n> **Note** IPC may be unsupported in certain circumstances, so caller should check\nfor ENOTSUP error.\n\n# Arguments\n\n* `name` -\nThe name argument plays as the nonredundant key to find the action.\n* `action` -\nThe action argument is the function pointer to the action function.\n\n# Returns\n\n- 0 on success.\n- (<0) on failure."]
    pub fn rte_mp_action_register(
        name: *const ::core::ffi::c_char,
        action: rte_mp_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister an action function for primary/secondary communication.\nCall this function to unregister an action  if the calling component does\nnot want to response the messages from the corresponding component in its\nprimary process or secondary processes.\n> **Note** IPC may be unsupported in certain circumstances, so caller should check\nfor ENOTSUP error.\n\n# Arguments\n\n* `name` -\nThe name argument plays as the nonredundant key to find the action."]
    pub fn rte_mp_action_unregister(name: *const ::core::ffi::c_char);
}
unsafe extern "C" {
    #[doc = "Send a message to the peer process.\nThis function will send a message which will be responded by the action\nidentified by name in the peer process.\n\n# Arguments\n\n* `msg` -\nThe msg argument contains the customized message.\n\n# Returns\n\n- On success, return 0.\n- On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_sendmsg(msg: *mut rte_mp_msg) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Send a request to the peer process and expect a reply.\nThis function sends a request message to the peer process, and will\nblock until receiving reply message from the peer process.\n> **Note** The caller is responsible to free reply->replies.\n> **Note** This API must not be used inside memory-related or IPC callbacks, and\nno memory allocations should take place inside such callback.\n> **Note** IPC may be unsupported in certain circumstances, so caller should check\nfor ENOTSUP error.\n\n# Arguments\n\n* `req` -\nThe req argument contains the customized request message.\n* `reply` -\nThe reply argument will be for storing all the replied messages;\nthe caller is responsible for free reply->msgs.\n* `ts` -\nThe ts argument specifies how long we can wait for the peer(s) to reply.\n\n# Returns\n\n- On success, return 0.\n- On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_sync(
        req: *mut rte_mp_msg,
        reply: *mut rte_mp_reply,
        ts: *const timespec,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Send a request to the peer process and expect a reply in a separate callback.\nThis function sends a request message to the peer process, and will not\nblock. Instead, reply will be received in a separate callback.\n> **Note** IPC may be unsupported in certain circumstances, so caller should check\nfor ENOTSUP error.\n\n# Arguments\n\n* `req` -\nThe req argument contains the customized request message.\n* `ts` -\nThe ts argument specifies how long we can wait for the peer(s) to reply.\n* `clb` -\nThe callback to trigger when all responses for this request have arrived.\n\n# Returns\n\n- On success, return 0.\n- On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_async(
        req: *mut rte_mp_msg,
        ts: *const timespec,
        clb: rte_mp_async_reply_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Send a reply to the peer process.\nThis function will send a reply message in response to a request message\nreceived previously.\n> **Note** When handling IPC request callbacks, the reply must be sent even in\ncases of error handling. Simply returning success or failure will *not*\nsend a response to the requestor.\nImplementation of error signalling mechanism is up to the application.\n\n# Arguments\n\n* `msg` -\nThe msg argument contains the customized message.\n* `peer` -\nThe peer argument is the pointer to the peer socket path.\n\n# Returns\n\n- On success, return 0.\n- On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_reply(
        msg: *mut rte_mp_msg,
        peer: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
#[doc = "Usage function typedef used by the application usage function.\nUse this function typedef to define and call rte_set_application_usage_hook()\nroutine."]
pub type rte_usage_hook_t =
    ::core::option::Option<unsafe extern "C" fn(prgname: *const ::core::ffi::c_char)>;
unsafe extern "C" {
    #[doc = "Add application usage routine callout from the eal_usage() routine.\nThis function allows the application to include its usage message\nin the EAL system usage message. The routine rte_set_application_usage_hook()\nneeds to be called before the rte_eal_init() routine in the application.\nThis routine is optional for the application and will behave as if the set\nroutine was never called as the default behavior.\n\n# Arguments\n\n* `usage_func` -\nThe func argument is a function pointer to the application usage routine.\nCalled function is defined using rte_usage_hook_t typedef, which is of\nthe form void rte_usage_func(const char * prgname).\nCalling this routine with a NULL value will reset the usage hook routine and\nreturn the current value, which could be NULL.\n\n# Returns\n\n- Returns the current value of the rte_application_usage pointer to allow\nthe caller to daisy chain the usage routines if needing more then one."]
    pub fn rte_set_application_usage_hook(usage_func: rte_usage_hook_t) -> rte_usage_hook_t;
}
unsafe extern "C" {
    #[doc = "Whether EAL is using huge pages (disabled by --no-huge option).\nThe no-huge mode is not compatible with all drivers or features.\n\n# Returns\n\nNonzero if hugepages are enabled."]
    pub fn rte_eal_has_hugepages() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Whether EAL is using PCI bus.\nDisabled by --no-pci option.\n\n# Returns\n\nNonzero if the PCI bus is enabled."]
    pub fn rte_eal_has_pci() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Whether the EAL was asked to create UIO device.\n\n# Returns\n\nNonzero if true."]
    pub fn rte_eal_create_uio_dev() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "The user-configured vfio interrupt mode.\n\n# Returns\n\nInterrupt mode configured with the command line,\nRTE_INTR_MODE_NONE by default."]
    pub fn rte_eal_vfio_intr_mode() -> rte_intr_mode::Type;
}
unsafe extern "C" {
    #[doc = "Copy the user-configured vfio VF token.\n\n# Arguments\n\n* `vf_token` -\nvfio VF token configured with the command line is copied\ninto this parameter, zero uuid by default."]
    pub fn rte_eal_vfio_get_vf_token(vf_token: *mut ::core::ffi::c_uchar);
}
unsafe extern "C" {
    #[doc = "A wrap API for syscall gettid.\n\n# Returns\n\nOn success, returns the thread ID of calling process.\nIt is always successful."]
    pub fn rte_sys_gettid() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get system unique thread id.\n\n# Returns\n\nOn success, returns the thread ID of calling process.\nIt is always successful."]
    #[link_name = "rte_gettid_w"]
    pub fn rte_gettid() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the OS-specific EAL base address.\n\n# Returns\n\nThe base address."]
    pub fn rte_eal_get_baseaddr() -> u64;
}
pub mod rte_iova_mode {
    #[doc = "IOVA mapping mode.\nIOVA mapping mode is iommu programming mode of a device.\nThat device (for example: IOMMU backed DMA device) based\non rte_iova_mode will generate physical or virtual address."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Don't care mode"]
    pub const RTE_IOVA_DC: Type = 0;
    #[doc = "DMA using physical address"]
    pub const RTE_IOVA_PA: Type = 1;
    #[doc = "DMA using virtual address"]
    pub const RTE_IOVA_VA: Type = 2;
}
unsafe extern "C" {
    #[doc = "Get the iova mode\n\n# Returns\n\nenum rte_iova_mode value."]
    pub fn rte_eal_iova_mode() -> rte_iova_mode::Type;
}
unsafe extern "C" {
    #[doc = "Get user provided pool ops name for mbuf\n\n# Returns\n\nreturns user provided pool ops name."]
    pub fn rte_eal_mbuf_user_pool_ops() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the runtime directory of DPDK\n\n# Returns\n\nThe runtime directory path of DPDK"]
    pub fn rte_eal_get_runtime_dir() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Convert a string describing a mask of core ids into an array of core ids.\nOn success, the passed array is filled with the orders of the core ids\npresent in the mask (-1 indicating that a core id is absent).\nFor example, passing a 0xa coremask results in cores[1] = 0, cores[3] = 1,\nand the rest of the array is set to -1.\n\n# Arguments\n\n* `coremask` -\nA string describing a mask of core ids.\n* `cores` -\nAn array where to store the core ids orders.\nThis array must be at least RTE_MAX_LCORE large.\n\n# Returns\n\n0 on success, -1 if the string content was invalid."]
    pub fn rte_eal_parse_coremask(
        coremask: *const ::core::ffi::c_char,
        cores: *mut ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
pub mod rte_lcore_state_t {
    #[doc = "State of an lcore."]
    pub type Type = ::core::ffi::c_uint;
    pub const WAIT: Type = 0;
    pub const RUNNING: Type = 1;
}
#[doc = "Definition of a remote launch function."]
pub type lcore_function_t = ::core::option::Option<
    unsafe extern "C" fn(arg1: *mut ::core::ffi::c_void) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Launch a function on another lcore.\nTo be executed on the MAIN lcore only.\nSends a message to a worker lcore (identified by the worker_id) that\nis in the WAIT state (this is true after the first call to\nrte_eal_init()). This can be checked by first calling\nrte_eal_wait_lcore(worker_id).\nWhen the remote lcore receives the message, it switches to\nthe RUNNING state, then calls the function f with argument arg. Once the\nexecution is done, the remote lcore switches to WAIT state and\nthe return value of f is stored in a local variable to be read using\nrte_eal_wait_lcore().\nThe MAIN lcore returns as soon as the message is sent and knows\nnothing about the completion of f.\nNote: This function is not designed to offer optimum\nperformance. It is just a practical way to launch a function on\nanother lcore at initialization time.\n\n# Arguments\n\n* `f` -\nThe function to be called.\n* `arg` -\nThe argument for the function.\n* `worker_id` -\nThe identifier of the lcore on which the function should be executed.\n\n# Returns\n\n- 0: Success. Execution of function f started on the remote lcore.\n- (-EBUSY): The remote lcore is not in a WAIT state.\n- (-EPIPE): Error reading or writing pipe to worker thread"]
    pub fn rte_eal_remote_launch(
        f: lcore_function_t,
        arg: *mut ::core::ffi::c_void,
        worker_id: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
pub mod rte_rmt_call_main_t {
    #[doc = "This enum indicates whether the main core must execute the handler\nlaunched on all logical cores."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< lcore handler not executed by main core."]
    pub const SKIP_MAIN: Type = 0;
    #[doc = "< lcore handler executed by main core."]
    pub const CALL_MAIN: Type = 1;
}
unsafe extern "C" {
    #[doc = "Launch a function on all lcores.\nCheck that each WORKER lcore is in a WAIT state, then call\nrte_eal_remote_launch() for each lcore.\n\n# Arguments\n\n* `f` -\nThe function to be called.\n* `arg` -\nThe argument for the function.\n* `call_main` -\nIf call_main set to SKIP_MAIN, the MAIN lcore does not call\nthe function. If call_main is set to CALL_MAIN, the function\nis also called on main before returning. In any case, the main\nlcore returns as soon as it finished its job and knows nothing\nabout the completion of f on the other lcores.\n\n# Returns\n\n- 0: Success. Execution of function f started on all remote lcores.\n- (-EBUSY): At least one remote lcore is not in a WAIT state. In this\ncase, no message is sent to any of the lcores."]
    pub fn rte_eal_mp_remote_launch(
        f: lcore_function_t,
        arg: *mut ::core::ffi::c_void,
        call_main: rte_rmt_call_main_t::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the state of the lcore identified by worker_id.\nTo be executed on the MAIN lcore only.\n\n# Arguments\n\n* `worker_id` -\nThe identifier of the lcore.\n\n# Returns\n\nThe state of the lcore."]
    pub fn rte_eal_get_lcore_state(worker_id: ::core::ffi::c_uint) -> rte_lcore_state_t::Type;
}
unsafe extern "C" {
    #[doc = "Wait until an lcore finishes its job.\nTo be executed on the MAIN lcore only.\nIf the lcore identified by the worker_id is in RUNNING state, wait until\nthe lcore finishes its job and moves to the WAIT state.\n\n# Arguments\n\n* `worker_id` -\nThe identifier of the lcore.\n\n# Returns\n\n- 0: If the remote launch function was never called on the lcore\nidentified by the worker_id.\n- The value that was returned by the previous remote launch\nfunction call."]
    pub fn rte_eal_wait_lcore(worker_id: ::core::ffi::c_uint) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Wait until all lcores finish their jobs.\nTo be executed on the MAIN lcore only. Issue an\nrte_eal_wait_lcore() for every lcore. The return values are\nignored.\nAfter a call to rte_eal_mp_wait_lcore(), the caller can assume\nthat all worker lcores are in a WAIT state."]
    pub fn rte_eal_mp_wait_lcore();
}
#[doc = "Thread id descriptor."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_thread_t {
    #[doc = "< thread identifier"]
    pub opaque_id: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_thread_t"][::core::mem::size_of::<rte_thread_t>() - 8usize];
    ["Alignment of rte_thread_t"][::core::mem::align_of::<rte_thread_t>() - 8usize];
    ["Offset of field: rte_thread_t::opaque_id"]
        [::core::mem::offset_of!(rte_thread_t, opaque_id) - 0usize];
};
#[doc = "Thread function\nFunction pointer to thread start routine.\n\n# Arguments\n\n* `arg` -\nArgument passed to rte_thread_create().\n\n# Returns\n\nThread function exit value."]
pub type rte_thread_func =
    ::core::option::Option<unsafe extern "C" fn(arg: *mut ::core::ffi::c_void) -> u32>;
pub mod rte_thread_priority {
    #[doc = "Thread priority values."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_THREAD_PRIORITY_NORMAL: Type = 0;
    pub const RTE_THREAD_PRIORITY_REALTIME_CRITICAL: Type = 1;
}
#[doc = "Representation for thread attributes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thread_attr_t {
    #[doc = "< thread priority"]
    pub priority: rte_thread_priority::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_thread_attr_t"][::core::mem::size_of::<rte_thread_attr_t>() - 4usize];
    ["Alignment of rte_thread_attr_t"][::core::mem::align_of::<rte_thread_attr_t>() - 4usize];
    ["Offset of field: rte_thread_attr_t::priority"]
        [::core::mem::offset_of!(rte_thread_attr_t, priority) - 0usize];
};
impl Default for rte_thread_attr_t {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct eal_tls_key {
    _unused: [u8; 0],
}
#[doc = "TLS key type, an opaque pointer."]
pub type rte_thread_key = *mut eal_tls_key;
unsafe extern "C" {
    #[doc = "Create a new thread that will invoke the 'thread_func' routine.\n\n# Arguments\n\n* `thread_id` -\nA pointer that will store the id of the newly created thread.\n* `thread_attr` -\nAttributes that are used at the creation of the new thread.\n* `thread_func` -\nThe routine that the new thread will invoke when starting execution.\n* `arg` -\nArgument to be passed to the 'thread_func' routine.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_create(
        thread_id: *mut rte_thread_t,
        thread_attr: *const rte_thread_attr_t,
        thread_func: rte_thread_func,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a control thread.\nCreates a control thread with the given name and attributes. The\naffinity of the new thread is based on the CPU affinity retrieved\nat the time rte_eal_init() was called, the EAL threads are then\nexcluded. If setting the name of the thread fails, the error is\nignored and a debug message is logged.\n\n# Arguments\n\n* `thread` -\nFilled with the thread id of the new created thread.\n* `name` -\nThe name of the control thread\n(max RTE_THREAD_NAME_SIZE characters including '\\0'). * `thread_func` -\nFunction to be executed by the new thread.\n* `arg` -\nArgument passed to thread_func.\n\n# Returns\n\nOn success, returns 0; on error, it returns a negative value\ncorresponding to the error number."]
    pub fn rte_thread_create_control(
        thread: *mut rte_thread_t,
        name: *const ::core::ffi::c_char,
        thread_func: rte_thread_func,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create an internal control thread.\nCreates a control thread with the given name prefixed.\nIf setting the name of the thread fails, the error is ignored and logged.\nThe affinity of the new thread is based on the CPU affinity retrieved\nat the time rte_eal_init() was called, the EAL threads are then excluded.\n\n# Arguments\n\n* `id` -\nFilled with the thread ID of the new created thread.\n* `name` -\nThe name of the control thread.\nSee RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\nThe name of the driver or library should be first,\nthen followed by a hyphen and more details.\nIt will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function.\n* `func` -\nFunction to be executed by the new thread.\n* `arg` -\nArgument passed to func.\n\n# Returns\n\nOn success, returns 0; a negative value otherwise."]
    pub fn rte_thread_create_internal_control(
        id: *mut rte_thread_t,
        name: *const ::core::ffi::c_char,
        func: rte_thread_func,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Waits for the thread identified by 'thread_id' to terminate\n\n# Arguments\n\n* `thread_id` -\nThe identifier of the thread.\n* `value_ptr` -\nStores the exit status of the thread.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_join(thread_id: rte_thread_t, value_ptr: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Indicate that the return value of the thread is not needed and\nall thread resources should be release when the thread terminates.\n\n# Arguments\n\n* `thread_id` -\nThe id of the thread to be detached.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_detach(thread_id: rte_thread_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the id of the calling thread.\n\n# Returns\n\nReturn the thread id of the calling thread."]
    pub fn rte_thread_self() -> rte_thread_t;
}
unsafe extern "C" {
    #[doc = "Set the name of the thread.\nThis API is a noop if the underlying platform does not\nsupport setting the thread name or the platform-specific\nAPI used to set the thread name fails.\n\n# Arguments\n\n* `thread_id` -\nThe id of the thread to set name.\n* `thread_name` -\nThe name to set. Truncated to RTE_THREAD_NAME_SIZE,\nincluding terminating NUL if necessary."]
    pub fn rte_thread_set_name(thread_id: rte_thread_t, thread_name: *const ::core::ffi::c_char);
}
unsafe extern "C" {
    #[doc = "Set the name of an internal thread with the common prefix.\nThis API is a noop if the underlying platform does not support\nsetting the thread name, or if it fails.\n\n# Arguments\n\n* `id` -\nThe ID of the thread to set name.\n* `name` -\nThe name to set after being prefixed.\nSee RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\nThe name of the driver or library should be first,\nthen followed by a hyphen and more details.\nIt will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function."]
    pub fn rte_thread_set_prefixed_name(id: rte_thread_t, name: *const ::core::ffi::c_char);
}
unsafe extern "C" {
    #[doc = "Check if 2 thread ids are equal.\n\n# Arguments\n\n* `t1` -\nFirst thread id.\n* `t2` -\nSecond thread id.\n\n# Returns\n\nIf the ids are equal, return nonzero.\nOtherwise, return 0."]
    pub fn rte_thread_equal(t1: rte_thread_t, t2: rte_thread_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize the attributes of a thread.\nThese attributes can be passed to the rte_thread_create() function\nthat will create a new thread and set its attributes according to attr.\n\n# Arguments\n\n* `attr` -\nThread attributes to initialize.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_init(attr: *mut rte_thread_attr_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the thread priority value in the thread attributes pointed to\nby 'thread_attr'.\n\n# Arguments\n\n* `thread_attr` -\nPoints to the thread attributes in which priority will be updated.\n* `priority` -\nPoints to the value of the priority to be set.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_set_priority(
        thread_attr: *mut rte_thread_attr_t,
        priority: rte_thread_priority::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the priority of a thread.\n\n# Arguments\n\n* `thread_id` -\nId of the thread for which to get priority.\n* `priority` -\nLocation to store the retrieved priority.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_get_priority(
        thread_id: rte_thread_t,
        priority: *mut rte_thread_priority::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the priority of a thread.\n\n# Arguments\n\n* `thread_id` -\nId of the thread for which to set priority.\n* `priority` -\nPriority value to be set.\n\n# Returns\n\nOn success, return 0.\nOn failure, return a positive errno-style error number."]
    pub fn rte_thread_set_priority(
        thread_id: rte_thread_t,
        priority: rte_thread_priority::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a TLS data key visible to all threads in the process.\nthe created key is later used to get/set a value.\nand optional destructor can be set to be called when a thread exits.\n\n# Arguments\n\n* `key` -\nPointer to store the allocated key.\n* `destructor` -\nThe function to be called when the thread exits.\nIgnored on Windows OS.\n\n# Returns\n\nOn success, zero.\nOn failure, a negative number and an error number is set in rte_errno.\nrte_errno can be: ENOMEM  - Memory allocation error.\nENOEXEC - Specific OS error."]
    pub fn rte_thread_key_create(
        key: *mut rte_thread_key,
        destructor: ::core::option::Option<unsafe extern "C" fn(arg1: *mut ::core::ffi::c_void)>,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Delete a TLS data key visible to all threads in the process.\n\n# Arguments\n\n* `key` -\nThe key allocated by rte_thread_key_create().\n\n# Returns\n\nOn success, zero.\nOn failure, a negative number and an error number is set in rte_errno.\nrte_errno can be: EINVAL  - Invalid parameter passed.\nENOEXEC - Specific OS error."]
    pub fn rte_thread_key_delete(key: rte_thread_key) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set value bound to the TLS key on behalf of the calling thread.\n\n# Arguments\n\n* `key` -\nThe key allocated by rte_thread_key_create().\n* `value` -\nThe value bound to the rte_thread_key key for the calling thread.\n\n# Returns\n\nOn success, zero.\nOn failure, a negative number and an error number is set in rte_errno.\nrte_errno can be: EINVAL  - Invalid parameter passed.\nENOEXEC - Specific OS error."]
    pub fn rte_thread_value_set(
        key: rte_thread_key,
        value: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get value bound to the TLS key on behalf of the calling thread.\n\n# Arguments\n\n* `key` -\nThe key allocated by rte_thread_key_create().\n\n# Returns\n\nOn success, value data pointer (can also be NULL).\nOn failure, NULL and an error number is set in rte_errno.\nrte_errno can be: EINVAL  - Invalid parameter passed.\nENOEXEC - Specific OS error."]
    pub fn rte_thread_value_get(key: rte_thread_key) -> *mut ::core::ffi::c_void;
}
pub mod rte_lcore_role_t {
    #[doc = "The lcore role (used in RTE or not)."]
    pub type Type = ::core::ffi::c_uint;
    pub const ROLE_RTE: Type = 0;
    pub const ROLE_OFF: Type = 1;
    pub const ROLE_SERVICE: Type = 2;
    pub const ROLE_NON_EAL: Type = 3;
}
unsafe extern "C" {
    #[doc = "Get a lcore's role.\n\n# Arguments\n\n* `lcore_id` -\nThe identifier of the lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n\n# Returns\n\nThe role of the lcore."]
    pub fn rte_eal_lcore_role(lcore_id: ::core::ffi::c_uint) -> rte_lcore_role_t::Type;
}
unsafe extern "C" {
    #[doc = "Test if the core supplied has a specific role\n\n# Arguments\n\n* `lcore_id` -\nThe identifier of the lcore, which MUST be between 0 and\nRTE_MAX_LCORE-1.\n* `role` -\nThe role to be checked against.\n\n# Returns\n\nBoolean value: positive if test is true; otherwise returns 0."]
    pub fn rte_lcore_has_role(
        lcore_id: ::core::ffi::c_uint,
        role: rte_lcore_role_t::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the Application thread ID of the execution unit.\nNote: in most cases the lcore id returned here will also correspond\nto the processor id of the CPU on which the thread is pinned, this\nwill not be the case if the user has explicitly changed the thread to\ncore affinities using --lcores EAL argument e.g. --lcores '(0-3)@10' to run threads with lcore IDs 0, 1, 2 and 3 on physical core 10..\n\n# Returns\n\nLogical core ID (in EAL thread or registered non-EAL thread) or\nLCORE_ID_ANY (in unregistered non-EAL thread)"]
    #[link_name = "rte_lcore_id_w"]
    pub fn rte_lcore_id() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the id of the main lcore\n\n# Returns\n\nthe id of the main lcore"]
    pub fn rte_get_main_lcore() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of execution units (lcores) on the system.\n\n# Returns\n\nthe number of execution units (lcores) on the system."]
    pub fn rte_lcore_count() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the index of the lcore starting from zero.\nWhen option -c or -l is given, the index corresponds\nto the order in the list.\nFor example:\n-c 0x30, lcore 4 has index 0, and 5 has index 1.\n-l 22,18 lcore 22 has index 0, and 18 has index 1.\n\n# Arguments\n\n* `lcore_id` -\nThe targeted lcore, or -1 for the current one.\n\n# Returns\n\nThe relative index, or -1 if not enabled."]
    pub fn rte_lcore_index(lcore_id: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the ID of the physical socket of the logical core we are\nrunning on.\n\n# Returns\n\nthe ID of current lcoreid's physical socket"]
    pub fn rte_socket_id() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return number of physical sockets detected on the system.\nNote that number of nodes may not be correspondent to their physical id's:\nfor example, a system may report two socket id's, but the actual socket id's\nmay be 0 and 8.\n\n# Returns\n\nthe number of physical sockets as recognized by EAL"]
    pub fn rte_socket_count() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return socket id with a particular index.\nThis will return socket id at a particular position in list of all detected\nphysical socket id's. For example, on a machine with sockets [0, 8], passing\n1 as a parameter will return 8.\n\n# Arguments\n\n* `idx` -\nindex of physical socket id to return\n\n# Returns\n\n- physical socket id as recognized by EAL\n- -1 on error, with errno set to EINVAL"]
    pub fn rte_socket_id_by_idx(idx: ::core::ffi::c_uint) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the ID of the physical socket of the specified lcore\n\n# Arguments\n\n* `lcore_id` -\nthe targeted lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n\n# Returns\n\nthe ID of lcoreid's physical socket"]
    pub fn rte_lcore_to_socket_id(lcore_id: ::core::ffi::c_uint) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the id of the lcore on a socket starting from zero.\n\n# Arguments\n\n* `lcore_id` -\nThe targeted lcore, or -1 for the current one.\n\n# Returns\n\nThe relative index, or -1 if not enabled."]
    pub fn rte_lcore_to_cpu_id(lcore_id: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if an lcore is enabled.\n\n# Arguments\n\n* `lcore_id` -\nThe identifier of the lcore, which MUST be between 0 and\nRTE_MAX_LCORE-1.\n\n# Returns\n\nTrue if the given lcore is enabled; false otherwise."]
    pub fn rte_lcore_is_enabled(lcore_id: ::core::ffi::c_uint) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the next enabled lcore ID.\n\n# Arguments\n\n* `i` -\nThe current lcore (reference).\n* `skip_main` -\nIf true, do not return the ID of the main lcore.\n* `wrap` -\nIf true, go back to 0 when RTE_MAX_LCORE is reached; otherwise,\nreturn RTE_MAX_LCORE.\n\n# Returns\n\nThe next lcore_id or RTE_MAX_LCORE if not found."]
    pub fn rte_get_next_lcore(
        i: ::core::ffi::c_uint,
        skip_main: ::core::ffi::c_int,
        wrap: ::core::ffi::c_int,
    ) -> ::core::ffi::c_uint;
}
#[doc = "Callback prototype for initializing lcores.\n\n# Arguments\n\n* `lcore_id` -\nThe lcore to consider.\n* `arg` -\nAn opaque pointer passed at callback registration.\n\n# Returns\n\n- -1 when refusing this operation,\n- 0 otherwise."]
pub type rte_lcore_init_cb = ::core::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::core::ffi::c_uint,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Callback prototype for uninitializing lcores.\n\n# Arguments\n\n* `lcore_id` -\nThe lcore to consider.\n* `arg` -\nAn opaque pointer passed at callback registration."]
pub type rte_lcore_uninit_cb = ::core::option::Option<
    unsafe extern "C" fn(lcore_id: ::core::ffi::c_uint, arg: *mut ::core::ffi::c_void),
>;
unsafe extern "C" {
    #[doc = "Register callbacks invoked when initializing and uninitializing a lcore.\nThis function calls the init callback with all initialized lcores.\nAny error reported by the init callback triggers a rollback calling the\nuninit callback for each lcore.\nIf this step succeeds, the callbacks are put in the lcore callbacks list\nthat will get called for each lcore allocation/release.\nNote: callbacks execution is serialised under a write lock protecting the\nlcores and callbacks list.\n\n# Arguments\n\n* `name` -\nA name serving as a small description for this callback.\n* `init` -\nThe callback invoked when a lcore_id is initialized.\ninit can be NULL.\n* `uninit` -\nThe callback invoked when a lcore_id is uninitialized.\nuninit can be NULL.\n* `arg` -\nAn optional argument that gets passed to the callback when it gets\ninvoked.\n\n# Returns\n\nOn success, returns an opaque pointer for the registered object.\nOn failure (either memory allocation issue in the function itself or an\nerror is returned by the init callback itself), returns NULL."]
    pub fn rte_lcore_callback_register(
        name: *const ::core::ffi::c_char,
        init: rte_lcore_init_cb,
        uninit: rte_lcore_uninit_cb,
        arg: *mut ::core::ffi::c_void,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Unregister callbacks previously registered with rte_lcore_callback_register.\nThis function calls the uninit callback with all initialized lcores.\nThe callbacks are then removed from the lcore callbacks list.\n\n# Arguments\n\n* `handle` -\nThe handle pointer returned by a former successful call to\nrte_lcore_callback_register."]
    pub fn rte_lcore_callback_unregister(handle: *mut ::core::ffi::c_void);
}
#[doc = "Callback prototype for iterating over lcores.\n\n# Arguments\n\n* `lcore_id` -\nThe lcore to consider.\n* `arg` -\nAn opaque pointer coming from the caller.\n\n# Returns\n\n- 0 lets the iteration continue.\n- !0 makes the iteration stop."]
pub type rte_lcore_iterate_cb = ::core::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::core::ffi::c_uint,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Iterate on all active lcores (ROLE_RTE, ROLE_SERVICE and ROLE_NON_EAL).\nNo modification on the lcore states is allowed in the callback.\nNote: as opposed to init/uninit callbacks, iteration callbacks can be\ninvoked in parallel as they are run under a read lock protecting the lcores\nand callbacks list.\n\n# Arguments\n\n* `cb` -\nThe callback that gets passed each lcore.\n* `arg` -\nAn opaque pointer passed to cb.\n\n# Returns\n\nSame return code as the callback last invocation (see rte_lcore_iterate_cb\ndescription)."]
    pub fn rte_lcore_iterate(
        cb: rte_lcore_iterate_cb,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
#[doc = "lcore usage statistics."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_lcore_usage {
    #[doc = "The total amount of time that the application has been running on\nthis lcore, in TSC cycles."]
    pub total_cycles: u64,
    #[doc = "The amount of time the application was busy, handling some\nworkload on this lcore, in TSC cycles."]
    pub busy_cycles: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_lcore_usage"][::core::mem::size_of::<rte_lcore_usage>() - 16usize];
    ["Alignment of rte_lcore_usage"][::core::mem::align_of::<rte_lcore_usage>() - 8usize];
    ["Offset of field: rte_lcore_usage::total_cycles"]
        [::core::mem::offset_of!(rte_lcore_usage, total_cycles) - 0usize];
    ["Offset of field: rte_lcore_usage::busy_cycles"]
        [::core::mem::offset_of!(rte_lcore_usage, busy_cycles) - 8usize];
};
#[doc = "Callback to allow applications to report lcore usage.\n\n# Arguments\n\n* `lcore_id` [in]  -\nThe lcore to consider.\n* `usage` [out]  -\nCounters representing this lcore usage. This can never be NULL.\n\n# Returns\n\n- 0 if fields in usage were updated successfully. The fields that the\napplication does not support must not be modified.\n- a negative value if the information is not available or if any error\noccurred."]
pub type rte_lcore_usage_cb = ::core::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::core::ffi::c_uint,
        usage: *mut rte_lcore_usage,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Register a callback from an application to be called in rte_lcore_dump() and\nthe /eal/lcore/info telemetry endpoint handler. Applications are expected to\nreport lcore usage statistics via this callback.\nIf a callback was already registered, it can be replaced with another callback\nor unregistered with NULL. The previously registered callback may remain in\nuse for an undetermined period of time.\n\n# Arguments\n\n* `cb` -\nThe callback function."]
    pub fn rte_lcore_register_usage_cb(cb: rte_lcore_usage_cb);
}
unsafe extern "C" {
    #[doc = "List all lcores.\n\n# Arguments\n\n* `f` -\nThe output stream where the dump should be sent."]
    pub fn rte_lcore_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Register current non-EAL thread as a lcore.\n> **Note** This API is not compatible with the multi-process feature:\n- if a primary process registers a non-EAL thread, then no secondary process\nwill initialise.\n- if a secondary process initialises successfully, trying to register a\nnon-EAL thread from either primary or secondary processes will always end\nup with the thread getting LCORE_ID_ANY as lcore.\n\n# Returns\n\nOn success, return 0; otherwise return -1 with rte_errno set."]
    pub fn rte_thread_register() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister current thread and release lcore if one was associated."]
    pub fn rte_thread_unregister();
}
#[doc = "SSE/SSE2 types"]
pub type __m128i = [::core::ffi::c_longlong; 2usize];
#[doc = "The memory order is an integer type in GCC built-ins,\nnot an enumerated type like in C11."]
pub type rte_memory_order = ::core::ffi::c_int;
#[doc = "128-bit integer structure."]
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub struct rte_int128_t {
    pub anon1: rte_int128_t__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_int128_t__bindgen_ty_1 {
    pub val: [u64; 2usize],
    pub int128: i128,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_int128_t__bindgen_ty_1"]
        [::core::mem::size_of::<rte_int128_t__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_int128_t__bindgen_ty_1"]
        [::core::mem::align_of::<rte_int128_t__bindgen_ty_1>() - 16usize];
    ["Offset of field: rte_int128_t__bindgen_ty_1::val"]
        [::core::mem::offset_of!(rte_int128_t__bindgen_ty_1, val) - 0usize];
    ["Offset of field: rte_int128_t__bindgen_ty_1::int128"]
        [::core::mem::offset_of!(rte_int128_t__bindgen_ty_1, int128) - 0usize];
};
impl Default for rte_int128_t__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_int128_t"][::core::mem::size_of::<rte_int128_t>() - 16usize];
    ["Alignment of rte_int128_t"][::core::mem::align_of::<rte_int128_t>() - 16usize];
};
impl Default for rte_int128_t {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "From Intel Software Development Manual; Vol 3;\n8.2.2 Memory Ordering in P6 and More Recent Processor Families:\n...\n. Reads are not reordered with other reads.\n. Writes are not reordered with older reads.\n. Writes to memory are not reordered with other writes,\nwith the following exceptions:\n. streaming stores (writes) executed with the non-temporal move\ninstructions (MOVNTI, MOVNTQ, MOVNTDQ, MOVNTPS, and MOVNTPD); and\n. string operations (see Section 8.2.4.1).\n...\n. Reads may be reordered with older writes to different locations but not\nwith older writes to the same location.\n. Reads or writes cannot be reordered with I/O instructions,\nlocked instructions, or serializing instructions.\n. Reads cannot pass earlier LFENCE and MFENCE instructions.\n. Writes ... cannot pass earlier LFENCE, SFENCE, and MFENCE instructions.\n. LFENCE instructions cannot pass earlier reads.\n. SFENCE instructions cannot pass earlier writes ...\n. MFENCE instructions cannot pass earlier reads, writes ...\nAs pointed by Java guys, that makes possible to use lock-prefixed\ninstructions to get the same effect as mfence and on most modern HW\nthat gives a better performance then using mfence:\nhttps://shipilev.net/blog/2014/on-the-fence-with-dependencies/\nBasic idea is to use lock prefixed add with some dummy memory location\nas the destination. From their experiments 128B(2 cache lines) below\ncurrent stack pointer looks like a good candidate.\nSo below we use that technique for rte_smp_mb() implementation."]
    #[link_name = "rte_smp_mb_w"]
    pub fn rte_smp_mb();
}
unsafe extern "C" {
    #[doc = "Pause CPU execution for a short while\nThis call is intended for tight loops which poll a shared resource or wait\nfor an event. A short pause within the loop may reduce the power consumption."]
    #[link_name = "rte_pause_w"]
    pub fn rte_pause();
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 16-bit expected value, with a relaxed\nmemory ordering model meaning the loads around this API can be reordered.\n\n# Arguments\n\n* `addr` -\nA pointer to the memory location.\n* `expected` -\nA 16-bit expected value to be in the memory location.\n* `memorder` -\nTwo different memory orders that can be specified:\nrte_memory_order_acquire and rte_memory_order_relaxed."]
    #[link_name = "rte_wait_until_equal_16_w"]
    pub fn rte_wait_until_equal_16(addr: *mut u16, expected: u16, memorder: rte_memory_order);
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 32-bit expected value, with a relaxed\nmemory ordering model meaning the loads around this API can be reordered.\n\n# Arguments\n\n* `addr` -\nA pointer to the memory location.\n* `expected` -\nA 32-bit expected value to be in the memory location.\n* `memorder` -\nTwo different memory orders that can be specified:\nrte_memory_order_acquire and rte_memory_order_relaxed."]
    #[link_name = "rte_wait_until_equal_32_w"]
    pub fn rte_wait_until_equal_32(addr: *mut u32, expected: u32, memorder: rte_memory_order);
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 64-bit expected value, with a relaxed\nmemory ordering model meaning the loads around this API can be reordered.\n\n# Arguments\n\n* `addr` -\nA pointer to the memory location.\n* `expected` -\nA 64-bit expected value to be in the memory location.\n* `memorder` -\nTwo different memory orders that can be specified:\nrte_memory_order_acquire and rte_memory_order_relaxed."]
    #[link_name = "rte_wait_until_equal_64_w"]
    pub fn rte_wait_until_equal_64(addr: *mut u64, expected: u64, memorder: rte_memory_order);
}
#[doc = "The rte_spinlock_t type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_spinlock_t {
    #[doc = "< lock status 0 = unlocked, 1 = locked"]
    pub locked: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_spinlock_t"][::core::mem::size_of::<rte_spinlock_t>() - 4usize];
    ["Alignment of rte_spinlock_t"][::core::mem::align_of::<rte_spinlock_t>() - 4usize];
    ["Offset of field: rte_spinlock_t::locked"]
        [::core::mem::offset_of!(rte_spinlock_t, locked) - 0usize];
};
unsafe extern "C" {
    #[doc = "Initialize the spinlock to an unlocked state.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock."]
    #[link_name = "rte_spinlock_init_w"]
    pub fn rte_spinlock_init(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Take the spinlock.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock."]
    #[link_name = "rte_spinlock_lock_w"]
    pub fn rte_spinlock_lock(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Release the spinlock.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock."]
    #[link_name = "rte_spinlock_unlock_w"]
    pub fn rte_spinlock_unlock(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take the lock.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock.\n\n# Returns\n\n1 if the lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_spinlock_trylock_w"]
    pub fn rte_spinlock_trylock(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the lock is taken.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock.\n\n# Returns\n\n1 if the lock is currently taken; 0 otherwise."]
    #[link_name = "rte_spinlock_is_locked_w"]
    pub fn rte_spinlock_is_locked(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if hardware transactional memory (lock elision) is supported\n\n# Returns\n\n1 if the hardware transactional memory is supported; 0 otherwise."]
    #[link_name = "rte_tm_supported_w"]
    pub fn rte_tm_supported() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction,\nif it fails or not available take the spinlock.\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock."]
    #[link_name = "rte_spinlock_lock_tm_w"]
    pub fn rte_spinlock_lock_tm(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the spinlock if\nthe spinlock is used as a fall-back\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock."]
    #[link_name = "rte_spinlock_unlock_tm_w"]
    pub fn rte_spinlock_unlock_tm(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction,\nif it fails or not available try to take the lock.\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `sl` -\nA pointer to the spinlock.\n\n# Returns\n\n1 if the hardware memory transaction is successfully started\nor lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_spinlock_trylock_tm_w"]
    pub fn rte_spinlock_trylock_tm(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
#[doc = "The rte_spinlock_recursive_t type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_spinlock_recursive_t {
    #[doc = "< the actual spinlock"]
    pub sl: rte_spinlock_t,
    #[doc = "< core id using lock, -1 for unused"]
    pub user: ::core::ffi::c_int,
    #[doc = "< count of time this lock has been called"]
    pub count: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_spinlock_recursive_t"]
        [::core::mem::size_of::<rte_spinlock_recursive_t>() - 12usize];
    ["Alignment of rte_spinlock_recursive_t"]
        [::core::mem::align_of::<rte_spinlock_recursive_t>() - 4usize];
    ["Offset of field: rte_spinlock_recursive_t::sl"]
        [::core::mem::offset_of!(rte_spinlock_recursive_t, sl) - 0usize];
    ["Offset of field: rte_spinlock_recursive_t::user"]
        [::core::mem::offset_of!(rte_spinlock_recursive_t, user) - 4usize];
    ["Offset of field: rte_spinlock_recursive_t::count"]
        [::core::mem::offset_of!(rte_spinlock_recursive_t, count) - 8usize];
};
unsafe extern "C" {
    #[doc = "Initialize the recursive spinlock to an unlocked state.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock."]
    #[link_name = "rte_spinlock_recursive_init_w"]
    pub fn rte_spinlock_recursive_init(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Take the recursive spinlock.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock."]
    #[link_name = "rte_spinlock_recursive_lock_w"]
    pub fn rte_spinlock_recursive_lock(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Release the recursive spinlock.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock."]
    #[link_name = "rte_spinlock_recursive_unlock_w"]
    pub fn rte_spinlock_recursive_unlock(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Try to take the recursive lock.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock.\n\n# Returns\n\n1 if the lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_spinlock_recursive_trylock_w"]
    pub fn rte_spinlock_recursive_trylock(slr: *mut rte_spinlock_recursive_t)
    -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction,\nif it fails or not available take the recursive spinlocks\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock."]
    #[link_name = "rte_spinlock_recursive_lock_tm_w"]
    pub fn rte_spinlock_recursive_lock_tm(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the recursive spinlock\nif the recursive spinlock is used as a fall-back\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock."]
    #[link_name = "rte_spinlock_recursive_unlock_tm_w"]
    pub fn rte_spinlock_recursive_unlock_tm(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction,\nif it fails or not available try to take the recursive lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `slr` -\nA pointer to the recursive spinlock.\n\n# Returns\n\n1 if the hardware memory transaction is successfully started\nor lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_spinlock_recursive_trylock_tm_w"]
    pub fn rte_spinlock_recursive_trylock_tm(
        slr: *mut rte_spinlock_recursive_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[link_name = "rte_xbegin_w"]
    pub fn rte_xbegin() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[link_name = "rte_xend_w"]
    pub fn rte_xend();
}
unsafe extern "C" {
    #[link_name = "rte_xtest_w"]
    pub fn rte_xtest() -> ::core::ffi::c_int;
}
pub mod rte_cpu_flag_t {
    #[doc = "Enumeration of all CPU features supported"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< SSE3"]
    pub const RTE_CPUFLAG_SSE3: Type = 0;
    #[doc = "< PCLMULQDQ"]
    pub const RTE_CPUFLAG_PCLMULQDQ: Type = 1;
    #[doc = "< DTES64"]
    pub const RTE_CPUFLAG_DTES64: Type = 2;
    #[doc = "< MONITOR"]
    pub const RTE_CPUFLAG_MONITOR: Type = 3;
    #[doc = "< DS_CPL"]
    pub const RTE_CPUFLAG_DS_CPL: Type = 4;
    #[doc = "< VMX"]
    pub const RTE_CPUFLAG_VMX: Type = 5;
    #[doc = "< SMX"]
    pub const RTE_CPUFLAG_SMX: Type = 6;
    #[doc = "< EIST"]
    pub const RTE_CPUFLAG_EIST: Type = 7;
    #[doc = "< TM2"]
    pub const RTE_CPUFLAG_TM2: Type = 8;
    #[doc = "< SSSE3"]
    pub const RTE_CPUFLAG_SSSE3: Type = 9;
    #[doc = "< CNXT_ID"]
    pub const RTE_CPUFLAG_CNXT_ID: Type = 10;
    #[doc = "< FMA"]
    pub const RTE_CPUFLAG_FMA: Type = 11;
    #[doc = "< CMPXCHG16B"]
    pub const RTE_CPUFLAG_CMPXCHG16B: Type = 12;
    #[doc = "< XTPR"]
    pub const RTE_CPUFLAG_XTPR: Type = 13;
    #[doc = "< PDCM"]
    pub const RTE_CPUFLAG_PDCM: Type = 14;
    #[doc = "< PCID"]
    pub const RTE_CPUFLAG_PCID: Type = 15;
    #[doc = "< DCA"]
    pub const RTE_CPUFLAG_DCA: Type = 16;
    #[doc = "< SSE4_1"]
    pub const RTE_CPUFLAG_SSE4_1: Type = 17;
    #[doc = "< SSE4_2"]
    pub const RTE_CPUFLAG_SSE4_2: Type = 18;
    #[doc = "< X2APIC"]
    pub const RTE_CPUFLAG_X2APIC: Type = 19;
    #[doc = "< MOVBE"]
    pub const RTE_CPUFLAG_MOVBE: Type = 20;
    #[doc = "< POPCNT"]
    pub const RTE_CPUFLAG_POPCNT: Type = 21;
    #[doc = "< TSC_DEADLINE"]
    pub const RTE_CPUFLAG_TSC_DEADLINE: Type = 22;
    #[doc = "< AES"]
    pub const RTE_CPUFLAG_AES: Type = 23;
    #[doc = "< XSAVE"]
    pub const RTE_CPUFLAG_XSAVE: Type = 24;
    #[doc = "< OSXSAVE"]
    pub const RTE_CPUFLAG_OSXSAVE: Type = 25;
    #[doc = "< AVX"]
    pub const RTE_CPUFLAG_AVX: Type = 26;
    #[doc = "< F16C"]
    pub const RTE_CPUFLAG_F16C: Type = 27;
    #[doc = "< RDRAND"]
    pub const RTE_CPUFLAG_RDRAND: Type = 28;
    #[doc = "< Running in a VM"]
    pub const RTE_CPUFLAG_HYPERVISOR: Type = 29;
    #[doc = "< FPU"]
    pub const RTE_CPUFLAG_FPU: Type = 30;
    #[doc = "< VME"]
    pub const RTE_CPUFLAG_VME: Type = 31;
    #[doc = "< DE"]
    pub const RTE_CPUFLAG_DE: Type = 32;
    #[doc = "< PSE"]
    pub const RTE_CPUFLAG_PSE: Type = 33;
    #[doc = "< TSC"]
    pub const RTE_CPUFLAG_TSC: Type = 34;
    #[doc = "< MSR"]
    pub const RTE_CPUFLAG_MSR: Type = 35;
    #[doc = "< PAE"]
    pub const RTE_CPUFLAG_PAE: Type = 36;
    #[doc = "< MCE"]
    pub const RTE_CPUFLAG_MCE: Type = 37;
    #[doc = "< CX8"]
    pub const RTE_CPUFLAG_CX8: Type = 38;
    #[doc = "< APIC"]
    pub const RTE_CPUFLAG_APIC: Type = 39;
    #[doc = "< SEP"]
    pub const RTE_CPUFLAG_SEP: Type = 40;
    #[doc = "< MTRR"]
    pub const RTE_CPUFLAG_MTRR: Type = 41;
    #[doc = "< PGE"]
    pub const RTE_CPUFLAG_PGE: Type = 42;
    #[doc = "< MCA"]
    pub const RTE_CPUFLAG_MCA: Type = 43;
    #[doc = "< CMOV"]
    pub const RTE_CPUFLAG_CMOV: Type = 44;
    #[doc = "< PAT"]
    pub const RTE_CPUFLAG_PAT: Type = 45;
    #[doc = "< PSE36"]
    pub const RTE_CPUFLAG_PSE36: Type = 46;
    #[doc = "< PSN"]
    pub const RTE_CPUFLAG_PSN: Type = 47;
    #[doc = "< CLFSH"]
    pub const RTE_CPUFLAG_CLFSH: Type = 48;
    #[doc = "< DS"]
    pub const RTE_CPUFLAG_DS: Type = 49;
    #[doc = "< ACPI"]
    pub const RTE_CPUFLAG_ACPI: Type = 50;
    #[doc = "< MMX"]
    pub const RTE_CPUFLAG_MMX: Type = 51;
    #[doc = "< FXSR"]
    pub const RTE_CPUFLAG_FXSR: Type = 52;
    #[doc = "< SSE"]
    pub const RTE_CPUFLAG_SSE: Type = 53;
    #[doc = "< SSE2"]
    pub const RTE_CPUFLAG_SSE2: Type = 54;
    #[doc = "< SS"]
    pub const RTE_CPUFLAG_SS: Type = 55;
    #[doc = "< HTT"]
    pub const RTE_CPUFLAG_HTT: Type = 56;
    #[doc = "< TM"]
    pub const RTE_CPUFLAG_TM: Type = 57;
    #[doc = "< PBE"]
    pub const RTE_CPUFLAG_PBE: Type = 58;
    #[doc = "< DIGTEMP"]
    pub const RTE_CPUFLAG_DIGTEMP: Type = 59;
    #[doc = "< TRBOBST"]
    pub const RTE_CPUFLAG_TRBOBST: Type = 60;
    #[doc = "< ARAT"]
    pub const RTE_CPUFLAG_ARAT: Type = 61;
    #[doc = "< PLN"]
    pub const RTE_CPUFLAG_PLN: Type = 62;
    #[doc = "< ECMD"]
    pub const RTE_CPUFLAG_ECMD: Type = 63;
    #[doc = "< PTM"]
    pub const RTE_CPUFLAG_PTM: Type = 64;
    #[doc = "< MPERF_APERF_MSR"]
    pub const RTE_CPUFLAG_MPERF_APERF_MSR: Type = 65;
    #[doc = "< ACNT2"]
    pub const RTE_CPUFLAG_ACNT2: Type = 66;
    #[doc = "< ENERGY_EFF"]
    pub const RTE_CPUFLAG_ENERGY_EFF: Type = 67;
    #[doc = "< FSGSBASE"]
    pub const RTE_CPUFLAG_FSGSBASE: Type = 68;
    #[doc = "< BMI1"]
    pub const RTE_CPUFLAG_BMI1: Type = 69;
    #[doc = "< Hardware Lock elision"]
    pub const RTE_CPUFLAG_HLE: Type = 70;
    #[doc = "< AVX2"]
    pub const RTE_CPUFLAG_AVX2: Type = 71;
    #[doc = "< SMEP"]
    pub const RTE_CPUFLAG_SMEP: Type = 72;
    #[doc = "< BMI2"]
    pub const RTE_CPUFLAG_BMI2: Type = 73;
    #[doc = "< ERMS"]
    pub const RTE_CPUFLAG_ERMS: Type = 74;
    #[doc = "< INVPCID"]
    pub const RTE_CPUFLAG_INVPCID: Type = 75;
    #[doc = "< Transactional memory"]
    pub const RTE_CPUFLAG_RTM: Type = 76;
    #[doc = "< AVX512F"]
    pub const RTE_CPUFLAG_AVX512F: Type = 77;
    #[doc = "< RDSEED instruction"]
    pub const RTE_CPUFLAG_RDSEED: Type = 78;
    #[doc = "< LAHF_SAHF"]
    pub const RTE_CPUFLAG_LAHF_SAHF: Type = 79;
    #[doc = "< LZCNT"]
    pub const RTE_CPUFLAG_LZCNT: Type = 80;
    #[doc = "< SYSCALL"]
    pub const RTE_CPUFLAG_SYSCALL: Type = 81;
    #[doc = "< XD"]
    pub const RTE_CPUFLAG_XD: Type = 82;
    #[doc = "< 1GB_PG"]
    pub const RTE_CPUFLAG_1GB_PG: Type = 83;
    #[doc = "< RDTSCP"]
    pub const RTE_CPUFLAG_RDTSCP: Type = 84;
    #[doc = "< EM64T"]
    pub const RTE_CPUFLAG_EM64T: Type = 85;
    #[doc = "< INVTSC"]
    pub const RTE_CPUFLAG_INVTSC: Type = 86;
    #[doc = "< AVX512 Doubleword and Quadword"]
    pub const RTE_CPUFLAG_AVX512DQ: Type = 87;
    #[doc = "< AVX512 Integer Fused Multiply-Add"]
    pub const RTE_CPUFLAG_AVX512IFMA: Type = 88;
    #[doc = "< AVX512 Conflict Detection"]
    pub const RTE_CPUFLAG_AVX512CD: Type = 89;
    #[doc = "< AVX512 Byte and Word"]
    pub const RTE_CPUFLAG_AVX512BW: Type = 90;
    #[doc = "< AVX512 Vector Length"]
    pub const RTE_CPUFLAG_AVX512VL: Type = 91;
    #[doc = "< AVX512 Vector Bit Manipulation"]
    pub const RTE_CPUFLAG_AVX512VBMI: Type = 92;
    #[doc = "< AVX512 Vector Bit Manipulation 2"]
    pub const RTE_CPUFLAG_AVX512VBMI2: Type = 93;
    #[doc = "< Galois Field New Instructions"]
    pub const RTE_CPUFLAG_GFNI: Type = 94;
    #[doc = "< Vector AES"]
    pub const RTE_CPUFLAG_VAES: Type = 95;
    #[doc = "< Vector Carry-less Multiply"]
    pub const RTE_CPUFLAG_VPCLMULQDQ: Type = 96;
    pub const RTE_CPUFLAG_AVX512VNNI: Type = 97;
    #[doc = "< AVX512 Bit Algorithms"]
    pub const RTE_CPUFLAG_AVX512BITALG: Type = 98;
    #[doc = "< AVX512 Vector Popcount"]
    pub const RTE_CPUFLAG_AVX512VPOPCNTDQ: Type = 99;
    #[doc = "< Cache Line Demote"]
    pub const RTE_CPUFLAG_CLDEMOTE: Type = 100;
    #[doc = "< Direct Store Instructions"]
    pub const RTE_CPUFLAG_MOVDIRI: Type = 101;
    #[doc = "< Direct Store Instructions 64B"]
    pub const RTE_CPUFLAG_MOVDIR64B: Type = 102;
    #[doc = "< AVX512 Two Register Intersection"]
    pub const RTE_CPUFLAG_AVX512VP2INTERSECT: Type = 103;
    #[doc = "< UMONITOR/UMWAIT/TPAUSE"]
    pub const RTE_CPUFLAG_WAITPKG: Type = 104;
    #[doc = "< MONITORX"]
    pub const RTE_CPUFLAG_MONITORX: Type = 105;
}
#[doc = "Structure used to describe platform-specific intrinsics that may or may not\nbe supported at runtime."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_cpu_intrinsics {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_cpu_intrinsics"][::core::mem::size_of::<rte_cpu_intrinsics>() - 4usize];
    ["Alignment of rte_cpu_intrinsics"][::core::mem::align_of::<rte_cpu_intrinsics>() - 4usize];
};
impl rte_cpu_intrinsics {
    #[inline]
    pub fn power_monitor(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_monitor_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_monitor_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn power_pause(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_pause(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_pause_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_pause_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn power_monitor_multi(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor_multi(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_monitor_multi_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_monitor_multi_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        power_monitor: u32,
        power_pause: u32,
        power_monitor_multi: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let power_monitor: u32 = unsafe { ::core::mem::transmute(power_monitor) };
            power_monitor as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let power_pause: u32 = unsafe { ::core::mem::transmute(power_pause) };
            power_pause as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let power_monitor_multi: u32 = unsafe { ::core::mem::transmute(power_monitor_multi) };
            power_monitor_multi as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = "Check CPU support for various intrinsics at runtime.\n\n# Arguments\n\n* `intrinsics` -\nPointer to a structure to be filled."]
    pub fn rte_cpu_get_intrinsics_support(intrinsics: *mut rte_cpu_intrinsics);
}
unsafe extern "C" {
    #[doc = "Get name of CPU flag\n\n# Arguments\n\n* `feature` -\nCPU flag ID\n\n# Returns\n\nflag name\nNULL if flag ID is invalid"]
    pub fn rte_cpu_get_flag_name(feature: rte_cpu_flag_t::Type) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Function for checking a CPU flag availability\n\n# Arguments\n\n* `feature` -\nCPU flag to query CPU for\n\n# Returns\n\n1 if flag is available\n0 if flag is not available\n-ENOENT if flag is invalid"]
    pub fn rte_cpu_get_flag_enabled(feature: rte_cpu_flag_t::Type) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "This function checks that the currently used CPU supports the CPU features\nthat were specified at compile time. It is called automatically within the\nEAL, so does not need to be used by applications.  This version returns a\nresult so that decisions may be made (for instance, graceful shutdowns)."]
    pub fn rte_cpu_is_supported() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "This function attempts to retrieve a value from the auxiliary vector.\nIf it is unsuccessful, the result will be 0, and errno will be set.\n\n# Returns\n\nA value from the auxiliary vector.  When the value is 0, check\nerrno to determine if an error occurred."]
    pub fn rte_cpu_getauxval(type_: ::core::ffi::c_ulong) -> ::core::ffi::c_ulong;
}
unsafe extern "C" {
    #[doc = "This function retrieves a value from the auxiliary vector, and compares it\nas a string against the value retrieved.\n\n# Returns\n\nThe result of calling strcmp() against the value retrieved from\nthe auxiliary vector.  When the value is 0 (meaning a match is found),\ncheck errno to determine if an error occurred."]
    pub fn rte_cpu_strcmp_auxval(
        type_: ::core::ffi::c_ulong,
        str_: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Change the stream that will be used by the logging system.\nThis can be done at any time. The f argument represents the stream\nto be used to send the logs. If f is NULL, the default output is\nused (stderr).\n\n# Arguments\n\n* `f` -\nPointer to the stream.\n\n# Returns\n\n- 0 on success.\n- Negative on error."]
    pub fn rte_openlog_stream(f: *mut FILE) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the stream used by the logging system (see rte_openlog_stream()\nto change it).\n\n# Returns\n\nPointer to the stream."]
    pub fn rte_log_get_stream() -> *mut FILE;
}
unsafe extern "C" {
    #[doc = "Set the global log level.\nAfter this call, logs with a level lower or equal than the level\npassed as argument will be displayed.\n\n# Arguments\n\n* `level` -\nLog level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8)."]
    pub fn rte_log_set_global_level(level: u32);
}
unsafe extern "C" {
    #[doc = "Get the global log level.\n\n# Returns\n\nThe current global log level."]
    pub fn rte_log_get_global_level() -> u32;
}
unsafe extern "C" {
    #[doc = "Get the log level for a given type.\n\n# Arguments\n\n* `logtype` -\nThe log type identifier.\n\n# Returns\n\n0 on success, a negative value if logtype is invalid."]
    pub fn rte_log_get_level(logtype: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "For a given `logtype`, check if a log with `loglevel` can be printed.\n\n# Arguments\n\n* `logtype` -\nThe log type identifier\n* `loglevel` -\nLog level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n\n# Returns\n\nReturns 'true' if log can be printed and 'false' if it can't."]
    pub fn rte_log_can_log(logtype: u32, loglevel: u32) -> bool;
}
unsafe extern "C" {
    #[doc = "Set the log level for a given type based on globbing pattern.\n\n# Arguments\n\n* `pattern` -\nThe globbing pattern identifying the log type.\n* `level` -\nThe level to be set.\n\n# Returns\n\n0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_pattern(
        pattern: *const ::core::ffi::c_char,
        level: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the log level for a given type based on regular expression.\n\n# Arguments\n\n* `regex` -\nThe regular expression identifying the log type.\n* `level` -\nThe level to be set.\n\n# Returns\n\n0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_regexp(
        regex: *const ::core::ffi::c_char,
        level: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the log level for a given type.\n\n# Arguments\n\n* `logtype` -\nThe log type identifier.\n* `level` -\nThe level to be set.\n\n# Returns\n\n0 on success, a negative value if logtype or level is invalid."]
    pub fn rte_log_set_level(logtype: u32, level: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the current loglevel for the message being processed.\nBefore calling the user-defined stream for logging, the log\nsubsystem sets a per-lcore variable containing the loglevel and the\nlogtype of the message being processed. This information can be\naccessed by the user-defined log output function through this\nfunction.\n\n# Returns\n\nThe loglevel of the message being processed."]
    pub fn rte_log_cur_msg_loglevel() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the current logtype for the message being processed.\nBefore calling the user-defined stream for logging, the log\nsubsystem sets a per-lcore variable containing the loglevel and the\nlogtype of the message being processed. This information can be\naccessed by the user-defined log output function through this\nfunction.\n\n# Returns\n\nThe logtype of the message being processed."]
    pub fn rte_log_cur_msg_logtype() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register a dynamic log type\nIf a log is already registered with the same type, the returned value\nis the same than the previous one.\n\n# Arguments\n\n* `name` -\nThe string identifying the log type.\n\n# Returns\n\n- >0: success, the returned value is the log type identifier.\n- (-ENOMEM): cannot allocate memory."]
    pub fn rte_log_register(name: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register a dynamic log type and try to pick its level from EAL options\nrte_log_register() is called inside. If successful, the function tries\nto search for matching regexp in the list of EAL log level options and\npick the level from the last matching entry. If nothing can be applied\nfrom the list, the level will be set to the user-defined default value.\n\n# Arguments\n\n* `name` -\nName for the log type to be registered\n* `level_def` -\nFallback level to be set if the global list has no matching options\n\n# Returns\n\n- >=0: the newly registered log type\n- <0: rte_log_register() error value"]
    pub fn rte_log_register_type_and_pick_level(
        name: *const ::core::ffi::c_char,
        level_def: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump name of each logtype, one per line.\n\n# Arguments\n\n* `out` -\nStream where the list is sent.\n* `prefix` -\nString preceding each logtype in the output."]
    pub fn rte_log_list_types(out: *mut FILE, prefix: *const ::core::ffi::c_char);
}
unsafe extern "C" {
    #[doc = "Dump log information.\nDump the global level and the registered log types.\n\n# Arguments\n\n* `f` -\nThe output stream where the dump should be sent."]
    pub fn rte_log_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Generates a log message.\nThe message will be sent in the stream defined by the previous call\nto rte_openlog_stream().\nThe level argument determines if the log should be displayed or\nnot, depending on the loglevel settings.\nThe preferred alternative is the RTE_LOG() because it adds the\nlevel and type in the logged string.\n\n# Arguments\n\n* `level` -\nLog level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n* `logtype` -\nThe log type, for example, RTE_LOGTYPE_EAL.\n* `format` -\nThe format string, as in printf(3), followed by the variable arguments\nrequired by the format.\n\n# Returns\n\n- 0: Success.\n- Negative on error."]
    pub fn rte_log(
        level: u32,
        logtype: u32,
        format: *const ::core::ffi::c_char,
        ...
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Generates a log message.\nThe message will be sent in the stream defined by the previous call\nto rte_openlog_stream().\nThe level argument determines if the log should be displayed or\nnot, depending on the loglevel settings. A trailing\nnewline may be added if needed.\nThe preferred alternative is the RTE_LOG() because it adds the\nlevel and type in the logged string.\n\n# Arguments\n\n* `level` -\nLog level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n* `logtype` -\nThe log type, for example, RTE_LOGTYPE_EAL.\n* `format` -\nThe format string, as in printf(3), followed by the variable arguments\nrequired by the format.\n* `ap` -\nThe va_list of the variable arguments required by the format.\n\n# Returns\n\n- 0: Success.\n- Negative on error."]
    pub fn rte_vlog(
        level: u32,
        logtype: u32,
        format: *const ::core::ffi::c_char,
        ap: *mut __va_list_tag,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the stack of the calling core to the standard error."]
    pub fn rte_dump_stack();
}
unsafe extern "C" {
    #[doc = "Get the measured frequency of the RDTSC counter\n\n# Returns\n\nThe TSC frequency for this lcore"]
    pub fn rte_get_tsc_hz() -> u64;
}
unsafe extern "C" {
    #[doc = "Return the number of TSC cycles since boot\n\n# Returns\n\nthe number of cycles"]
    #[link_name = "rte_get_tsc_cycles_w"]
    pub fn rte_get_tsc_cycles() -> u64;
}
unsafe extern "C" {
    #[doc = "Get the number of cycles since boot from the default timer.\n\n# Returns\n\nThe number of cycles"]
    #[link_name = "rte_get_timer_cycles_w"]
    pub fn rte_get_timer_cycles() -> u64;
}
unsafe extern "C" {
    #[doc = "Get the number of cycles in one second for the default timer.\n\n# Returns\n\nThe number of cycles in one second."]
    #[link_name = "rte_get_timer_hz_w"]
    pub fn rte_get_timer_hz() -> u64;
}
unsafe extern "C" {
    #[doc = "Wait at least us microseconds.\nThis function can be replaced with user-defined function.\n\n# See also\n\n> [`rte_delay_us_callback_register`]\n\n# Arguments\n\n* `us` -\nThe number of microseconds to wait."]
    pub static mut rte_delay_us:
        ::core::option::Option<unsafe extern "C" fn(us: ::core::ffi::c_uint)>;
}
unsafe extern "C" {
    #[doc = "Wait at least ms milliseconds.\n\n# Arguments\n\n* `ms` -\nThe number of milliseconds to wait."]
    #[link_name = "rte_delay_ms_w"]
    pub fn rte_delay_ms(ms: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Blocking delay function.\n\n# Arguments\n\n* `us` -\nNumber of microseconds to wait."]
    pub fn rte_delay_us_block(us: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Delay function that uses system sleep.\nDoes not block the CPU core.\n\n# Arguments\n\n* `us` -\nNumber of microseconds to wait."]
    pub fn rte_delay_us_sleep(us: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Replace rte_delay_us with user defined function.\n\n# Arguments\n\n* `userfunc` -\nUser function which replaces rte_delay_us. rte_delay_us_block restores\nbuiltin block delay function."]
    pub fn rte_delay_us_callback_register(
        userfunc: ::core::option::Option<unsafe extern "C" fn(arg1: ::core::ffi::c_uint)>,
    );
}
unsafe extern "C" {
    #[link_name = "rte_rdtsc_w"]
    pub fn rte_rdtsc() -> u64;
}
unsafe extern "C" {
    #[link_name = "rte_rdtsc_precise_w"]
    pub fn rte_rdtsc_precise() -> u64;
}
unsafe extern "C" {
    pub static mut rte_rtm_supported: u8;
}
unsafe extern "C" {
    #[link_name = "rte_try_tm_w"]
    pub fn rte_try_tm(lock: *mut ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the target bit from a 32-bit value without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe target bit."]
    #[link_name = "rte_bit_relaxed_get32_w"]
    pub fn rte_bit_relaxed_get32(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Set the target bit in a 32-bit value to 1 without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to set.\n* `addr` -\nThe address holding the bit."]
    #[link_name = "rte_bit_relaxed_set32_w"]
    pub fn rte_bit_relaxed_set32(nr: ::core::ffi::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    #[doc = "Clear the target bit in a 32-bit value to 0 without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to clear.\n* `addr` -\nThe address holding the bit."]
    #[link_name = "rte_bit_relaxed_clear32_w"]
    pub fn rte_bit_relaxed_clear32(nr: ::core::ffi::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 32-bit value, then set it to 1 without\nmemory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get and set.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe original bit."]
    #[link_name = "rte_bit_relaxed_test_and_set32_w"]
    pub fn rte_bit_relaxed_test_and_set32(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 32-bit value, then clear it to 0 without\nmemory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get and clear.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe original bit."]
    #[link_name = "rte_bit_relaxed_test_and_clear32_w"]
    pub fn rte_bit_relaxed_test_and_clear32(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Get the target bit from a 64-bit value without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe target bit."]
    #[link_name = "rte_bit_relaxed_get64_w"]
    pub fn rte_bit_relaxed_get64(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Set the target bit in a 64-bit value to 1 without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to set.\n* `addr` -\nThe address holding the bit."]
    #[link_name = "rte_bit_relaxed_set64_w"]
    pub fn rte_bit_relaxed_set64(nr: ::core::ffi::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    #[doc = "Clear the target bit in a 64-bit value to 0 without memory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to clear.\n* `addr` -\nThe address holding the bit."]
    #[link_name = "rte_bit_relaxed_clear64_w"]
    pub fn rte_bit_relaxed_clear64(nr: ::core::ffi::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 64-bit value, then set it to 1 without\nmemory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get and set.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe original bit."]
    #[link_name = "rte_bit_relaxed_test_and_set64_w"]
    pub fn rte_bit_relaxed_test_and_set64(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 64-bit value, then clear it to 0 without\nmemory ordering.\n\n# Arguments\n\n* `nr` -\nThe target bit to get and clear.\n* `addr` -\nThe address holding the bit.\n\n# Returns\n\nThe original bit."]
    #[link_name = "rte_bit_relaxed_test_and_clear64_w"]
    pub fn rte_bit_relaxed_test_and_clear64(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Get the count of leading 0-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of leading zero bits."]
    #[link_name = "rte_clz32_w"]
    pub fn rte_clz32(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of leading 0-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of leading zero bits."]
    #[link_name = "rte_clz64_w"]
    pub fn rte_clz64(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of trailing 0-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of trailing zero bits."]
    #[link_name = "rte_ctz32_w"]
    pub fn rte_ctz32(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of trailing 0-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of trailing zero bits."]
    #[link_name = "rte_ctz64_w"]
    pub fn rte_ctz64(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of 1-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of 1-bits."]
    #[link_name = "rte_popcount32_w"]
    pub fn rte_popcount32(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of 1-bits in v.\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nThe count of 1-bits."]
    #[link_name = "rte_popcount64_w"]
    pub fn rte_popcount64(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSearch v from least significant bit (LSB) to the most\nsignificant bit (MSB) for a set bit (1).\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nBit index + 1 if a set bit is found, zero otherwise."]
    #[link_name = "rte_ffs32_w"]
    pub fn rte_ffs32(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSearch v from least significant bit (LSB) to the most\nsignificant bit (MSB) for a set bit (1).\n\n# Arguments\n\n* `v` -\nThe value.\n\n# Returns\n\nBit index + 1 if a set bit is found, zero otherwise."]
    #[link_name = "rte_ffs64_w"]
    pub fn rte_ffs64(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Combines 32b inputs most significant set bits into the least\nsignificant bits to construct a value with the same MSBs as x\nbut all 1's under it.\n\n# Arguments\n\n* `x` -\nThe integer whose MSBs need to be combined with its LSBs\n\n# Returns\n\nThe combined value."]
    #[link_name = "rte_combine32ms1b_w"]
    pub fn rte_combine32ms1b(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Combines 64b inputs most significant set bits into the least\nsignificant bits to construct a value with the same MSBs as x\nbut all 1's under it.\n\n# Arguments\n\n* `v` -\nThe integer whose MSBs need to be combined with its LSBs\n\n# Returns\n\nThe combined value."]
    #[link_name = "rte_combine64ms1b_w"]
    pub fn rte_combine64ms1b(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit\n(starting from zero).\nIf a least significant 1 bit is found, its bit index is returned.\nIf the content of the input parameter is zero, then the content of the return\nvalue is undefined.\n\n# Arguments\n\n* `v` -\ninput parameter, should not be zero.\n\n# Returns\n\nleast significant set bit in the input parameter."]
    #[link_name = "rte_bsf32_w"]
    pub fn rte_bsf32(v: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit\n(starting from zero). Safe version (checks for input parameter being zero).\n@warning ``pos`` must be a valid pointer. It is not checked!\n\n# Arguments\n\n* `v` -\nThe input parameter.\n* `pos` -\nIf ``v`` was not 0, this value will contain position of least significant\nbit within the input parameter.\n\n# Returns\n\nReturns 0 if ``v`` was 0, otherwise returns 1."]
    #[link_name = "rte_bsf32_safe_w"]
    pub fn rte_bsf32_safe(v: u32, pos: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit\n(starting from zero).\nIf a least significant 1 bit is found, its bit index is returned.\nIf the content of the input parameter is zero, then the content of the return\nvalue is undefined.\n\n# Arguments\n\n* `v` -\ninput parameter, should not be zero.\n\n# Returns\n\nleast significant set bit in the input parameter."]
    #[link_name = "rte_bsf64_w"]
    pub fn rte_bsf64(v: u64) -> u32;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit\n(starting from zero). Safe version (checks for input parameter being zero).\n@warning ``pos`` must be a valid pointer. It is not checked!\n\n# Arguments\n\n* `v` -\nThe input parameter.\n* `pos` -\nIf ``v`` was not 0, this value will contain position of least significant\nbit within the input parameter.\n\n# Returns\n\nReturns 0 if ``v`` was 0, otherwise returns 1."]
    #[link_name = "rte_bsf64_safe_w"]
    pub fn rte_bsf64_safe(v: u64, pos: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the last (most-significant) bit set.\n> **Note** The last (most significant) bit is at position 32.\n> **Note** rte_fls_u32(0) = 0, rte_fls_u32(1) = 1, rte_fls_u32(0x80000000) = 32\n\n# Arguments\n\n* `x` -\nThe input parameter.\n\n# Returns\n\nThe last (most-significant) bit set, or 0 if the input is 0."]
    #[link_name = "rte_fls_u32_w"]
    pub fn rte_fls_u32(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the last (most-significant) bit set.\n> **Note** The last (most significant) bit is at position 64.\n> **Note** rte_fls_u64(0) = 0, rte_fls_u64(1) = 1,\nrte_fls_u64(0x8000000000000000) = 64\n\n# Arguments\n\n* `x` -\nThe input parameter.\n\n# Returns\n\nThe last (most-significant) bit set, or 0 if the input is 0."]
    #[link_name = "rte_fls_u64_w"]
    pub fn rte_fls_u64(x: u64) -> u32;
}
unsafe extern "C" {
    #[doc = "Returns true if n is a power of 2\n\n# Arguments\n\n* `n` -\nNumber to check\n\n# Returns\n\n1 if true, 0 otherwise"]
    #[link_name = "rte_is_power_of_2_w"]
    pub fn rte_is_power_of_2(n: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Aligns input parameter to the next power of 2\n\n# Arguments\n\n* `x` -\nThe integer value to align\n\n# Returns\n\nInput parameter aligned to the next power of 2"]
    #[link_name = "rte_align32pow2_w"]
    pub fn rte_align32pow2(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Aligns input parameter to the previous power of 2\n\n# Arguments\n\n* `x` -\nThe integer value to align\n\n# Returns\n\nInput parameter aligned to the previous power of 2"]
    #[link_name = "rte_align32prevpow2_w"]
    pub fn rte_align32prevpow2(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Aligns 64b input parameter to the next power of 2\n\n# Arguments\n\n* `v` -\nThe 64b value to align\n\n# Returns\n\nInput parameter aligned to the next power of 2"]
    #[link_name = "rte_align64pow2_w"]
    pub fn rte_align64pow2(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Aligns 64b input parameter to the previous power of 2\n\n# Arguments\n\n* `v` -\nThe 64b value to align\n\n# Returns\n\nInput parameter aligned to the previous power of 2"]
    #[link_name = "rte_align64prevpow2_w"]
    pub fn rte_align64prevpow2(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Return the rounded-up log2 of a integer.\n> **Note** Contrary to the logarithm mathematical operation,\nrte_log2_u32(0) == 0 and not -inf.\n\n# Arguments\n\n* `v` -\nThe input parameter.\n\n# Returns\n\nThe rounded-up log2 of the input, or 0 if the input is 0."]
    #[link_name = "rte_log2_u32_w"]
    pub fn rte_log2_u32(v: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the rounded-up log2 of a 64-bit integer.\n> **Note** Contrary to the logarithm mathematical operation,\nrte_log2_u64(0) == 0 and not -inf.\n\n# Arguments\n\n* `v` -\nThe input parameter.\n\n# Returns\n\nThe rounded-up log2 of the input, or 0 if the input is 0."]
    #[link_name = "rte_log2_u64_w"]
    pub fn rte_log2_u64(v: u64) -> u32;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_rwlock_t {
    pub cnt: i32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_rwlock_t"][::core::mem::size_of::<rte_rwlock_t>() - 4usize];
    ["Alignment of rte_rwlock_t"][::core::mem::align_of::<rte_rwlock_t>() - 4usize];
    ["Offset of field: rte_rwlock_t::cnt"][::core::mem::offset_of!(rte_rwlock_t, cnt) - 0usize];
};
unsafe extern "C" {
    #[doc = "Initialize the rwlock to an unlocked state.\n\n# Arguments\n\n* `rwl` -\nA pointer to the rwlock structure."]
    #[link_name = "rte_rwlock_init_w"]
    pub fn rte_rwlock_init(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Take a read lock. Loop until the lock is held.\n> **Note** The RW lock isn't recursive, so calling this function on the same\nlock twice without releasing it could potentially result in a deadlock\nscenario when a write lock is involved.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_read_lock_w"]
    pub fn rte_rwlock_read_lock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take a read lock.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure.\n\n# Returns\n\n- zero if the lock is successfully taken\n- -EBUSY if lock could not be acquired for reading because a\nwriter holds the lock"]
    #[link_name = "rte_rwlock_read_trylock_w"]
    pub fn rte_rwlock_read_trylock(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Release a read lock.\n\n# Arguments\n\n* `rwl` -\nA pointer to the rwlock structure."]
    #[link_name = "rte_rwlock_read_unlock_w"]
    pub fn rte_rwlock_read_unlock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take a write lock.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure.\n\n# Returns\n\n- zero if the lock is successfully taken\n- -EBUSY if lock could not be acquired for writing because\nit was already locked for reading or writing"]
    #[link_name = "rte_rwlock_write_trylock_w"]
    pub fn rte_rwlock_write_trylock(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Take a write lock. Loop until the lock is held.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_write_lock_w"]
    pub fn rte_rwlock_write_lock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Release a write lock.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_write_unlock_w"]
    pub fn rte_rwlock_write_unlock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Test if the write lock is taken.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure.\n\n# Returns\n\n1 if the write lock is currently taken; 0 otherwise."]
    #[link_name = "rte_rwlock_write_is_locked_w"]
    pub fn rte_rwlock_write_is_locked(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it\nfails or not available take a read lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_read_lock_tm_w"]
    pub fn rte_rwlock_read_lock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the read lock if the lock is used as a fall-back\n\n# Arguments\n\n* `rwl` -\nA pointer to the rwlock structure."]
    #[link_name = "rte_rwlock_read_unlock_tm_w"]
    pub fn rte_rwlock_read_unlock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it\nfails or not available take a write lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory\ntransaction always aborts the transaction since the CPU is not able to\nroll-back should the transaction fail. Therefore, hardware transactional\nlocks are not advised to be used around rte_eth_rx_burst() and\nrte_eth_tx_burst() calls.\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_write_lock_tm_w"]
    pub fn rte_rwlock_write_lock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the write lock if the lock is used as a fall-back\n\n# Arguments\n\n* `rwl` -\nA pointer to a rwlock structure."]
    #[link_name = "rte_rwlock_write_unlock_tm_w"]
    pub fn rte_rwlock_write_unlock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Internal helpers used for lock annotations."]
    pub fn rte_mcfg_mem_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_tailq_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_mempool_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_timer_get_lock() -> *mut rte_spinlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_ethdev_get_lock() -> *mut rte_spinlock_t;
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_unlock();
}
unsafe extern "C" {
    #[doc = "Lock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_lock();
}
unsafe extern "C" {
    #[doc = "Unlock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_unlock();
}
unsafe extern "C" {
    #[doc = "If true, pages are put in single files (per memseg list),\nas opposed to creating a file per page."]
    pub fn rte_mcfg_get_single_file_segments() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_fbarray {
    #[doc = "< name associated with an array"]
    pub name: [::core::ffi::c_char; 64usize],
    #[doc = "< number of entries stored"]
    pub count: ::core::ffi::c_uint,
    #[doc = "< current length of the array"]
    pub len: ::core::ffi::c_uint,
    #[doc = "< size of each element"]
    pub elt_sz: ::core::ffi::c_uint,
    #[doc = "< data pointer"]
    pub data: *mut ::core::ffi::c_void,
    #[doc = "< multiprocess lock"]
    pub rwlock: rte_rwlock_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbarray"][::core::mem::size_of::<rte_fbarray>() - 96usize];
    ["Alignment of rte_fbarray"][::core::mem::align_of::<rte_fbarray>() - 8usize];
    ["Offset of field: rte_fbarray::name"][::core::mem::offset_of!(rte_fbarray, name) - 0usize];
    ["Offset of field: rte_fbarray::count"][::core::mem::offset_of!(rte_fbarray, count) - 64usize];
    ["Offset of field: rte_fbarray::len"][::core::mem::offset_of!(rte_fbarray, len) - 68usize];
    ["Offset of field: rte_fbarray::elt_sz"]
        [::core::mem::offset_of!(rte_fbarray, elt_sz) - 72usize];
    ["Offset of field: rte_fbarray::data"][::core::mem::offset_of!(rte_fbarray, data) - 80usize];
    ["Offset of field: rte_fbarray::rwlock"]
        [::core::mem::offset_of!(rte_fbarray, rwlock) - 88usize];
};
impl Default for rte_fbarray {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Set up ``rte_fbarray`` structure and allocate underlying resources.\nCall this function to correctly set up ``rte_fbarray`` and allocate\nunderlying files that will be backing the data in the current process. Note\nthat in order to use and share ``rte_fbarray`` between multiple processes,\ndata pointed to by ``arr`` pointer must itself be allocated in shared memory.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated ``rte_fbarray`` structure.\n* `name` -\nUnique name to be assigned to this array.\n* `len` -\nNumber of elements initially available in the array.\n* `elt_sz` -\nSize of each element.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_init(
        arr: *mut rte_fbarray,
        name: *const ::core::ffi::c_char,
        len: ::core::ffi::c_uint,
        elt_sz: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Attach to a file backing an already allocated and correctly set up\n``rte_fbarray`` structure.\nCall this function to attach to file that will be backing the data in the\ncurrent process. The structure must have been previously correctly set up\nwith a call to ``rte_fbarray_init()``. Calls to ``rte_fbarray_attach()`` are\nusually meant to be performed in a multiprocessing scenario, with data\npointed to by ``arr`` pointer allocated in shared memory.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up rte_fbarray structure.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_attach(arr: *mut rte_fbarray) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Deallocate resources for an already allocated and correctly set up\n``rte_fbarray`` structure, and remove the underlying file.\nCall this function to deallocate all resources associated with an\n``rte_fbarray`` structure within the current process. This will also\nzero-fill data pointed to by ``arr`` pointer and remove the underlying file\nbacking the data, so it is expected that by the time this function is called,\nall other processes have detached from this ``rte_fbarray``.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_destroy(arr: *mut rte_fbarray) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Deallocate resources for an already allocated and correctly set up\n``rte_fbarray`` structure.\nCall this function to deallocate all resources associated with an\n``rte_fbarray`` structure within current process.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_detach(arr: *mut rte_fbarray) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get pointer to element residing at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `idx` -\nIndex of an element to get a pointer to.\n\n# Returns\n\n- non-NULL pointer on success.\n- NULL on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_get(
        arr: *const rte_fbarray,
        idx: ::core::ffi::c_uint,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Find index of a specified element within the array.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `elt` -\nPointer to element to find index to.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_idx(
        arr: *const rte_fbarray,
        elt: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Mark specified element as used.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `idx` -\nElement index to mark as used.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_used(
        arr: *mut rte_fbarray,
        idx: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Mark specified element as free.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `idx` -\nElement index to mark as free.\n\n# Returns\n\n- 0 on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_free(
        arr: *mut rte_fbarray,
        idx: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check whether element at specified index is marked as used.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `idx` -\nElement index to check as used.\n\n# Returns\n\n- 1 if element is used.\n- 0 if element is unused.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_is_used(
        arr: *mut rte_fbarray,
        idx: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of next free element, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of next used element, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of next chunk of ``n`` free elements, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n* `n` -\nNumber of free elements to look for.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of next chunk of ``n`` used elements, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n* `n` -\nNumber of used elements to look for.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find how many more free entries there are, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find how many more used entries there are, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of previous free element, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of previous used element, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find lowest start index of chunk of ``n`` free elements, down from specified\nindex.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n* `n` -\nNumber of free elements to look for.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find lowest start index of chunk of ``n`` used elements, down from specified\nindex.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n* `n` -\nNumber of used elements to look for.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find how many more free entries there are before specified index (like\n``rte_fbarray_find_contig_free`` but going in reverse).\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find how many more used entries there are before specified index (like\n``rte_fbarray_find_contig_used`` but going in reverse).\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of biggest chunk of free elements, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of biggest chunk of used elements, starting at specified index.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of biggest chunk of free elements before a specified index (like\n``rte_fbarray_find_biggest_free``, but going in reverse).\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_free(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find index of biggest chunk of used elements before a specified index (like\n``rte_fbarray_find_biggest_used``, but going in reverse).\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `start` -\nElement index to start search from.\n\n# Returns\n\n- non-negative integer on success.\n- -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_used(
        arr: *mut rte_fbarray,
        start: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump ``rte_fbarray`` metadata.\n\n# Arguments\n\n* `arr` -\nValid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n* `f` -\nFile object to dump information into."]
    pub fn rte_fbarray_dump_metadata(arr: *mut rte_fbarray, f: *mut FILE);
}
#[doc = "Physical memory segment descriptor."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memseg {
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub anon1: rte_memseg__bindgen_ty_1,
    #[doc = "< Length of the segment."]
    pub len: usize,
    #[doc = "< The pagesize of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Number of channels."]
    pub nchannel: u32,
    #[doc = "< Number of ranks."]
    pub nrank: u32,
    #[doc = "< Memseg-specific flags"]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::core::ffi::c_void,
    #[doc = "< Makes sure addr is always 64 bits"]
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg__bindgen_ty_1"]
        [::core::mem::size_of::<rte_memseg__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memseg__bindgen_ty_1"]
        [::core::mem::align_of::<rte_memseg__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memseg__bindgen_ty_1::addr"]
        [::core::mem::offset_of!(rte_memseg__bindgen_ty_1, addr) - 0usize];
    ["Offset of field: rte_memseg__bindgen_ty_1::addr_64"]
        [::core::mem::offset_of!(rte_memseg__bindgen_ty_1, addr_64) - 0usize];
};
impl Default for rte_memseg__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg"][::core::mem::size_of::<rte_memseg>() - 48usize];
    ["Alignment of rte_memseg"][::core::mem::align_of::<rte_memseg>() - 1usize];
    ["Offset of field: rte_memseg::iova"][::core::mem::offset_of!(rte_memseg, iova) - 0usize];
    ["Offset of field: rte_memseg::len"][::core::mem::offset_of!(rte_memseg, len) - 16usize];
    ["Offset of field: rte_memseg::hugepage_sz"]
        [::core::mem::offset_of!(rte_memseg, hugepage_sz) - 24usize];
    ["Offset of field: rte_memseg::socket_id"]
        [::core::mem::offset_of!(rte_memseg, socket_id) - 32usize];
    ["Offset of field: rte_memseg::nchannel"]
        [::core::mem::offset_of!(rte_memseg, nchannel) - 36usize];
    ["Offset of field: rte_memseg::nrank"][::core::mem::offset_of!(rte_memseg, nrank) - 40usize];
    ["Offset of field: rte_memseg::flags"][::core::mem::offset_of!(rte_memseg, flags) - 44usize];
};
impl Default for rte_memseg {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "memseg list is a special case as we need to store a bunch of other data\ntogether with the array itself."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_memseg_list {
    pub anon1: rte_memseg_list__bindgen_ty_1,
    #[doc = "< Page size for all memsegs in this list."]
    pub page_sz: u64,
    #[doc = "< Socket ID for all memsegs in this list."]
    pub socket_id: ::core::ffi::c_int,
    #[doc = "< version number for multiprocess sync."]
    pub version: u32,
    #[doc = "< Length of memory area covered by this memseg list."]
    pub len: usize,
    #[doc = "< 1 if this list points to external memory"]
    pub external: ::core::ffi::c_uint,
    #[doc = "< 1 if this list points to a heap"]
    pub heap: ::core::ffi::c_uint,
    pub memseg_arr: rte_fbarray,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg_list__bindgen_ty_1 {
    pub base_va: *mut ::core::ffi::c_void,
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg_list__bindgen_ty_1"]
        [::core::mem::size_of::<rte_memseg_list__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memseg_list__bindgen_ty_1"]
        [::core::mem::align_of::<rte_memseg_list__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memseg_list__bindgen_ty_1::base_va"]
        [::core::mem::offset_of!(rte_memseg_list__bindgen_ty_1, base_va) - 0usize];
    ["Offset of field: rte_memseg_list__bindgen_ty_1::addr_64"]
        [::core::mem::offset_of!(rte_memseg_list__bindgen_ty_1, addr_64) - 0usize];
};
impl Default for rte_memseg_list__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg_list"][::core::mem::size_of::<rte_memseg_list>() - 136usize];
    ["Alignment of rte_memseg_list"][::core::mem::align_of::<rte_memseg_list>() - 8usize];
    ["Offset of field: rte_memseg_list::page_sz"]
        [::core::mem::offset_of!(rte_memseg_list, page_sz) - 8usize];
    ["Offset of field: rte_memseg_list::socket_id"]
        [::core::mem::offset_of!(rte_memseg_list, socket_id) - 16usize];
    ["Offset of field: rte_memseg_list::version"]
        [::core::mem::offset_of!(rte_memseg_list, version) - 20usize];
    ["Offset of field: rte_memseg_list::len"]
        [::core::mem::offset_of!(rte_memseg_list, len) - 24usize];
    ["Offset of field: rte_memseg_list::external"]
        [::core::mem::offset_of!(rte_memseg_list, external) - 32usize];
    ["Offset of field: rte_memseg_list::heap"]
        [::core::mem::offset_of!(rte_memseg_list, heap) - 36usize];
    ["Offset of field: rte_memseg_list::memseg_arr"]
        [::core::mem::offset_of!(rte_memseg_list, memseg_arr) - 40usize];
};
impl Default for rte_memseg_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Lock page in physical memory and prevent from swapping.\n\n# Arguments\n\n* `virt` -\nThe virtual address.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_mem_lock_page(virt: *const ::core::ffi::c_void) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get physical address of any mapped virtual address in the current process.\nIt is found by browsing the /proc/self/pagemap special file.\nThe page must be locked.\n\n# Arguments\n\n* `virt` -\nThe virtual address.\n\n# Returns\n\nThe physical address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2phy(virt: *const ::core::ffi::c_void) -> phys_addr_t;
}
unsafe extern "C" {
    #[doc = "Get IO virtual address of any mapped virtual address in the current process.\n> **Note** This function will not check internal page table. Instead, in IOVA as\nPA mode, it will fall back to getting real physical address (which may\nnot match the expected IOVA, such as what was specified for external\nmemory).\n\n# Arguments\n\n* `virt` -\nThe virtual address.\n\n# Returns\n\nThe IO address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2iova(virt: *const ::core::ffi::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Get virtual memory address corresponding to iova address.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n\n# Arguments\n\n* `iova` -\nThe iova address.\n\n# Returns\n\nVirtual address corresponding to iova address (or NULL if address does not\nexist within DPDK memory map)."]
    pub fn rte_mem_iova2virt(iova: rte_iova_t) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Get memseg to which a particular virtual address belongs.\n\n# Arguments\n\n* `virt` -\nThe virtual address.\n* `msl` -\nThe memseg list in which to look up based on ``virt`` address\n(can be NULL).\n\n# Returns\n\nMemseg pointer on success, or NULL on error."]
    pub fn rte_mem_virt2memseg(
        virt: *const ::core::ffi::c_void,
        msl: *const rte_memseg_list,
    ) -> *mut rte_memseg;
}
unsafe extern "C" {
    #[doc = "Get memseg list corresponding to virtual memory address.\n\n# Arguments\n\n* `virt` -\nThe virtual address.\n\n# Returns\n\nMemseg list to which this virtual address belongs to."]
    pub fn rte_mem_virt2memseg_list(virt: *const ::core::ffi::c_void) -> *mut rte_memseg_list;
}
#[doc = "Memseg walk function prototype.\nReturning 0 will continue walk\nReturning 1 will stop the walk\nReturning -1 will stop the walk and report error"]
pub type rte_memseg_walk_t = ::core::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Memseg contig walk function prototype. This will trigger a callback on every\nVA-contiguous area starting at memseg ``ms``, so total valid VA space at each\ncallback call will be [``ms->addr``, ``ms->addr + len``).\nReturning 0 will continue walk\nReturning 1 will stop the walk\nReturning -1 will stop the walk and report error"]
pub type rte_memseg_contig_walk_t = ::core::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        len: usize,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Memseg list walk function prototype. This will trigger a callback on every\nallocated memseg list.\nReturning 0 will continue walk\nReturning 1 will stop the walk\nReturning -1 will stop the walk and report error"]
pub type rte_memseg_list_walk_t = ::core::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Walk list of all memsegs.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n> **Note** This function will also walk through externally allocated segments. It\nis up to the user to decide whether to skip through these segments.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_walk(
        func: rte_memseg_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Walk each VA-contiguous area.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n> **Note** This function will also walk through externally allocated segments. It\nis up to the user to decide whether to skip through these segments.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_contig_walk(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Walk each allocated memseg list.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n> **Note** This function will also walk through externally allocated segments. It\nis up to the user to decide whether to skip through these segments.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_list_walk(
        func: rte_memseg_list_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Walk list of all memsegs without performing any locking.\n> **Note** This function does not perform any locking, and is only safe to call\nfrom within memory-related callback functions.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_walk_thread_unsafe(
        func: rte_memseg_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Walk each VA-contiguous area without performing any locking.\n> **Note** This function does not perform any locking, and is only safe to call\nfrom within memory-related callback functions.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_contig_walk_thread_unsafe(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Walk each allocated memseg list without performing any locking.\n> **Note** This function does not perform any locking, and is only safe to call\nfrom within memory-related callback functions.\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator\n\n# Returns\n\n0 if walked over the entire list\n1 if stopped by the user\n-1 if user function reported error"]
    pub fn rte_memseg_list_walk_thread_unsafe(
        func: rte_memseg_list_walk_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return file descriptor associated with a particular memseg (if available).\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n> **Note** This returns an internal file descriptor. Performing any operations on\nthis file descriptor is inherently dangerous, so it should be treated\nas read-only for all intents and purposes.\n\n# Arguments\n\n* `ms` -\nA pointer to memseg for which to get file descriptor.\n\n# Returns\n\nValid file descriptor in case of success.\n-1 in case of error, with ``rte_errno`` set to the following values:\n- EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n- ENODEV  - ``ms`` fd is not available\n- ENOENT  - ``ms`` is an unused segment\n- ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd(ms: *const rte_memseg) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return file descriptor associated with a particular memseg (if available).\n> **Note** This function does not perform any locking, and is only safe to call\nfrom within memory-related callback functions.\n> **Note** This returns an internal file descriptor. Performing any operations on\nthis file descriptor is inherently dangerous, so it should be treated\nas read-only for all intents and purposes.\n\n# Arguments\n\n* `ms` -\nA pointer to memseg for which to get file descriptor.\n\n# Returns\n\nValid file descriptor in case of success.\n-1 in case of error, with ``rte_errno`` set to the following values:\n- EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n- ENODEV  - ``ms`` fd is not available\n- ENOENT  - ``ms`` is an unused segment\n- ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_thread_unsafe(ms: *const rte_memseg) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get offset into segment file descriptor associated with a particular memseg\n(if available).\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n\n# Arguments\n\n* `ms` -\nA pointer to memseg for which to get file descriptor.\n* `offset` -\nA pointer to offset value where the result will be stored.\n\n# Returns\n\nValid file descriptor in case of success.\n-1 in case of error, with ``rte_errno`` set to the following values:\n- EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n- EINVAL  - ``offset`` pointer was NULL\n- ENODEV  - ``ms`` fd is not available\n- ENOENT  - ``ms`` is an unused segment\n- ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get offset into segment file descriptor associated with a particular memseg\n(if available).\n> **Note** This function does not perform any locking, and is only safe to call\nfrom within memory-related callback functions.\n\n# Arguments\n\n* `ms` -\nA pointer to memseg for which to get file descriptor.\n* `offset` -\nA pointer to offset value where the result will be stored.\n\n# Returns\n\nValid file descriptor in case of success.\n-1 in case of error, with ``rte_errno`` set to the following values:\n- EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n- EINVAL  - ``offset`` pointer was NULL\n- ENODEV  - ``ms`` fd is not available\n- ENOENT  - ``ms`` is an unused segment\n- ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset_thread_unsafe(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register external memory chunk with DPDK.\n> **Note** Using this API is mutually exclusive with ``rte_malloc`` family of\nAPI's.\n> **Note** This API will not perform any DMA mapping. It is expected that user\nwill do that themselves.\n> **Note** Before accessing this memory in other processes, it needs to be\nattached in each of those processes by calling ``rte_extmem_attach`` in\neach other process.\n\n# Arguments\n\n* `va_addr` -\nStart of virtual area to register. Must be aligned by ``page_sz``.\n* `len` -\nLength of virtual area to register. Must be aligned by ``page_sz``.\n* `iova_addrs` -\nArray of page IOVA addresses corresponding to each page in this memory\narea. Can be NULL, in which case page IOVA addresses will be set to\nRTE_BAD_IOVA.\n* `n_pages` -\nNumber of elements in the iova_addrs array. Ignored if  ``iova_addrs``\nis NULL.\n* `page_sz` -\nPage size of the underlying memory\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nEEXIST - memory chunk is already registered\nENOSPC - no more space in internal config to store a new memory chunk"]
    pub fn rte_extmem_register(
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
        iova_addrs: *mut rte_iova_t,
        n_pages: ::core::ffi::c_uint,
        page_sz: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister external memory chunk with DPDK.\n> **Note** Using this API is mutually exclusive with ``rte_malloc`` family of\nAPI's.\n> **Note** This API will not perform any DMA unmapping. It is expected that user\nwill do that themselves.\n> **Note** Before calling this function, all other processes must call\n``rte_extmem_detach`` to detach from the memory area.\n\n# Arguments\n\n* `va_addr` -\nStart of virtual area to unregister\n* `len` -\nLength of virtual area to unregister\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nENOENT - memory chunk was not found"]
    pub fn rte_extmem_unregister(
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Attach to external memory chunk registered in another process.\n> **Note** Using this API is mutually exclusive with ``rte_malloc`` family of\nAPI's.\n> **Note** This API will not perform any DMA mapping. It is expected that user\nwill do that themselves.\n\n# Arguments\n\n* `va_addr` -\nStart of virtual area to register\n* `len` -\nLength of virtual area to register\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nENOENT - memory chunk was not found"]
    pub fn rte_extmem_attach(va_addr: *mut ::core::ffi::c_void, len: usize) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Detach from external memory chunk registered in another process.\n> **Note** Using this API is mutually exclusive with ``rte_malloc`` family of\nAPI's.\n> **Note** This API will not perform any DMA unmapping. It is expected that user\nwill do that themselves.\n\n# Arguments\n\n* `va_addr` -\nStart of virtual area to unregister\n* `len` -\nLength of virtual area to unregister\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nENOENT - memory chunk was not found"]
    pub fn rte_extmem_detach(va_addr: *mut ::core::ffi::c_void, len: usize) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the physical memory layout to a file.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_dump_physmem_layout(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Get the total amount of available physical memory.\n> **Note** This function read-locks the memory hotplug subsystem, and thus cannot\nbe used within memory-related callback functions.\n\n# Returns\n\nThe total amount of available physical memory in bytes."]
    pub fn rte_eal_get_physmem_size() -> u64;
}
unsafe extern "C" {
    #[doc = "Get the number of memory channels.\n\n# Returns\n\nThe number of memory channels on the system. The value is 0 if unknown\nor not the same on all devices."]
    pub fn rte_memory_get_nchannel() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the number of memory ranks.\n\n# Returns\n\nThe number of memory ranks on the system. The value is 0 if unknown or\nnot the same on all devices."]
    pub fn rte_memory_get_nrank() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Check if all currently allocated memory segments are compliant with\nsupplied DMA address width.\n\n# Arguments\n\n* `maskbits` -\nAddress width to check against."]
    pub fn rte_mem_check_dma_mask(maskbits: u8) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if all currently allocated memory segments are compliant with\nsupplied DMA address width. This function will use\nrte_memseg_walk_thread_unsafe instead of rte_memseg_walk implying\nmemory_hotplug_lock will not be acquired avoiding deadlock during\nmemory initialization.\nThis function is just for EAL core memory internal use. Drivers should\nuse the previous rte_mem_check_dma_mask.\n\n# Arguments\n\n* `maskbits` -\nAddress width to check against."]
    pub fn rte_mem_check_dma_mask_thread_unsafe(maskbits: u8) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set dma mask to use once memory initialization is done. Previous functions\nrte_mem_check_dma_mask and rte_mem_check_dma_mask_thread_unsafe can not be\nused safely until memory has been initialized."]
    pub fn rte_mem_set_dma_mask(maskbits: u8);
}
unsafe extern "C" {
    #[doc = "Drivers based on uio will not load unless physical\naddresses are obtainable. It is only possible to get\nphysical addresses when running as a privileged user.\n\n# Returns\n\n1 if the system is able to obtain physical addresses.\n0 if using DMA addresses through an IOMMU."]
    pub fn rte_eal_using_phys_addrs() -> ::core::ffi::c_int;
}
pub mod rte_mem_event {
    #[doc = "Enum indicating which kind of memory event has happened. Used by callbacks to\ndistinguish between memory allocations and deallocations."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Allocation event."]
    pub const RTE_MEM_EVENT_ALLOC: Type = 0;
    #[doc = "< Deallocation event."]
    pub const RTE_MEM_EVENT_FREE: Type = 1;
}
#[doc = "Function typedef used to register callbacks for memory events."]
pub type rte_mem_event_callback_t = ::core::option::Option<
    unsafe extern "C" fn(
        event_type: rte_mem_event::Type,
        addr: *const ::core::ffi::c_void,
        len: usize,
        arg: *mut ::core::ffi::c_void,
    ),
>;
unsafe extern "C" {
    #[doc = "Function used to register callbacks for memory events.\n> **Note** callbacks will happen while memory hotplug subsystem is write-locked,\ntherefore some functions (e.g. `rte_memseg_walk()`) will cause a\ndeadlock when called from within such callbacks.\n> **Note** mem event callbacks not being supported is an expected error condition,\nso user code needs to handle this situation. In these cases, return\nvalue will be -1, and rte_errno will be set to ENOTSUP.\n\n# Arguments\n\n* `name` -\nName associated with specified callback to be added to the list.\n* `clb` -\nCallback function pointer.\n* `arg` -\nArgument to pass to the callback.\n\n# Returns\n\n0 on successful callback register\n-1 on unsuccessful callback register, with rte_errno value indicating\nreason for failure."]
    pub fn rte_mem_event_callback_register(
        name: *const ::core::ffi::c_char,
        clb: rte_mem_event_callback_t,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Function used to unregister callbacks for memory events.\n\n# Arguments\n\n* `name` -\nName associated with specified callback to be removed from the list.\n* `arg` -\nArgument to look for among callbacks with specified callback name.\n\n# Returns\n\n0 on successful callback unregister\n-1 on unsuccessful callback unregister, with rte_errno value indicating\nreason for failure."]
    pub fn rte_mem_event_callback_unregister(
        name: *const ::core::ffi::c_char,
        arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
#[doc = "Function typedef used to register memory allocation validation callbacks.\nReturning 0 will allow allocation attempt to continue. Returning -1 will\nprevent allocation from succeeding."]
pub type rte_mem_alloc_validator_t = ::core::option::Option<
    unsafe extern "C" fn(
        socket_id: ::core::ffi::c_int,
        cur_limit: usize,
        new_len: usize,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Register validator callback for memory allocations.\nCallbacks registered by this function will be called right before memory\nallocator is about to trigger allocation of more pages from the system if\nsaid allocation will bring total memory usage above specified limit on\nspecified socket. User will be able to cancel pending allocation if callback\nreturns -1.\n> **Note** callbacks will happen while memory hotplug subsystem is write-locked,\ntherefore some functions (e.g. `rte_memseg_walk()`) will cause a\ndeadlock when called from within such callbacks.\n> **Note** validator callbacks not being supported is an expected error condition,\nso user code needs to handle this situation. In these cases, return\nvalue will be -1, and rte_errno will be set to ENOTSUP.\n\n# Arguments\n\n* `name` -\nName associated with specified callback to be added to the list.\n* `clb` -\nCallback function pointer.\n* `socket_id` -\nSocket ID on which to watch for allocations.\n* `limit` -\nLimit above which to trigger callbacks.\n\n# Returns\n\n0 on successful callback register\n-1 on unsuccessful callback register, with rte_errno value indicating\nreason for failure."]
    pub fn rte_mem_alloc_validator_register(
        name: *const ::core::ffi::c_char,
        clb: rte_mem_alloc_validator_t,
        socket_id: ::core::ffi::c_int,
        limit: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister validator callback for memory allocations.\n\n# Arguments\n\n* `name` -\nName associated with specified callback to be removed from the list.\n* `socket_id` -\nSocket ID on which to watch for allocations.\n\n# Returns\n\n0 on successful callback unregister\n-1 on unsuccessful callback unregister, with rte_errno value indicating\nreason for failure."]
    pub fn rte_mem_alloc_validator_unregister(
        name: *const ::core::ffi::c_char,
        socket_id: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
#[doc = "A structure describing a memzone, which is a contiguous portion of\nphysical memory identified by a name."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memzone {
    #[doc = "< Name of the memory zone."]
    pub name: [::core::ffi::c_char; 32usize],
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub anon1: rte_memzone__bindgen_ty_1,
    #[doc = "< Length of the memzone."]
    pub len: usize,
    #[doc = "< The page size of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Characteristics of this memzone."]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memzone__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::core::ffi::c_void,
    #[doc = "< Makes sure addr is always 64-bits"]
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memzone__bindgen_ty_1"]
        [::core::mem::size_of::<rte_memzone__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memzone__bindgen_ty_1"]
        [::core::mem::align_of::<rte_memzone__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memzone__bindgen_ty_1::addr"]
        [::core::mem::offset_of!(rte_memzone__bindgen_ty_1, addr) - 0usize];
    ["Offset of field: rte_memzone__bindgen_ty_1::addr_64"]
        [::core::mem::offset_of!(rte_memzone__bindgen_ty_1, addr_64) - 0usize];
};
impl Default for rte_memzone__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memzone"][::core::mem::size_of::<rte_memzone>() - 72usize];
    ["Alignment of rte_memzone"][::core::mem::align_of::<rte_memzone>() - 1usize];
    ["Offset of field: rte_memzone::name"][::core::mem::offset_of!(rte_memzone, name) - 0usize];
    ["Offset of field: rte_memzone::iova"][::core::mem::offset_of!(rte_memzone, iova) - 32usize];
    ["Offset of field: rte_memzone::len"][::core::mem::offset_of!(rte_memzone, len) - 48usize];
    ["Offset of field: rte_memzone::hugepage_sz"]
        [::core::mem::offset_of!(rte_memzone, hugepage_sz) - 56usize];
    ["Offset of field: rte_memzone::socket_id"]
        [::core::mem::offset_of!(rte_memzone, socket_id) - 64usize];
    ["Offset of field: rte_memzone::flags"][::core::mem::offset_of!(rte_memzone, flags) - 68usize];
};
impl Default for rte_memzone {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Set the maximum number of memzones.\nThis function can only be called prior to rte_eal_init().\n\n# Arguments\n\n* `max` -\nMaximum number of memzones.\n\n# Returns\n\n0 on success, -1 otherwise."]
    pub fn rte_memzone_max_set(max: usize) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the maximum number of memzones.\n@note: The maximum value will not change after calling rte_eal_init().\n\n# Returns\n\nMaximum number of memzones."]
    pub fn rte_memzone_max_get() -> usize;
}
unsafe extern "C" {
    #[doc = "Reserve a portion of physical memory.\nThis function reserves some memory and returns a pointer to a\ncorrectly filled memzone descriptor. If the allocation cannot be\ndone, return NULL.\n> **Note** Reserving memzones with len set to 0 will only attempt to allocate\nmemzones from memory that is already available. It will not trigger any\nnew allocations.\n@note: When reserving memzones with len set to 0, it is preferable to also\nset a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\nwill likely not yield expected results. Specifically, the resulting memzone\nmay not necessarily be the biggest memzone available, but rather biggest\nmemzone available on socket id corresponding to an lcore from which\nreservation was called.\n\n# Arguments\n\n* `name` -\nThe name of the memzone. If it already exists, the function will\nfail and return NULL.\n* `len` -\nThe size of the memory to be reserved. If it\nis 0, the biggest contiguous zone will be reserved.\n* `socket_id` -\nThe socket identifier in the case of\nNUMA. The value can be SOCKET_ID_ANY if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nThe flags parameter is used to request memzones to be\ntaken from specifically sized hugepages.\n- RTE_MEMZONE_2MB - Reserved from 2MB pages\n- RTE_MEMZONE_1GB - Reserved from 1GB pages\n- RTE_MEMZONE_16MB - Reserved from 16MB pages\n- RTE_MEMZONE_16GB - Reserved from 16GB pages\n- RTE_MEMZONE_256KB - Reserved from 256KB pages\n- RTE_MEMZONE_256MB - Reserved from 256MB pages\n- RTE_MEMZONE_512MB - Reserved from 512MB pages\n- RTE_MEMZONE_4GB - Reserved from 4GB pages\n- RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\nthe requested page size is unavailable.\nIf this flag is not set, the function\nwill return error on an unavailable size\nrequest.\n- RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\nThis option should be used when allocating\nmemory intended for hardware rings etc.\n\n# Returns\n\nA pointer to a correctly-filled read-only memzone descriptor, or NULL\non error.\nOn error case, rte_errno will be set appropriately:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone\n- EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve(
        name: *const ::core::ffi::c_char,
        len: usize,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = "Reserve a portion of physical memory with alignment on a specified\nboundary.\nThis function reserves some memory with alignment on a specified\nboundary, and returns a pointer to a correctly filled memzone\ndescriptor. If the allocation cannot be done or if the alignment\nis not a power of 2, returns NULL.\n> **Note** Reserving memzones with len set to 0 will only attempt to allocate\nmemzones from memory that is already available. It will not trigger any\nnew allocations.\n@note: When reserving memzones with len set to 0, it is preferable to also\nset a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\nwill likely not yield expected results. Specifically, the resulting memzone\nmay not necessarily be the biggest memzone available, but rather biggest\nmemzone available on socket id corresponding to an lcore from which\nreservation was called.\n\n# Arguments\n\n* `name` -\nThe name of the memzone. If it already exists, the function will\nfail and return NULL.\n* `len` -\nThe size of the memory to be reserved. If it\nis 0, the biggest contiguous zone will be reserved.\n* `socket_id` -\nThe socket identifier in the case of\nNUMA. The value can be SOCKET_ID_ANY if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nThe flags parameter is used to request memzones to be\ntaken from specifically sized hugepages.\n- RTE_MEMZONE_2MB - Reserved from 2MB pages\n- RTE_MEMZONE_1GB - Reserved from 1GB pages\n- RTE_MEMZONE_16MB - Reserved from 16MB pages\n- RTE_MEMZONE_16GB - Reserved from 16GB pages\n- RTE_MEMZONE_256KB - Reserved from 256KB pages\n- RTE_MEMZONE_256MB - Reserved from 256MB pages\n- RTE_MEMZONE_512MB - Reserved from 512MB pages\n- RTE_MEMZONE_4GB - Reserved from 4GB pages\n- RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\nthe requested page size is unavailable.\nIf this flag is not set, the function\nwill return error on an unavailable size\nrequest.\n- RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\nThis option should be used when allocating\nmemory intended for hardware rings etc.\n* `align` -\nAlignment for resulting memzone. Must be a power of 2.\n\n# Returns\n\nA pointer to a correctly-filled read-only memzone descriptor, or NULL\non error.\nOn error case, rte_errno will be set appropriately:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone\n- EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_aligned(
        name: *const ::core::ffi::c_char,
        len: usize,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
        align: ::core::ffi::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = "Reserve a portion of physical memory with specified alignment and\nboundary.\nThis function reserves some memory with specified alignment and\nboundary, and returns a pointer to a correctly filled memzone\ndescriptor. If the allocation cannot be done or if the alignment\nor boundary are not a power of 2, returns NULL.\nMemory buffer is reserved in a way, that it wouldn't cross specified\nboundary. That implies that requested length should be less or equal\nthen boundary.\n> **Note** Reserving memzones with len set to 0 will only attempt to allocate\nmemzones from memory that is already available. It will not trigger any\nnew allocations.\n@note: When reserving memzones with len set to 0, it is preferable to also\nset a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\nwill likely not yield expected results. Specifically, the resulting memzone\nmay not necessarily be the biggest memzone available, but rather biggest\nmemzone available on socket id corresponding to an lcore from which\nreservation was called.\n\n# Arguments\n\n* `name` -\nThe name of the memzone. If it already exists, the function will\nfail and return NULL.\n* `len` -\nThe size of the memory to be reserved. If it\nis 0, the biggest contiguous zone will be reserved.\n* `socket_id` -\nThe socket identifier in the case of\nNUMA. The value can be SOCKET_ID_ANY if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nThe flags parameter is used to request memzones to be\ntaken from specifically sized hugepages.\n- RTE_MEMZONE_2MB - Reserved from 2MB pages\n- RTE_MEMZONE_1GB - Reserved from 1GB pages\n- RTE_MEMZONE_16MB - Reserved from 16MB pages\n- RTE_MEMZONE_16GB - Reserved from 16GB pages\n- RTE_MEMZONE_256KB - Reserved from 256KB pages\n- RTE_MEMZONE_256MB - Reserved from 256MB pages\n- RTE_MEMZONE_512MB - Reserved from 512MB pages\n- RTE_MEMZONE_4GB - Reserved from 4GB pages\n- RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\nthe requested page size is unavailable.\nIf this flag is not set, the function\nwill return error on an unavailable size\nrequest.\n- RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\nThis option should be used when allocating\nmemory intended for hardware rings etc.\n* `align` -\nAlignment for resulting memzone. Must be a power of 2.\n* `bound` -\nBoundary for resulting memzone. Must be a power of 2 or zero.\nZero value implies no boundary condition.\n\n# Returns\n\nA pointer to a correctly-filled read-only memzone descriptor, or NULL\non error.\nOn error case, rte_errno will be set appropriately:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone\n- EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_bounded(
        name: *const ::core::ffi::c_char,
        len: usize,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
        align: ::core::ffi::c_uint,
        bound: ::core::ffi::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = "Free a memzone.\n\n# Arguments\n\n* `mz` -\nA pointer to the memzone\n\n# Returns\n\n-EINVAL - invalid parameter.\n0 - success"]
    pub fn rte_memzone_free(mz: *const rte_memzone) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Lookup for a memzone.\nGet a pointer to a descriptor of an already reserved memory\nzone identified by the name given as an argument.\n\n# Arguments\n\n* `name` -\nThe name of the memzone.\n\n# Returns\n\nA pointer to a read-only memzone descriptor."]
    pub fn rte_memzone_lookup(name: *const ::core::ffi::c_char) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = "Dump all reserved memzones to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_memzone_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Walk list of all memzones\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator"]
    pub fn rte_memzone_walk(
        func: ::core::option::Option<
            unsafe extern "C" fn(arg1: *const rte_memzone, arg: *mut ::core::ffi::c_void),
        >,
        arg: *mut ::core::ffi::c_void,
    );
}
pub mod rte_ring_queue_behavior {
    #[doc = "enqueue/dequeue behavior types"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Enq/Deq a fixed number of items from a ring"]
    pub const RTE_RING_QUEUE_FIXED: Type = 0;
    #[doc = "Enq/Deq as many items as possible from ring"]
    pub const RTE_RING_QUEUE_VARIABLE: Type = 1;
}
pub mod rte_ring_sync_type {
    #[doc = "prod/cons sync types"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< multi-thread safe (default mode)"]
    pub const RTE_RING_SYNC_MT: Type = 0;
    #[doc = "< single thread only"]
    pub const RTE_RING_SYNC_ST: Type = 1;
    #[doc = "< multi-thread relaxed tail sync"]
    pub const RTE_RING_SYNC_MT_RTS: Type = 2;
    #[doc = "< multi-thread head/tail sync"]
    pub const RTE_RING_SYNC_MT_HTS: Type = 3;
}
#[doc = "structures to hold a pair of head/tail values and other metadata.\nDepending on sync_type format of that structure might be different,\nbut offset for *sync_type* and *tail* values should remain the same."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_headtail {
    #[doc = "< prod/consumer head."]
    pub head: u32,
    #[doc = "< prod/consumer tail."]
    pub tail: u32,
    pub anon1: rte_ring_headtail__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ring_headtail__bindgen_ty_1 {
    #[doc = "sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type::Type,
    #[doc = "deprecated -  True if single prod/cons"]
    pub single: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_headtail__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ring_headtail__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ring_headtail__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ring_headtail__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ring_headtail__bindgen_ty_1::sync_type"]
        [::core::mem::offset_of!(rte_ring_headtail__bindgen_ty_1, sync_type) - 0usize];
    ["Offset of field: rte_ring_headtail__bindgen_ty_1::single"]
        [::core::mem::offset_of!(rte_ring_headtail__bindgen_ty_1, single) - 0usize];
};
impl Default for rte_ring_headtail__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_headtail"][::core::mem::size_of::<rte_ring_headtail>() - 12usize];
    ["Alignment of rte_ring_headtail"][::core::mem::align_of::<rte_ring_headtail>() - 4usize];
    ["Offset of field: rte_ring_headtail::head"]
        [::core::mem::offset_of!(rte_ring_headtail, head) - 0usize];
    ["Offset of field: rte_ring_headtail::tail"]
        [::core::mem::offset_of!(rte_ring_headtail, tail) - 4usize];
};
impl Default for rte_ring_headtail {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_rts_poscnt {
    #[doc = "raw 8B value to read/write *cnt* and *pos* as one atomic op"]
    pub raw: u64,
    pub val: __rte_ring_rts_poscnt__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct __rte_ring_rts_poscnt__bindgen_ty_1 {
    #[doc = "< head/tail reference counter"]
    pub cnt: u32,
    #[doc = "< head/tail position"]
    pub pos: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_rts_poscnt__bindgen_ty_1"]
        [::core::mem::size_of::<__rte_ring_rts_poscnt__bindgen_ty_1>() - 8usize];
    ["Alignment of __rte_ring_rts_poscnt__bindgen_ty_1"]
        [::core::mem::align_of::<__rte_ring_rts_poscnt__bindgen_ty_1>() - 4usize];
    ["Offset of field: __rte_ring_rts_poscnt__bindgen_ty_1::cnt"]
        [::core::mem::offset_of!(__rte_ring_rts_poscnt__bindgen_ty_1, cnt) - 0usize];
    ["Offset of field: __rte_ring_rts_poscnt__bindgen_ty_1::pos"]
        [::core::mem::offset_of!(__rte_ring_rts_poscnt__bindgen_ty_1, pos) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_rts_poscnt"][::core::mem::size_of::<__rte_ring_rts_poscnt>() - 8usize];
    ["Alignment of __rte_ring_rts_poscnt"]
        [::core::mem::align_of::<__rte_ring_rts_poscnt>() - 8usize];
    ["Offset of field: __rte_ring_rts_poscnt::raw"]
        [::core::mem::offset_of!(__rte_ring_rts_poscnt, raw) - 0usize];
    ["Offset of field: __rte_ring_rts_poscnt::val"]
        [::core::mem::offset_of!(__rte_ring_rts_poscnt, val) - 0usize];
};
impl Default for __rte_ring_rts_poscnt {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_rts_headtail {
    pub tail: __rte_ring_rts_poscnt,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type::Type,
    #[doc = "< max allowed distance between head/tail"]
    pub htd_max: u32,
    pub head: __rte_ring_rts_poscnt,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_rts_headtail"][::core::mem::size_of::<rte_ring_rts_headtail>() - 24usize];
    ["Alignment of rte_ring_rts_headtail"]
        [::core::mem::align_of::<rte_ring_rts_headtail>() - 8usize];
    ["Offset of field: rte_ring_rts_headtail::tail"]
        [::core::mem::offset_of!(rte_ring_rts_headtail, tail) - 0usize];
    ["Offset of field: rte_ring_rts_headtail::sync_type"]
        [::core::mem::offset_of!(rte_ring_rts_headtail, sync_type) - 8usize];
    ["Offset of field: rte_ring_rts_headtail::htd_max"]
        [::core::mem::offset_of!(rte_ring_rts_headtail, htd_max) - 12usize];
    ["Offset of field: rte_ring_rts_headtail::head"]
        [::core::mem::offset_of!(rte_ring_rts_headtail, head) - 16usize];
};
impl Default for rte_ring_rts_headtail {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_hts_pos {
    #[doc = "raw 8B value to read/write *head* and *tail* as one atomic op"]
    pub raw: u64,
    pub pos: __rte_ring_hts_pos__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct __rte_ring_hts_pos__bindgen_ty_1 {
    #[doc = "< head position"]
    pub head: u32,
    #[doc = "< tail position"]
    pub tail: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_hts_pos__bindgen_ty_1"]
        [::core::mem::size_of::<__rte_ring_hts_pos__bindgen_ty_1>() - 8usize];
    ["Alignment of __rte_ring_hts_pos__bindgen_ty_1"]
        [::core::mem::align_of::<__rte_ring_hts_pos__bindgen_ty_1>() - 4usize];
    ["Offset of field: __rte_ring_hts_pos__bindgen_ty_1::head"]
        [::core::mem::offset_of!(__rte_ring_hts_pos__bindgen_ty_1, head) - 0usize];
    ["Offset of field: __rte_ring_hts_pos__bindgen_ty_1::tail"]
        [::core::mem::offset_of!(__rte_ring_hts_pos__bindgen_ty_1, tail) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_hts_pos"][::core::mem::size_of::<__rte_ring_hts_pos>() - 8usize];
    ["Alignment of __rte_ring_hts_pos"][::core::mem::align_of::<__rte_ring_hts_pos>() - 8usize];
    ["Offset of field: __rte_ring_hts_pos::raw"]
        [::core::mem::offset_of!(__rte_ring_hts_pos, raw) - 0usize];
    ["Offset of field: __rte_ring_hts_pos::pos"]
        [::core::mem::offset_of!(__rte_ring_hts_pos, pos) - 0usize];
};
impl Default for __rte_ring_hts_pos {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_hts_headtail {
    pub ht: __rte_ring_hts_pos,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_hts_headtail"][::core::mem::size_of::<rte_ring_hts_headtail>() - 16usize];
    ["Alignment of rte_ring_hts_headtail"]
        [::core::mem::align_of::<rte_ring_hts_headtail>() - 8usize];
    ["Offset of field: rte_ring_hts_headtail::ht"]
        [::core::mem::offset_of!(rte_ring_hts_headtail, ht) - 0usize];
    ["Offset of field: rte_ring_hts_headtail::sync_type"]
        [::core::mem::offset_of!(rte_ring_hts_headtail, sync_type) - 8usize];
};
impl Default for rte_ring_hts_headtail {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "An RTE ring structure.\nThe producer and the consumer have a head and a tail index. The particularity\nof these index is that they are not between 0 and size(ring)-1. These indexes\nare between 0 and 2^32 -1, and we mask their value when we access the ring[]\nfield. Thanks to this assumption, we can do subtractions between 2 index\nvalues in a modulo-32bit base: that's why the overflow of the indexes is not\na problem."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_ring {
    pub name: [::core::ffi::c_char; 29usize],
    #[doc = "< Flags supplied at creation."]
    pub flags: ::core::ffi::c_int,
    pub memzone: *const rte_memzone,
    #[doc = "< Size of ring."]
    pub size: u32,
    #[doc = "< Mask (size-1) of ring."]
    pub mask: u32,
    #[doc = "< Usable size of ring"]
    pub capacity: u32,
    pub __bindgen_padding_0: [u8; 4usize],
    pub cache_guard_0: [::core::ffi::c_char; 64usize],
    pub anon1: rte_ring__bindgen_ty_1,
    pub cache_guard_1: [::core::ffi::c_char; 64usize],
    pub anon2: rte_ring__bindgen_ty_2,
    pub cache_guard_2: [::core::ffi::c_char; 64usize],
}
#[doc = "Ring producer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_1 {
    pub prod: rte_ring_headtail,
    pub hts_prod: rte_ring_hts_headtail,
    pub rts_prod: rte_ring_rts_headtail,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring__bindgen_ty_1"][::core::mem::size_of::<rte_ring__bindgen_ty_1>() - 64usize];
    ["Alignment of rte_ring__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ring__bindgen_ty_1>() - 64usize];
    ["Offset of field: rte_ring__bindgen_ty_1::prod"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_1, prod) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_1::hts_prod"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_1, hts_prod) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_1::rts_prod"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_1, rts_prod) - 0usize];
};
impl Default for rte_ring__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Ring consumer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_2 {
    pub cons: rte_ring_headtail,
    pub hts_cons: rte_ring_hts_headtail,
    pub rts_cons: rte_ring_rts_headtail,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring__bindgen_ty_2"][::core::mem::size_of::<rte_ring__bindgen_ty_2>() - 64usize];
    ["Alignment of rte_ring__bindgen_ty_2"]
        [::core::mem::align_of::<rte_ring__bindgen_ty_2>() - 64usize];
    ["Offset of field: rte_ring__bindgen_ty_2::cons"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_2, cons) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_2::hts_cons"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_2, hts_cons) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_2::rts_cons"]
        [::core::mem::offset_of!(rte_ring__bindgen_ty_2, rts_cons) - 0usize];
};
impl Default for rte_ring__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring"][::core::mem::size_of::<rte_ring>() - 384usize];
    ["Alignment of rte_ring"][::core::mem::align_of::<rte_ring>() - 64usize];
    ["Offset of field: rte_ring::name"][::core::mem::offset_of!(rte_ring, name) - 0usize];
    ["Offset of field: rte_ring::flags"][::core::mem::offset_of!(rte_ring, flags) - 32usize];
    ["Offset of field: rte_ring::memzone"][::core::mem::offset_of!(rte_ring, memzone) - 40usize];
    ["Offset of field: rte_ring::size"][::core::mem::offset_of!(rte_ring, size) - 48usize];
    ["Offset of field: rte_ring::mask"][::core::mem::offset_of!(rte_ring, mask) - 52usize];
    ["Offset of field: rte_ring::capacity"][::core::mem::offset_of!(rte_ring, capacity) - 56usize];
    ["Offset of field: rte_ring::cache_guard_0"]
        [::core::mem::offset_of!(rte_ring, cache_guard_0) - 64usize];
    ["Offset of field: rte_ring::cache_guard_1"]
        [::core::mem::offset_of!(rte_ring, cache_guard_1) - 192usize];
    ["Offset of field: rte_ring::cache_guard_2"]
        [::core::mem::offset_of!(rte_ring, cache_guard_2) - 320usize];
};
impl Default for rte_ring {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Calculate the memory size needed for a ring with given element size\nThis function returns the number of bytes needed for a ring, given\nthe number of elements in it and the size of the element. This value\nis the sum of the size of the structure rte_ring and the size of the\nmemory needed for storing the elements. The value is aligned to a cache\nline size.\n\n# Arguments\n\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\n* `count` -\nThe number of elements in the ring (must be a power of 2).\n\n# Returns\n\n- The memory size needed for the ring on success.\n- -EINVAL - esize is not a multiple of 4 or count provided is not a\npower of 2."]
    pub fn rte_ring_get_memsize_elem(
        esize: ::core::ffi::c_uint,
        count: ::core::ffi::c_uint,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = "Create a new ring named *name* that stores elements with given size.\nThis function uses ``memzone_reserve()`` to allocate memory. Then it\ncalls rte_ring_init() to initialize an empty ring.\nThe new ring size is set to *count*, which must be a power of\ntwo. Water marking is disabled by default. The real usable ring size\nis *count-1* instead of *count* to differentiate a full ring from an\nempty ring.\nThe ring is added in RTE_TAILQ_RING list.\n\n# Arguments\n\n* `name` -\nThe name of the ring.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\n* `count` -\nThe number of elements in the ring (must be a power of 2).\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in case of\nNUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nAn OR of the following:\n- One of mutually exclusive flags that define producer behavior:\n- RING_F_SP_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"single-producer\".\n- RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer RTS mode\".\n- RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer HTS mode\".\nIf none of these flags is set, then default \"multi-producer\"\nbehavior is selected.\n- One of mutually exclusive flags that define consumer behavior:\n- RING_F_SC_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"single-consumer\". Otherwise, it is \"multi-consumers\".\n- RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer RTS mode\".\n- RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer HTS mode\".\nIf none of these flags is set, then default \"multi-consumer\"\nbehavior is selected.\n\n# Returns\n\nOn success, the pointer to the new allocated ring. NULL on error with\nrte_errno set appropriately. Possible errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - esize is not a multiple of 4 or count provided is not a\npower of 2.\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create_elem(
        name: *const ::core::ffi::c_char,
        esize: ::core::ffi::c_uint,
        count: ::core::ffi::c_uint,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
    ) -> *mut rte_ring;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_enqueue_bulk_elem_w"]
    pub fn rte_ring_mp_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring\n@warning This API is NOT multi-producers safe\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_sp_enqueue_bulk_elem_w"]
    pub fn rte_ring_sp_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_hts_enqueue_bulk_elem_w"]
    pub fn rte_ring_mp_hts_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS ring (multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_hts_dequeue_bulk_elem_w"]
    pub fn rte_ring_mc_hts_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_hts_enqueue_burst_elem_w"]
    pub fn rte_ring_mp_hts_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS  ring (multi-consumers safe).\nWhen the requested objects are more than the available objects,\nonly dequeue the actual number of objects.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_hts_dequeue_burst_elem_w"]
    pub fn rte_ring_mc_hts_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_hts_enqueue_bulk_w"]
    pub fn rte_ring_mp_hts_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS ring (multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_hts_dequeue_bulk_w"]
    pub fn rte_ring_mc_hts_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_hts_enqueue_burst_w"]
    pub fn rte_ring_mp_hts_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS  ring (multi-consumers safe).\nWhen the requested objects are more than the available objects,\nonly dequeue the actual number of objects.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_hts_dequeue_burst_w"]
    pub fn rte_ring_mc_hts_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_rts_enqueue_bulk_elem_w"]
    pub fn rte_ring_mp_rts_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS ring (multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_rts_dequeue_bulk_elem_w"]
    pub fn rte_ring_mc_rts_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_rts_enqueue_burst_elem_w"]
    pub fn rte_ring_mp_rts_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS  ring (multi-consumers safe).\nWhen the requested objects are more than the available objects,\nonly dequeue the actual number of objects.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_rts_dequeue_burst_elem_w"]
    pub fn rte_ring_mc_rts_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_rts_enqueue_bulk_w"]
    pub fn rte_ring_mp_rts_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS ring (multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_rts_dequeue_bulk_w"]
    pub fn rte_ring_mc_rts_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_rts_enqueue_burst_w"]
    pub fn rte_ring_mp_rts_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS  ring (multi-consumers safe).\nWhen the requested objects are more than the available objects,\nonly dequeue the actual number of objects.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_rts_dequeue_burst_w"]
    pub fn rte_ring_mc_rts_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return producer max Head-Tail-Distance (HTD).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nProducer HTD value, if producer is set in appropriate sync mode,\nor UINT32_MAX otherwise."]
    #[link_name = "rte_ring_get_prod_htd_max_w"]
    pub fn rte_ring_get_prod_htd_max(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    #[doc = "Set producer max Head-Tail-Distance (HTD).\nNote that producer has to use appropriate sync mode (RTS).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `v` -\nnew HTD value to setup.\n\n# Returns\n\nZero on success, or negative error code otherwise."]
    #[link_name = "rte_ring_set_prod_htd_max_w"]
    pub fn rte_ring_set_prod_htd_max(r: *mut rte_ring, v: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return consumer max Head-Tail-Distance (HTD).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nConsumer HTD value, if consumer is set in appropriate sync mode,\nor UINT32_MAX otherwise."]
    #[link_name = "rte_ring_get_cons_htd_max_w"]
    pub fn rte_ring_get_cons_htd_max(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    #[doc = "Set consumer max Head-Tail-Distance (HTD).\nNote that consumer has to use appropriate sync mode (RTS).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `v` -\nnew HTD value to setup.\n\n# Returns\n\nZero on success, or negative error code otherwise."]
    #[link_name = "rte_ring_set_cons_htd_max_w"]
    pub fn rte_ring_set_cons_htd_max(r: *mut rte_ring, v: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_bulk_elem_w"]
    pub fn rte_ring_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_mp_enqueue_elem_w"]
    pub fn rte_ring_mp_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring\n@warning This API is NOT multi-producers safe\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_sp_enqueue_elem_w"]
    pub fn rte_ring_sp_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring.\nThis function calls the multi-producer or the single-producer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_enqueue_elem_w"]
    pub fn rte_ring_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_dequeue_bulk_elem_w"]
    pub fn rte_ring_mc_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table,\nmust be strictly positive.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_sc_dequeue_bulk_elem_w"]
    pub fn rte_ring_sc_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_dequeue_bulk_elem_w"]
    pub fn rte_ring_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to the object that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success; objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue; no object is\ndequeued."]
    #[link_name = "rte_ring_mc_dequeue_elem_w"]
    pub fn rte_ring_mc_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (NOT multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to the object that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success; objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue, no object is\ndequeued."]
    #[link_name = "rte_ring_sc_dequeue_elem_w"]
    pub fn rte_ring_sc_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring.\nThis function calls the multi-consumers or the single-consumer\nversion depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to the object that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n\n# Returns\n\n- 0: Success, objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue, no object is\ndequeued."]
    #[link_name = "rte_ring_dequeue_elem_w"]
    pub fn rte_ring_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_enqueue_burst_elem_w"]
    pub fn rte_ring_mp_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring\n@warning This API is NOT multi-producers safe\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_sp_enqueue_burst_elem_w"]
    pub fn rte_ring_sp_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_enqueue_burst_elem_w"]
    pub fn rte_ring_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe). When the request\nobjects are more than the available objects, only dequeue the actual number\nof objects\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_dequeue_burst_elem_w"]
    pub fn rte_ring_mc_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).When the\nrequest objects are more than the available objects, only dequeue the\nactual number of objects\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_sc_dequeue_burst_elem_w"]
    pub fn rte_ring_sc_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue multiple objects from a ring up to a maximum number.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- Number of objects dequeued"]
    #[link_name = "rte_ring_dequeue_burst_elem_w"]
    pub fn rte_ring_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves for user such ability.\nUser has to call appropriate enqueue_elem_finish() to copy objects into the\nqueue and complete given enqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_bulk_elem_start_w"]
    pub fn rte_ring_enqueue_bulk_elem_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves for user such ability.\nUser has to call appropriate enqueue_finish() to copy objects into the\nqueue and complete given enqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_bulk_start_w"]
    pub fn rte_ring_enqueue_bulk_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves for user such ability.\nUser has to call appropriate enqueue_elem_finish() to copy objects into the\nqueue and complete given enqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nActual number of objects that can be enqueued."]
    #[link_name = "rte_ring_enqueue_burst_elem_start_w"]
    pub fn rte_ring_enqueue_burst_elem_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves for user such ability.\nUser has to call appropriate enqueue_finish() to copy objects into the\nqueue and complete given enqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nActual number of objects that can be enqueued."]
    #[link_name = "rte_ring_enqueue_burst_start_w"]
    pub fn rte_ring_enqueue_burst_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete to enqueue several objects on the ring.\nNote that number of objects to enqueue should not exceed previous\nenqueue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to add to the ring from the obj_table."]
    #[link_name = "rte_ring_enqueue_elem_finish_w"]
    pub fn rte_ring_enqueue_elem_finish(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Complete to enqueue several objects on the ring.\nNote that number of objects to enqueue should not exceed previous\nenqueue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects.\n* `n` -\nThe number of objects to add to the ring from the obj_table."]
    #[link_name = "rte_ring_enqueue_finish_w"]
    pub fn rte_ring_enqueue_finish(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that user has to call appropriate dequeue_finish()\nto complete given dequeue operation and actually remove objects the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n."]
    #[link_name = "rte_ring_dequeue_bulk_elem_start_w"]
    pub fn rte_ring_dequeue_bulk_elem_start(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that user has to call appropriate dequeue_finish()\nto complete given dequeue operation and actually remove objects the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nActual number of objects dequeued."]
    #[link_name = "rte_ring_dequeue_bulk_start_w"]
    pub fn rte_ring_dequeue_bulk_start(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that user has to call appropriate dequeue_finish()\nto complete given dequeue operation and actually remove objects the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of objects that will be filled.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe actual number of objects dequeued."]
    #[link_name = "rte_ring_dequeue_burst_elem_start_w"]
    pub fn rte_ring_dequeue_burst_elem_start(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that user has to call appropriate dequeue_finish()\nto complete given dequeue operation and actually remove objects the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe actual number of objects dequeued."]
    #[link_name = "rte_ring_dequeue_burst_start_w"]
    pub fn rte_ring_dequeue_burst_start(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete to dequeue several objects from the ring.\nNote that number of objects to dequeue should not exceed previous\ndequeue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring."]
    #[link_name = "rte_ring_dequeue_elem_finish_w"]
    pub fn rte_ring_dequeue_elem_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Complete to dequeue several objects from the ring.\nNote that number of objects to dequeue should not exceed previous\ndequeue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring."]
    #[link_name = "rte_ring_dequeue_finish_w"]
    pub fn rte_ring_dequeue_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
#[doc = "Ring zero-copy information structure.\nThis structure contains the pointers and length of the space\nreserved on the ring storage."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_ring_zc_data {
    #[doc = "Pointer to the first space in the ring"]
    pub ptr1: *mut ::core::ffi::c_void,
    #[doc = "Pointer to the second space in the ring if there is wrap-around.\nIt contains valid value only if wrap-around happens."]
    pub ptr2: *mut ::core::ffi::c_void,
    #[doc = "Number of elements in the first pointer. If this is equal to\nthe number of elements requested, then ptr2 is NULL.\nOtherwise, subtracting n1 from number of elements requested\nwill give the number of elements available at ptr2."]
    pub n1: ::core::ffi::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_zc_data"][::core::mem::size_of::<rte_ring_zc_data>() - 64usize];
    ["Alignment of rte_ring_zc_data"][::core::mem::align_of::<rte_ring_zc_data>() - 64usize];
    ["Offset of field: rte_ring_zc_data::ptr1"]
        [::core::mem::offset_of!(rte_ring_zc_data, ptr1) - 0usize];
    ["Offset of field: rte_ring_zc_data::ptr2"]
        [::core::mem::offset_of!(rte_ring_zc_data, ptr2) - 8usize];
    ["Offset of field: rte_ring_zc_data::n1"]
        [::core::mem::offset_of!(rte_ring_zc_data, n1) - 16usize];
};
impl Default for rte_ring_zc_data {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves space for the user on the ring.\nUser has to copy objects into the queue using the returned pointers.\nUser should call rte_ring_enqueue_zc_elem_finish to complete the\nenqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\n* `n` -\nThe number of objects to add in the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `free_space` -\nIf non-NULL, returns the amount of space in the ring after the\nreservation operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_zc_bulk_elem_start_w"]
    pub fn rte_ring_enqueue_zc_bulk_elem_start(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several pointers to objects on the ring.\nNote that no actual pointers are put in the queue by this function,\nit just reserves space for the user on the ring.\nUser has to copy pointers to objects into the queue using the\nreturned pointers.\nUser should call rte_ring_enqueue_zc_finish to complete the\nenqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `free_space` -\nIf non-NULL, returns the amount of space in the ring after the\nreservation operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_zc_bulk_start_w"]
    pub fn rte_ring_enqueue_zc_bulk_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring.\nNote that no actual objects are put in the queue by this function,\nit just reserves space for the user on the ring.\nUser has to copy objects into the queue using the returned pointers.\nUser should call rte_ring_enqueue_zc_elem_finish to complete the\nenqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\n* `n` -\nThe number of objects to add in the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `free_space` -\nIf non-NULL, returns the amount of space in the ring after the\nreservation operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_zc_burst_elem_start_w"]
    pub fn rte_ring_enqueue_zc_burst_elem_start(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several pointers to objects on the ring.\nNote that no actual pointers are put in the queue by this function,\nit just reserves space for the user on the ring.\nUser has to copy pointers to objects into the queue using the\nreturned pointers.\nUser should call rte_ring_enqueue_zc_finish to complete the\nenqueue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add in the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `free_space` -\nIf non-NULL, returns the amount of space in the ring after the\nreservation operation has finished.\n\n# Returns\n\nThe number of objects that can be enqueued, either 0 or n."]
    #[link_name = "rte_ring_enqueue_zc_burst_start_w"]
    pub fn rte_ring_enqueue_zc_burst_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete enqueuing several objects on the ring.\nNote that number of objects to enqueue should not exceed previous\nenqueue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to add to the ring."]
    #[link_name = "rte_ring_enqueue_zc_elem_finish_w"]
    pub fn rte_ring_enqueue_zc_elem_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Complete enqueuing several pointers to objects on the ring.\nNote that number of objects to enqueue should not exceed previous\nenqueue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of pointers to objects to add to the ring."]
    #[link_name = "rte_ring_enqueue_zc_finish_w"]
    pub fn rte_ring_enqueue_zc_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that no actual objects are copied from the queue by this function.\nUser has to copy objects from the queue using the returned pointers.\nUser should call rte_ring_dequeue_zc_elem_finish to complete the\ndequeue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\n* `n` -\nThe number of objects to remove from the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects that can be dequeued, either 0 or n."]
    #[link_name = "rte_ring_dequeue_zc_bulk_elem_start_w"]
    pub fn rte_ring_dequeue_zc_bulk_elem_start(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several pointers to objects from the ring.\nNote that no actual pointers are removed from the queue by this function.\nUser has to copy pointers to objects from the queue using the\nreturned pointers.\nUser should call rte_ring_dequeue_zc_finish to complete the\ndequeue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects that can be dequeued, either 0 or n."]
    #[link_name = "rte_ring_dequeue_zc_bulk_start_w"]
    pub fn rte_ring_dequeue_zc_bulk_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring.\nNote that no actual objects are copied from the queue by this function.\nUser has to copy objects from the queue using the returned pointers.\nUser should call rte_ring_dequeue_zc_elem_finish to complete the\ndequeue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `esize` -\nThe size of ring element, in bytes. It must be a multiple of 4.\nThis must be the same value used while creating the ring. Otherwise\nthe results are undefined.\n* `n` -\nThe number of objects to dequeue from the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects that can be dequeued, either 0 or n."]
    #[link_name = "rte_ring_dequeue_zc_burst_elem_start_w"]
    pub fn rte_ring_dequeue_zc_burst_elem_start(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several pointers to objects from the ring.\nNote that no actual pointers are removed from the queue by this function.\nUser has to copy pointers to objects from the queue using the\nreturned pointers.\nUser should call rte_ring_dequeue_zc_finish to complete the\ndequeue operation.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring.\n* `zcd` -\nStructure containing the pointers and length of the space\nreserved on the ring storage.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects that can be dequeued, either 0 or n."]
    #[link_name = "rte_ring_dequeue_zc_burst_start_w"]
    pub fn rte_ring_dequeue_zc_burst_start(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete dequeuing several objects from the ring.\nNote that number of objects to dequeued should not exceed previous\ndequeue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring."]
    #[link_name = "rte_ring_dequeue_zc_elem_finish_w"]
    pub fn rte_ring_dequeue_zc_elem_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Complete dequeuing several objects from the ring.\nNote that number of objects to dequeued should not exceed previous\ndequeue_start return value.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `n` -\nThe number of objects to remove from the ring."]
    #[link_name = "rte_ring_dequeue_zc_finish_w"]
    pub fn rte_ring_dequeue_zc_finish(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Calculate the memory size needed for a ring\nThis function returns the number of bytes needed for a ring, given\nthe number of elements in it. This value is the sum of the size of\nthe structure rte_ring and the size of the memory needed by the\nobjects pointers. The value is aligned to a cache line size.\n\n# Arguments\n\n* `count` -\nThe number of elements in the ring (must be a power of 2).\n\n# Returns\n\n- The memory size needed for the ring on success.\n- -EINVAL if count is not a power of 2."]
    pub fn rte_ring_get_memsize(count: ::core::ffi::c_uint) -> isize;
}
unsafe extern "C" {
    #[doc = "Initialize a ring structure.\nInitialize a ring structure in memory pointed by \"r\". The size of the\nmemory area must be large enough to store the ring structure and the\nobject table. It is advised to use rte_ring_get_memsize() to get the\nappropriate size.\nThe ring size is set to *count*, which must be a power of two.\nThe real usable ring size is *count-1* instead of *count* to\ndifferentiate a full ring from an empty ring.\nThe ring is not added in RTE_TAILQ_RING global list. Indeed, the\nmemory given by the caller may not be shareable among dpdk\nprocesses.\n\n# Arguments\n\n* `r` -\nThe pointer to the ring structure followed by the objects table.\n* `name` -\nThe name of the ring.\n* `count` -\nThe number of elements in the ring (must be a power of 2,\nunless RING_F_EXACT_SZ is set in flags).\n* `flags` -\nAn OR of the following:\n- One of mutually exclusive flags that define producer behavior:\n- RING_F_SP_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"single-producer\".\n- RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer RTS mode\".\n- RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer HTS mode\".\nIf none of these flags is set, then default \"multi-producer\"\nbehavior is selected.\n- One of mutually exclusive flags that define consumer behavior:\n- RING_F_SC_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"single-consumer\". Otherwise, it is \"multi-consumers\".\n- RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer RTS mode\".\n- RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer HTS mode\".\nIf none of these flags is set, then default \"multi-consumer\"\nbehavior is selected.\n- RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\nrequested number of entries, and the requested size will be rounded up\nto the next power of two, but the usable space will be exactly that\nrequested. Worst case, if a power-of-2 size is requested, half the\nring space will be wasted.\nWithout this flag set, the ring size requested must be a power of 2,\nand the usable space will be that size - 1.\n\n# Returns\n\n0 on success, or a negative value on error."]
    pub fn rte_ring_init(
        r: *mut rte_ring,
        name: *const ::core::ffi::c_char,
        count: ::core::ffi::c_uint,
        flags: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "De-allocate all memory used by the ring.\n\n# Arguments\n\n* `r` -\nRing to free.\nIf NULL then, the function does nothing."]
    pub fn rte_ring_free(r: *mut rte_ring);
}
unsafe extern "C" {
    #[doc = "Create a new ring named *name* in memory.\nThis function uses ``memzone_reserve()`` to allocate memory. Then it\ncalls rte_ring_init() to initialize an empty ring.\nThe new ring size is set to *count*, which must be a power of two.\nThe real usable ring size is *count-1* instead of *count* to\ndifferentiate a full ring from an empty ring.\nThe ring is added in RTE_TAILQ_RING list.\n\n# Arguments\n\n* `name` -\nThe name of the ring.\n* `count` -\nThe size of the ring (must be a power of 2,\nunless RING_F_EXACT_SZ is set in flags).\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in case of\nNUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nAn OR of the following:\n- One of mutually exclusive flags that define producer behavior:\n- RING_F_SP_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"single-producer\".\n- RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer RTS mode\".\n- RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\nusing ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\nis \"multi-producer HTS mode\".\nIf none of these flags is set, then default \"multi-producer\"\nbehavior is selected.\n- One of mutually exclusive flags that define consumer behavior:\n- RING_F_SC_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"single-consumer\". Otherwise, it is \"multi-consumers\".\n- RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer RTS mode\".\n- RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\nusing ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\nis \"multi-consumer HTS mode\".\nIf none of these flags is set, then default \"multi-consumer\"\nbehavior is selected.\n- RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\nrequested number of entries, and the requested size will be rounded up\nto the next power of two, but the usable space will be exactly that\nrequested. Worst case, if a power-of-2 size is requested, half the\nring space will be wasted.\nWithout this flag set, the ring size requested must be a power of 2,\nand the usable space will be that size - 1.\n\n# Returns\n\nOn success, the pointer to the new allocated ring. NULL on error with\nrte_errno set appropriately. Possible errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - count provided is not a power of 2\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create(
        name: *const ::core::ffi::c_char,
        count: ::core::ffi::c_uint,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
    ) -> *mut rte_ring;
}
unsafe extern "C" {
    #[doc = "Dump the status of the ring to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `r` -\nA pointer to the ring structure."]
    pub fn rte_ring_dump(f: *mut FILE, r: *const rte_ring);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDump the status of a headtail to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `prefix` -\nA string to prefix each output line with\n* `r` -\nA pointer to a ring headtail structure."]
    pub fn rte_ring_headtail_dump(
        f: *mut FILE,
        prefix: *const ::core::ffi::c_char,
        r: *const rte_ring_headtail,
    );
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_mp_enqueue_bulk_w"]
    pub fn rte_ring_mp_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring (NOT multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_sp_enqueue_bulk_w"]
    pub fn rte_ring_sp_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\nThe number of objects enqueued, either 0 or n"]
    #[link_name = "rte_ring_enqueue_bulk_w"]
    pub fn rte_ring_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_mp_enqueue_w"]
    pub fn rte_ring_mp_enqueue(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (NOT multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_sp_enqueue_w"]
    pub fn rte_ring_sp_enqueue(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring.\nThis function calls the multi-producer or the single-producer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj` -\nA pointer to the object to be added.\n\n# Returns\n\n- 0: Success; objects enqueued.\n- -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    #[link_name = "rte_ring_enqueue_w"]
    pub fn rte_ring_enqueue(r: *mut rte_ring, obj: *mut ::core::ffi::c_void) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_mc_dequeue_bulk_w"]
    pub fn rte_ring_mc_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table,\nmust be strictly positive.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_sc_dequeue_bulk_w"]
    pub fn rte_ring_sc_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\nThe number of objects dequeued, either 0 or n"]
    #[link_name = "rte_ring_dequeue_bulk_w"]
    pub fn rte_ring_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to a void * pointer (object) that will be filled.\n\n# Returns\n\n- 0: Success; objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue; no object is\ndequeued."]
    #[link_name = "rte_ring_mc_dequeue_w"]
    pub fn rte_ring_mc_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (NOT multi-consumers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to a void * pointer (object) that will be filled.\n\n# Returns\n\n- 0: Success; objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue, no object is\ndequeued."]
    #[link_name = "rte_ring_sc_dequeue_w"]
    pub fn rte_ring_sc_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring.\nThis function calls the multi-consumers or the single-consumer\nversion depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_p` -\nA pointer to a void * pointer (object) that will be filled.\n\n# Returns\n\n- 0: Success, objects dequeued.\n- -ENOENT: Not enough entries in the ring to dequeue, no object is\ndequeued."]
    #[link_name = "rte_ring_dequeue_w"]
    pub fn rte_ring_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Flush a ring.\nThis function flush all the elements in a ring\n@warning Make sure the ring is not in use while calling this function.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure."]
    pub fn rte_ring_reset(r: *mut rte_ring);
}
unsafe extern "C" {
    #[doc = "Return the number of entries in a ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nThe number of entries in the ring."]
    #[link_name = "rte_ring_count_w"]
    pub fn rte_ring_count(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of free entries in a ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nThe number of free entries in the ring."]
    #[link_name = "rte_ring_free_count_w"]
    pub fn rte_ring_free_count(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Test if a ring is full.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\n- 1: The ring is full.\n- 0: The ring is not full."]
    #[link_name = "rte_ring_full_w"]
    pub fn rte_ring_full(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if a ring is empty.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\n- 1: The ring is empty.\n- 0: The ring is not empty."]
    #[link_name = "rte_ring_empty_w"]
    pub fn rte_ring_empty(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the size of the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nThe size of the data store used by the ring.\nNOTE: this is not the same as the usable space in the ring. To query that\nuse ``rte_ring_get_capacity()``."]
    #[link_name = "rte_ring_get_size_w"]
    pub fn rte_ring_get_size(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of elements which can be stored in the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nThe usable size of the ring."]
    #[link_name = "rte_ring_get_capacity_w"]
    pub fn rte_ring_get_capacity(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return sync type used by producer in the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nProducer sync type value."]
    #[link_name = "rte_ring_get_prod_sync_type_w"]
    pub fn rte_ring_get_prod_sync_type(r: *const rte_ring) -> rte_ring_sync_type::Type;
}
unsafe extern "C" {
    #[doc = "Check is the ring for single producer.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\ntrue if ring is SP, zero otherwise."]
    #[link_name = "rte_ring_is_prod_single_w"]
    pub fn rte_ring_is_prod_single(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return sync type used by consumer in the ring.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\nConsumer sync type value."]
    #[link_name = "rte_ring_get_cons_sync_type_w"]
    pub fn rte_ring_get_cons_sync_type(r: *const rte_ring) -> rte_ring_sync_type::Type;
}
unsafe extern "C" {
    #[doc = "Check is the ring for single consumer.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n\n# Returns\n\ntrue if ring is SC, zero otherwise."]
    #[link_name = "rte_ring_is_cons_single_w"]
    pub fn rte_ring_is_cons_single(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the status of all rings on the console\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_ring_list_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Search a ring from its name\n\n# Arguments\n\n* `name` -\nThe name of the ring.\n\n# Returns\n\nThe pointer to the ring matching the name, or NULL if not found,\nwith rte_errno set appropriately. Possible rte_errno values include:\n- ENOENT - required entry not available to return."]
    pub fn rte_ring_lookup(name: *const ::core::ffi::c_char) -> *mut rte_ring;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the\nproducer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_mp_enqueue_burst_w"]
    pub fn rte_ring_mp_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring (NOT multi-producers safe).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_sp_enqueue_burst_w"]
    pub fn rte_ring_sp_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the ring from the obj_table.\n* `free_space` -\nif non-NULL, returns the amount of space in the ring after the\nenqueue operation has finished.\n\n# Returns\n\n- n: Actual number of objects enqueued."]
    #[link_name = "rte_ring_enqueue_burst_w"]
    pub fn rte_ring_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe). When the request\nobjects are more than the available objects, only dequeue the actual number\nof objects\nThis function uses a \"compare and set\" instruction to move the\nconsumer index atomically.\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_mc_dequeue_burst_w"]
    pub fn rte_ring_mc_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).When the\nrequest objects are more than the available objects, only dequeue the\nactual number of objects\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    #[link_name = "rte_ring_sc_dequeue_burst_w"]
    pub fn rte_ring_sc_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue multiple objects from a ring up to a maximum number.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behaviour that was specified at\nring creation time (see flags).\n\n# Arguments\n\n* `r` -\nA pointer to the ring structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to dequeue from the ring to the obj_table.\n* `available` -\nIf non-NULL, returns the number of remaining ring entries after the\ndequeue has finished.\n\n# Returns\n\n- Number of objects dequeued"]
    #[link_name = "rte_ring_dequeue_burst_w"]
    pub fn rte_ring_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
#[doc = "64 bits vector size to use with unsigned 8 bits elements.\na = (rte_v64u8_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v64u8_t = [u8; 8usize];
#[doc = "64 bits vector size to use with unsigned 16 bits elements.\na = (rte_v64u16_t){ a0, a1, a2, a3 }"]
pub type rte_v64u16_t = [u16; 4usize];
#[doc = "64 bits vector size to use with unsigned 32 bits elements.\na = (rte_v64u32_t){ a0, a1 }"]
pub type rte_v64u32_t = [u32; 2usize];
#[doc = "128 bits vector size to use with unsigned 8 bits elements.\na = (rte_v128u8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v128u8_t = [u8; 16usize];
#[doc = "128 bits vector size to use with unsigned 16 bits elements.\na = (rte_v128u16_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v128u16_t = [u16; 8usize];
#[doc = "128 bits vector size to use with unsigned 32 bits elements.\na = (rte_v128u32_t){ a0, a1, a2, a3 }"]
pub type rte_v128u32_t = [u32; 4usize];
#[doc = "128 bits vector size to use with unsigned 64 bits elements.\na = (rte_v128u64_t){ a0, a1 }"]
pub type rte_v128u64_t = [u64; 2usize];
#[doc = "256 bits vector size to use with unsigned 8 bits elements.\na = (rte_v256u8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15,\na16, a17, a18, a19, a20, a21, a22, a23,\na24, a25, a26, a27, a28, a29, a30, a31 }"]
pub type rte_v256u8_t = [u8; 32usize];
#[doc = "256 bits vector size to use with unsigned 16 bits elements.\na = (rte_v256u16_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v256u16_t = [u16; 16usize];
#[doc = "256 bits vector size to use with unsigned 32 bits elements.\na = (rte_v256u32_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v256u32_t = [u32; 8usize];
#[doc = "256 bits vector size to use with unsigned 64 bits elements.\na = (rte_v256u64_t){ a0, a1, a2, a3 }"]
pub type rte_v256u64_t = [u64; 4usize];
#[doc = "64 bits vector size to use with 8 bits elements.\na = (rte_v64s8_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v64s8_t = [i8; 8usize];
#[doc = "64 bits vector size to use with 16 bits elements.\na = (rte_v64s16_t){ a0, a1, a2, a3 }"]
pub type rte_v64s16_t = [i16; 4usize];
#[doc = "64 bits vector size to use with 32 bits elements.\na = (rte_v64s32_t){ a0, a1 }"]
pub type rte_v64s32_t = [i32; 2usize];
#[doc = "128 bits vector size to use with 8 bits elements.\na = (rte_v128s8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v128s8_t = [i8; 16usize];
#[doc = "128 bits vector size to use with 16 bits elements.\na = (rte_v128s16_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v128s16_t = [i16; 8usize];
#[doc = "128 bits vector size to use with 32 bits elements.\na = (rte_v128s32_t){ a0, a1, a2, a3 }"]
pub type rte_v128s32_t = [i32; 4usize];
#[doc = "128 bits vector size to use with 64 bits elements.\na = (rte_v128s64_t){ a1, a2 }"]
pub type rte_v128s64_t = [i64; 2usize];
#[doc = "256 bits vector size to use with 8 bits elements.\na = (rte_v256s8_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15,\na16, a17, a18, a19, a20, a21, a22, a23,\na24, a25, a26, a27, a28, a29, a30, a31 }"]
pub type rte_v256s8_t = [i8; 32usize];
#[doc = "256 bits vector size to use with 16 bits elements.\na = (rte_v256s16_t){ a00, a01, a02, a03, a04, a05, a06, a07,\na08, a09, a10, a11, a12, a13, a14, a15 }"]
pub type rte_v256s16_t = [i16; 16usize];
#[doc = "256 bits vector size to use with 32 bits elements.\na = (rte_v256s32_t){ a0, a1, a2, a3, a4, a5, a6, a7 }"]
pub type rte_v256s32_t = [i32; 8usize];
#[doc = "256 bits vector size to use with 64 bits elements.\na = (rte_v256s64_t){ a0, a1, a2, a3 }"]
pub type rte_v256s64_t = [i64; 4usize];
pub mod rte_vect_max_simd {
    #[doc = "The max SIMD bitwidth value to limit vector path selection."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_VECT_SIMD_DISABLED: Type = 64;
    pub const RTE_VECT_SIMD_128: Type = 128;
    #[doc = "< Limits path selection to AVX2 or below."]
    pub const RTE_VECT_SIMD_256: Type = 256;
    #[doc = "< Limits path selection to AVX512 or below."]
    pub const RTE_VECT_SIMD_512: Type = 512;
    pub const RTE_VECT_SIMD_MAX: Type = 32768;
}
unsafe extern "C" {
    #[doc = "Get the supported SIMD bitwidth.\n\n# Returns\n\nuint16_t bitwidth."]
    pub fn rte_vect_get_max_simd_bitwidth() -> u16;
}
unsafe extern "C" {
    #[doc = "Set the supported SIMD bitwidth.\nThis API should only be called once at initialization, before EAL init.\n\n# Arguments\n\n* `bitwidth` -\nuint16_t bitwidth.\n\n# Returns\n\n- 0 on success.\n- -EINVAL on invalid bitwidth parameter.\n- -EPERM if bitwidth is forced."]
    pub fn rte_vect_set_max_simd_bitwidth(bitwidth: u16) -> ::core::ffi::c_int;
}
pub type xmm_t = __m128i;
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_xmm {
    pub x: xmm_t,
    pub u8_: [u8; 16usize],
    pub u16_: [u16; 8usize],
    pub u32_: [u32; 4usize],
    pub u64_: [u64; 2usize],
    pub pd: [f64; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_xmm"][::core::mem::size_of::<rte_xmm>() - 16usize];
    ["Alignment of rte_xmm"][::core::mem::align_of::<rte_xmm>() - 16usize];
    ["Offset of field: rte_xmm::x"][::core::mem::offset_of!(rte_xmm, x) - 0usize];
    ["Offset of field: rte_xmm::u8_"][::core::mem::offset_of!(rte_xmm, u8_) - 0usize];
    ["Offset of field: rte_xmm::u16_"][::core::mem::offset_of!(rte_xmm, u16_) - 0usize];
    ["Offset of field: rte_xmm::u32_"][::core::mem::offset_of!(rte_xmm, u32_) - 0usize];
    ["Offset of field: rte_xmm::u64_"][::core::mem::offset_of!(rte_xmm, u64_) - 0usize];
    ["Offset of field: rte_xmm::pd"][::core::mem::offset_of!(rte_xmm, pd) - 0usize];
};
impl Default for rte_xmm {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub type rte_xmm_t = rte_xmm;
unsafe extern "C" {
    #[doc = "Copy bytes from one location to another. The locations must not overlap.\n> **Note** This is implemented as a macro, so it's address should not be taken\nand care is needed as parameter expressions may be evaluated multiple times.\n\n# Arguments\n\n* `dst` -\nPointer to the destination of the data.\n* `src` -\nPointer to the source data.\n* `n` -\nNumber of bytes to copy.\n\n# Returns\n\nPointer to the destination data."]
    #[link_name = "rte_memcpy_w"]
    pub fn rte_memcpy(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Copy bytes from one location to another,\nlocations should not overlap.\nUse with n <= 15."]
    #[link_name = "rte_mov15_or_less_w"]
    pub fn rte_mov15_or_less(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Copy 16 bytes from one location to another,\nlocations should not overlap."]
    #[link_name = "rte_mov16_w"]
    pub fn rte_mov16(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 32 bytes from one location to another,\nlocations should not overlap."]
    #[link_name = "rte_mov32_w"]
    pub fn rte_mov32(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 64 bytes from one location to another,\nlocations should not overlap."]
    #[link_name = "rte_mov64_w"]
    pub fn rte_mov64(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 128 bytes from one location to another,\nlocations should not overlap."]
    #[link_name = "rte_mov128_w"]
    pub fn rte_mov128(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 256 bytes from one location to another,\nlocations should not overlap."]
    #[link_name = "rte_mov256_w"]
    pub fn rte_mov256(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[link_name = "rte_memcpy_generic_w"]
    pub fn rte_memcpy_generic(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[link_name = "rte_memcpy_aligned_w"]
    pub fn rte_memcpy_aligned(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Takes string \"string\" parameter and splits it at character \"delim\"\nup to maxtokens-1 times - to give \"maxtokens\" resulting tokens. Like\nstrtok or strsep functions, this modifies its input string, by replacing\ninstances of \"delim\" with '\\\\0'. All resultant tokens are returned in the\n\"tokens\" array which must have enough entries to hold \"maxtokens\".\n\n# Arguments\n\n* `string` -\nThe input string to be split into tokens\n* `stringlen` -\nThe max length of the input buffer\n* `tokens` -\nThe array to hold the pointers to the tokens in the string\n* `maxtokens` -\nThe number of elements in the tokens array. At most, maxtokens-1 splits\nof the string will be done.\n* `delim` -\nThe character on which the split of the data will be done\n\n# Returns\n\nThe number of tokens in the tokens array."]
    pub fn rte_strsplit(
        string: *mut ::core::ffi::c_char,
        stringlen: ::core::ffi::c_int,
        tokens: *mut *mut ::core::ffi::c_char,
        maxtokens: ::core::ffi::c_int,
        delim: ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal DPDK-specific version of strlcpy for systems without\nlibc or libbsd copies of the function"]
    #[link_name = "rte_strlcpy_w"]
    pub fn rte_strlcpy(
        dst: *mut ::core::ffi::c_char,
        src: *const ::core::ffi::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    #[doc = "@internal DPDK-specific version of strlcat for systems without\nlibc or libbsd copies of the function"]
    #[link_name = "rte_strlcat_w"]
    pub fn rte_strlcat(
        dst: *mut ::core::ffi::c_char,
        src: *const ::core::ffi::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    #[doc = "Copy string src to buffer dst of size dsize.\nAt most dsize-1 chars will be copied.\nAlways NUL-terminates, unless (dsize == 0).\n\n# Arguments\n\n* `dst` -\nThe destination string.\n* `src` -\nThe input string to be copied.\n* `dsize` -\nLength in bytes of the destination buffer.\n\n# Returns\n\nThe number of bytes copied (terminating NUL-byte excluded) on success.\n-E2BIG if the destination buffer is too small.\nrte_errno is set."]
    pub fn rte_strscpy(
        dst: *mut ::core::ffi::c_char,
        src: *const ::core::ffi::c_char,
        dsize: usize,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSearch for the first non whitespace character.\n\n# Arguments\n\n* `src` -\nThe input string to be analysed.\n\n# Returns\n\nThe address of the first non whitespace character."]
    #[link_name = "rte_str_skip_leading_spaces_w"]
    pub fn rte_str_skip_leading_spaces(
        src: *const ::core::ffi::c_char,
    ) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Test if trace is enabled.\n\n# Returns\n\ntrue if trace is enabled, false otherwise."]
    pub fn rte_trace_is_enabled() -> bool;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nTest if trace feature is enabled at compile time.\n\n# Returns\n\ntrue if trace feature is enabled, false otherwise."]
    #[link_name = "rte_trace_feature_is_enabled_w"]
    pub fn rte_trace_feature_is_enabled() -> bool;
}
pub mod rte_trace_mode {
    #[doc = "Enumerate trace mode operation."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "In this mode, when no space is left in the trace buffer, the\nsubsequent events overwrite the old events."]
    pub const RTE_TRACE_MODE_OVERWRITE: Type = 0;
    #[doc = "In this mode, when no space is left in the trace buffer, the\nsubsequent events shall not be recorded."]
    pub const RTE_TRACE_MODE_DISCARD: Type = 1;
}
unsafe extern "C" {
    #[doc = "Set the trace mode.\n\n# Arguments\n\n* `mode` -\nTrace mode."]
    pub fn rte_trace_mode_set(mode: rte_trace_mode::Type);
}
unsafe extern "C" {
    #[doc = "Get the trace mode.\n\n# Returns\n\nThe current trace mode."]
    pub fn rte_trace_mode_get() -> rte_trace_mode::Type;
}
unsafe extern "C" {
    #[doc = "Enable/Disable a set of tracepoints based on globbing pattern.\n\n# Arguments\n\n* `pattern` -\nThe globbing pattern identifying the tracepoint.\n* `enable` -\ntrue to enable tracepoint, false to disable the tracepoint, upon match.\n\n# Returns\n\n- 0: Success and no pattern match.\n- 1: Success and found pattern match.\n- (-ERANGE): Tracepoint object is not registered."]
    pub fn rte_trace_pattern(
        pattern: *const ::core::ffi::c_char,
        enable: bool,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable/Disable a set of tracepoints based on regular expression.\n\n# Arguments\n\n* `regex` -\nA regular expression identifying the tracepoint.\n* `enable` -\ntrue to enable tracepoint, false to disable the tracepoint, upon match.\n\n# Returns\n\n- 0: Success and no pattern match.\n- 1: Success and found pattern match.\n- (-ERANGE): Tracepoint object is not registered.\n- (-EINVAL): Invalid regular expression rule."]
    pub fn rte_trace_regexp(regex: *const ::core::ffi::c_char, enable: bool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Save the trace buffer to the trace directory.\nBy default, trace directory will be created at $HOME directory and this can\nbe overridden by --trace-dir EAL parameter.\n\n# Returns\n\n- 0: Success.\n- <0 : Failure."]
    pub fn rte_trace_save() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the trace metadata to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n\n# Returns\n\n- 0: Success.\n- <0 : Failure."]
    pub fn rte_trace_metadata_dump(f: *mut FILE) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the trace subsystem status to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_trace_dump(f: *mut FILE);
}
#[doc = "The tracepoint object."]
pub type rte_trace_point_t = u64;
unsafe extern "C" {
    #[doc = "Enable recording events of the given tracepoint in the trace buffer.\n\n# Arguments\n\n* `tp` -\nThe tracepoint object to enable.\n\n# Returns\n\n- 0: Success.\n- (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_enable(tp: *mut rte_trace_point_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable recording events of the given tracepoint in the trace buffer.\n\n# Arguments\n\n* `tp` -\nThe tracepoint object to disable.\n\n# Returns\n\n- 0: Success.\n- (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_disable(tp: *mut rte_trace_point_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if recording events from the given tracepoint is enabled.\n\n# Arguments\n\n* `tp` -\nThe tracepoint object.\n\n# Returns\n\ntrue if tracepoint is enabled, false otherwise."]
    pub fn rte_trace_point_is_enabled(tp: *mut rte_trace_point_t) -> bool;
}
unsafe extern "C" {
    #[doc = "Lookup a tracepoint object from its name.\n\n# Arguments\n\n* `name` -\nThe name of the tracepoint.\n\n# Returns\n\nThe tracepoint object or NULL if not found."]
    pub fn rte_trace_point_lookup(name: *const ::core::ffi::c_char) -> *mut rte_trace_point_t;
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_ops_dequeue_bulk_w"]
    pub fn rte_mempool_trace_ops_dequeue_bulk(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *mut *mut ::core::ffi::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_ops_dequeue_contig_blocks_w"]
    pub fn rte_mempool_trace_ops_dequeue_contig_blocks(
        mempool: *mut ::core::ffi::c_void,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_ops_enqueue_bulk_w"]
    pub fn rte_mempool_trace_ops_enqueue_bulk(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *const *mut ::core::ffi::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_generic_put_w"]
    pub fn rte_mempool_trace_generic_put(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *const *mut ::core::ffi::c_void,
        nb_objs: u32,
        cache: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_put_bulk_w"]
    pub fn rte_mempool_trace_put_bulk(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *const *mut ::core::ffi::c_void,
        nb_objs: u32,
        cache: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_generic_get_w"]
    pub fn rte_mempool_trace_generic_get(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *const *mut ::core::ffi::c_void,
        nb_objs: u32,
        cache: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_get_bulk_w"]
    pub fn rte_mempool_trace_get_bulk(
        mempool: *mut ::core::ffi::c_void,
        obj_table: *mut *mut ::core::ffi::c_void,
        nb_objs: u32,
        cache: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_get_contig_blocks_w"]
    pub fn rte_mempool_trace_get_contig_blocks(
        mempool: *mut ::core::ffi::c_void,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_default_cache_w"]
    pub fn rte_mempool_trace_default_cache(
        mempool: *mut ::core::ffi::c_void,
        lcore_id: u32,
        default_cache: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_mempool_trace_cache_flush_w"]
    pub fn rte_mempool_trace_cache_flush(
        cache: *mut ::core::ffi::c_void,
        mempool: *mut ::core::ffi::c_void,
    );
}
#[doc = "A structure that stores a per-core object cache."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_cache {
    #[doc = "< Size of the cache"]
    pub size: u32,
    #[doc = "< Threshold before we flush excess elements"]
    pub flushthresh: u32,
    #[doc = "< Current cache count"]
    pub len: u32,
    pub __bindgen_padding_0: [u64; 6usize],
    #[doc = "Cache objects\nCache is allocated to this size to allow it to overflow in certain\ncases to avoid needless emptying of cache."]
    pub objs: [*mut ::core::ffi::c_void; 1024usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_cache"][::core::mem::size_of::<rte_mempool_cache>() - 8256usize];
    ["Alignment of rte_mempool_cache"][::core::mem::align_of::<rte_mempool_cache>() - 64usize];
    ["Offset of field: rte_mempool_cache::size"]
        [::core::mem::offset_of!(rte_mempool_cache, size) - 0usize];
    ["Offset of field: rte_mempool_cache::flushthresh"]
        [::core::mem::offset_of!(rte_mempool_cache, flushthresh) - 4usize];
    ["Offset of field: rte_mempool_cache::len"]
        [::core::mem::offset_of!(rte_mempool_cache, len) - 8usize];
    ["Offset of field: rte_mempool_cache::objs"]
        [::core::mem::offset_of!(rte_mempool_cache, objs) - 64usize];
};
impl Default for rte_mempool_cache {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure that stores the size of mempool elements."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mempool_objsz {
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    pub total_size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objsz"][::core::mem::size_of::<rte_mempool_objsz>() - 16usize];
    ["Alignment of rte_mempool_objsz"][::core::mem::align_of::<rte_mempool_objsz>() - 4usize];
    ["Offset of field: rte_mempool_objsz::elt_size"]
        [::core::mem::offset_of!(rte_mempool_objsz, elt_size) - 0usize];
    ["Offset of field: rte_mempool_objsz::header_size"]
        [::core::mem::offset_of!(rte_mempool_objsz, header_size) - 4usize];
    ["Offset of field: rte_mempool_objsz::trailer_size"]
        [::core::mem::offset_of!(rte_mempool_objsz, trailer_size) - 8usize];
    ["Offset of field: rte_mempool_objsz::total_size"]
        [::core::mem::offset_of!(rte_mempool_objsz, total_size) - 12usize];
};
#[doc = "Mempool object header structure\nEach object stored in mempools are prefixed by this header structure,\nit allows to retrieve the mempool pointer from the object and to\niterate on all objects attached to a mempool. When debug is enabled,\na cookie is also added in this structure preventing corruptions and\ndouble-frees."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_objhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the object."]
    pub mp: *mut rte_mempool,
    #[doc = "< IO address of the object."]
    pub iova: rte_iova_t,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr__bindgen_ty_1 {
    #[doc = "next element"]
    pub stqe_next: *mut rte_mempool_objhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mempool_objhdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool_objhdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mempool_objhdr__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool_objhdr__bindgen_ty_1::stqe_next"]
        [::core::mem::offset_of!(rte_mempool_objhdr__bindgen_ty_1, stqe_next) - 0usize];
};
impl Default for rte_mempool_objhdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr"][::core::mem::size_of::<rte_mempool_objhdr>() - 24usize];
    ["Alignment of rte_mempool_objhdr"][::core::mem::align_of::<rte_mempool_objhdr>() - 8usize];
    ["Offset of field: rte_mempool_objhdr::next"]
        [::core::mem::offset_of!(rte_mempool_objhdr, next) - 0usize];
    ["Offset of field: rte_mempool_objhdr::mp"]
        [::core::mem::offset_of!(rte_mempool_objhdr, mp) - 8usize];
    ["Offset of field: rte_mempool_objhdr::iova"]
        [::core::mem::offset_of!(rte_mempool_objhdr, iova) - 16usize];
};
impl Default for rte_mempool_objhdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A list of object headers type"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr_list {
    #[doc = "first element"]
    pub stqh_first: *mut rte_mempool_objhdr,
    #[doc = "addr of last next element"]
    pub stqh_last: *mut *mut rte_mempool_objhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr_list"]
        [::core::mem::size_of::<rte_mempool_objhdr_list>() - 16usize];
    ["Alignment of rte_mempool_objhdr_list"]
        [::core::mem::align_of::<rte_mempool_objhdr_list>() - 8usize];
    ["Offset of field: rte_mempool_objhdr_list::stqh_first"]
        [::core::mem::offset_of!(rte_mempool_objhdr_list, stqh_first) - 0usize];
    ["Offset of field: rte_mempool_objhdr_list::stqh_last"]
        [::core::mem::offset_of!(rte_mempool_objhdr_list, stqh_last) - 8usize];
};
impl Default for rte_mempool_objhdr_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@internal Logtype used for mempool related messages."]
    pub static mut rte_mempool_logtype: ::core::ffi::c_int;
}
#[doc = "A list of memory where objects are stored"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr_list {
    #[doc = "first element"]
    pub stqh_first: *mut rte_mempool_memhdr,
    #[doc = "addr of last next element"]
    pub stqh_last: *mut *mut rte_mempool_memhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr_list"]
        [::core::mem::size_of::<rte_mempool_memhdr_list>() - 16usize];
    ["Alignment of rte_mempool_memhdr_list"]
        [::core::mem::align_of::<rte_mempool_memhdr_list>() - 8usize];
    ["Offset of field: rte_mempool_memhdr_list::stqh_first"]
        [::core::mem::offset_of!(rte_mempool_memhdr_list, stqh_first) - 0usize];
    ["Offset of field: rte_mempool_memhdr_list::stqh_last"]
        [::core::mem::offset_of!(rte_mempool_memhdr_list, stqh_last) - 8usize];
};
impl Default for rte_mempool_memhdr_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Callback used to free a memory chunk"]
pub type rte_mempool_memchunk_free_cb_t = ::core::option::Option<
    unsafe extern "C" fn(memhdr: *mut rte_mempool_memhdr, opaque: *mut ::core::ffi::c_void),
>;
#[doc = "Mempool objects memory header structure\nThe memory chunks where objects are stored. Each chunk is virtually\nand physically contiguous."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_memhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the chunk"]
    pub mp: *mut rte_mempool,
    #[doc = "< Virtual address of the chunk"]
    pub addr: *mut ::core::ffi::c_void,
    #[doc = "< IO address of the chunk"]
    pub iova: rte_iova_t,
    #[doc = "< length of the chunk"]
    pub len: usize,
    #[doc = "< Free callback"]
    pub free_cb: rte_mempool_memchunk_free_cb_t,
    #[doc = "< Argument passed to the free callback"]
    pub opaque: *mut ::core::ffi::c_void,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr__bindgen_ty_1 {
    #[doc = "next element"]
    pub stqe_next: *mut rte_mempool_memhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mempool_memhdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool_memhdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mempool_memhdr__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool_memhdr__bindgen_ty_1::stqe_next"]
        [::core::mem::offset_of!(rte_mempool_memhdr__bindgen_ty_1, stqe_next) - 0usize];
};
impl Default for rte_mempool_memhdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr"][::core::mem::size_of::<rte_mempool_memhdr>() - 56usize];
    ["Alignment of rte_mempool_memhdr"][::core::mem::align_of::<rte_mempool_memhdr>() - 8usize];
    ["Offset of field: rte_mempool_memhdr::next"]
        [::core::mem::offset_of!(rte_mempool_memhdr, next) - 0usize];
    ["Offset of field: rte_mempool_memhdr::mp"]
        [::core::mem::offset_of!(rte_mempool_memhdr, mp) - 8usize];
    ["Offset of field: rte_mempool_memhdr::addr"]
        [::core::mem::offset_of!(rte_mempool_memhdr, addr) - 16usize];
    ["Offset of field: rte_mempool_memhdr::iova"]
        [::core::mem::offset_of!(rte_mempool_memhdr, iova) - 24usize];
    ["Offset of field: rte_mempool_memhdr::len"]
        [::core::mem::offset_of!(rte_mempool_memhdr, len) - 32usize];
    ["Offset of field: rte_mempool_memhdr::free_cb"]
        [::core::mem::offset_of!(rte_mempool_memhdr, free_cb) - 40usize];
    ["Offset of field: rte_mempool_memhdr::opaque"]
        [::core::mem::offset_of!(rte_mempool_memhdr, opaque) - 48usize];
};
impl Default for rte_mempool_memhdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Additional information about the mempool\nThe structure is cache-line aligned to avoid ABI breakages in\na number of cases when something small is added."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_info {
    #[doc = "Number of objects in the contiguous block"]
    pub contig_block_size: ::core::ffi::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_info"][::core::mem::size_of::<rte_mempool_info>() - 64usize];
    ["Alignment of rte_mempool_info"][::core::mem::align_of::<rte_mempool_info>() - 64usize];
    ["Offset of field: rte_mempool_info::contig_block_size"]
        [::core::mem::offset_of!(rte_mempool_info, contig_block_size) - 0usize];
};
impl Default for rte_mempool_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "The RTE mempool structure."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mempool {
    #[doc = "< Name of mempool."]
    pub name: [::core::ffi::c_char; 26usize],
    pub anon1: rte_mempool__bindgen_ty_1,
    #[doc = "< optional args for ops alloc."]
    pub pool_config: *mut ::core::ffi::c_void,
    #[doc = "< Memzone where pool is alloc'd."]
    pub mz: *const rte_memzone,
    #[doc = "< Flags of the mempool."]
    pub flags: ::core::ffi::c_uint,
    #[doc = "< Socket id passed at create."]
    pub socket_id: ::core::ffi::c_int,
    #[doc = "< Max size of the mempool."]
    pub size: u32,
    pub cache_size: u32,
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    #[doc = "< Size of private data."]
    pub private_data_size: ::core::ffi::c_uint,
    #[doc = "Index into rte_mempool_ops_table array of mempool ops\nstructs, which contain callback function pointers.\nWe're using an index here rather than pointers to the callbacks\nto facilitate any secondary processes that may want to use\nthis mempool."]
    pub ops_index: i32,
    #[doc = "< Per-lcore local cache"]
    pub local_cache: *mut rte_mempool_cache,
    #[doc = "< Number of populated objects."]
    pub populated_size: u32,
    #[doc = "< List of objects in pool"]
    pub elt_list: rte_mempool_objhdr_list,
    #[doc = "< Number of memory chunks"]
    pub nb_mem_chunks: u32,
    #[doc = "< List of memory chunks"]
    pub mem_list: rte_mempool_memhdr_list,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mempool__bindgen_ty_1 {
    #[doc = "< Ring or pool to store objects."]
    pub pool_data: *mut ::core::ffi::c_void,
    #[doc = "< External mempool identifier."]
    pub pool_id: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mempool__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mempool__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool__bindgen_ty_1::pool_data"]
        [::core::mem::offset_of!(rte_mempool__bindgen_ty_1, pool_data) - 0usize];
    ["Offset of field: rte_mempool__bindgen_ty_1::pool_id"]
        [::core::mem::offset_of!(rte_mempool__bindgen_ty_1, pool_id) - 0usize];
};
impl Default for rte_mempool__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool"][::core::mem::size_of::<rte_mempool>() - 192usize];
    ["Alignment of rte_mempool"][::core::mem::align_of::<rte_mempool>() - 64usize];
    ["Offset of field: rte_mempool::name"][::core::mem::offset_of!(rte_mempool, name) - 0usize];
    ["Offset of field: rte_mempool::pool_config"]
        [::core::mem::offset_of!(rte_mempool, pool_config) - 40usize];
    ["Offset of field: rte_mempool::mz"][::core::mem::offset_of!(rte_mempool, mz) - 48usize];
    ["Offset of field: rte_mempool::flags"][::core::mem::offset_of!(rte_mempool, flags) - 56usize];
    ["Offset of field: rte_mempool::socket_id"]
        [::core::mem::offset_of!(rte_mempool, socket_id) - 60usize];
    ["Offset of field: rte_mempool::size"][::core::mem::offset_of!(rte_mempool, size) - 64usize];
    ["Offset of field: rte_mempool::cache_size"]
        [::core::mem::offset_of!(rte_mempool, cache_size) - 68usize];
    ["Offset of field: rte_mempool::elt_size"]
        [::core::mem::offset_of!(rte_mempool, elt_size) - 72usize];
    ["Offset of field: rte_mempool::header_size"]
        [::core::mem::offset_of!(rte_mempool, header_size) - 76usize];
    ["Offset of field: rte_mempool::trailer_size"]
        [::core::mem::offset_of!(rte_mempool, trailer_size) - 80usize];
    ["Offset of field: rte_mempool::private_data_size"]
        [::core::mem::offset_of!(rte_mempool, private_data_size) - 84usize];
    ["Offset of field: rte_mempool::ops_index"]
        [::core::mem::offset_of!(rte_mempool, ops_index) - 88usize];
    ["Offset of field: rte_mempool::local_cache"]
        [::core::mem::offset_of!(rte_mempool, local_cache) - 96usize];
    ["Offset of field: rte_mempool::populated_size"]
        [::core::mem::offset_of!(rte_mempool, populated_size) - 104usize];
    ["Offset of field: rte_mempool::elt_list"]
        [::core::mem::offset_of!(rte_mempool, elt_list) - 112usize];
    ["Offset of field: rte_mempool::nb_mem_chunks"]
        [::core::mem::offset_of!(rte_mempool, nb_mem_chunks) - 128usize];
    ["Offset of field: rte_mempool::mem_list"]
        [::core::mem::offset_of!(rte_mempool, mem_list) - 136usize];
};
impl Default for rte_mempool {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "return the header of a mempool object (internal)"]
    #[link_name = "rte_mempool_get_header_w"]
    pub fn rte_mempool_get_header(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool_objhdr;
}
unsafe extern "C" {
    #[doc = "Return a pointer to the mempool owning this object.\n\n# Arguments\n\n* `obj` -\nAn object that is owned by a pool. If this is not the case,\nthe behavior is undefined.\n\n# Returns\n\nA pointer to the mempool structure."]
    #[link_name = "rte_mempool_from_obj_w"]
    pub fn rte_mempool_from_obj(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objtlr {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "return the trailer of a mempool object (internal)"]
    #[link_name = "rte_mempool_get_trailer_w"]
    pub fn rte_mempool_get_trailer(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool_objtlr;
}
unsafe extern "C" {
    #[doc = "@internal Check and update cookies or panic.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n* `obj_table_const` -\nPointer to a table of void * pointers (objects).\n* `n` -\nIndex of object in object table.\n* `free` -\n- 0: object is supposed to be allocated, mark it as free\n- 1: object is supposed to be free, mark it as allocated\n- 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_check_cookies(
        mp: *const rte_mempool,
        obj_table_const: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free: ::core::ffi::c_int,
    );
}
unsafe extern "C" {
    #[doc = "@internal Check contiguous object blocks and update cookies or panic.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n* `first_obj_table_const` -\nPointer to a table of void * pointers (first object of the contiguous\nobject blocks).\n* `n` -\nNumber of contiguous object blocks.\n* `free` -\n- 0: object is supposed to be allocated, mark it as free\n- 1: object is supposed to be free, mark it as allocated\n- 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_contig_blocks_check_cookies(
        mp: *const rte_mempool,
        first_obj_table_const: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free: ::core::ffi::c_int,
    );
}
#[doc = "Prototype for implementation specific data provisioning function.\nThe function should provide the implementation specific memory for\nuse by the other mempool ops functions in a given mempool ops struct.\nE.g. the default ops provides an instance of the rte_ring for this purpose.\nit will most likely point to a different type of data structure, and\nwill be transparent to the application programmer.\nThis function should set mp->pool_data."]
pub type rte_mempool_alloc_t =
    ::core::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool) -> ::core::ffi::c_int>;
#[doc = "Free the opaque private data pointed to by mp->pool_data pointer."]
pub type rte_mempool_free_t = ::core::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool)>;
#[doc = "Enqueue 'n' objects into the external pool.\n\n# Returns\n\n- 0: Success\n- <0: Error"]
pub type rte_mempool_enqueue_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Dequeue 'n' objects from the external pool.\n\n# Returns\n\n- 0: Success\n- <0: Error"]
pub type rte_mempool_dequeue_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Dequeue a number of contiguous object blocks from the external pool."]
pub type rte_mempool_dequeue_contig_blocks_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Return the number of available objects in the external pool."]
pub type rte_mempool_get_count =
    ::core::option::Option<unsafe extern "C" fn(mp: *const rte_mempool) -> ::core::ffi::c_uint>;
#[doc = "Calculate memory size required to store given number of objects.\nIf mempool objects are not required to be IOVA-contiguous\n(the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is set), min_chunk_size defines\nvirtually contiguous chunk size. Otherwise, if mempool objects must\nbe IOVA-contiguous (the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is clear),\nmin_chunk_size defines IOVA-contiguous chunk size.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to the memory pool.\n* `obj_num` [in]  -\nNumber of objects.\n* `pg_shift` [in]  -\nLOG2 of the physical pages size. If set to 0, ignore page boundaries.\n* `min_chunk_size` [out]  -\nLocation for minimum size of the memory chunk which may be used to\nstore memory pool objects.\n* `align` [out]  -\nLocation for required memory chunk alignment.\n\n# Returns\n\nRequired memory size."]
pub type rte_mempool_calc_mem_size_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize,
>;
unsafe extern "C" {
    #[doc = "@internal Helper to calculate memory size required to store given\nnumber of objects.\nThis function is internal to mempool library and mempool drivers.\nIf page boundaries may be ignored, it is just a product of total\nobject size including header and trailer and number of objects.\nOtherwise, it is a number of pages required to store given number of\nobjects without crossing page boundary.\nNote that if object size is bigger than page size, then it assumes\nthat pages are grouped in subsets of physically continuous pages big\nenough to store at least one object.\nMinimum size of memory chunk is the total element size.\nRequired memory chunk alignment is the cache line size.\n\n# Arguments\n\n* `mp` [in]  -\nA pointer to the mempool structure.\n* `obj_num` [in]  -\nNumber of objects to be added in mempool.\n* `pg_shift` [in]  -\nLOG2 of the physical pages size. If set to 0, ignore page boundaries.\n* `chunk_reserve` [in]  -\nAmount of memory that must be reserved at the beginning of each page,\nor at the beginning of the memory area if pg_shift is 0.\n* `min_chunk_size` [out]  -\nLocation for minimum size of the memory chunk which may be used to\nstore memory pool objects.\n* `align` [out]  -\nLocation for required memory chunk alignment.\n\n# Returns\n\nRequired memory size."]
    pub fn rte_mempool_op_calc_mem_size_helper(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        chunk_reserve: usize,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = "Default way to calculate memory size required to store given number of\nobjects.\nEquivalent to rte_mempool_op_calc_mem_size_helper(mp, obj_num, pg_shift,\n0, min_chunk_size, align)."]
    pub fn rte_mempool_op_calc_mem_size_default(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
#[doc = "Function to be called for each populated object.\n\n# Arguments\n\n* `mp` [in]  -\nA pointer to the mempool structure.\n* `opaque` [in]  -\nAn opaque pointer passed to iterator.\n* `vaddr` [in]  -\nObject virtual address.\n* `iova` [in]  -\nInput/output virtual address of the object or RTE_BAD_IOVA."]
pub type rte_mempool_populate_obj_cb_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::core::ffi::c_void,
        vaddr: *mut ::core::ffi::c_void,
        iova: rte_iova_t,
    ),
>;
#[doc = "Populate memory pool objects using provided memory chunk.\nPopulated objects should be enqueued to the pool, e.g. using\nrte_mempool_ops_enqueue_bulk().\nIf the given IO address is unknown (iova = RTE_BAD_IOVA),\nthe chunk doesn't need to be physically contiguous (only virtually),\nand allocated objects may span two pages.\n\n# Arguments\n\n* `mp` [in]  -\nA pointer to the mempool structure.\n* `max_objs` [in]  -\nMaximum number of objects to be populated.\n* `vaddr` [in]  -\nThe virtual address of memory that should be used to store objects.\n* `iova` [in]  -\nThe IO address\n* `len` [in]  -\nThe length of memory in bytes.\n* `obj_cb` [in]  -\nCallback function to be executed for each populated object.\n* `obj_cb_arg` [in]  -\nAn opaque pointer passed to the callback function.\n\n# Returns\n\nThe number of objects added on success.\nOn error, no objects are populated and a negative errno is returned."]
pub type rte_mempool_populate_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        max_objs: ::core::ffi::c_uint,
        vaddr: *mut ::core::ffi::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "@internal Helper to populate memory pool object using provided memory\nchunk: just slice objects one by one, taking care of not\ncrossing page boundaries.\nIf RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ is set in flags, the addresses\nof object headers will be aligned on a multiple of total_elt_sz.\nThis feature is used by octeontx hardware.\nThis function is internal to mempool library and mempool drivers.\n\n# Arguments\n\n* `mp` [in]  -\nA pointer to the mempool structure.\n* `flags` [in]  -\nLogical OR of following flags:\n- RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ: align objects on addresses\nmultiple of total_elt_sz.\n* `max_objs` [in]  -\nMaximum number of objects to be added in mempool.\n* `vaddr` [in]  -\nThe virtual address of memory that should be used to store objects.\n* `iova` [in]  -\nThe IO address corresponding to vaddr, or RTE_BAD_IOVA.\n* `len` [in]  -\nThe length of memory in bytes.\n* `obj_cb` [in]  -\nCallback function to be executed for each populated object.\n* `obj_cb_arg` [in]  -\nAn opaque pointer passed to the callback function.\n\n# Returns\n\nThe number of objects added in mempool."]
    pub fn rte_mempool_op_populate_helper(
        mp: *mut rte_mempool,
        flags: ::core::ffi::c_uint,
        max_objs: ::core::ffi::c_uint,
        vaddr: *mut ::core::ffi::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Default way to populate memory pool object using provided memory chunk.\nEquivalent to rte_mempool_op_populate_helper(mp, 0, max_objs, vaddr, iova,\nlen, obj_cb, obj_cb_arg)."]
    pub fn rte_mempool_op_populate_default(
        mp: *mut rte_mempool,
        max_objs: ::core::ffi::c_uint,
        vaddr: *mut ::core::ffi::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
#[doc = "Get some additional information about a mempool."]
pub type rte_mempool_get_info_t = ::core::option::Option<
    unsafe extern "C" fn(mp: *const rte_mempool, info: *mut rte_mempool_info) -> ::core::ffi::c_int,
>;
#[doc = "Structure defining mempool operations structure"]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_ops {
    #[doc = "< Name of mempool ops struct."]
    pub name: [::core::ffi::c_char; 32usize],
    #[doc = "< Allocate private data."]
    pub alloc: rte_mempool_alloc_t,
    #[doc = "< Free the external pool."]
    pub free: rte_mempool_free_t,
    #[doc = "< Enqueue an object."]
    pub enqueue: rte_mempool_enqueue_t,
    #[doc = "< Dequeue an object."]
    pub dequeue: rte_mempool_dequeue_t,
    #[doc = "< Get qty of available objs."]
    pub get_count: rte_mempool_get_count,
    #[doc = "Optional callback to calculate memory size required to\nstore specified number of objects."]
    pub calc_mem_size: rte_mempool_calc_mem_size_t,
    #[doc = "Optional callback to populate mempool objects using\nprovided memory chunk."]
    pub populate: rte_mempool_populate_t,
    #[doc = "Get mempool info"]
    pub get_info: rte_mempool_get_info_t,
    #[doc = "Dequeue a number of contiguous object blocks."]
    pub dequeue_contig_blocks: rte_mempool_dequeue_contig_blocks_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_ops"][::core::mem::size_of::<rte_mempool_ops>() - 128usize];
    ["Alignment of rte_mempool_ops"][::core::mem::align_of::<rte_mempool_ops>() - 64usize];
    ["Offset of field: rte_mempool_ops::name"]
        [::core::mem::offset_of!(rte_mempool_ops, name) - 0usize];
    ["Offset of field: rte_mempool_ops::alloc"]
        [::core::mem::offset_of!(rte_mempool_ops, alloc) - 32usize];
    ["Offset of field: rte_mempool_ops::free"]
        [::core::mem::offset_of!(rte_mempool_ops, free) - 40usize];
    ["Offset of field: rte_mempool_ops::enqueue"]
        [::core::mem::offset_of!(rte_mempool_ops, enqueue) - 48usize];
    ["Offset of field: rte_mempool_ops::dequeue"]
        [::core::mem::offset_of!(rte_mempool_ops, dequeue) - 56usize];
    ["Offset of field: rte_mempool_ops::get_count"]
        [::core::mem::offset_of!(rte_mempool_ops, get_count) - 64usize];
    ["Offset of field: rte_mempool_ops::calc_mem_size"]
        [::core::mem::offset_of!(rte_mempool_ops, calc_mem_size) - 72usize];
    ["Offset of field: rte_mempool_ops::populate"]
        [::core::mem::offset_of!(rte_mempool_ops, populate) - 80usize];
    ["Offset of field: rte_mempool_ops::get_info"]
        [::core::mem::offset_of!(rte_mempool_ops, get_info) - 88usize];
    ["Offset of field: rte_mempool_ops::dequeue_contig_blocks"]
        [::core::mem::offset_of!(rte_mempool_ops, dequeue_contig_blocks) - 96usize];
};
impl Default for rte_mempool_ops {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Structure storing the table of registered ops structs, each of which contain\nthe function pointers for the mempool ops functions.\nEach process has its own storage for this ops struct array so that\nthe mempools can be shared across primary and secondary processes.\nThe indices used to access the array are valid across processes, whereas\nany function pointers stored directly in the mempool struct would not be.\nThis results in us simply having \"ops_index\" in the mempool struct."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_ops_table {
    #[doc = "< Spinlock for add/delete."]
    pub sl: rte_spinlock_t,
    #[doc = "< Number of used ops structs in the table."]
    pub num_ops: u32,
    pub __bindgen_padding_0: [u64; 7usize],
    #[doc = "Storage for all possible ops structs."]
    pub ops: [rte_mempool_ops; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_ops_table"][::core::mem::size_of::<rte_mempool_ops_table>() - 2112usize];
    ["Alignment of rte_mempool_ops_table"]
        [::core::mem::align_of::<rte_mempool_ops_table>() - 64usize];
    ["Offset of field: rte_mempool_ops_table::sl"]
        [::core::mem::offset_of!(rte_mempool_ops_table, sl) - 0usize];
    ["Offset of field: rte_mempool_ops_table::num_ops"]
        [::core::mem::offset_of!(rte_mempool_ops_table, num_ops) - 4usize];
    ["Offset of field: rte_mempool_ops_table::ops"]
        [::core::mem::offset_of!(rte_mempool_ops_table, ops) - 64usize];
};
impl Default for rte_mempool_ops_table {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Array of registered ops structs."]
    pub static mut rte_mempool_ops_table: rte_mempool_ops_table;
}
unsafe extern "C" {
    #[doc = "@internal Get the mempool ops struct from its index.\n\n# Arguments\n\n* `ops_index` -\nThe index of the ops struct in the ops struct table. It must be a valid\nindex: (0 <= idx < num_ops).\n\n# Returns\n\nThe pointer to the ops struct in the table."]
    #[link_name = "rte_mempool_get_ops_w"]
    pub fn rte_mempool_get_ops(ops_index: ::core::ffi::c_int) -> *mut rte_mempool_ops;
}
unsafe extern "C" {
    #[doc = "@internal Wrapper for mempool_ops alloc callback.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n\n# Returns\n\n- 0: Success; successfully allocated mempool pool_data.\n- <0: Error; code of alloc function."]
    pub fn rte_mempool_ops_alloc(mp: *mut rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Wrapper for mempool_ops dequeue callback.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n* `obj_table` -\nPointer to a table of void * pointers (objects).\n* `n` -\nNumber of objects to get.\n\n# Returns\n\n- 0: Success; got n objects.\n- <0: Error; code of dequeue function."]
    #[link_name = "rte_mempool_ops_dequeue_bulk_w"]
    pub fn rte_mempool_ops_dequeue_bulk(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Wrapper for mempool_ops dequeue_contig_blocks callback.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to the memory pool.\n* `first_obj_table` [out]  -\nPointer to a table of void * pointers (first objects).\n* `n` [in]  -\nNumber of blocks to get.\n\n# Returns\n\n- 0: Success; got n objects.\n- <0: Error; code of dequeue function."]
    #[link_name = "rte_mempool_ops_dequeue_contig_blocks_w"]
    pub fn rte_mempool_ops_dequeue_contig_blocks(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal wrapper for mempool_ops enqueue callback.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n* `obj_table` -\nPointer to a table of void * pointers (objects).\n* `n` -\nNumber of objects to put.\n\n# Returns\n\n- 0: Success; n objects supplied.\n- <0: Error; code of enqueue function."]
    #[link_name = "rte_mempool_ops_enqueue_bulk_w"]
    pub fn rte_mempool_ops_enqueue_bulk(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal wrapper for mempool_ops get_count callback.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n\n# Returns\n\nThe number of available objects in the external pool."]
    pub fn rte_mempool_ops_get_count(mp: *const rte_mempool) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "@internal wrapper for mempool_ops calc_mem_size callback.\nAPI to calculate size of memory required to store specified number of\nobject.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to the memory pool.\n* `obj_num` [in]  -\nNumber of objects.\n* `pg_shift` [in]  -\nLOG2 of the physical pages size. If set to 0, ignore page boundaries.\n* `min_chunk_size` [out]  -\nLocation for minimum size of the memory chunk which may be used to\nstore memory pool objects.\n* `align` [out]  -\nLocation for required memory chunk alignment.\n\n# Returns\n\nRequired memory size aligned at page boundary."]
    pub fn rte_mempool_ops_calc_mem_size(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = "@internal wrapper for mempool_ops populate callback.\nPopulate memory pool objects using provided memory chunk.\n\n# Arguments\n\n* `mp` [in]  -\nA pointer to the mempool structure.\n* `max_objs` [in]  -\nMaximum number of objects to be populated.\n* `vaddr` [in]  -\nThe virtual address of memory that should be used to store objects.\n* `iova` [in]  -\nThe IO address\n* `len` [in]  -\nThe length of memory in bytes.\n* `obj_cb` [in]  -\nCallback function to be executed for each populated object.\n* `obj_cb_arg` [in]  -\nAn opaque pointer passed to the callback function.\n\n# Returns\n\nThe number of objects added on success.\nOn error, no objects are populated and a negative errno is returned."]
    pub fn rte_mempool_ops_populate(
        mp: *mut rte_mempool,
        max_objs: ::core::ffi::c_uint,
        vaddr: *mut ::core::ffi::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Wrapper for mempool_ops get_info callback.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to the memory pool.\n* `info` [out]  -\nPointer to the rte_mempool_info structure\n\n# Returns\n\n- 0: Success; The mempool driver supports retrieving supplementary\nmempool information\n- -ENOTSUP - doesn't support get_info ops (valid case)."]
    pub fn rte_mempool_ops_get_info(
        mp: *const rte_mempool,
        info: *mut rte_mempool_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal wrapper for mempool_ops free callback.\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool."]
    pub fn rte_mempool_ops_free(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = "Set the ops of a mempool.\nThis can only be done on a mempool that is not populated, i.e. just after\na call to rte_mempool_create_empty().\n\n# Arguments\n\n* `mp` -\nPointer to the memory pool.\n* `name` -\nName of the ops structure to use for this mempool.\n* `pool_config` -\nOpaque data that can be passed by the application to the ops functions.\n\n# Returns\n\n- 0: Success; the mempool is now using the requested ops functions.\n- -EINVAL - Invalid ops struct name provided.\n- -EEXIST - mempool already has an ops struct assigned."]
    pub fn rte_mempool_set_ops_byname(
        mp: *mut rte_mempool,
        name: *const ::core::ffi::c_char,
        pool_config: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register mempool operations.\n\n# Arguments\n\n* `ops` -\nPointer to an ops structure to register.\n\n# Returns\n\n- >=0: Success; return the index of the ops struct in the table.\n- -EINVAL - some missing callbacks while registering ops struct.\n- -ENOSPC - the maximum number of ops structs has been reached."]
    pub fn rte_mempool_register_ops(ops: *const rte_mempool_ops) -> ::core::ffi::c_int;
}
#[doc = "An object callback function for mempool.\nUsed by rte_mempool_create() and rte_mempool_obj_iter()."]
pub type rte_mempool_obj_cb_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::core::ffi::c_void,
        obj: *mut ::core::ffi::c_void,
        obj_idx: ::core::ffi::c_uint,
    ),
>;
pub type rte_mempool_obj_ctor_t = rte_mempool_obj_cb_t;
#[doc = "A memory callback function for mempool.\nUsed by rte_mempool_mem_iter()."]
pub type rte_mempool_mem_cb_t = ::core::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::core::ffi::c_void,
        memhdr: *mut rte_mempool_memhdr,
        mem_idx: ::core::ffi::c_uint,
    ),
>;
#[doc = "A mempool constructor callback function.\nArguments are the mempool and the opaque pointer given by the user in\nrte_mempool_create()."]
pub type rte_mempool_ctor_t = ::core::option::Option<
    unsafe extern "C" fn(arg1: *mut rte_mempool, arg2: *mut ::core::ffi::c_void),
>;
unsafe extern "C" {
    #[doc = "Free a mempool\nUnlink the mempool from global list, free the memory chunks, and all\nmemory referenced by the mempool. The objects must not be used by\nother cores as they will be freed.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\nIf NULL then, the function does nothing."]
    pub fn rte_mempool_free(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = "Create a new mempool named *name* in memory.\nThis function uses ``rte_memzone_reserve()`` to allocate memory. The\npool contains n elements of elt_size. Its size is set to n.\n\n# Arguments\n\n* `name` -\nThe name of the mempool.\n* `n` -\nThe number of elements in the mempool. The optimum size (in terms of\nmemory usage) for a mempool is when n is a power of two minus one:\nn = (2^q - 1).\n* `elt_size` -\nThe size of each element.\n* `cache_size` -\nIf cache_size is non-zero, the rte_mempool library will try to\nlimit the accesses to the common lockless pool, by maintaining a\nper-lcore object cache. This argument must be lower or equal to\nRTE_MEMPOOL_CACHE_MAX_SIZE and n / 1.5. It is advised to choose\ncache_size to have \"n modulo cache_size == 0\": if this is\nnot the case, some elements will always stay in the pool and will\nnever be used. The access to the per-lcore table is of course\nfaster than the multi-producer/consumer pool. The cache can be\ndisabled if the cache_size argument is set to 0; it can be useful to\navoid losing objects in cache.\n* `private_data_size` -\nThe size of the private data appended after the mempool\nstructure. This is useful for storing some private data after the\nmempool structure, as is done for rte_mbuf_pool for example.\n* `mp_init` -\nA function pointer that is called for initialization of the pool,\nbefore object initialization. The user can initialize the private\ndata in this function if needed. This parameter can be NULL if\nnot needed.\n* `mp_init_arg` -\nAn opaque pointer to data that can be used in the mempool\nconstructor function.\n* `obj_init` -\nA function pointer that is called for each object at\ninitialization of the pool. The user can set some meta data in\nobjects if needed. This parameter can be NULL if not needed.\nThe obj_init() function takes the mempool pointer, the init_arg,\nthe object pointer and the object number as parameters.\n* `obj_init_arg` -\nAn opaque pointer to data that can be used as an argument for\neach call to the object constructor function.\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in the case of\nNUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nThe *flags* arguments is an OR of following flags:\n- RTE_MEMPOOL_F_NO_SPREAD: By default, objects addresses are spread\nbetween channels in RAM: the pool allocator will add padding\nbetween objects depending on the hardware configuration. See\nMemory alignment constraints for details. If this flag is set,\nthe allocator will just align them to a cache line.\n- RTE_MEMPOOL_F_NO_CACHE_ALIGN: By default, the returned objects are\ncache-aligned. This flag removes this constraint, and no\npadding will be present between objects. This flag implies\nRTE_MEMPOOL_F_NO_SPREAD.\n- RTE_MEMPOOL_F_SP_PUT: If this flag is set, the default behavior\nwhen using rte_mempool_put() or rte_mempool_put_bulk() is\n\"single-producer\". Otherwise, it is \"multi-producers\".\n- RTE_MEMPOOL_F_SC_GET: If this flag is set, the default behavior\nwhen using rte_mempool_get() or rte_mempool_get_bulk() is\n\"single-consumer\". Otherwise, it is \"multi-consumers\".\n- RTE_MEMPOOL_F_NO_IOVA_CONTIG: If set, allocated objects won't\nnecessarily be contiguous in IO memory.\n\n# Returns\n\nThe pointer to the new allocated mempool, on success. NULL on error\nwith rte_errno set appropriately. Possible rte_errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - cache size provided is too large or an unknown flag was passed\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_mempool_create(
        name: *const ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
        elt_size: ::core::ffi::c_uint,
        cache_size: ::core::ffi::c_uint,
        private_data_size: ::core::ffi::c_uint,
        mp_init: rte_mempool_ctor_t,
        mp_init_arg: *mut ::core::ffi::c_void,
        obj_init: rte_mempool_obj_cb_t,
        obj_init_arg: *mut ::core::ffi::c_void,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = "Create an empty mempool\nThe mempool is allocated and initialized, but it is not populated: no\nmemory is allocated for the mempool elements. The user has to call\nrte_mempool_populate_*() to add memory chunks to the pool. Once\npopulated, the user may also want to initialize each object with\nrte_mempool_obj_iter().\n\n# Arguments\n\n* `name` -\nThe name of the mempool.\n* `n` -\nThe maximum number of elements that can be added in the mempool.\nThe optimum size (in terms of memory usage) for a mempool is when n\nis a power of two minus one: n = (2^q - 1).\n* `elt_size` -\nThe size of each element.\n* `cache_size` -\nSize of the cache. See rte_mempool_create() for details.\n* `private_data_size` -\nThe size of the private data appended after the mempool\nstructure. This is useful for storing some private data after the\nmempool structure, as is done for rte_mbuf_pool for example.\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in the case of\nNUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nFlags controlling the behavior of the mempool. See\nrte_mempool_create() for details.\n\n# Returns\n\nThe pointer to the new allocated mempool, on success. NULL on error\nwith rte_errno set appropriately. See rte_mempool_create() for details."]
    pub fn rte_mempool_create_empty(
        name: *const ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
        elt_size: ::core::ffi::c_uint,
        cache_size: ::core::ffi::c_uint,
        private_data_size: ::core::ffi::c_uint,
        socket_id: ::core::ffi::c_int,
        flags: ::core::ffi::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = "Add physically contiguous memory for objects in the pool at init\nAdd a virtually and physically contiguous memory chunk in the pool\nwhere objects can be instantiated.\nIf the given IO address is unknown (iova = RTE_BAD_IOVA),\nthe chunk doesn't need to be physically contiguous (only virtually),\nand allocated objects may span two pages.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `vaddr` -\nThe virtual address of memory that should be used to store objects.\n* `iova` -\nThe IO address\n* `len` -\nThe length of memory in bytes.\n* `free_cb` -\nThe callback used to free this chunk when destroying the mempool.\n* `opaque` -\nAn opaque argument passed to free_cb.\n\n# Returns\n\nThe number of objects added on success (strictly positive).\nOn error, the chunk is not added in the memory list of the\nmempool the following code is returned:\n(0): not enough room in chunk for one object.\n(-ENOSPC): mempool is already populated.\n(-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_iova(
        mp: *mut rte_mempool,
        vaddr: *mut ::core::ffi::c_char,
        iova: rte_iova_t,
        len: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add virtually contiguous memory for objects in the pool at init\nAdd a virtually contiguous memory chunk in the pool where objects can\nbe instantiated.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `addr` -\nThe virtual address of memory that should be used to store objects.\n* `len` -\nThe length of memory in bytes.\n* `pg_sz` -\nThe size of memory pages in this virtual area.\n* `free_cb` -\nThe callback used to free this chunk when destroying the mempool.\n* `opaque` -\nAn opaque argument passed to free_cb.\n\n# Returns\n\nThe number of objects added on success (strictly positive).\nOn error, the chunk is not added in the memory list of the\nmempool the following code is returned:\n(0): not enough room in chunk for one object.\n(-ENOSPC): mempool is already populated.\n(-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_virt(
        mp: *mut rte_mempool,
        addr: *mut ::core::ffi::c_char,
        len: usize,
        pg_sz: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add memory for objects in the pool at init\nThis is the default function used by rte_mempool_create() to populate\nthe mempool. It adds memory allocated using rte_memzone_reserve().\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nThe number of objects added on success.\nOn error, the chunk is not added in the memory list of the\nmempool and a negative errno is returned."]
    pub fn rte_mempool_populate_default(mp: *mut rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add memory from anonymous mapping for objects in the pool at init\nThis function mmap an anonymous memory zone that is locked in\nmemory to store the objects of the mempool.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nThe number of objects added on success.\nOn error, 0 is returned, rte_errno is set, and the chunk is not added in\nthe memory list of the mempool."]
    pub fn rte_mempool_populate_anon(mp: *mut rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Call a function for each mempool element\nIterate across all objects attached to a rte_mempool and call the\ncallback function on it.\n\n# Arguments\n\n* `mp` -\nA pointer to an initialized mempool.\n* `obj_cb` -\nA function pointer that is called for each object.\n* `obj_cb_arg` -\nAn opaque pointer passed to the callback function.\n\n# Returns\n\nNumber of objects iterated."]
    pub fn rte_mempool_obj_iter(
        mp: *mut rte_mempool,
        obj_cb: rte_mempool_obj_cb_t,
        obj_cb_arg: *mut ::core::ffi::c_void,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Call a function for each mempool memory chunk\nIterate across all memory chunks attached to a rte_mempool and call\nthe callback function on it.\n\n# Arguments\n\n* `mp` -\nA pointer to an initialized mempool.\n* `mem_cb` -\nA function pointer that is called for each memory chunk.\n* `mem_cb_arg` -\nAn opaque pointer passed to the callback function.\n\n# Returns\n\nNumber of memory chunks iterated."]
    pub fn rte_mempool_mem_iter(
        mp: *mut rte_mempool,
        mem_cb: rte_mempool_mem_cb_t,
        mem_cb_arg: *mut ::core::ffi::c_void,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Dump the status of the mempool to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `mp` -\nA pointer to the mempool structure."]
    pub fn rte_mempool_dump(f: *mut FILE, mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = "Create a user-owned mempool cache.\nThis can be used by unregistered non-EAL threads to enable caching when they\ninteract with a mempool.\n\n# Arguments\n\n* `size` -\nThe size of the mempool cache. See rte_mempool_create()'s cache_size\nparameter description for more information. The same limits and\nconsiderations apply here too.\n* `socket_id` -\nThe socket identifier in the case of NUMA. The value can be\nSOCKET_ID_ANY if there is no NUMA constraint for the reserved zone."]
    pub fn rte_mempool_cache_create(
        size: u32,
        socket_id: ::core::ffi::c_int,
    ) -> *mut rte_mempool_cache;
}
unsafe extern "C" {
    #[doc = "Free a user-owned mempool cache.\n\n# Arguments\n\n* `cache` -\nA pointer to the mempool cache."]
    pub fn rte_mempool_cache_free(cache: *mut rte_mempool_cache);
}
unsafe extern "C" {
    #[doc = "Get a pointer to the per-lcore default mempool cache.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `lcore_id` -\nThe logical core id.\n\n# Returns\n\nA pointer to the mempool cache or NULL if disabled or unregistered non-EAL\nthread."]
    #[link_name = "rte_mempool_default_cache_w"]
    pub fn rte_mempool_default_cache(
        mp: *mut rte_mempool,
        lcore_id: ::core::ffi::c_uint,
    ) -> *mut rte_mempool_cache;
}
unsafe extern "C" {
    #[doc = "Flush a user-owned mempool cache to the specified mempool.\n\n# Arguments\n\n* `cache` -\nA pointer to the mempool cache.\n* `mp` -\nA pointer to the mempool."]
    #[link_name = "rte_mempool_cache_flush_w"]
    pub fn rte_mempool_cache_flush(cache: *mut rte_mempool_cache, mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = "@internal Put several objects back in the mempool; used internally.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to store back in the mempool, must be strictly\npositive.\n* `cache` -\nA pointer to a mempool cache structure. May be NULL if not needed."]
    #[link_name = "rte_mempool_do_generic_put_w"]
    pub fn rte_mempool_do_generic_put(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    #[doc = "Put several objects back in the mempool.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the mempool from the obj_table.\n* `cache` -\nA pointer to a mempool cache structure. May be NULL if not needed."]
    #[link_name = "rte_mempool_generic_put_w"]
    pub fn rte_mempool_generic_put(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    #[doc = "Put several objects back in the mempool.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nmempool creation time (see flags).\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to add in the mempool from obj_table."]
    #[link_name = "rte_mempool_put_bulk_w"]
    pub fn rte_mempool_put_bulk(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Put one object back in the mempool.\nThis function calls the multi-producer or the single-producer\nversion depending on the default behavior that was specified at\nmempool creation time (see flags).\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj` -\nA pointer to the object to be added."]
    #[link_name = "rte_mempool_put_w"]
    pub fn rte_mempool_put(mp: *mut rte_mempool, obj: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "@internal Get several objects from the mempool; used internally.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to get, must be strictly positive.\n* `cache` -\nA pointer to a mempool cache structure. May be NULL if not needed.\n\n# Returns\n\n- 0: Success.\n- <0: Error; code of driver dequeue function."]
    #[link_name = "rte_mempool_do_generic_get_w"]
    pub fn rte_mempool_do_generic_get(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get several objects from the mempool.\nIf cache is enabled, objects will be retrieved first from cache,\nsubsequently from the common pool. Note that it can return -ENOENT when\nthe local cache and common pool are empty, even if cache from other\nlcores are full.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to get from mempool to obj_table.\n* `cache` -\nA pointer to a mempool cache structure. May be NULL if not needed.\n\n# Returns\n\n- 0: Success; objects taken.\n- -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    #[link_name = "rte_mempool_generic_get_w"]
    pub fn rte_mempool_generic_get(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get several objects from the mempool.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behaviour that was specified at\nmempool creation time (see flags).\nIf cache is enabled, objects will be retrieved first from cache,\nsubsequently from the common pool. Note that it can return -ENOENT when\nthe local cache and common pool are empty, even if cache from other\nlcores are full.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects) that will be filled.\n* `n` -\nThe number of objects to get from the mempool to obj_table.\n\n# Returns\n\n- 0: Success; objects taken\n- -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    #[link_name = "rte_mempool_get_bulk_w"]
    pub fn rte_mempool_get_bulk(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get one object from the mempool.\nThis function calls the multi-consumers or the single-consumer\nversion, depending on the default behavior that was specified at\nmempool creation (see flags).\nIf cache is enabled, objects will be retrieved first from cache,\nsubsequently from the common pool. Note that it can return -ENOENT when\nthe local cache and common pool are empty, even if cache from other\nlcores are full.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `obj_p` -\nA pointer to a void * pointer (object) that will be filled.\n\n# Returns\n\n- 0: Success; objects taken.\n- -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    #[link_name = "rte_mempool_get_w"]
    pub fn rte_mempool_get(
        mp: *mut rte_mempool,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get a contiguous blocks of objects from the mempool.\nIf cache is enabled, consider to flush it first, to reuse objects\nas soon as possible.\nThe application should check that the driver supports the operation\nby calling rte_mempool_ops_get_info() and checking that `contig_block_size`\nis not zero.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n* `first_obj_table` -\nA pointer to a pointer to the first object in each block.\n* `n` -\nThe number of blocks to get from mempool.\n\n# Returns\n\n- 0: Success; blocks taken.\n- -ENOBUFS: Not enough entries in the mempool; no object is retrieved.\n- -EOPNOTSUPP: The mempool driver does not support block dequeue"]
    #[link_name = "rte_mempool_get_contig_blocks_w"]
    pub fn rte_mempool_get_contig_blocks(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the number of entries in the mempool.\nWhen cache is enabled, this function has to browse the length of\nall lcores, so it should not be used in a data path, but only for\ndebug purposes. User-owned mempool caches are not accounted for.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nThe number of entries in the mempool."]
    pub fn rte_mempool_avail_count(mp: *const rte_mempool) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of elements which have been allocated from the mempool\nWhen cache is enabled, this function has to browse the length of\nall lcores, so it should not be used in a data path, but only for\ndebug purposes.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nThe number of free entries in the mempool."]
    pub fn rte_mempool_in_use_count(mp: *const rte_mempool) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Test if the mempool is full.\nWhen cache is enabled, this function has to browse the length of all\nlcores, so it should not be used in a data path, but only for debug\npurposes. User-owned mempool caches are not accounted for.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\n- 1: The mempool is full.\n- 0: The mempool is not full."]
    #[link_name = "rte_mempool_full_w"]
    pub fn rte_mempool_full(mp: *const rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the mempool is empty.\nWhen cache is enabled, this function has to browse the length of all\nlcores, so it should not be used in a data path, but only for debug\npurposes. User-owned mempool caches are not accounted for.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\n- 1: The mempool is empty.\n- 0: The mempool is not empty."]
    #[link_name = "rte_mempool_empty_w"]
    pub fn rte_mempool_empty(mp: *const rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the IO address of elt, which is an element of the pool mp.\n\n# Arguments\n\n* `elt` -\nA pointer (virtual address) to the element of the pool.\n\n# Returns\n\nThe IO address of the elt element.\nIf the mempool was created with RTE_MEMPOOL_F_NO_IOVA_CONTIG, the\nreturned value is RTE_BAD_IOVA."]
    #[link_name = "rte_mempool_virt2iova_w"]
    pub fn rte_mempool_virt2iova(elt: *const ::core::ffi::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Check the consistency of mempool objects.\nVerify the coherency of fields in the mempool structure. Also check\nthat the cookies of mempool objects (even the ones that are not\npresent in pool) have a correct value. If not, a panic will occur.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure."]
    pub fn rte_mempool_audit(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = "Return a pointer to the private data in an mempool structure.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nA pointer to the private data."]
    #[link_name = "rte_mempool_get_priv_w"]
    pub fn rte_mempool_get_priv(mp: *mut rte_mempool) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Dump the status of all mempools on the console\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_mempool_list_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Search a mempool from its name\n\n# Arguments\n\n* `name` -\nThe name of the mempool.\n\n# Returns\n\nThe pointer to the mempool matching the name, or NULL if not found.\nNULL on error\nwith rte_errno set appropriately. Possible rte_errno values include:\n- ENOENT - required entry not available to return."]
    pub fn rte_mempool_lookup(name: *const ::core::ffi::c_char) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = "Get the header, trailer and total size of a mempool element.\nGiven a desired size of the mempool element and mempool flags,\ncalculates header, trailer, body and total sizes of the mempool object.\n\n# Arguments\n\n* `elt_size` -\nThe size of each element, without header and trailer.\n* `flags` -\nThe flags used for the mempool creation.\nConsult rte_mempool_create() for more information about possible values.\nThe size of each element.\n* `sz` -\nThe calculated detailed size the mempool object. May be NULL.\n\n# Returns\n\nTotal size of the mempool object."]
    pub fn rte_mempool_calc_obj_size(elt_size: u32, flags: u32, sz: *mut rte_mempool_objsz) -> u32;
}
unsafe extern "C" {
    #[doc = "Walk list of all memory pools\n\n# Arguments\n\n* `func` -\nIterator function\n* `arg` -\nArgument passed to iterator"]
    pub fn rte_mempool_walk(
        func: ::core::option::Option<
            unsafe extern "C" fn(arg1: *mut rte_mempool, arg: *mut ::core::ffi::c_void),
        >,
        arg: *mut ::core::ffi::c_void,
    );
}
#[doc = "A structure used to retrieve information about the memory range\nof the mempool."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_mem_range_info {
    #[doc = "Start of the memory range used by mempool objects"]
    pub start: *mut ::core::ffi::c_void,
    #[doc = "Length of the memory range used by mempool objects"]
    pub length: usize,
    #[doc = "Are all memory addresses used by mempool objects contiguous"]
    pub is_contiguous: bool,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_mem_range_info"]
        [::core::mem::size_of::<rte_mempool_mem_range_info>() - 24usize];
    ["Alignment of rte_mempool_mem_range_info"]
        [::core::mem::align_of::<rte_mempool_mem_range_info>() - 8usize];
    ["Offset of field: rte_mempool_mem_range_info::start"]
        [::core::mem::offset_of!(rte_mempool_mem_range_info, start) - 0usize];
    ["Offset of field: rte_mempool_mem_range_info::length"]
        [::core::mem::offset_of!(rte_mempool_mem_range_info, length) - 8usize];
    ["Offset of field: rte_mempool_mem_range_info::is_contiguous"]
        [::core::mem::offset_of!(rte_mempool_mem_range_info, is_contiguous) - 16usize];
};
impl Default for rte_mempool_mem_range_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nGet information about the memory range used to store objects in the mempool.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to an initialized mempool.\n* `mem_range` [out]  -\nPointer to struct which is used to return lowest address,\nlength of the memory range containing all the addresses,\nand whether these addresses are contiguous.\n\n# Returns\n\n0 on success, -EINVAL if mempool is not valid or mem_range is NULL."]
    pub fn rte_mempool_get_mem_range(
        mp: *const rte_mempool,
        mem_range: *mut rte_mempool_mem_range_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nReturn alignment of objects stored in the mempool.\n\n# Arguments\n\n* `mp` [in]  -\nPointer to a mempool.\n\n# Returns\n\nObject alignment if mp is valid. 0 if mp is NULL.\n"]
    pub fn rte_mempool_get_obj_alignment(mp: *const rte_mempool) -> usize;
}
unsafe extern "C" {
    #[doc = "@internal Get page size used for mempool object allocation.\nThis function is internal to mempool library and mempool drivers."]
    pub fn rte_mempool_get_page_size(mp: *mut rte_mempool, pg_sz: *mut usize)
    -> ::core::ffi::c_int;
}
pub mod rte_mempool_event {
    #[doc = "Mempool event type.\n@internal "]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Occurs after a mempool is fully populated."]
    pub const RTE_MEMPOOL_EVENT_READY: Type = 0;
    #[doc = "Occurs before the destruction of a mempool begins."]
    pub const RTE_MEMPOOL_EVENT_DESTROY: Type = 1;
}
#[doc = "@internal Mempool event callback.\nrte_mempool_event_callback_register() may be called from within the callback,\nbut the callbacks registered this way will not be invoked for the same event.\nrte_mempool_event_callback_unregister() may only be safely called\nto remove the running callback."]
pub type rte_mempool_event_callback = ::core::option::Option<
    unsafe extern "C" fn(
        event: rte_mempool_event::Type,
        mp: *mut rte_mempool,
        user_data: *mut ::core::ffi::c_void,
    ),
>;
unsafe extern "C" {
    #[doc = "@internal Register a callback function invoked on mempool life cycle event.\nThe function will be invoked in the process\nthat performs an action which triggers the callback.\nRegistration is process-private,\ni.e. each process must manage callbacks on its own if needed.\n\n# Arguments\n\n* `func` -\nCallback function.\n* `user_data` -\nUser data.\n\n# Returns\n\n0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_register(
        func: rte_mempool_event_callback,
        user_data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Unregister a callback added with rte_mempool_event_callback_register().\n`func` and `user_data` must exactly match registration parameters.\n\n# Arguments\n\n* `func` -\nCallback function.\n* `user_data` -\nUser data.\n\n# Returns\n\n0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_unregister(
        func: rte_mempool_event_callback,
        user_data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels.\n\n# Arguments\n\n* `p` -\nAddress to prefetch"]
    #[link_name = "rte_prefetch0_w"]
    pub fn rte_prefetch0(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels except the 0th cache level.\n\n# Arguments\n\n* `p` -\nAddress to prefetch"]
    #[link_name = "rte_prefetch1_w"]
    pub fn rte_prefetch1(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels except the 0th and 1th cache\nlevels.\n\n# Arguments\n\n* `p` -\nAddress to prefetch"]
    #[link_name = "rte_prefetch2_w"]
    pub fn rte_prefetch2(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels (non-temporal/transient version)\nThe non-temporal prefetch is intended as a prefetch hint that processor will\nuse the prefetched data only once or short period, unlike the\nrte_prefetch0() function which imply that prefetched data to use repeatedly.\n\n# Arguments\n\n* `p` -\nAddress to prefetch"]
    #[link_name = "rte_prefetch_non_temporal_w"]
    pub fn rte_prefetch_non_temporal(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, with intention to write. This\nprefetch variant hints to the CPU that the program is expecting to write to\nthe cache line being prefetched.\n\n# Arguments\n\n* `p` - Address to prefetch"]
    #[link_name = "rte_prefetch0_write_w"]
    pub fn rte_prefetch0_write(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, except the 0th, with intention\nto write. This prefetch variant hints to the CPU that the program is\nexpecting to write to the cache line being prefetched.\n\n# Arguments\n\n* `p` - Address to prefetch"]
    #[link_name = "rte_prefetch1_write_w"]
    pub fn rte_prefetch1_write(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, except the 0th and 1st, with\nintention to write. This prefetch variant hints to the CPU that the program\nis expecting to write to the cache line being prefetched.\n\n# Arguments\n\n* `p` - Address to prefetch"]
    #[link_name = "rte_prefetch2_write_w"]
    pub fn rte_prefetch2_write(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nDemote a cache line to a more distant level of cache from the processor.\nCLDEMOTE hints to hardware to move (demote) a cache line from the closest to\nthe processor to a level more distant from the processor. It is a hint and\nnot guaranteed. rte_cldemote is intended to move the cache line to the more\nremote cache, where it expects sharing to be efficient and to indicate that\na line may be accessed by a different core in the future.\n\n# Arguments\n\n* `p` -\nAddress to demote"]
    #[link_name = "rte_cldemote_w"]
    pub fn rte_cldemote(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "Get the name of the l2 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_l2_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the l3 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_l3_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the l4 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_l4_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the tunnel packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_tunnel_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the inner_l2 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l2_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the inner_l3 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l3_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the name of the inner_l4 packet type\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n\n# Returns\n\nA non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l4_name(ptype: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Write the packet type name into the buffer\n\n# Arguments\n\n* `ptype` -\nThe packet type value.\n* `buf` -\nThe buffer where the string is written.\n* `buflen` -\nThe length of the buffer.\n\n# Returns\n\n- 0 on success\n- (-1) if the buffer is too small"]
    pub fn rte_get_ptype_name(
        ptype: u32,
        buf: *mut ::core::ffi::c_char,
        buflen: usize,
    ) -> ::core::ffi::c_int;
}
#[doc = "The following types should be used when handling values according to a\nspecific byte ordering, which may differ from that of the host CPU.\nLibraries, public APIs and applications are encouraged to use them for\ndocumentation purposes."]
pub type rte_be16_t = u16;
pub type rte_be32_t = u32;
pub type rte_be64_t = u64;
pub type rte_le16_t = u16;
pub type rte_le32_t = u32;
pub type rte_le64_t = u64;
unsafe extern "C" {
    #[doc = "An internal function to swap bytes in a 16-bit value.\nIt is used by rte_bswap16() when the value is constant. Do not use\nthis function directly; rte_bswap16() is preferred."]
    #[link_name = "rte_constant_bswap16_w"]
    pub fn rte_constant_bswap16(x: u16) -> u16;
}
unsafe extern "C" {
    #[doc = "An internal function to swap bytes in a 32-bit value.\nIt is used by rte_bswap32() when the value is constant. Do not use\nthis function directly; rte_bswap32() is preferred."]
    #[link_name = "rte_constant_bswap32_w"]
    pub fn rte_constant_bswap32(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "An internal function to swap bytes of a 64-bit value.\nIt is used by rte_bswap64() when the value is constant. Do not use\nthis function directly; rte_bswap64() is preferred."]
    #[link_name = "rte_constant_bswap64_w"]
    pub fn rte_constant_bswap64(x: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "An architecture-optimized byte swap for a 16-bit value.\nDo not use this function directly. The preferred function is rte_bswap16()."]
    #[link_name = "rte_arch_bswap16_w"]
    pub fn rte_arch_bswap16(_x: u16) -> u16;
}
unsafe extern "C" {
    #[doc = "An architecture-optimized byte swap for a 32-bit value.\nDo not use this function directly. The preferred function is rte_bswap32()."]
    #[link_name = "rte_arch_bswap32_w"]
    pub fn rte_arch_bswap32(_x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "An architecture-optimized byte swap for a 64-bit value.\nDo not use this function directly. The preferred function is rte_bswap64().\n/\n/* 64-bit mode"]
    #[link_name = "rte_arch_bswap64_w"]
    pub fn rte_arch_bswap64(_x: u64) -> u64;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf_sched {
    #[doc = "< Queue ID."]
    pub queue_id: u32,
    pub traffic_class: u8,
    pub color: u8,
    #[doc = "< Reserved."]
    pub reserved: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_sched"][::core::mem::size_of::<rte_mbuf_sched>() - 8usize];
    ["Alignment of rte_mbuf_sched"][::core::mem::align_of::<rte_mbuf_sched>() - 4usize];
    ["Offset of field: rte_mbuf_sched::queue_id"]
        [::core::mem::offset_of!(rte_mbuf_sched, queue_id) - 0usize];
    ["Offset of field: rte_mbuf_sched::traffic_class"]
        [::core::mem::offset_of!(rte_mbuf_sched, traffic_class) - 4usize];
    ["Offset of field: rte_mbuf_sched::color"]
        [::core::mem::offset_of!(rte_mbuf_sched, color) - 5usize];
    ["Offset of field: rte_mbuf_sched::reserved"]
        [::core::mem::offset_of!(rte_mbuf_sched, reserved) - 6usize];
};
pub mod _bindgen_ty_2 {
    #[doc = "enum for the tx_offload bit-fields lengths and offsets.\ndefines the layout of rte_mbuf tx_offload field."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_MBUF_L2_LEN_BITS: Type = 7;
    pub const RTE_MBUF_L3_LEN_BITS: Type = 9;
    pub const RTE_MBUF_L4_LEN_BITS: Type = 8;
    pub const RTE_MBUF_TSO_SEGSZ_BITS: Type = 16;
    pub const RTE_MBUF_OUTL3_LEN_BITS: Type = 9;
    pub const RTE_MBUF_OUTL2_LEN_BITS: Type = 7;
    pub const RTE_MBUF_TXOFLD_UNUSED_BITS: Type = 8;
    pub const RTE_MBUF_L2_LEN_OFS: Type = 0;
    pub const RTE_MBUF_L3_LEN_OFS: Type = 7;
    pub const RTE_MBUF_L4_LEN_OFS: Type = 16;
    pub const RTE_MBUF_TSO_SEGSZ_OFS: Type = 24;
    pub const RTE_MBUF_OUTL3_LEN_OFS: Type = 40;
    pub const RTE_MBUF_OUTL2_LEN_OFS: Type = 49;
    pub const RTE_MBUF_TXOFLD_UNUSED_OFS: Type = 56;
}
#[doc = "The generic rte_mbuf, containing a packet mbuf."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mbuf {
    #[doc = "< Virtual address of segment buffer."]
    pub buf_addr: *mut ::core::ffi::c_void,
    #[doc = "Physical address of segment buffer.\nThis field is undefined if the build is configured to use only\nvirtual address as IOVA (i.e. RTE_IOVA_IN_MBUF is 0).\nForce alignment to 8-bytes, so as to ensure we have the exact\nlayout for the first cache line for 32-bit and 64-bit. This makes\nworking on vector drivers easier."]
    pub buf_iova: rte_iova_t,
    pub anon1: rte_mbuf__bindgen_ty_1,
    #[doc = "< Offload features."]
    pub ol_flags: u64,
    pub anon2: rte_mbuf__bindgen_ty_2,
    #[doc = "< Pool from which mbuf was allocated."]
    pub pool: *mut rte_mempool,
    #[doc = "Next segment of scattered packet. Must be NULL in the last\nsegment or in case of non-segmented packet."]
    pub next: *mut rte_mbuf,
    pub anon3: rte_mbuf__bindgen_ty_3,
    #[doc = "Shared data for external buffer attached to mbuf. See\nrte_pktmbuf_attach_extbuf()."]
    pub shinfo: *mut rte_mbuf_ext_shared_info,
    #[doc = "Size of the application private data. In case of an indirect\nmbuf, it stores the direct mbuf private data size."]
    pub priv_size: u16,
    #[doc = "Timesync flags for use with IEEE1588."]
    pub timesync: u16,
    #[doc = "< Reserved for dynamic fields."]
    pub dynfield1: [u32; 9usize],
}
#[doc = "next 8 bytes are initialised on RX descriptor rearm"]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_1 {
    pub rearm_data: [u64; 1usize],
    pub anon1: rte_mbuf__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_1__bindgen_ty_1 {
    pub data_off: u16,
    #[doc = "Reference counter. Its size should at least equal to the size\nof port field (16 bits), to support zero-copy broadcast.\nIt should only be accessed using the following functions:\nrte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and\nrte_mbuf_refcnt_set(). The functionality of these functions (atomic,\nor non-atomic) is controlled by the RTE_MBUF_REFCNT_ATOMIC flag."]
    pub refcnt: u16,
    #[doc = "Number of segments. Only valid for the first segment of an mbuf\nchain."]
    pub nb_segs: u16,
    #[doc = "Input port (16 bits to support more than 256 virtual ports).\nThe event eth Tx adapter uses this field to specify the output port."]
    pub port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::data_off"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, data_off) - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::refcnt"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, refcnt) - 2usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::nb_segs"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, nb_segs) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::port"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, port) - 6usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_1"][::core::mem::size_of::<rte_mbuf__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1::rearm_data"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_1, rearm_data) - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "remaining 24 bytes are set on RX when pulling packet from descriptor"]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2 {
    #[doc = "void * type of the array elements is retained for driver compatibility."]
    pub rx_descriptor_fields1: [*mut ::core::ffi::c_void; 3usize],
    pub anon1: rte_mbuf__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1 {
    pub anon1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    #[doc = "< Total pkt len: sum of all segments."]
    pub pkt_len: u32,
    #[doc = "< Amount of data in segment buffer."]
    pub data_len: u16,
    #[doc = "VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_VLAN is set."]
    pub vlan_tci: u16,
    pub anon2: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    #[doc = "Outer VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_QINQ is set."]
    pub vlan_tci_outer: u16,
    #[doc = "< Length of segment buffer."]
    pub buf_len: u16,
}
#[doc = "The packet type, which is the combination of outer/inner L2, L3, L4\nand tunnel types. The packet_type is about data really present in the\nmbuf. Example: if vlan stripping is enabled, a received vlan packet\nwould have RTE_PTYPE_L2_ETHER and not RTE_PTYPE_L2_VLAN because the\nvlan is stripped from the data."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< L2/L3/L4 and tunnel information."]
    pub packet_type: u32,
    pub anon1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    pub anon1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    pub _bitfield_align_2: [u8; 0],
    pub _bitfield_2: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub inner_esp_next_proto : u8 , pub anon1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , }
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
};
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn inner_l2_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l2_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l2_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn inner_l3_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l3_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l3_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        inner_l2_type: u8,
        inner_l3_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l2_type: u8 = unsafe { ::core::mem::transmute(inner_l2_type) };
            inner_l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let inner_l3_type: u8 = unsafe { ::core::mem::transmute(inner_l3_type) };
            inner_l3_type as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 1usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 1usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::inner_esp_next_proto",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        inner_esp_next_proto
    ) - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1>(
        ) - 4usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1>(
        ) - 1usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn l2_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l2_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l3_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l4_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tun_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(12usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_tun_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(12usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tun_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                12usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_tun_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                12usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_type: u8,
        l3_type: u8,
        l4_type: u8,
        tun_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let l2_type: u8 = unsafe { ::core::mem::transmute(l2_type) };
            l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let l3_type: u8 = unsafe { ::core::mem::transmute(l3_type) };
            l3_type as u64
        });
        __bindgen_bitfield_unit.set(8usize, 4u8, {
            let l4_type: u8 = unsafe { ::core::mem::transmute(l4_type) };
            l4_type as u64
        });
        __bindgen_bitfield_unit.set(12usize, 4u8, {
            let tun_type: u8 = unsafe { ::core::mem::transmute(tun_type) };
            tun_type as u64
        });
        __bindgen_bitfield_unit
    }
    #[inline]
    pub fn inner_l4_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_2.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_2.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l4_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_2),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l4_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_2),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_2(inner_l4_type: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l4_type: u8 = unsafe { ::core::mem::transmute(inner_l4_type) };
            inner_l4_type as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::packet_type"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        packet_type
    )
        - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< hash information"]
    pub hash: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    #[doc = "< RSS hash result if RSS enabled"]
    pub rss: u32,
    #[doc = "< Filter identifier if FDIR enabled"]
    pub fdir: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    pub sched: rte_mbuf_sched,
    #[doc = "< Eventdev ethdev Tx adapter"]
    pub txadapter: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    pub usr: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 { pub anon1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub hi : u32 , }
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub anon1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub lo : u32 , }
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub hash: u16,
    pub id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 2usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::hash"] [:: core :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , hash) - 0usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::id"] [:: core :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , id) - 2usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::lo"] [:: core :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , lo) - 0usize] ;
};
impl Default
    for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        >() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        >() - 4usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::hi",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        hi
    ) - 4usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    pub reserved1: u32,
    pub reserved2: u16,
    pub txq: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        >() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        >() - 4usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::reserved1",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        reserved1
    ) - 0usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::reserved2",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        reserved2
    ) - 4usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::txq",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        txq
    ) - 6usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1>(
        ) - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1>(
        ) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::rss"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        rss
    )
        - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::fdir"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        fdir
    )
        - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::sched"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        sched
    )
        - 0usize];
    [
        "Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::txadapter",
    ][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        txadapter
    ) - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::usr"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        usr
    )
        - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::hash"][::core::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        hash
    ) - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1>() - 24usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::pkt_len"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, pkt_len) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::data_len"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, data_len) - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::vlan_tci"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, vlan_tci) - 10usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::vlan_tci_outer"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, vlan_tci_outer) - 20usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::buf_len"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, buf_len) - 22usize];
};
impl Default for rte_mbuf__bindgen_ty_2__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2"][::core::mem::size_of::<rte_mbuf__bindgen_ty_2>() - 24usize];
    ["Alignment of rte_mbuf__bindgen_ty_2"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2::rx_descriptor_fields1"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_2, rx_descriptor_fields1) - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "fields to support TX offloads"]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_3 {
    #[doc = "< combined for easy fetch"]
    pub tx_offload: u64,
    pub anon1: rte_mbuf__bindgen_ty_3__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(8))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 7usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_3__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mbuf__bindgen_ty_3__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_3__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_3__bindgen_ty_1>() - 8usize];
};
impl rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    #[inline]
    pub fn l2_len(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                7u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l2_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                7u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_len(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                9u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l3_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                9u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_len(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u64) }
    }
    #[inline]
    pub fn set_l4_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                8u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l4_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tso_segsz(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 16u8) as u64) }
    }
    #[inline]
    pub fn set_tso_segsz(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tso_segsz_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                16u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_tso_segsz_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn outer_l3_len(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(40usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(40usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn outer_l3_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                40usize,
                9u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_outer_l3_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                40usize,
                9u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn outer_l2_len(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(49usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(49usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn outer_l2_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                49usize,
                7u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_outer_l2_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                49usize,
                7u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_len: u64,
        l3_len: u64,
        l4_len: u64,
        tso_segsz: u64,
        outer_l3_len: u64,
        outer_l2_len: u64,
    ) -> __BindgenBitfieldUnit<[u8; 7usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 7usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 7u8, {
            let l2_len: u64 = unsafe { ::core::mem::transmute(l2_len) };
            l2_len as u64
        });
        __bindgen_bitfield_unit.set(7usize, 9u8, {
            let l3_len: u64 = unsafe { ::core::mem::transmute(l3_len) };
            l3_len as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let l4_len: u64 = unsafe { ::core::mem::transmute(l4_len) };
            l4_len as u64
        });
        __bindgen_bitfield_unit.set(24usize, 16u8, {
            let tso_segsz: u64 = unsafe { ::core::mem::transmute(tso_segsz) };
            tso_segsz as u64
        });
        __bindgen_bitfield_unit.set(40usize, 9u8, {
            let outer_l3_len: u64 = unsafe { ::core::mem::transmute(outer_l3_len) };
            outer_l3_len as u64
        });
        __bindgen_bitfield_unit.set(49usize, 7u8, {
            let outer_l2_len: u64 = unsafe { ::core::mem::transmute(outer_l2_len) };
            outer_l2_len as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_3"][::core::mem::size_of::<rte_mbuf__bindgen_ty_3>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_3"]
        [::core::mem::align_of::<rte_mbuf__bindgen_ty_3>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_3::tx_offload"]
        [::core::mem::offset_of!(rte_mbuf__bindgen_ty_3, tx_offload) - 0usize];
};
impl Default for rte_mbuf__bindgen_ty_3 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf"][::core::mem::size_of::<rte_mbuf>() - 128usize];
    ["Alignment of rte_mbuf"][::core::mem::align_of::<rte_mbuf>() - 64usize];
    ["Offset of field: rte_mbuf::buf_addr"][::core::mem::offset_of!(rte_mbuf, buf_addr) - 0usize];
    ["Offset of field: rte_mbuf::buf_iova"][::core::mem::offset_of!(rte_mbuf, buf_iova) - 8usize];
    ["Offset of field: rte_mbuf::ol_flags"][::core::mem::offset_of!(rte_mbuf, ol_flags) - 24usize];
    ["Offset of field: rte_mbuf::pool"][::core::mem::offset_of!(rte_mbuf, pool) - 56usize];
    ["Offset of field: rte_mbuf::next"][::core::mem::offset_of!(rte_mbuf, next) - 64usize];
    ["Offset of field: rte_mbuf::shinfo"][::core::mem::offset_of!(rte_mbuf, shinfo) - 80usize];
    ["Offset of field: rte_mbuf::priv_size"]
        [::core::mem::offset_of!(rte_mbuf, priv_size) - 88usize];
    ["Offset of field: rte_mbuf::timesync"][::core::mem::offset_of!(rte_mbuf, timesync) - 90usize];
    ["Offset of field: rte_mbuf::dynfield1"]
        [::core::mem::offset_of!(rte_mbuf, dynfield1) - 92usize];
};
impl Default for rte_mbuf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Function typedef of callback to free externally attached buffer."]
pub type rte_mbuf_extbuf_free_callback_t = ::core::option::Option<
    unsafe extern "C" fn(addr: *mut ::core::ffi::c_void, opaque: *mut ::core::ffi::c_void),
>;
#[doc = "Shared data at the end of an external buffer."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_ext_shared_info {
    #[doc = "< Free callback function"]
    pub free_cb: rte_mbuf_extbuf_free_callback_t,
    #[doc = "< Free callback argument"]
    pub fcb_opaque: *mut ::core::ffi::c_void,
    pub refcnt: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_ext_shared_info"]
        [::core::mem::size_of::<rte_mbuf_ext_shared_info>() - 24usize];
    ["Alignment of rte_mbuf_ext_shared_info"]
        [::core::mem::align_of::<rte_mbuf_ext_shared_info>() - 8usize];
    ["Offset of field: rte_mbuf_ext_shared_info::free_cb"]
        [::core::mem::offset_of!(rte_mbuf_ext_shared_info, free_cb) - 0usize];
    ["Offset of field: rte_mbuf_ext_shared_info::fcb_opaque"]
        [::core::mem::offset_of!(rte_mbuf_ext_shared_info, fcb_opaque) - 8usize];
    ["Offset of field: rte_mbuf_ext_shared_info::refcnt"]
        [::core::mem::offset_of!(rte_mbuf_ext_shared_info, refcnt) - 16usize];
};
impl Default for rte_mbuf_ext_shared_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Get the name of a RX offload flag\n\n# Arguments\n\n* `mask` -\nThe mask describing the flag.\n\n# Returns\n\nThe name of this flag, or NULL if it's not a valid RX flag."]
    pub fn rte_get_rx_ol_flag_name(mask: u64) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Dump the list of RX offload flags in a buffer\n\n# Arguments\n\n* `mask` -\nThe mask describing the RX flags.\n* `buf` -\nThe output buffer.\n* `buflen` -\nThe length of the buffer.\n\n# Returns\n\n0 on success, (-1) on error."]
    pub fn rte_get_rx_ol_flag_list(
        mask: u64,
        buf: *mut ::core::ffi::c_char,
        buflen: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the name of a TX offload flag\n\n# Arguments\n\n* `mask` -\nThe mask describing the flag. Usually only one bit must be set.\nSeveral bits can be given if they belong to the same mask.\nEx: RTE_MBUF_F_TX_L4_MASK.\n\n# Returns\n\nThe name of this flag, or NULL if it's not a valid TX flag."]
    pub fn rte_get_tx_ol_flag_name(mask: u64) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Dump the list of TX offload flags in a buffer\n\n# Arguments\n\n* `mask` -\nThe mask describing the TX flags.\n* `buf` -\nThe output buffer.\n* `buflen` -\nThe length of the buffer.\n\n# Returns\n\n0 on success, (-1) on error."]
    pub fn rte_get_tx_ol_flag_list(
        mask: u64,
        buf: *mut ::core::ffi::c_char,
        buflen: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Prefetch the first part of the mbuf\nThe first 64 bytes of the mbuf corresponds to fields that are used early\nin the receive path. If the cache line of the architecture is higher than\n64B, the second part will also be prefetched.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf."]
    #[link_name = "rte_mbuf_prefetch_part1_w"]
    pub fn rte_mbuf_prefetch_part1(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Prefetch the second part of the mbuf\nThe next 64 bytes of the mbuf corresponds to fields that are used in the\ntransmit path. If the cache line of the architecture is higher than 64B,\nthis function does nothing as it is expected that the full mbuf is\nalready in cache.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf."]
    #[link_name = "rte_mbuf_prefetch_part2_w"]
    pub fn rte_mbuf_prefetch_part2(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Get the application private size of mbufs stored in a pktmbuf_pool\nThe private size of mbuf is a zone located between the rte_mbuf\nstructure and the data buffer where an application can store data\nassociated to a packet.\n\n# Arguments\n\n* `mp` -\nThe packet mbuf pool.\n\n# Returns\n\nThe private size of mbufs stored in this mempool."]
    #[link_name = "rte_pktmbuf_priv_size_w"]
    pub fn rte_pktmbuf_priv_size(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the IOVA address of the mbuf data buffer.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe IOVA address of the mbuf."]
    #[link_name = "rte_mbuf_iova_get_w"]
    pub fn rte_mbuf_iova_get(m: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Set the IOVA address of the mbuf data buffer.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `iova` -\nValue to set as IOVA address of the mbuf."]
    #[link_name = "rte_mbuf_iova_set_w"]
    pub fn rte_mbuf_iova_set(m: *mut rte_mbuf, iova: rte_iova_t);
}
unsafe extern "C" {
    #[doc = "Return the IO address of the beginning of the mbuf data\n\n# Arguments\n\n* `mb` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe IO address of the beginning of the mbuf data"]
    #[link_name = "rte_mbuf_data_iova_w"]
    pub fn rte_mbuf_data_iova(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Return the default IO address of the beginning of the mbuf data\nThis function is used by drivers in their receive function, as it\nreturns the location where data should be written by the NIC, taking\nthe default headroom in account.\n\n# Arguments\n\n* `mb` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe IO address of the beginning of the mbuf data"]
    #[link_name = "rte_mbuf_data_iova_default_w"]
    pub fn rte_mbuf_data_iova_default(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Return the mbuf owning the data buffer address of an indirect mbuf.\n\n# Arguments\n\n* `mi` -\nThe pointer to the indirect mbuf.\n\n# Returns\n\nThe address of the direct mbuf corresponding to buffer_addr."]
    #[link_name = "rte_mbuf_from_indirect_w"]
    pub fn rte_mbuf_from_indirect(mi: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Return address of buffer embedded in the given mbuf.\nThe return value shall be same as mb->buf_addr if the mbuf is already\ninitialized and direct. However, this API is useful if mempool of the\nmbuf is already known because it doesn't need to access mbuf contents in\norder to get the mempool pointer.\n\n# Arguments\n\n* `mb` -\nThe pointer to the mbuf.\n* `mp` -\nThe pointer to the mempool of the mbuf.\n\n# Returns\n\nThe pointer of the mbuf buffer."]
    #[link_name = "rte_mbuf_buf_addr_w"]
    pub fn rte_mbuf_buf_addr(mb: *mut rte_mbuf, mp: *mut rte_mempool) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Return the default address of the beginning of the mbuf data.\n\n# Arguments\n\n* `mb` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe pointer of the beginning of the mbuf data."]
    #[link_name = "rte_mbuf_data_addr_default_w"]
    pub fn rte_mbuf_data_addr_default(mb: *mut rte_mbuf) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Return address of buffer embedded in the given mbuf.\n@note: Accessing mempool pointer of a mbuf is expensive because the\npointer is stored in the 2nd cache line of mbuf. If mempool is known, it\nis better not to reference the mempool pointer in mbuf but calling\nrte_mbuf_buf_addr() would be more efficient.\n\n# Arguments\n\n* `md` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe address of the data buffer owned by the mbuf."]
    #[link_name = "rte_mbuf_to_baddr_w"]
    pub fn rte_mbuf_to_baddr(md: *mut rte_mbuf) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Return the starting address of the private data area embedded in\nthe given mbuf.\nNote that no check is made to ensure that a private data area\nactually exists in the supplied mbuf.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n\n# Returns\n\nThe starting address of the private data area of the given mbuf."]
    #[link_name = "rte_mbuf_to_priv_w"]
    pub fn rte_mbuf_to_priv(m: *mut rte_mbuf) -> *mut ::core::ffi::c_void;
}
#[doc = "Private data in case of pktmbuf pool.\nA structure that contains some pktmbuf_pool-specific data that are\nappended after the mempool structure (in private data)."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pktmbuf_pool_private {
    #[doc = "< Size of data space in each mbuf."]
    pub mbuf_data_room_size: u16,
    #[doc = "< Size of private area in each mbuf."]
    pub mbuf_priv_size: u16,
    #[doc = "< reserved for future use."]
    pub flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pktmbuf_pool_private"]
        [::core::mem::size_of::<rte_pktmbuf_pool_private>() - 8usize];
    ["Alignment of rte_pktmbuf_pool_private"]
        [::core::mem::align_of::<rte_pktmbuf_pool_private>() - 4usize];
    ["Offset of field: rte_pktmbuf_pool_private::mbuf_data_room_size"]
        [::core::mem::offset_of!(rte_pktmbuf_pool_private, mbuf_data_room_size) - 0usize];
    ["Offset of field: rte_pktmbuf_pool_private::mbuf_priv_size"]
        [::core::mem::offset_of!(rte_pktmbuf_pool_private, mbuf_priv_size) - 2usize];
    ["Offset of field: rte_pktmbuf_pool_private::flags"]
        [::core::mem::offset_of!(rte_pktmbuf_pool_private, flags) - 4usize];
};
unsafe extern "C" {
    #[doc = "Return the flags from private data in an mempool structure.\n\n# Arguments\n\n* `mp` -\nA pointer to the mempool structure.\n\n# Returns\n\nThe flags from the private data structure."]
    #[link_name = "rte_pktmbuf_priv_flags_w"]
    pub fn rte_pktmbuf_priv_flags(mp: *mut rte_mempool) -> u32;
}
unsafe extern "C" {
    #[doc = "Reads the value of an mbuf's refcnt.\n\n# Arguments\n\n* `m` -\nMbuf to read\n\n# Returns\n\nReference count number."]
    #[link_name = "rte_mbuf_refcnt_read_w"]
    pub fn rte_mbuf_refcnt_read(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Sets an mbuf's refcnt to a defined value.\n\n# Arguments\n\n* `m` -\nMbuf to update\n* `new_value` -\nValue set"]
    #[link_name = "rte_mbuf_refcnt_set_w"]
    pub fn rte_mbuf_refcnt_set(m: *mut rte_mbuf, new_value: u16);
}
unsafe extern "C" {
    #[doc = "Adds given value to an mbuf's refcnt and returns its new value.\n\n# Arguments\n\n* `m` -\nMbuf to update\n* `value` -\nValue to add/subtract\n\n# Returns\n\nUpdated value"]
    #[link_name = "rte_mbuf_refcnt_update_w"]
    pub fn rte_mbuf_refcnt_update(m: *mut rte_mbuf, value: i16) -> u16;
}
unsafe extern "C" {
    #[doc = "Reads the refcnt of an external buffer.\n\n# Arguments\n\n* `shinfo` -\nShared data of the external buffer.\n\n# Returns\n\nReference count number."]
    #[link_name = "rte_mbuf_ext_refcnt_read_w"]
    pub fn rte_mbuf_ext_refcnt_read(shinfo: *const rte_mbuf_ext_shared_info) -> u16;
}
unsafe extern "C" {
    #[doc = "Set refcnt of an external buffer.\n\n# Arguments\n\n* `shinfo` -\nShared data of the external buffer.\n* `new_value` -\nValue set"]
    #[link_name = "rte_mbuf_ext_refcnt_set_w"]
    pub fn rte_mbuf_ext_refcnt_set(shinfo: *mut rte_mbuf_ext_shared_info, new_value: u16);
}
unsafe extern "C" {
    #[doc = "Add given value to refcnt of an external buffer and return its new\nvalue.\n\n# Arguments\n\n* `shinfo` -\nShared data of the external buffer.\n* `value` -\nValue to add/subtract\n\n# Returns\n\nUpdated value"]
    #[link_name = "rte_mbuf_ext_refcnt_update_w"]
    pub fn rte_mbuf_ext_refcnt_update(shinfo: *mut rte_mbuf_ext_shared_info, value: i16) -> u16;
}
unsafe extern "C" {
    #[doc = "Sanity checks on an mbuf.\nCheck the consistency of the given mbuf. The function will cause a\npanic if corruption is detected.\n\n# Arguments\n\n* `m` -\nThe mbuf to be checked.\n* `is_header` -\nTrue if the mbuf is a packet header, false if it is a sub-segment\nof a packet (in this case, some fields like nb_segs are not checked)"]
    pub fn rte_mbuf_sanity_check(m: *const rte_mbuf, is_header: ::core::ffi::c_int);
}
unsafe extern "C" {
    #[doc = "Sanity checks on a mbuf.\nAlmost like rte_mbuf_sanity_check(), but this function gives the reason\nif corruption is detected rather than panic.\n\n# Arguments\n\n* `m` -\nThe mbuf to be checked.\n* `is_header` -\nTrue if the mbuf is a packet header, false if it is a sub-segment\nof a packet (in this case, some fields like nb_segs are not checked)\n* `reason` -\nA reference to a string pointer where to store the reason why a mbuf is\nconsidered invalid.\n\n# Returns\n\n- 0 if no issue has been found, reason is left untouched.\n- -1 if a problem is detected, reason then points to a string describing\nthe reason why the mbuf is deemed invalid."]
    pub fn rte_mbuf_check(
        m: *const rte_mbuf,
        is_header: ::core::ffi::c_int,
        reason: *mut *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Allocate an uninitialized mbuf from mempool *mp*.\nThis function can be used by PMDs (especially in RX functions) to\nallocate an uninitialized mbuf. The driver is responsible of\ninitializing all the required fields. See rte_pktmbuf_reset().\nFor standard needs, prefer rte_pktmbuf_alloc().\nThe caller can expect that the following fields of the mbuf structure\nare initialized: buf_addr, buf_iova, buf_len, refcnt=1, nb_segs=1,\nnext=NULL, pool, priv_size. The other fields must be initialized\nby the caller.\n\n# Arguments\n\n* `mp` -\nThe mempool from which mbuf is allocated.\n\n# Returns\n\n- The pointer to the new mbuf on success.\n- NULL if allocation failed."]
    #[link_name = "rte_mbuf_raw_alloc_w"]
    pub fn rte_mbuf_raw_alloc(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** This API may change, or be removed, without prior notice.\nAllocate a bulk of uninitialized mbufs from mempool *mp*.\nThis function can be used by PMDs (especially in Rx functions)\nto allocate a bulk of uninitialized mbufs.\nThe driver is responsible of initializing all the required fields.\nSee rte_pktmbuf_reset().\nFor standard needs, prefer rte_pktmbuf_alloc_bulk().\nThe caller can expect that the following fields of the mbuf structure\nare initialized:\nbuf_addr, buf_iova, buf_len, refcnt=1, nb_segs=1, next=NULL, pool, priv_size.\nThe other fields must be initialized by the caller.\n\n# Arguments\n\n* `mp` -\nThe mempool from which mbufs are allocated.\n* `mbufs` -\nArray of pointers to mbufs.\n* `count` -\nArray size.\n\n# Returns\n\n- 0: Success.\n- -ENOENT: Not enough entries in the mempool; no mbufs are retrieved."]
    #[link_name = "rte_mbuf_raw_alloc_bulk_w"]
    pub fn rte_mbuf_raw_alloc_bulk(
        mp: *mut rte_mempool,
        mbufs: *mut *mut rte_mbuf,
        count: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Put mbuf back into its original mempool.\nThe caller must ensure that the mbuf is direct and properly\nreinitialized (refcnt=1, next=NULL, nb_segs=1), as done by\nrte_pktmbuf_prefree_seg().\nThis function should be used with care, when optimization is\nrequired. For standard needs, prefer rte_pktmbuf_free() or\nrte_pktmbuf_free_seg().\n\n# Arguments\n\n* `m` -\nThe mbuf to be freed."]
    #[link_name = "rte_mbuf_raw_free_w"]
    pub fn rte_mbuf_raw_free(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** This API may change, or be removed, without prior notice.\nPut a bulk of mbufs allocated from the same mempool back into the mempool.\nThe caller must ensure that the mbufs come from the specified mempool,\nare direct and properly reinitialized (refcnt=1, next=NULL, nb_segs=1),\nas done by rte_pktmbuf_prefree_seg().\nThis function should be used with care, when optimization is required.\nFor standard needs, prefer rte_pktmbuf_free_bulk().\n\n# See also\n\n> [`RTE_ETH_TX_OFFLOAD_MBUF_FAST_FREE`]\n\n# Arguments\n\n* `mp` -\nThe mempool to which the mbufs belong.\n* `mbufs` -\nArray of pointers to packet mbufs.\nThe array must not contain NULL pointers.\n* `count` -\nArray size."]
    #[link_name = "rte_mbuf_raw_free_bulk_w"]
    pub fn rte_mbuf_raw_free_bulk(
        mp: *mut rte_mempool,
        mbufs: *mut *mut rte_mbuf,
        count: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "The packet mbuf constructor.\nThis function initializes some fields in the mbuf structure that are\nnot modified by the user once created (origin pool, buffer start\naddress, and so on). This function is given as a callback function to\nrte_mempool_obj_iter() or rte_mempool_create() at pool creation time.\nThis function expects that the mempool private area was previously\ninitialized with rte_pktmbuf_pool_init().\n\n# Arguments\n\n* `mp` -\nThe mempool from which mbufs originate.\n* `opaque_arg` -\nA pointer that can be used by the user to retrieve useful information\nfor mbuf initialization. This pointer is the opaque argument passed to\nrte_mempool_obj_iter() or rte_mempool_create().\n* `m` -\nThe mbuf to initialize.\n* `i` -\nThe index of the mbuf in the pool table."]
    pub fn rte_pktmbuf_init(
        mp: *mut rte_mempool,
        opaque_arg: *mut ::core::ffi::c_void,
        m: *mut ::core::ffi::c_void,
        i: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "A packet mbuf pool constructor.\nThis function initializes the mempool private data in the case of a\npktmbuf pool. This private data is needed by the driver. The\nfunction must be called on the mempool before it is used, or it\ncan be given as a callback function to rte_mempool_create() at\npool creation. It can be extended by the user, for example, to\nprovide another packet size.\nThe mempool private area size must be at least equal to\nsizeof(struct rte_pktmbuf_pool_private).\n\n# Arguments\n\n* `mp` -\nThe mempool from which mbufs originate.\n* `opaque_arg` -\nA pointer that can be used by the user to retrieve useful information\nfor mbuf initialization. This pointer is the opaque argument passed to\nrte_mempool_create()."]
    pub fn rte_pktmbuf_pool_init(mp: *mut rte_mempool, opaque_arg: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "Create a mbuf pool.\nThis function creates and initializes a packet mbuf pool. It is\na wrapper to rte_mempool functions.\n\n# Arguments\n\n* `name` -\nThe name of the mbuf pool.\n* `n` -\nThe number of elements in the mbuf pool. The optimum size (in terms\nof memory usage) for a mempool is when n is a power of two minus one:\nn = (2^q - 1).\n* `cache_size` -\nSize of the per-core object cache. See rte_mempool_create() for\ndetails.\n* `priv_size` -\nSize of application private are between the rte_mbuf structure\nand the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n* `data_room_size` -\nSize of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n* `socket_id` -\nThe socket identifier where the memory should be allocated. The\nvalue can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\nreserved zone.\n\n# Returns\n\nThe pointer to the new allocated mempool, on success. NULL on error\nwith rte_errno set appropriately. Possible rte_errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - cache size provided is too large, or priv_size is not aligned.\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create(
        name: *const ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
        cache_size: ::core::ffi::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::core::ffi::c_int,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = "Create a mbuf pool with a given mempool ops name\nThis function creates and initializes a packet mbuf pool. It is\na wrapper to rte_mempool functions.\n\n# Arguments\n\n* `name` -\nThe name of the mbuf pool.\n* `n` -\nThe number of elements in the mbuf pool. The optimum size (in terms\nof memory usage) for a mempool is when n is a power of two minus one:\nn = (2^q - 1).\n* `cache_size` -\nSize of the per-core object cache. See rte_mempool_create() for\ndetails.\n* `priv_size` -\nSize of application private are between the rte_mbuf structure\nand the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n* `data_room_size` -\nSize of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n* `socket_id` -\nThe socket identifier where the memory should be allocated. The\nvalue can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\nreserved zone.\n* `ops_name` -\nThe mempool ops name to be used for this mempool instead of\ndefault mempool. The value can be *NULL* to use default mempool.\n\n# Returns\n\nThe pointer to the new allocated mempool, on success. NULL on error\nwith rte_errno set appropriately. Possible rte_errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - cache size provided is too large, or priv_size is not aligned.\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_by_ops(
        name: *const ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
        cache_size: ::core::ffi::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::core::ffi::c_int,
        ops_name: *const ::core::ffi::c_char,
    ) -> *mut rte_mempool;
}
#[doc = "A structure that describes the pinned external buffer segment."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pktmbuf_extmem {
    #[doc = "< The virtual address of data buffer."]
    pub buf_ptr: *mut ::core::ffi::c_void,
    #[doc = "< The IO address of the data buffer."]
    pub buf_iova: rte_iova_t,
    #[doc = "< External buffer length in bytes."]
    pub buf_len: usize,
    #[doc = "< mbuf element size in bytes."]
    pub elt_size: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pktmbuf_extmem"][::core::mem::size_of::<rte_pktmbuf_extmem>() - 32usize];
    ["Alignment of rte_pktmbuf_extmem"][::core::mem::align_of::<rte_pktmbuf_extmem>() - 8usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_ptr"]
        [::core::mem::offset_of!(rte_pktmbuf_extmem, buf_ptr) - 0usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_iova"]
        [::core::mem::offset_of!(rte_pktmbuf_extmem, buf_iova) - 8usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_len"]
        [::core::mem::offset_of!(rte_pktmbuf_extmem, buf_len) - 16usize];
    ["Offset of field: rte_pktmbuf_extmem::elt_size"]
        [::core::mem::offset_of!(rte_pktmbuf_extmem, elt_size) - 24usize];
};
impl Default for rte_pktmbuf_extmem {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Create a mbuf pool with external pinned data buffers.\nThis function creates and initializes a packet mbuf pool that contains\nonly mbufs with external buffer. It is a wrapper to rte_mempool functions.\n\n# Arguments\n\n* `name` -\nThe name of the mbuf pool.\n* `n` -\nThe number of elements in the mbuf pool. The optimum size (in terms\nof memory usage) for a mempool is when n is a power of two minus one:\nn = (2^q - 1).\n* `cache_size` -\nSize of the per-core object cache. See rte_mempool_create() for\ndetails.\n* `priv_size` -\nSize of application private are between the rte_mbuf structure\nand the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n* `data_room_size` -\nSize of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n* `socket_id` -\nThe socket identifier where the memory should be allocated. The\nvalue can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\nreserved zone.\n* `ext_mem` -\nPointer to the array of structures describing the external memory\nfor data buffers. It is caller responsibility to register this memory\nwith rte_extmem_register() (if needed), map this memory to appropriate\nphysical device, etc.\n* `ext_num` -\nNumber of elements in the ext_mem array.\n\n# Returns\n\nThe pointer to the new allocated mempool, on success. NULL on error\nwith rte_errno set appropriately. Possible rte_errno values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- EINVAL - cache size provided is too large, or priv_size is not aligned.\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_extbuf(
        name: *const ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
        cache_size: ::core::ffi::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::core::ffi::c_int,
        ext_mem: *const rte_pktmbuf_extmem,
        ext_num: ::core::ffi::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = "Get the data room size of mbufs stored in a pktmbuf_pool\nThe data room size is the amount of data that can be stored in a\nmbuf including the headroom (RTE_PKTMBUF_HEADROOM).\n\n# Arguments\n\n* `mp` -\nThe packet mbuf pool.\n\n# Returns\n\nThe data room size of mbufs stored in this mempool."]
    #[link_name = "rte_pktmbuf_data_room_size_w"]
    pub fn rte_pktmbuf_data_room_size(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    #[doc = "Reset the data_off field of a packet mbuf to its default value.\nThe given mbuf must have only one segment, which should be empty.\n\n# Arguments\n\n* `m` -\nThe packet mbuf's data_off field has to be reset."]
    #[link_name = "rte_pktmbuf_reset_headroom_w"]
    pub fn rte_pktmbuf_reset_headroom(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Reset the fields of a packet mbuf to their default values.\nThe given mbuf must have only one segment.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be reset."]
    #[link_name = "rte_pktmbuf_reset_w"]
    pub fn rte_pktmbuf_reset(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Allocate a new mbuf from a mempool.\nThis new mbuf contains one segment, which has a length of 0. The pointer\nto data is initialized to have some bytes of headroom in the buffer\n(if buffer size allows).\n\n# Arguments\n\n* `mp` -\nThe mempool from which the mbuf is allocated.\n\n# Returns\n\n- The pointer to the new mbuf on success.\n- NULL if allocation failed."]
    #[link_name = "rte_pktmbuf_alloc_w"]
    pub fn rte_pktmbuf_alloc(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Allocate a bulk of mbufs, initialize refcnt and reset the fields to default\nvalues.\n\n# Arguments\n\n* `pool` -\nThe mempool from which mbufs are allocated.\n* `mbufs` -\nArray of pointers to mbufs\n* `count` -\nArray size\n\n# Returns\n\n- 0: Success\n- -ENOENT: Not enough entries in the mempool; no mbufs are retrieved."]
    #[link_name = "rte_pktmbuf_alloc_bulk_w"]
    pub fn rte_pktmbuf_alloc_bulk(
        pool: *mut rte_mempool,
        mbufs: *mut *mut rte_mbuf,
        count: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize shared data at the end of an external buffer before attaching\nto a mbuf by ``rte_pktmbuf_attach_extbuf()``. This is not a mandatory\ninitialization but a helper function to simply spare a few bytes at the\nend of the buffer for shared data. If shared data is allocated\nseparately, this should not be called but application has to properly\ninitialize the shared data according to its need.\nFree callback and its argument is saved and the refcnt is set to 1.\n@warning The value of buf_len will be reduced to RTE_PTR_DIFF(shinfo, buf_addr)\nafter this initialization. This shall be used for\n``rte_pktmbuf_attach_extbuf()``\n\n# Arguments\n\n* `buf_addr` -\nThe pointer to the external buffer.\n* `buf_len` [in,out]  -\nThe pointer to length of the external buffer. Input value must be\nlarger than the size of ``struct rte_mbuf_ext_shared_info`` and\npadding for alignment. If not enough, this function will return NULL.\nAdjusted buffer length will be returned through this pointer.\n* `free_cb` -\nFree callback function to call when the external buffer needs to be\nfreed.\n* `fcb_opaque` -\nArgument for the free callback function.\n\n# Returns\n\nA pointer to the initialized shared data on success, return NULL\notherwise."]
    #[link_name = "rte_pktmbuf_ext_shinfo_init_helper_w"]
    pub fn rte_pktmbuf_ext_shinfo_init_helper(
        buf_addr: *mut ::core::ffi::c_void,
        buf_len: *mut u16,
        free_cb: rte_mbuf_extbuf_free_callback_t,
        fcb_opaque: *mut ::core::ffi::c_void,
    ) -> *mut rte_mbuf_ext_shared_info;
}
unsafe extern "C" {
    #[doc = "Attach an external buffer to a mbuf.\nUser-managed anonymous buffer can be attached to an mbuf. When attaching\nit, corresponding free callback function and its argument should be\nprovided via shinfo. This callback function will be called once all the\nmbufs are detached from the buffer (refcnt becomes zero).\nThe headroom length of the attaching mbuf will be set to zero and this\ncan be properly adjusted after attachment. For example, ``rte_pktmbuf_adj()``\nor ``rte_pktmbuf_reset_headroom()`` might be used.\nSimilarly, the packet length is initialized to 0. If the buffer contains\ndata, the user has to adjust ``data_len`` and the ``pkt_len`` field of\nthe mbuf accordingly.\nMore mbufs can be attached to the same external buffer by\n``rte_pktmbuf_attach()`` once the external buffer has been attached by\nthis API.\nDetachment can be done by either ``rte_pktmbuf_detach_extbuf()`` or\n``rte_pktmbuf_detach()``.\nMemory for shared data must be provided and user must initialize all of\nthe content properly, especially free callback and refcnt. The pointer\nof shared data will be stored in m->shinfo.\n``rte_pktmbuf_ext_shinfo_init_helper`` can help to simply spare a few\nbytes at the end of buffer for the shared data, store free callback and\nits argument and set the refcnt to 1. The following is an example:\nstruct rte_mbuf_ext_shared_info *shinfo =\nrte_pktmbuf_ext_shinfo_init_helper(buf_addr, &buf_len,\nfree_cb, fcb_arg);\nrte_pktmbuf_attach_extbuf(m, buf_addr, buf_iova, buf_len, shinfo);\nrte_pktmbuf_reset_headroom(m);\nrte_pktmbuf_adj(m, data_len);\nAttaching an external buffer is quite similar to mbuf indirection in\nreplacing buffer addresses and length of a mbuf, but a few differences:\n- When an indirect mbuf is attached, refcnt of the direct mbuf would be\n2 as long as the direct mbuf itself isn't freed after the attachment.\nIn such cases, the buffer area of a direct mbuf must be read-only. But\nexternal buffer has its own refcnt and it starts from 1. Unless\nmultiple mbufs are attached to a mbuf having an external buffer, the\nexternal buffer is writable.\n- There's no need to allocate buffer from a mempool. Any buffer can be\nattached with appropriate free callback and its IO address.\n- Smaller metadata is required to maintain shared data such as refcnt.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `buf_addr` -\nThe pointer to the external buffer.\n* `buf_iova` -\nIO address of the external buffer.\n* `buf_len` -\nThe size of the external buffer.\n* `shinfo` -\nUser-provided memory for shared data of the external buffer."]
    #[link_name = "rte_pktmbuf_attach_extbuf_w"]
    pub fn rte_pktmbuf_attach_extbuf(
        m: *mut rte_mbuf,
        buf_addr: *mut ::core::ffi::c_void,
        buf_iova: rte_iova_t,
        buf_len: u16,
        shinfo: *mut rte_mbuf_ext_shared_info,
    );
}
unsafe extern "C" {
    #[doc = "Copy dynamic fields from msrc to mdst.\n\n# Arguments\n\n* `mdst` -\nThe destination mbuf.\n* `msrc` -\nThe source mbuf."]
    #[link_name = "rte_mbuf_dynfield_copy_w"]
    pub fn rte_mbuf_dynfield_copy(mdst: *mut rte_mbuf, msrc: *const rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Attach packet mbuf to another packet mbuf.\nIf the mbuf we are attaching to isn't a direct buffer and is attached to\nan external buffer, the mbuf being attached will be attached to the\nexternal buffer instead of mbuf indirection.\nOtherwise, the mbuf will be indirectly attached. After attachment we\nrefer the mbuf we attached as 'indirect', while mbuf we attached to as\n'direct'.  The direct mbuf's reference counter is incremented.\nRight now, not supported:\n- attachment for already indirect mbuf (e.g. - mi has to be direct).\n- mbuf we trying to attach (mi) is used by someone else\ne.g. it's reference counter is greater then 1.\n\n# Arguments\n\n* `mi` -\nThe indirect packet mbuf.\n* `m` -\nThe packet mbuf we're attaching to."]
    #[link_name = "rte_pktmbuf_attach_w"]
    pub fn rte_pktmbuf_attach(mi: *mut rte_mbuf, m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Detach a packet mbuf from external buffer or direct buffer.\n- decrement refcnt and free the external/direct buffer if refcnt\nbecomes zero.\n- restore original mbuf address and length values.\n- reset pktmbuf data and data_len to their default values.\nAll other fields of the given packet mbuf will be left intact.\nIf the packet mbuf was allocated from the pool with pinned\nexternal buffers the rte_pktmbuf_detach does nothing with the\nmbuf of this kind, because the pinned buffers are not supposed\nto be detached.\n\n# Arguments\n\n* `m` -\nThe indirect attached packet mbuf."]
    #[link_name = "rte_pktmbuf_detach_w"]
    pub fn rte_pktmbuf_detach(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Decrease reference counter and unlink a mbuf segment\nThis function does the same than a free, except that it does not\nreturn the segment to its pool.\nIt decreases the reference counter, and if it reaches 0, it is\ndetached from its parent for an indirect mbuf.\n\n# Arguments\n\n* `m` -\nThe mbuf to be unlinked\n\n# Returns\n\n- (m) if it is the last reference. It can be recycled or freed.\n- (NULL) if the mbuf still has remaining references on it."]
    #[link_name = "rte_pktmbuf_prefree_seg_w"]
    pub fn rte_pktmbuf_prefree_seg(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Free a segment of a packet mbuf into its original mempool.\nFree an mbuf, without parsing other segments in case of chained\nbuffers.\n\n# Arguments\n\n* `m` -\nThe packet mbuf segment to be freed."]
    #[link_name = "rte_pktmbuf_free_seg_w"]
    pub fn rte_pktmbuf_free_seg(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Free a packet mbuf back into its original mempool.\nFree an mbuf, and all its segments in case of chained buffers. Each\nsegment is added back into its original mempool.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be freed. If NULL, the function does nothing."]
    #[link_name = "rte_pktmbuf_free_w"]
    pub fn rte_pktmbuf_free(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Free a bulk of packet mbufs back into their original mempools.\nFree a bulk of mbufs, and all their segments in case of chained buffers.\nEach segment is added back into its original mempool.\n\n# Arguments\n\n* `mbufs` -\nArray of pointers to packet mbufs.\nThe array may contain NULL pointers.\n* `count` -\nArray size."]
    pub fn rte_pktmbuf_free_bulk(mbufs: *mut *mut rte_mbuf, count: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Create a \"clone\" of the given packet mbuf.\nWalks through all segments of the given packet mbuf, and for each of them:\n- Creates a new packet mbuf from the given pool.\n- Attaches newly created mbuf to the segment.\nThen updates pkt_len and nb_segs of the \"clone\" packet mbuf to match values\nfrom the original packet mbuf.\n\n# Arguments\n\n* `md` -\nThe packet mbuf to be cloned.\n* `mp` -\nThe mempool from which the \"clone\" mbufs are allocated.\n\n# Returns\n\n- The pointer to the new \"clone\" mbuf on success.\n- NULL if allocation fails."]
    pub fn rte_pktmbuf_clone(md: *mut rte_mbuf, mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Create a full copy of a given packet mbuf.\nCopies all the data from a given packet mbuf to a newly allocated\nset of mbufs. The private data are is not copied.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be copied.\n* `mp` -\nThe mempool from which the \"clone\" mbufs are allocated.\n* `offset` -\nThe number of bytes to skip before copying.\nIf the mbuf does not have that many bytes, it is an error\nand NULL is returned.\n* `length` -\nThe upper limit on bytes to copy.  Passing UINT32_MAX\nmeans all data (after offset).\n\n# Returns\n\n- The pointer to the new \"clone\" mbuf on success.\n- NULL if allocation fails."]
    pub fn rte_pktmbuf_copy(
        m: *const rte_mbuf,
        mp: *mut rte_mempool,
        offset: u32,
        length: u32,
    ) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Adds given value to the refcnt of all packet mbuf segments.\nWalks through all segments of given packet mbuf and for each of them\ninvokes rte_mbuf_refcnt_update().\n\n# Arguments\n\n* `m` -\nThe packet mbuf whose refcnt to be updated.\n* `v` -\nThe value to add to the mbuf's segments refcnt."]
    #[link_name = "rte_pktmbuf_refcnt_update_w"]
    pub fn rte_pktmbuf_refcnt_update(m: *mut rte_mbuf, v: i16);
}
unsafe extern "C" {
    #[doc = "Get the headroom in a packet mbuf.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\nThe length of the headroom."]
    #[link_name = "rte_pktmbuf_headroom_w"]
    pub fn rte_pktmbuf_headroom(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the tailroom of a packet mbuf.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\nThe length of the tailroom."]
    #[link_name = "rte_pktmbuf_tailroom_w"]
    pub fn rte_pktmbuf_tailroom(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the last segment of the packet.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\nThe last segment of the given mbuf."]
    #[link_name = "rte_pktmbuf_lastseg_w"]
    pub fn rte_pktmbuf_lastseg(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Prepend len bytes to an mbuf data area.\nReturns a pointer to the new\ndata start address. If there is not enough headroom in the first\nsegment, the function will return NULL, without modifying the mbuf.\n\n# Arguments\n\n* `m` -\nThe pkt mbuf.\n* `len` -\nThe amount of data to prepend (in bytes).\n\n# Returns\n\nA pointer to the start of the newly prepended data, or\nNULL if there is not enough headroom space in the first segment"]
    #[link_name = "rte_pktmbuf_prepend_w"]
    pub fn rte_pktmbuf_prepend(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Append len bytes to an mbuf.\nAppend len bytes to an mbuf and return a pointer to the start address\nof the added data. If there is not enough tailroom in the last\nsegment, the function will return NULL, without modifying the mbuf.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n* `len` -\nThe amount of data to append (in bytes).\n\n# Returns\n\nA pointer to the start of the newly appended data, or\nNULL if there is not enough tailroom space in the last segment"]
    #[link_name = "rte_pktmbuf_append_w"]
    pub fn rte_pktmbuf_append(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Remove len bytes at the beginning of an mbuf.\nReturns a pointer to the start address of the new data area. If the\nlength is greater than the length of the first segment, then the\nfunction will fail and return NULL, without modifying the mbuf.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n* `len` -\nThe amount of data to remove (in bytes).\n\n# Returns\n\nA pointer to the new start of the data."]
    #[link_name = "rte_pktmbuf_adj_w"]
    pub fn rte_pktmbuf_adj(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Remove len bytes of data at the end of the mbuf.\nIf the length is greater than the length of the last segment, the\nfunction will fail and return -1 without modifying the mbuf.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n* `len` -\nThe amount of data to remove (in bytes).\n\n# Returns\n\n- 0: On success.\n- -1: On error."]
    #[link_name = "rte_pktmbuf_trim_w"]
    pub fn rte_pktmbuf_trim(m: *mut rte_mbuf, len: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if mbuf data is contiguous.\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\n- 1, if all data is contiguous (one segment).\n- 0, if there is several segments."]
    #[link_name = "rte_pktmbuf_is_contiguous_w"]
    pub fn rte_pktmbuf_is_contiguous(m: *const rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read len data bytes in a mbuf at specified offset.\nIf the data is contiguous, return the pointer in the mbuf data, else\ncopy the data in the buffer provided by the user and return its\npointer.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `off` -\nThe offset of the data in the mbuf.\n* `len` -\nThe amount of bytes to read.\n* `buf` -\nThe buffer where data is copied if it is not contiguous in mbuf\ndata. Its length should be at least equal to the len parameter.\n\n# Returns\n\nThe pointer to the data, either in the mbuf if it is contiguous,\nor in the user buffer. If mbuf is too small, NULL is returned."]
    #[link_name = "rte_pktmbuf_read_w"]
    pub fn rte_pktmbuf_read(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        buf: *mut ::core::ffi::c_void,
    ) -> *const ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Chain an mbuf to another, thereby creating a segmented packet.\nNote: The implementation will do a linear walk over the segments to find\nthe tail entry. For cases when there are many segments, it's better to\nchain the entries manually.\n\n# Arguments\n\n* `head` -\nThe head of the mbuf chain (the first packet)\n* `tail` -\nThe mbuf to put last in the chain\n\n# Returns\n\n- 0, on success.\n- -EOVERFLOW, if the chain segment limit exceeded"]
    #[link_name = "rte_pktmbuf_chain_w"]
    pub fn rte_pktmbuf_chain(head: *mut rte_mbuf, tail: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "For given input values generate raw tx_offload value.\nNote that it is caller responsibility to make sure that input parameters\ndon't exceed maximum bit-field values.\n\n# Arguments\n\n* `il2` -\nl2_len value.\n* `il3` -\nl3_len value.\n* `il4` -\nl4_len value.\n* `tso` -\ntso_segsz value.\n* `ol3` -\nouter_l3_len value.\n* `ol2` -\nouter_l2_len value.\n* `unused` -\nunused value.\n\n# Returns\n\nraw tx_offload value."]
    #[link_name = "rte_mbuf_tx_offload_w"]
    pub fn rte_mbuf_tx_offload(
        il2: u64,
        il3: u64,
        il4: u64,
        tso: u64,
        ol3: u64,
        ol2: u64,
        unused: u64,
    ) -> u64;
}
unsafe extern "C" {
    #[doc = "Validate general requirements for Tx offload in mbuf.\nThis function checks correctness and completeness of Tx offload settings.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be validated.\n\n# Returns\n\n0 if packet is valid"]
    #[link_name = "rte_validate_tx_offload_w"]
    pub fn rte_validate_tx_offload(m: *const rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Linearize data in mbuf.\nThis function moves the mbuf data in the first segment if there is enough\ntailroom. The subsequent segments are unchained and freed.\n\n# Arguments\n\n* `mbuf` -\nmbuf to linearize\n\n# Returns\n\n- 0, on success\n- -1, on error"]
    #[link_name = "rte_pktmbuf_linearize_w"]
    pub fn rte_pktmbuf_linearize(mbuf: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump an mbuf structure to a file.\nDump all fields for the given packet mbuf and all its associated\nsegments (in the case of a chained buffer).\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `m` -\nThe packet mbuf.\n* `dump_len` -\nIf dump_len != 0, also dump the \"dump_len\" first data bytes of\nthe packet."]
    pub fn rte_pktmbuf_dump(f: *mut FILE, m: *const rte_mbuf, dump_len: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched queue_id field."]
    #[link_name = "rte_mbuf_sched_queue_get_w"]
    pub fn rte_mbuf_sched_queue_get(m: *const rte_mbuf) -> u32;
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched traffic_class field."]
    #[link_name = "rte_mbuf_sched_traffic_class_get_w"]
    pub fn rte_mbuf_sched_traffic_class_get(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched color field."]
    #[link_name = "rte_mbuf_sched_color_get_w"]
    pub fn rte_mbuf_sched_color_get(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    #[doc = "Get the values of mbuf sched queue_id, traffic_class and color.\n\n# Arguments\n\n* `m` -\nMbuf to read\n* `queue_id` -\nReturns the queue id\n* `traffic_class` -\nReturns the traffic class id\n* `color` -\nReturns the colour id"]
    #[link_name = "rte_mbuf_sched_get_w"]
    pub fn rte_mbuf_sched_get(
        m: *const rte_mbuf,
        queue_id: *mut u32,
        traffic_class: *mut u8,
        color: *mut u8,
    );
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched queue_id to the defined value."]
    #[link_name = "rte_mbuf_sched_queue_set_w"]
    pub fn rte_mbuf_sched_queue_set(m: *mut rte_mbuf, queue_id: u32);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched traffic_class id to the defined value."]
    #[link_name = "rte_mbuf_sched_traffic_class_set_w"]
    pub fn rte_mbuf_sched_traffic_class_set(m: *mut rte_mbuf, traffic_class: u8);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched color id to the defined value."]
    #[link_name = "rte_mbuf_sched_color_set_w"]
    pub fn rte_mbuf_sched_color_set(m: *mut rte_mbuf, color: u8);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched queue_id, traffic_class and color.\n\n# Arguments\n\n* `m` -\nMbuf to set\n* `queue_id` -\nQueue id value to be set\n* `traffic_class` -\nTraffic class id value to be set\n* `color` -\nColor id to be set"]
    #[link_name = "rte_mbuf_sched_set_w"]
    pub fn rte_mbuf_sched_set(m: *mut rte_mbuf, queue_id: u32, traffic_class: u8, color: u8);
}
#[doc = "Ethernet address:\nA universally administered address is uniquely assigned to a device by its\nmanufacturer. The first three octets (in transmission order) contain the\nOrganizationally Unique Identifier (OUI). The following three (MAC-48 and\nEUI-48) octets are assigned by that organization with the only constraint\nof uniqueness.\nA locally administered address is assigned to a device by a network\nadministrator and does not contain OUIs.\nSee http://standards.ieee.org/regauth/groupmac/tutorial.html"]
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ether_addr {
    #[doc = "< Addr bytes in tx order"]
    pub addr_bytes: [u8; 6usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ether_addr"][::core::mem::size_of::<rte_ether_addr>() - 6usize];
    ["Alignment of rte_ether_addr"][::core::mem::align_of::<rte_ether_addr>() - 2usize];
    ["Offset of field: rte_ether_addr::addr_bytes"]
        [::core::mem::offset_of!(rte_ether_addr, addr_bytes) - 0usize];
};
unsafe extern "C" {
    #[doc = "Check if two Ethernet addresses are the same.\n\n# Arguments\n\n* `ea1` -\nA pointer to the first ether_addr structure containing\nthe ethernet address.\n* `ea2` -\nA pointer to the second ether_addr structure containing\nthe ethernet address.\n\n# Returns\n\nTrue  (1) if the given two ethernet address are the same;\nFalse (0) otherwise."]
    #[link_name = "rte_is_same_ether_addr_w"]
    pub fn rte_is_same_ether_addr(
        ea1: *const rte_ether_addr,
        ea2: *const rte_ether_addr,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is filled with zeros.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is filled with zeros;\nfalse (0) otherwise."]
    #[link_name = "rte_is_zero_ether_addr_w"]
    pub fn rte_is_zero_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a unicast address.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is a unicast address;\nfalse (0) otherwise."]
    #[link_name = "rte_is_unicast_ether_addr_w"]
    pub fn rte_is_unicast_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a multicast address.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is a multicast address;\nfalse (0) otherwise."]
    #[link_name = "rte_is_multicast_ether_addr_w"]
    pub fn rte_is_multicast_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a broadcast address.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is a broadcast address;\nfalse (0) otherwise."]
    #[link_name = "rte_is_broadcast_ether_addr_w"]
    pub fn rte_is_broadcast_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a universally assigned address.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is a universally assigned address;\nfalse (0) otherwise."]
    #[link_name = "rte_is_universal_ether_addr_w"]
    pub fn rte_is_universal_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a locally assigned address.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is a locally assigned address;\nfalse (0) otherwise."]
    #[link_name = "rte_is_local_admin_ether_addr_w"]
    pub fn rte_is_local_admin_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a valid address. Checks that the address is a\nunicast address and is not filled with zeros.\n\n# Arguments\n\n* `ea` -\nA pointer to a ether_addr structure containing the ethernet address\nto check.\n\n# Returns\n\nTrue  (1) if the given ethernet address is valid;\nfalse (0) otherwise."]
    #[link_name = "rte_is_valid_assigned_ether_addr_w"]
    pub fn rte_is_valid_assigned_ether_addr(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Generate a random Ethernet address that is locally administered\nand not multicast.\n\n# Arguments\n\n* `addr` -\nA pointer to Ethernet address."]
    pub fn rte_eth_random_addr(addr: *mut u8);
}
unsafe extern "C" {
    #[doc = "Copy an Ethernet address.\n\n# Arguments\n\n* `ea_from` -\nA pointer to a ether_addr structure holding the Ethernet address to copy.\n* `ea_to` -\nA pointer to a ether_addr structure where to copy the Ethernet address."]
    #[link_name = "rte_ether_addr_copy_w"]
    pub fn rte_ether_addr_copy(ea_from: *const rte_ether_addr, ea_to: *mut rte_ether_addr);
}
unsafe extern "C" {
    #[doc = "Format 48bits Ethernet address in pattern xx:xx:xx:xx:xx:xx.\n\n# Arguments\n\n* `buf` -\nA pointer to buffer contains the formatted MAC address.\n* `size` -\nThe format buffer size.\n* `eth_addr` -\nA pointer to a ether_addr structure."]
    pub fn rte_ether_format_addr(
        buf: *mut ::core::ffi::c_char,
        size: u16,
        eth_addr: *const rte_ether_addr,
    );
}
unsafe extern "C" {
    #[doc = "Convert string with Ethernet address to an ether_addr.\n\n# Arguments\n\n* `str` -\nA pointer to buffer contains the formatted MAC address.\nAccepts either byte or word format separated by colon,\nhyphen or period.\nThe example formats are:\nXX:XX:XX:XX:XX:XX - Canonical form\nXX-XX-XX-XX-XX-XX - Windows and IEEE 802\nXXXX.XXXX.XXXX    - Cisco\nwhere XX is a hex digit: 0-9, a-f, or A-F.\nIn the byte format, leading zeros are optional.\n* `eth_addr` -\nA pointer to a ether_addr structure.\n\n# Returns\n\n0 if successful\n-1 and sets rte_errno if invalid string"]
    pub fn rte_ether_unformat_addr(
        str_: *const ::core::ffi::c_char,
        eth_addr: *mut rte_ether_addr,
    ) -> ::core::ffi::c_int;
}
#[doc = "Ethernet header: Contains the destination address, source address\nand frame type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ether_hdr {
    #[doc = "< Destination address."]
    pub dst_addr: rte_ether_addr,
    #[doc = "< Source address."]
    pub src_addr: rte_ether_addr,
    #[doc = "< Frame type."]
    pub ether_type: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ether_hdr"][::core::mem::size_of::<rte_ether_hdr>() - 14usize];
    ["Alignment of rte_ether_hdr"][::core::mem::align_of::<rte_ether_hdr>() - 2usize];
    ["Offset of field: rte_ether_hdr::dst_addr"]
        [::core::mem::offset_of!(rte_ether_hdr, dst_addr) - 0usize];
    ["Offset of field: rte_ether_hdr::src_addr"]
        [::core::mem::offset_of!(rte_ether_hdr, src_addr) - 6usize];
    ["Offset of field: rte_ether_hdr::ether_type"]
        [::core::mem::offset_of!(rte_ether_hdr, ether_type) - 12usize];
};
#[doc = "Ethernet VLAN Header.\nContains the 16-bit VLAN Tag Control Identifier and the Ethernet type\nof the encapsulated frame."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_vlan_hdr {
    #[doc = "< Priority (3) + CFI (1) + Identifier Code (12)"]
    pub vlan_tci: rte_be16_t,
    #[doc = "< Ethernet type of encapsulated frame."]
    pub eth_proto: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vlan_hdr"][::core::mem::size_of::<rte_vlan_hdr>() - 4usize];
    ["Alignment of rte_vlan_hdr"][::core::mem::align_of::<rte_vlan_hdr>() - 2usize];
    ["Offset of field: rte_vlan_hdr::vlan_tci"]
        [::core::mem::offset_of!(rte_vlan_hdr, vlan_tci) - 0usize];
    ["Offset of field: rte_vlan_hdr::eth_proto"]
        [::core::mem::offset_of!(rte_vlan_hdr, eth_proto) - 2usize];
};
unsafe extern "C" {
    #[doc = "Extract VLAN tag information into mbuf\nSoftware version of VLAN stripping\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\n- 0: Success\n- 1: not a vlan packet"]
    #[link_name = "rte_vlan_strip_w"]
    pub fn rte_vlan_strip(m: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Insert VLAN tag into mbuf.\nSoftware version of VLAN unstripping\n\n# Arguments\n\n* `m` -\nThe packet mbuf.\n\n# Returns\n\n- 0: On success\n-EPERM: mbuf is shared overwriting would be unsafe\n-ENOSPC: not enough headroom in mbuf"]
    #[link_name = "rte_vlan_insert_w"]
    pub fn rte_vlan_insert(m: *mut *mut rte_mbuf) -> ::core::ffi::c_int;
}
#[doc = "ARP header IPv4 payload."]
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_arp_ipv4 {
    pub _bindgen_opaque_blob: [u16; 10usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_arp_ipv4"][::core::mem::size_of::<rte_arp_ipv4>() - 20usize];
    ["Alignment of rte_arp_ipv4"][::core::mem::align_of::<rte_arp_ipv4>() - 2usize];
};
#[doc = "ARP header."]
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_arp_hdr {
    pub _bindgen_opaque_blob: [u16; 14usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_arp_hdr"][::core::mem::size_of::<rte_arp_hdr>() - 28usize];
    ["Alignment of rte_arp_hdr"][::core::mem::align_of::<rte_arp_hdr>() - 2usize];
};
unsafe extern "C" {
    #[doc = "Make a RARP packet based on MAC addr.\n\n# Arguments\n\n* `mpool` -\nPointer to the rte_mempool\n* `mac` -\nPointer to the MAC addr\n\n# Returns\n\n- RARP packet pointer on success, or NULL on error"]
    pub fn rte_net_make_rarp_packet(
        mpool: *mut rte_mempool,
        mac: *const rte_ether_addr,
    ) -> *mut rte_mbuf;
}
#[doc = "Bitmap data structure"]
#[repr(C)]
#[derive(Debug)]
pub struct rte_bitmap {
    #[doc = "< Bitmap array1"]
    pub array1: *mut u64,
    #[doc = "< Bitmap array2"]
    pub array2: *mut u64,
    #[doc = "< Number of 64-bit slabs in array1 that are actually used"]
    pub array1_size: u32,
    #[doc = "< Number of 64-bit slabs in array2"]
    pub array2_size: u32,
    #[doc = "< Bitmap scan: Index of current array1 slab"]
    pub index1: u32,
    #[doc = "< Bitmap scan: Offset of current bit within current array1 slab"]
    pub offset1: u32,
    #[doc = "< Bitmap scan: Index of current array2 slab"]
    pub index2: u32,
    #[doc = "< Bitmap scan: Go/stop condition for current array2 cache line"]
    pub go2: u32,
    #[doc = "Storage space for array1 and array2"]
    pub memory: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_bitmap"][::core::mem::size_of::<rte_bitmap>() - 40usize];
    ["Alignment of rte_bitmap"][::core::mem::align_of::<rte_bitmap>() - 8usize];
    ["Offset of field: rte_bitmap::array1"][::core::mem::offset_of!(rte_bitmap, array1) - 0usize];
    ["Offset of field: rte_bitmap::array2"][::core::mem::offset_of!(rte_bitmap, array2) - 8usize];
    ["Offset of field: rte_bitmap::array1_size"]
        [::core::mem::offset_of!(rte_bitmap, array1_size) - 16usize];
    ["Offset of field: rte_bitmap::array2_size"]
        [::core::mem::offset_of!(rte_bitmap, array2_size) - 20usize];
    ["Offset of field: rte_bitmap::index1"][::core::mem::offset_of!(rte_bitmap, index1) - 24usize];
    ["Offset of field: rte_bitmap::offset1"]
        [::core::mem::offset_of!(rte_bitmap, offset1) - 28usize];
    ["Offset of field: rte_bitmap::index2"][::core::mem::offset_of!(rte_bitmap, index2) - 32usize];
    ["Offset of field: rte_bitmap::go2"][::core::mem::offset_of!(rte_bitmap, go2) - 36usize];
    ["Offset of field: rte_bitmap::memory"][::core::mem::offset_of!(rte_bitmap, memory) - 40usize];
};
impl Default for rte_bitmap {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Bitmap memory footprint calculation\n\n# Arguments\n\n* `n_bits` -\nNumber of bits in the bitmap\n\n# Returns\n\nBitmap memory footprint measured in bytes on success, 0 on error"]
    #[link_name = "rte_bitmap_get_memory_footprint_w"]
    pub fn rte_bitmap_get_memory_footprint(n_bits: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Bitmap initialization\n\n# Arguments\n\n* `n_bits` -\nNumber of pre-allocated bits in array2.\n* `mem` -\nBase address of array1 and array2.\n* `mem_size` -\nMinimum expected size of bitmap.\n\n# Returns\n\nHandle to bitmap instance."]
    #[link_name = "rte_bitmap_init_w"]
    pub fn rte_bitmap_init(n_bits: u32, mem: *mut u8, mem_size: u32) -> *mut rte_bitmap;
}
unsafe extern "C" {
    #[doc = "Bitmap initialization with all bits set\n\n# Arguments\n\n* `n_bits` -\nNumber of pre-allocated bits in array2.\n* `mem` -\nBase address of array1 and array2.\n* `mem_size` -\nMinimum expected size of bitmap.\n\n# Returns\n\nHandle to bitmap instance."]
    #[link_name = "rte_bitmap_init_with_all_set_w"]
    pub fn rte_bitmap_init_with_all_set(
        n_bits: u32,
        mem: *mut u8,
        mem_size: u32,
    ) -> *mut rte_bitmap;
}
unsafe extern "C" {
    #[doc = "Bitmap free\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n\n# Returns\n\n0 upon success, error code otherwise"]
    #[link_name = "rte_bitmap_free_w"]
    pub fn rte_bitmap_free(bmp: *mut rte_bitmap) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Bitmap reset\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance"]
    #[link_name = "rte_bitmap_reset_w"]
    pub fn rte_bitmap_reset(bmp: *mut rte_bitmap);
}
unsafe extern "C" {
    #[doc = "Bitmap location prefetch into CPU L1 cache\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nBit position"]
    #[link_name = "rte_bitmap_prefetch0_w"]
    pub fn rte_bitmap_prefetch0(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    #[doc = "Bitmap bit get\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nBit position\n\n# Returns\n\n0 when bit is cleared, non-zero when bit is set"]
    #[link_name = "rte_bitmap_get_w"]
    pub fn rte_bitmap_get(bmp: *mut rte_bitmap, pos: u32) -> u64;
}
unsafe extern "C" {
    #[doc = "Bitmap bit set\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nBit position"]
    #[link_name = "rte_bitmap_set_w"]
    pub fn rte_bitmap_set(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    #[doc = "Bitmap slab set\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nBit position identifying the array2 slab\n* `slab` -\nValue to be assigned to the 64-bit slab in array2"]
    #[link_name = "rte_bitmap_set_slab_w"]
    pub fn rte_bitmap_set_slab(bmp: *mut rte_bitmap, pos: u32, slab: u64);
}
unsafe extern "C" {
    #[doc = "Bitmap bit clear\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nBit position"]
    #[link_name = "rte_bitmap_clear_w"]
    pub fn rte_bitmap_clear(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    #[doc = "Bitmap scan (with automatic wrap-around)\n\n# Arguments\n\n* `bmp` -\nHandle to bitmap instance\n* `pos` -\nWhen function call returns 1, pos contains the position of the next set\nbit, otherwise not modified\n* `slab` -\nWhen function call returns 1, slab contains the value of the entire 64-bit\nslab where the bit indicated by pos is located. Slabs are always 64-bit\naligned, so the position of the first bit of the slab (this bit is not\nnecessarily set) is pos / 64. Once a slab has been returned by the bitmap\nscan operation, the internal pointers of the bitmap are updated to point\nafter this slab, so the same slab will not be returned again if it\ncontains more than one bit which is set. When function call returns 0,\nslab is not modified.\n\n# Returns\n\n0 if there is no bit set in the bitmap, 1 otherwise"]
    #[link_name = "rte_bitmap_scan_w"]
    pub fn rte_bitmap_scan(
        bmp: *mut rte_bitmap,
        pos: *mut u32,
        slab: *mut u64,
    ) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_bus {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_device {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Retrieve a bus name.\n\n# Arguments\n\n* `bus` -\nA pointer to a rte_bus structure.\n\n# Returns\n\nA pointer to the bus name string."]
    pub fn rte_bus_name(bus: *const rte_bus) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Scan all the buses.\n\n# Returns\n\n0 in case of success in scanning all buses\n!0 in case of failure to scan"]
    pub fn rte_bus_scan() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "For each device on the buses, perform a driver 'match' and call the\ndriver-specific probe for device initialization.\n\n# Returns\n\n0 for successful match/probe\n!0 otherwise"]
    pub fn rte_bus_probe() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump information of all the buses registered with EAL.\n\n# Arguments\n\n* `f` -\nA valid and open output stream handle"]
    pub fn rte_bus_dump(f: *mut FILE);
}
#[doc = "Bus comparison function.\n\n# Arguments\n\n* `bus` -\nBus under test.\n* `data` -\nData to compare against.\n\n# Returns\n\n0 if the bus matches the data.\n!0 if the bus does not match.\n<0 if ordering is possible and the bus is lower than the data.\n>0 if ordering is possible and the bus is greater than the data."]
pub type rte_bus_cmp_t = ::core::option::Option<
    unsafe extern "C" fn(
        bus: *const rte_bus,
        data: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Bus iterator to find a particular bus.\nThis function compares each registered bus to find one that matches\nthe data passed as parameter.\nIf the comparison function returns zero this function will stop iterating\nover any more buses. To continue a search the bus of a previous search can\nbe passed via the start parameter.\n\n# Arguments\n\n* `start` -\nStarting point for the iteration.\n* `cmp` -\nComparison function.\n* `data` -\nData to pass to comparison function.\n\n# Returns\n\nA pointer to a rte_bus structure or NULL in case no bus matches"]
    pub fn rte_bus_find(
        start: *const rte_bus,
        cmp: rte_bus_cmp_t,
        data: *const ::core::ffi::c_void,
    ) -> *mut rte_bus;
}
unsafe extern "C" {
    #[doc = "Find the registered bus for a particular device."]
    pub fn rte_bus_find_by_device(dev: *const rte_device) -> *mut rte_bus;
}
unsafe extern "C" {
    #[doc = "Find the registered bus for a given name."]
    pub fn rte_bus_find_by_name(busname: *const ::core::ffi::c_char) -> *mut rte_bus;
}
unsafe extern "C" {
    #[doc = "Get the common iommu class of devices bound on to buses available in the\nsystem. RTE_IOVA_DC means that no preference has been expressed.\n\n# Returns\n\nenum rte_iova_mode value."]
    pub fn rte_bus_get_iommu_class() -> rte_iova_mode::Type;
}
pub type rte_intr_event_cb_t = ::core::option::Option<
    unsafe extern "C" fn(fd: ::core::ffi::c_int, arg: *mut ::core::ffi::c_void),
>;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_epoll_data {
    #[doc = "< event type"]
    pub event: u32,
    #[doc = "< User data"]
    pub data: *mut ::core::ffi::c_void,
    #[doc = "< IN: callback fun"]
    pub cb_fun: rte_intr_event_cb_t,
    #[doc = "< IN: callback arg"]
    pub cb_arg: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_epoll_data"][::core::mem::size_of::<rte_epoll_data>() - 32usize];
    ["Alignment of rte_epoll_data"][::core::mem::align_of::<rte_epoll_data>() - 8usize];
    ["Offset of field: rte_epoll_data::event"]
        [::core::mem::offset_of!(rte_epoll_data, event) - 0usize];
    ["Offset of field: rte_epoll_data::data"]
        [::core::mem::offset_of!(rte_epoll_data, data) - 8usize];
    ["Offset of field: rte_epoll_data::cb_fun"]
        [::core::mem::offset_of!(rte_epoll_data, cb_fun) - 16usize];
    ["Offset of field: rte_epoll_data::cb_arg"]
        [::core::mem::offset_of!(rte_epoll_data, cb_arg) - 24usize];
};
impl Default for rte_epoll_data {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod _bindgen_ty_3 {
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_EPOLL_INVALID: Type = 0;
    pub const RTE_EPOLL_VALID: Type = 1;
    pub const RTE_EPOLL_EXEC: Type = 2;
}
#[doc = "interrupt epoll event obj, taken by epoll_event.ptr"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_epoll_event {
    #[doc = "< OUT: event status"]
    pub status: u32,
    #[doc = "< OUT: event fd"]
    pub fd: ::core::ffi::c_int,
    #[doc = "< OUT: epoll instance the ev associated with"]
    pub epfd: ::core::ffi::c_int,
    pub epdata: rte_epoll_data,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_epoll_event"][::core::mem::size_of::<rte_epoll_event>() - 48usize];
    ["Alignment of rte_epoll_event"][::core::mem::align_of::<rte_epoll_event>() - 8usize];
    ["Offset of field: rte_epoll_event::status"]
        [::core::mem::offset_of!(rte_epoll_event, status) - 0usize];
    ["Offset of field: rte_epoll_event::fd"][::core::mem::offset_of!(rte_epoll_event, fd) - 4usize];
    ["Offset of field: rte_epoll_event::epfd"]
        [::core::mem::offset_of!(rte_epoll_event, epfd) - 8usize];
    ["Offset of field: rte_epoll_event::epdata"]
        [::core::mem::offset_of!(rte_epoll_event, epdata) - 16usize];
};
impl Default for rte_epoll_event {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "It waits for events on the epoll instance.\nRetries if signal received.\n\n# Arguments\n\n* `epfd` -\nEpoll instance fd on which the caller wait for events.\n* `events` -\nMemory area contains the events that will be available for the caller.\n* `maxevents` -\nUp to maxevents are returned, must greater than zero.\n* `timeout` -\nSpecifying a timeout of -1 causes a block indefinitely.\nSpecifying a timeout equal to zero cause to return immediately.\n\n# Returns\n\n- On success, returns the number of available event.\n- On failure, a negative value."]
    pub fn rte_epoll_wait(
        epfd: ::core::ffi::c_int,
        events: *mut rte_epoll_event,
        maxevents: ::core::ffi::c_int,
        timeout: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It waits for events on the epoll instance.\nDoes not retry if signal received.\n\n# Arguments\n\n* `epfd` -\nEpoll instance fd on which the caller wait for events.\n* `events` -\nMemory area contains the events that will be available for the caller.\n* `maxevents` -\nUp to maxevents are returned, must greater than zero.\n* `timeout` -\nSpecifying a timeout of -1 causes a block indefinitely.\nSpecifying a timeout equal to zero cause to return immediately.\n\n# Returns\n\n- On success, returns the number of available event.\n- On failure, a negative value."]
    pub fn rte_epoll_wait_interruptible(
        epfd: ::core::ffi::c_int,
        events: *mut rte_epoll_event,
        maxevents: ::core::ffi::c_int,
        timeout: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It performs control operations on epoll instance referred by the epfd.\nIt requests that the operation op be performed for the target fd.\n\n# Arguments\n\n* `epfd` -\nEpoll instance fd on which the caller perform control operations.\n* `op` -\nThe operation be performed for the target fd.\n* `fd` -\nThe target fd on which the control ops perform.\n* `event` -\nDescribes the object linked to the fd.\nNote: The caller must take care the object deletion after CTL_DEL.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_epoll_ctl(
        epfd: ::core::ffi::c_int,
        op: ::core::ffi::c_int,
        fd: ::core::ffi::c_int,
        event: *mut rte_epoll_event,
    ) -> ::core::ffi::c_int;
}
#[doc = "Interrupt handle"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_intr_handle {
    _unused: [u8; 0],
}
pub mod rte_intr_handle_type {
    #[doc = "The interrupt source type, e.g. UIO, VFIO, ALARM etc."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< generic unknown handle"]
    pub const RTE_INTR_HANDLE_UNKNOWN: Type = 0;
    #[doc = "< uio device handle"]
    pub const RTE_INTR_HANDLE_UIO: Type = 1;
    #[doc = "< uio generic handle"]
    pub const RTE_INTR_HANDLE_UIO_INTX: Type = 2;
    #[doc = "< vfio device handle (legacy)"]
    pub const RTE_INTR_HANDLE_VFIO_LEGACY: Type = 3;
    #[doc = "< vfio device handle (MSI)"]
    pub const RTE_INTR_HANDLE_VFIO_MSI: Type = 4;
    #[doc = "< vfio device handle (MSIX)"]
    pub const RTE_INTR_HANDLE_VFIO_MSIX: Type = 5;
    #[doc = "< alarm handle"]
    pub const RTE_INTR_HANDLE_ALARM: Type = 6;
    #[doc = "< external handler"]
    pub const RTE_INTR_HANDLE_EXT: Type = 7;
    #[doc = "< virtual device"]
    pub const RTE_INTR_HANDLE_VDEV: Type = 8;
    #[doc = "< device event handle"]
    pub const RTE_INTR_HANDLE_DEV_EVENT: Type = 9;
    #[doc = "< VFIO request handle"]
    pub const RTE_INTR_HANDLE_VFIO_REQ: Type = 10;
    #[doc = "< count of elements"]
    pub const RTE_INTR_HANDLE_MAX: Type = 11;
}
#[doc = "Function to be registered for the specific interrupt"]
pub type rte_intr_callback_fn =
    ::core::option::Option<unsafe extern "C" fn(cb_arg: *mut ::core::ffi::c_void)>;
#[doc = "Function to call after a callback is unregistered.\nCan be used to close fd and free cb_arg."]
pub type rte_intr_unregister_callback_fn = ::core::option::Option<
    unsafe extern "C" fn(intr_handle: *mut rte_intr_handle, cb_arg: *mut ::core::ffi::c_void),
>;
unsafe extern "C" {
    #[doc = "It registers the callback for the specific interrupt. Multiple\ncallbacks can be registered at the same time.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle.\n* `cb` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_callback_register(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It unregisters the callback according to the specified interrupt handle.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `cb` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback, (void *)-1 means to remove all\nregistered which has the same callback address.\n\n# Returns\n\n- On success, return the number of callback entities removed.\n- On failure, a negative value."]
    pub fn rte_intr_callback_unregister(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister the callback according to the specified interrupt handle,\nafter it's no longer active. Fail if source is not active.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `cb_fn` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback, (void *)-1 means to remove all\nregistered which has the same callback address.\n* `ucb_fn` -\ncallback to call before cb is unregistered (optional).\ncan be used to close fd and free cb_arg.\n\n# Returns\n\n- On success, return the number of callback entities marked for remove.\n- On failure, a negative value."]
    pub fn rte_intr_callback_unregister_pending(
        intr_handle: *const rte_intr_handle,
        cb_fn: rte_intr_callback_fn,
        cb_arg: *mut ::core::ffi::c_void,
        ucb_fn: rte_intr_unregister_callback_fn,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Loop until rte_intr_callback_unregister() succeeds.\nAfter a call to this function,\nthe callback provided by the specified interrupt handle is unregistered.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `cb` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback, (void *)-1 means to remove all\nregistered which has the same callback address.\n\n# Returns\n\n- On success, return the number of callback entities removed.\n- On failure, a negative value."]
    pub fn rte_intr_callback_unregister_sync(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It enables the interrupt for the specified handle.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_enable(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It disables the interrupt for the specified handle.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_disable(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It acknowledges an interrupt raised for the specified handle.\nThis function should be called at the end of each interrupt handler either\nfrom application or driver, so that currently raised interrupt is acked and\nfurther new interrupts are raised.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_ack(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if currently executing in interrupt context\n\n# Returns\n\n- non zero in case of interrupt context\n- zero in case of process context"]
    pub fn rte_thread_is_intr() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It allocates memory for interrupt instance. API takes flag as an argument\nwhich define from where memory should be allocated i.e. using DPDK memory\nmanagement library APIs or normal heap allocation.\nDefault memory allocation for event fds and event list array is done which\ncan be realloced later based on size of MSIX interrupts supported by a PCI\ndevice.\nThis function should be called from application or driver, before calling\nany of the interrupt APIs.\n\n# Arguments\n\n* `flags` -\nSee RTE_INTR_INSTANCE_F_* flags definitions.\n\n# Returns\n\n- On success, address of interrupt handle.\n- On failure, NULL."]
    pub fn rte_intr_instance_alloc(flags: u32) -> *mut rte_intr_handle;
}
unsafe extern "C" {
    #[doc = "Free the memory allocated for interrupt handle resources.\n\n# Arguments\n\n* `intr_handle` -\nInterrupt handle allocated with rte_intr_instance_alloc().\nIf intr_handle is NULL, no operation is performed."]
    pub fn rte_intr_instance_free(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = "Set the fd field of interrupt handle with user provided\nfile descriptor.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `fd` -\nfile descriptor value provided by user.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_fd_set(
        intr_handle: *mut rte_intr_handle,
        fd: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Returns the fd field of the given interrupt handle instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, fd field.\n- On failure, a negative value."]
    pub fn rte_intr_fd_get(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the type field of interrupt handle with user provided\ninterrupt type.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `type` -\ninterrupt type\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_type_set(
        intr_handle: *mut rte_intr_handle,
        type_: rte_intr_handle_type::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Returns the type field of the given interrupt handle instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, interrupt type\n- On failure, RTE_INTR_HANDLE_UNKNOWN."]
    pub fn rte_intr_type_get(intr_handle: *const rte_intr_handle) -> rte_intr_handle_type::Type;
}
unsafe extern "C" {
    #[doc = "@internal The function returns the per thread epoll instance.\n\n# Returns\n\nepfd the epoll instance referred to."]
    pub fn rte_intr_tls_epfd() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal # Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle.\n* `epfd` -\nEpoll instance fd which the intr vector associated to.\n* `op` -\nThe operation be performed for the vector.\nOperation type of {ADD, DEL}.\n* `vec` -\nRX intr vector number added to the epoll instance wait list.\n* `data` -\nUser raw data.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_rx_ctl(
        intr_handle: *mut rte_intr_handle,
        epfd: ::core::ffi::c_int,
        op: ::core::ffi::c_int,
        vec: ::core::ffi::c_uint,
        data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal It deletes registered eventfds.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle."]
    pub fn rte_intr_free_epoll_fd(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = "@internal It enables the packet I/O interrupt event if it's necessary.\nIt creates event fd for each interrupt vector when MSIX is used,\notherwise it multiplexes a single event fd.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle.\n* `nb_efd` -\nNumber of interrupt vector trying to enable.\nThe value 0 is not allowed.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_intr_efd_enable(
        intr_handle: *mut rte_intr_handle,
        nb_efd: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal It disables the packet I/O interrupt event.\nIt deletes registered eventfds and closes the open fds.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle."]
    pub fn rte_intr_efd_disable(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = "@internal The packet I/O interrupt on datapath is enabled or not.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle."]
    pub fn rte_intr_dp_is_en(intr_handle: *mut rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal The interrupt handle instance allows other causes or not.\nOther causes stand for any none packet I/O interrupts.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle."]
    pub fn rte_intr_allow_others(intr_handle: *mut rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal The multiple interrupt vector capability of interrupt handle instance.\nIt returns zero if no multiple interrupt vector support.\n\n# Arguments\n\n* `intr_handle` -\nPointer to the interrupt handle."]
    pub fn rte_intr_cap_multiple(intr_handle: *mut rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Creates a clone of src by allocating a new handle and copying src content.\n\n# Arguments\n\n* `src` -\nSource interrupt handle to be cloned.\n\n# Returns\n\n- On success, address of interrupt handle.\n- On failure, NULL."]
    pub fn rte_intr_instance_dup(src: *const rte_intr_handle) -> *mut rte_intr_handle;
}
unsafe extern "C" {
    #[doc = "@internal Set the device fd field of interrupt handle with user\nprovided dev fd. Device fd corresponds to VFIO device fd or UIO config fd.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `fd` -\ninterrupt type\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_dev_fd_set(
        intr_handle: *mut rte_intr_handle,
        fd: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the device fd field of the given interrupt handle instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, dev fd.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_dev_fd_get(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Set the max intr field of interrupt handle with user\nprovided max intr value.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `max_intr` -\ninterrupt type\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_max_intr_set(
        intr_handle: *mut rte_intr_handle,
        max_intr: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the max intr field of the given interrupt handle instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, max intr.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_max_intr_get(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Set the number of event fd field of interrupt handle\nwith user provided available event file descriptor value.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `nb_efd` -\nAvailable event fd\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_efd_set(
        intr_handle: *mut rte_intr_handle,
        nb_efd: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the number of available event fd field of the given interrupt handle\ninstance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, nb_efd\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_efd_get(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the number of interrupt vector field of the given interrupt handle\ninstance. This field is to configured on device probe time, and based on\nthis value efds and elist arrays are dynamically allocated. By default\nthis value is set to RTE_MAX_RXTX_INTR_VEC_ID.\nFor eg. in case of PCI device, its msix size is queried and efds/elist\narrays are allocated accordingly.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, nb_intr\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_intr_get(intr_handle: *const rte_intr_handle) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Set the event fd counter size field of interrupt handle\nwith user provided efd counter size.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `efd_counter_size` -\nsize of efd counter.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efd_counter_size_set(
        intr_handle: *mut rte_intr_handle,
        efd_counter_size: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the event fd counter size field of the given interrupt handle\ninstance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, efd_counter_size\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efd_counter_size_get(intr_handle: *const rte_intr_handle)
    -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Set the event fd array index with the given fd.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nefds array index to be set\n* `fd` -\nevent fd\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efds_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::core::ffi::c_int,
        fd: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the fd value of event fds array at a given index.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nefds array index to be returned\n\n# Returns\n\n- On success, fd\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efds_index_get(
        intr_handle: *const rte_intr_handle,
        index: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Set the epoll event object array index with the given\nelist instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nelist array index to be set\n* `elist` -\nepoll event instance of struct rte_epoll_event\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_elist_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::core::ffi::c_int,
        elist: rte_epoll_event,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the address of epoll event instance from elist array at a given\nindex.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nelist array index to be returned\n\n# Returns\n\n- On success, elist\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_elist_index_get(
        intr_handle: *mut rte_intr_handle,
        index: ::core::ffi::c_int,
    ) -> *mut rte_epoll_event;
}
unsafe extern "C" {
    #[doc = "@internal Allocates the memory of interrupt vector list array, with size defining the\nnumber of elements required in the array.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `name` -\nName assigned to the allocation, or NULL.\n* `size` -\nNumber of element required in the array.\n\n# Returns\n\n- On success, zero\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_alloc(
        intr_handle: *mut rte_intr_handle,
        name: *const ::core::ffi::c_char,
        size: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Sets the vector value at given index of interrupt vector list field of given\ninterrupt handle.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nintr_vec array index to be set\n* `vec` -\nInterrupt vector value.\n\n# Returns\n\n- On success, zero\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::core::ffi::c_int,
        vec: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the vector value at the given index of interrupt vector list array.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `index` -\nintr_vec array index to be returned\n\n# Returns\n\n- On success, interrupt vector\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_index_get(
        intr_handle: *const rte_intr_handle,
        index: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Frees the memory allocated for interrupt vector list array.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, zero\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_free(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = "@internal Reallocates the size efds and elist array based on size provided by user.\nBy default efds and elist array are allocated with default size\nRTE_MAX_RXTX_INTR_VEC_ID on interrupt handle array creation. Later on device\nprobe, device may have capability of more interrupts than\nRTE_MAX_RXTX_INTR_VEC_ID. Using this API, PMDs can reallocate the arrays as\nper the max interrupts capability of device.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `size` -\nefds and elist array size.\n\n# Returns\n\n- On success, zero\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_event_list_update(
        intr_handle: *mut rte_intr_handle,
        size: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Returns the Windows handle of the given interrupt instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n\n# Returns\n\n- On success, Windows handle.\n- On failure, NULL."]
    pub fn rte_intr_instance_windows_handle_get(
        intr_handle: *mut rte_intr_handle,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "@internal Set the Windows handle for the given interrupt instance.\n\n# Arguments\n\n* `intr_handle` -\npointer to the interrupt handle.\n* `windows_handle` -\nWindows handle to be set.\n\n# Returns\n\n- On success, zero\n- On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_instance_windows_handle_set(
        intr_handle: *mut rte_intr_handle,
        windows_handle: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
#[doc = "A structure describing an ID for a PCI driver. Each driver provides a\ntable of these IDs for each device that it supports."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pci_id {
    #[doc = "< Class ID or RTE_CLASS_ANY_ID."]
    pub class_id: u32,
    #[doc = "< Vendor ID or RTE_PCI_ANY_ID."]
    pub vendor_id: u16,
    #[doc = "< Device ID or RTE_PCI_ANY_ID."]
    pub device_id: u16,
    #[doc = "< Subsystem vendor ID or RTE_PCI_ANY_ID."]
    pub subsystem_vendor_id: u16,
    #[doc = "< Subsystem device ID or RTE_PCI_ANY_ID."]
    pub subsystem_device_id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pci_id"][::core::mem::size_of::<rte_pci_id>() - 12usize];
    ["Alignment of rte_pci_id"][::core::mem::align_of::<rte_pci_id>() - 4usize];
    ["Offset of field: rte_pci_id::class_id"]
        [::core::mem::offset_of!(rte_pci_id, class_id) - 0usize];
    ["Offset of field: rte_pci_id::vendor_id"]
        [::core::mem::offset_of!(rte_pci_id, vendor_id) - 4usize];
    ["Offset of field: rte_pci_id::device_id"]
        [::core::mem::offset_of!(rte_pci_id, device_id) - 6usize];
    ["Offset of field: rte_pci_id::subsystem_vendor_id"]
        [::core::mem::offset_of!(rte_pci_id, subsystem_vendor_id) - 8usize];
    ["Offset of field: rte_pci_id::subsystem_device_id"]
        [::core::mem::offset_of!(rte_pci_id, subsystem_device_id) - 10usize];
};
#[doc = "A structure describing the location of a PCI device."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pci_addr {
    #[doc = "< Device domain"]
    pub domain: u32,
    #[doc = "< Device bus"]
    pub bus: u8,
    #[doc = "< Device ID"]
    pub devid: u8,
    #[doc = "< Device function."]
    pub function: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pci_addr"][::core::mem::size_of::<rte_pci_addr>() - 8usize];
    ["Alignment of rte_pci_addr"][::core::mem::align_of::<rte_pci_addr>() - 4usize];
    ["Offset of field: rte_pci_addr::domain"]
        [::core::mem::offset_of!(rte_pci_addr, domain) - 0usize];
    ["Offset of field: rte_pci_addr::bus"][::core::mem::offset_of!(rte_pci_addr, bus) - 4usize];
    ["Offset of field: rte_pci_addr::devid"][::core::mem::offset_of!(rte_pci_addr, devid) - 5usize];
    ["Offset of field: rte_pci_addr::function"]
        [::core::mem::offset_of!(rte_pci_addr, function) - 6usize];
};
unsafe extern "C" {
    #[doc = "Utility function to write a pci device name, this device name can later be\nused to retrieve the corresponding rte_pci_addr using rte_pci_addr_parse().\n\n# Arguments\n\n* `addr` -\nThe PCI Bus-Device-Function address\n* `output` -\nThe output buffer string\n* `size` -\nThe output buffer size"]
    pub fn rte_pci_device_name(
        addr: *const rte_pci_addr,
        output: *mut ::core::ffi::c_char,
        size: usize,
    );
}
unsafe extern "C" {
    #[doc = "Utility function to compare two PCI device addresses.\n\n# Arguments\n\n* `addr` -\nThe PCI Bus-Device-Function address to compare\n* `addr2` -\nThe PCI Bus-Device-Function address to compare\n\n# Returns\n\n0 on equal PCI address.\nPositive on addr is greater than addr2.\nNegative on addr is less than addr2, or error."]
    pub fn rte_pci_addr_cmp(
        addr: *const rte_pci_addr,
        addr2: *const rte_pci_addr,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Utility function to parse a string into a PCI location.\n\n# Arguments\n\n* `str` -\nThe string to parse\n* `addr` -\nThe reference to the structure where the location\nis stored.\n\n# Returns\n\n0 on success\n<0 otherwise"]
    pub fn rte_pci_addr_parse(
        str_: *const ::core::ffi::c_char,
        addr: *mut rte_pci_addr,
    ) -> ::core::ffi::c_int;
}
#[doc = "Forward declarations"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pci_device {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pci_driver {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pci_ioport {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Map the PCI device resources in user space virtual memory address\nNote that driver should not call this function when flag\nRTE_PCI_DRV_NEED_MAPPING is set, as EAL will do that for\nyou when it's on.\n\n# Arguments\n\n* `dev` -\nA pointer to a rte_pci_device structure describing the device\nto use\n\n# Returns\n\n0 on success, negative on error and positive if no driver\nis found for the device."]
    pub fn rte_pci_map_device(dev: *mut rte_pci_device) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unmap this device\n\n# Arguments\n\n* `dev` -\nA pointer to a rte_pci_device structure describing the device\nto use"]
    pub fn rte_pci_unmap_device(dev: *mut rte_pci_device);
}
unsafe extern "C" {
    #[doc = "Dump the content of the PCI bus.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_pci_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Check whether this device has a PCI capability list.\n\n# Arguments\n\n* `dev` -\nA pointer to rte_pci_device structure.\n\n# Returns\n\ntrue/false"]
    pub fn rte_pci_has_capability_list(dev: *const rte_pci_device) -> bool;
}
unsafe extern "C" {
    #[doc = "Find device's PCI capability.\n\n# Arguments\n\n* `dev` -\nA pointer to rte_pci_device structure.\n* `cap` -\nCapability to be found, which can be any from\nRTE_PCI_CAP_ID_*, defined in librte_pci.\n\n# Returns\n\n> 0: The offset of the next matching capability structure\nwithin the device's PCI configuration space.\n< 0: An error in PCI config space read.\n= 0: Device does not support it."]
    pub fn rte_pci_find_capability(dev: *const rte_pci_device, cap: u8) -> off_t;
}
unsafe extern "C" {
    #[doc = "Find device's PCI capability starting from a previous offset in PCI\nconfiguration space.\n\n# Arguments\n\n* `dev` -\nA pointer to rte_pci_device structure.\n* `cap` -\nCapability to be found, which can be any from\nRTE_PCI_CAP_ID_*, defined in librte_pci.\n* `offset` -\nAn offset in the PCI configuration space from which the capability is\nlooked for.\n\n# Returns\n\n> 0: The offset of the next matching capability structure\nwithin the device's PCI configuration space.\n< 0: An error in PCI config space read.\n= 0: Device does not support it."]
    pub fn rte_pci_find_next_capability(
        dev: *const rte_pci_device,
        cap: u8,
        offset: off_t,
    ) -> off_t;
}
unsafe extern "C" {
    #[doc = "Find device's extended PCI capability.\n\n# Arguments\n\n* `dev` -\nA pointer to rte_pci_device structure.\n* `cap` -\nExtended capability to be found, which can be any from\nRTE_PCI_EXT_CAP_ID_*, defined in librte_pci.\n\n# Returns\n\n> 0: The offset of the next matching extended capability structure\nwithin the device's PCI configuration space.\n< 0: An error in PCI config space read.\n= 0: Device does not support it."]
    pub fn rte_pci_find_ext_capability(dev: *const rte_pci_device, cap: u32) -> off_t;
}
unsafe extern "C" {
    #[doc = "Enables/Disables Bus Master for device's PCI command register.\n\n# Arguments\n\n* `dev` -\nA pointer to rte_pci_device structure.\n* `enable` -\nEnable or disable Bus Master.\n\n# Returns\n\n0 on success, -1 on error in PCI config space read/write."]
    pub fn rte_pci_set_bus_master(dev: *const rte_pci_device, enable: bool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable/Disable PASID (Process Address Space ID).\n\n# Arguments\n\n* `dev` -\nA pointer to a rte_pci_device structure.\n* `offset` -\nOffset of the PASID external capability structure.\n* `enable` -\nFlag to enable or disable PASID.\n\n# Returns\n\n0 on success, -1 on error in PCI config space read/write."]
    pub fn rte_pci_pasid_set_state(
        dev: *const rte_pci_device,
        offset: off_t,
        enable: bool,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read PCI config space.\n\n# Arguments\n\n* `device` -\nA pointer to a rte_pci_device structure describing the device\nto use\n* `buf` -\nA data buffer where the bytes should be read into\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into PCI config space\n\n# Returns\n\nNumber of bytes read on success, negative on error."]
    pub fn rte_pci_read_config(
        device: *const rte_pci_device,
        buf: *mut ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Write PCI config space.\n\n# Arguments\n\n* `device` -\nA pointer to a rte_pci_device structure describing the device\nto use\n* `buf` -\nA data buffer containing the bytes should be written\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into PCI config space"]
    pub fn rte_pci_write_config(
        device: *const rte_pci_device,
        buf: *const ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRead from a MMIO PCI resource.\n\n# Arguments\n\n* `device` -\nA pointer to a rte_pci_device structure describing the device\nto use.\n* `bar` -\nIndex of the IO PCI resource we want to access.\n* `buf` -\nA data buffer where the bytes should be read into.\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into MMIO space described by @bar. # Returns\n\nNumber of bytes read on success, negative on error."]
    pub fn rte_pci_mmio_read(
        device: *const rte_pci_device,
        bar: ::core::ffi::c_int,
        buf: *mut ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nWrite to a MMIO PCI resource.\n\n# Arguments\n\n* `device` -\nA pointer to a rte_pci_device structure describing the device\nto use.\n* `bar` -\nIndex of the IO PCI resource we want to access.\n* `buf` -\nA data buffer containing the bytes should be written.\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into MMIO space described by @bar. # Returns\n\nNumber of bytes written on success, negative on error."]
    pub fn rte_pci_mmio_write(
        device: *const rte_pci_device,
        bar: ::core::ffi::c_int,
        buf: *const ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize a rte_pci_ioport object for a pci device io resource.\nThis object is then used to gain access to those io resources (see below).\n\n# Arguments\n\n* `dev` -\nA pointer to a rte_pci_device structure describing the device\nto use.\n* `bar` -\nIndex of the io pci resource we want to access.\n* `p` -\nThe rte_pci_ioport object to be initialized.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_pci_ioport_map(
        dev: *mut rte_pci_device,
        bar: ::core::ffi::c_int,
        p: *mut rte_pci_ioport,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Release any resources used in a rte_pci_ioport object.\n\n# Arguments\n\n* `p` -\nThe rte_pci_ioport object to be uninitialized.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_pci_ioport_unmap(p: *mut rte_pci_ioport) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read from a io pci resource.\n\n# Arguments\n\n* `p` -\nThe rte_pci_ioport object from which we want to read.\n* `data` -\nA data buffer where the bytes should be read into\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into the pci io resource."]
    pub fn rte_pci_ioport_read(
        p: *mut rte_pci_ioport,
        data: *mut ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    );
}
unsafe extern "C" {
    #[doc = "Write to a io pci resource.\n\n# Arguments\n\n* `p` -\nThe rte_pci_ioport object to which we want to write.\n* `data` -\nA data buffer where the bytes should be read into\n* `len` -\nThe length of the data buffer.\n* `offset` -\nThe offset into the pci io resource."]
    pub fn rte_pci_ioport_write(
        p: *mut rte_pci_ioport,
        data: *const ::core::ffi::c_void,
        len: usize,
        offset: off_t,
    );
}
pub type rte_vdev_scan_callback =
    ::core::option::Option<unsafe extern "C" fn(user_arg: *mut ::core::ffi::c_void)>;
unsafe extern "C" {
    #[doc = "Add a callback to be called on vdev scan\nbefore reading the devargs list.\nThis function cannot be called in a scan callback\nbecause of deadlock.\n\n# Arguments\n\n* `callback` -\nThe function to be called which can update the devargs list.\n* `user_arg` -\nAn opaque pointer passed to callback.\n\n# Returns\n\n0 on success, negative on error"]
    pub fn rte_vdev_add_custom_scan(
        callback: rte_vdev_scan_callback,
        user_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a registered scan callback.\nThis function cannot be called in a scan callback\nbecause of deadlock.\n\n# Arguments\n\n* `callback` -\nThe registered function to be removed.\n* `user_arg` -\nThe associated opaque pointer or (void*)-1 for any.\n\n# Returns\n\n0 on success"]
    pub fn rte_vdev_remove_custom_scan(
        callback: rte_vdev_scan_callback,
        user_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize a driver specified by name.\n\n# Arguments\n\n* `name` -\nThe pointer to a driver name to be initialized.\n* `args` -\nThe pointer to arguments used by driver initialization.\n\n# Returns\n\n0 on success, negative on error"]
    pub fn rte_vdev_init(
        name: *const ::core::ffi::c_char,
        args: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Uninitialize a driver specified by name.\n\n# Arguments\n\n* `name` -\nThe pointer to a driver name to be uninitialized.\n\n# Returns\n\n0 on success, negative on error"]
    pub fn rte_vdev_uninit(name: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_driver {
    _unused: [u8; 0],
}
pub mod rte_dev_event_type {
    #[doc = "The device event type."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< device being added"]
    pub const RTE_DEV_EVENT_ADD: Type = 0;
    #[doc = "< device being removed"]
    pub const RTE_DEV_EVENT_REMOVE: Type = 1;
    #[doc = "< max value of this enum"]
    pub const RTE_DEV_EVENT_MAX: Type = 2;
}
pub type rte_dev_event_cb_fn = ::core::option::Option<
    unsafe extern "C" fn(
        device_name: *const ::core::ffi::c_char,
        event: rte_dev_event_type::Type,
        cb_arg: *mut ::core::ffi::c_void,
    ),
>;
pub mod rte_dev_policy {
    #[doc = "Device policies."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_DEV_ALLOWED: Type = 0;
    pub const RTE_DEV_BLOCKED: Type = 1;
}
#[doc = "A generic memory resource representation."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mem_resource {
    #[doc = "< Physical address, 0 if not resource."]
    pub phys_addr: u64,
    #[doc = "< Length of the resource."]
    pub len: u64,
    #[doc = "< Virtual address, NULL when not mapped."]
    pub addr: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mem_resource"][::core::mem::size_of::<rte_mem_resource>() - 24usize];
    ["Alignment of rte_mem_resource"][::core::mem::align_of::<rte_mem_resource>() - 8usize];
    ["Offset of field: rte_mem_resource::phys_addr"]
        [::core::mem::offset_of!(rte_mem_resource, phys_addr) - 0usize];
    ["Offset of field: rte_mem_resource::len"]
        [::core::mem::offset_of!(rte_mem_resource, len) - 8usize];
    ["Offset of field: rte_mem_resource::addr"]
        [::core::mem::offset_of!(rte_mem_resource, addr) - 16usize];
};
impl Default for rte_mem_resource {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Retrieve a driver name.\n\n# Arguments\n\n* `driver` -\nA pointer to a driver structure.\n\n# Returns\n\nA pointer to the driver name string."]
    pub fn rte_driver_name(driver: *const rte_driver) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Retrieve a device bus.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA pointer to this device bus."]
    pub fn rte_dev_bus(dev: *const rte_device) -> *const rte_bus;
}
unsafe extern "C" {
    #[doc = "Retrieve bus specific information for a device.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA string describing this device or NULL if none is available."]
    pub fn rte_dev_bus_info(dev: *const rte_device) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Retrieve a device arguments.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA pointer to this device devargs."]
    pub fn rte_dev_devargs(dev: *const rte_device) -> *const rte_devargs;
}
unsafe extern "C" {
    #[doc = "Retrieve a device driver.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA pointer to this device driver."]
    pub fn rte_dev_driver(dev: *const rte_device) -> *const rte_driver;
}
unsafe extern "C" {
    #[doc = "Retrieve a device name.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA pointer to this device name."]
    pub fn rte_dev_name(dev: *const rte_device) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Retrieve a device numa node.\n\n# Arguments\n\n* `dev` -\nA pointer to a device structure.\n\n# Returns\n\nA pointer to this device numa node."]
    pub fn rte_dev_numa_node(dev: *const rte_device) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Query status of a device.\n\n# Arguments\n\n* `dev` -\nGeneric device pointer.\n\n# Returns\n\n(int)true if already probed successfully, 0 otherwise."]
    pub fn rte_dev_is_probed(dev: *const rte_device) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Hotplug add a given device to a specific bus.\nIn multi-process, it will request other processes to add the same device.\nA failure, in any process, will rollback the action\n\n# Arguments\n\n* `busname` -\nThe bus name the device is added to.\n* `devname` -\nThe device name. Based on this device name, eal will identify a driver\ncapable of handling it and pass it to the driver probing function.\n* `drvargs` -\nDevice arguments to be passed to the driver.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_eal_hotplug_add(
        busname: *const ::core::ffi::c_char,
        devname: *const ::core::ffi::c_char,
        drvargs: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add matching devices.\nIn multi-process, it will request other processes to add the same device.\nA failure, in any process, will rollback the action\n\n# Arguments\n\n* `devargs` -\nDevice arguments including bus, class and driver properties.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_dev_probe(devargs: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Hotplug remove a given device from a specific bus.\nIn multi-process, it will request other processes to remove the same device.\nA failure, in any process, will rollback the action\n\n# Arguments\n\n* `busname` -\nThe bus name the device is removed from.\n* `devname` -\nThe device name being removed.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_eal_hotplug_remove(
        busname: *const ::core::ffi::c_char,
        devname: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove one device.\nIn multi-process, it will request other processes to remove the same device.\nA failure, in any process, will rollback the action\n\n# Arguments\n\n* `dev` -\nData structure of the device to remove.\n\n# Returns\n\n0 on success, negative on error."]
    pub fn rte_dev_remove(dev: *mut rte_device) -> ::core::ffi::c_int;
}
#[doc = "Device comparison function.\nThis type of function is used to compare an rte_device with arbitrary\ndata.\n\n# Arguments\n\n* `dev` -\nDevice handle.\n* `data` -\nData to compare against. The type of this parameter is determined by\nthe kind of comparison performed by the function.\n\n# Returns\n\n0 if the device matches the data.\n!0 if the device does not match.\n<0 if ordering is possible and the device is lower than the data.\n>0 if ordering is possible and the device is greater than the data."]
pub type rte_dev_cmp_t = ::core::option::Option<
    unsafe extern "C" fn(
        dev: *const rte_device,
        data: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Iteration context.\nThis context carries over the current iteration state."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_iterator {
    #[doc = "< device string."]
    pub dev_str: *const ::core::ffi::c_char,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::core::ffi::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::core::ffi::c_char,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< current position."]
    pub device: *mut rte_device,
    #[doc = "< additional specialized context."]
    pub class_device: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_iterator"][::core::mem::size_of::<rte_dev_iterator>() - 56usize];
    ["Alignment of rte_dev_iterator"][::core::mem::align_of::<rte_dev_iterator>() - 8usize];
    ["Offset of field: rte_dev_iterator::dev_str"]
        [::core::mem::offset_of!(rte_dev_iterator, dev_str) - 0usize];
    ["Offset of field: rte_dev_iterator::bus_str"]
        [::core::mem::offset_of!(rte_dev_iterator, bus_str) - 8usize];
    ["Offset of field: rte_dev_iterator::cls_str"]
        [::core::mem::offset_of!(rte_dev_iterator, cls_str) - 16usize];
    ["Offset of field: rte_dev_iterator::bus"]
        [::core::mem::offset_of!(rte_dev_iterator, bus) - 24usize];
    ["Offset of field: rte_dev_iterator::cls"]
        [::core::mem::offset_of!(rte_dev_iterator, cls) - 32usize];
    ["Offset of field: rte_dev_iterator::device"]
        [::core::mem::offset_of!(rte_dev_iterator, device) - 40usize];
    ["Offset of field: rte_dev_iterator::class_device"]
        [::core::mem::offset_of!(rte_dev_iterator, class_device) - 48usize];
};
impl Default for rte_dev_iterator {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Device iteration function.\nFind the next device matching properties passed in parameters.\nThe function takes an additional ``start`` parameter, that is\nused as starting context when relevant.\nThe function returns the current element in the iteration.\nThis return value will potentially be used as a start parameter\nin subsequent calls to the function.\nThe additional iterator parameter is only there if a specific\nimplementation needs additional context. It must not be modified by\nthe iteration function itself.\n\n# Arguments\n\n* `start` -\nStarting iteration context.\n* `devstr` -\nDevice description string.\n* `it` -\nDevice iterator.\n\n# Returns\n\nThe address of the current element matching the device description\nstring."]
pub type rte_dev_iterate_t = ::core::option::Option<
    unsafe extern "C" fn(
        start: *const ::core::ffi::c_void,
        devstr: *const ::core::ffi::c_char,
        it: *const rte_dev_iterator,
    ) -> *mut ::core::ffi::c_void,
>;
unsafe extern "C" {
    #[doc = "Initializes a device iterator.\nThis iterator allows accessing a list of devices matching a criteria.\nThe device matching is made among all buses and classes currently registered,\nfiltered by the device description given as parameter.\nThis function will not allocate any memory. It is safe to stop the\niteration at any moment and let the iterator go out of context.\n\n# Arguments\n\n* `it` -\nDevice iterator handle.\n* `str` -\nDevice description string.\n\n# Returns\n\n0 on successful initialization.\n<0 on error."]
    pub fn rte_dev_iterator_init(
        it: *mut rte_dev_iterator,
        str_: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Iterates on a device iterator.\nGenerates a new rte_device handle corresponding to the next element\nin the list described in comprehension by the iterator.\nThe next object is returned, and the iterator is updated.\n\n# Arguments\n\n* `it` -\nDevice iterator handle.\n\n# Returns\n\nAn rte_device handle if found.\nNULL if an error occurred (rte_errno is set).\nNULL if no device could be found (rte_errno is not set)."]
    pub fn rte_dev_iterator_next(it: *mut rte_dev_iterator) -> *mut rte_device;
}
unsafe extern "C" {
    #[doc = "It registers the callback for the specific device.\nMultiple callbacks can be registered at the same time.\n\n# Arguments\n\n* `device_name` -\nThe device name, that is the param name of the struct rte_device,\nnull value means for all devices.\n* `cb_fn` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_dev_event_callback_register(
        device_name: *const ::core::ffi::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "It unregisters the callback according to the specified device.\n\n# Arguments\n\n* `device_name` -\nThe device name, that is the param name of the struct rte_device,\nnull value means for all devices and their callbacks.\n* `cb_fn` -\ncallback address.\n* `cb_arg` -\naddress of parameter for callback, (void *)-1 means to remove all\nregistered which has the same callback address.\n\n# Returns\n\n- On success, return the number of callback entities removed.\n- On failure, a negative value."]
    pub fn rte_dev_event_callback_unregister(
        device_name: *const ::core::ffi::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Executes all the user application registered callbacks for\nthe specific device.\n\n# Arguments\n\n* `device_name` -\nThe device name.\n* `event` -\nthe device event type."]
    pub fn rte_dev_event_callback_process(
        device_name: *const ::core::ffi::c_char,
        event: rte_dev_event_type::Type,
    );
}
unsafe extern "C" {
    #[doc = "Start the device event monitoring.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_dev_event_monitor_start() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Stop the device event monitoring.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_dev_event_monitor_stop() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable hotplug handling for devices.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_enable() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable hotplug handling for devices.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_disable() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Device level DMA map function.\nAfter a successful call, the memory segment will be mapped to the\ngiven device.\n@note: Memory must be registered in advance using rte_extmem_* APIs.\n\n# Arguments\n\n* `dev` -\nDevice pointer.\n* `addr` -\nVirtual address to map.\n* `iova` -\nIOVA address to map.\n* `len` -\nLength of the memory segment being mapped.\n\n# Returns\n\n0 if mapping was successful.\nNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_map(
        dev: *mut rte_device,
        addr: *mut ::core::ffi::c_void,
        iova: u64,
        len: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Device level DMA unmap function.\nAfter a successful call, the memory segment will no longer be\naccessible by the given device.\n@note: Memory must be registered in advance using rte_extmem_* APIs.\n\n# Arguments\n\n* `dev` -\nDevice pointer.\n* `addr` -\nVirtual address to unmap.\n* `iova` -\nIOVA address to unmap.\n* `len` -\nLength of the memory segment being mapped.\n\n# Returns\n\n0 if un-mapping was successful.\nNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_unmap(
        dev: *mut rte_device,
        addr: *mut ::core::ffi::c_void,
        iova: u64,
        len: usize,
    ) -> ::core::ffi::c_int;
}
#[doc = "Double linked list of classes"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_class_list {
    pub tqh_first: *mut rte_class,
    pub tqh_last: *mut *mut rte_class,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_class_list"][::core::mem::size_of::<rte_class_list>() - 16usize];
    ["Alignment of rte_class_list"][::core::mem::align_of::<rte_class_list>() - 8usize];
    ["Offset of field: rte_class_list::tqh_first"]
        [::core::mem::offset_of!(rte_class_list, tqh_first) - 0usize];
    ["Offset of field: rte_class_list::tqh_last"]
        [::core::mem::offset_of!(rte_class_list, tqh_last) - 8usize];
};
impl Default for rte_class_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure describing a generic device class."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_class {
    #[doc = "< Next device class in linked list"]
    pub next: rte_class__bindgen_ty_1,
    #[doc = "< Name of the class"]
    pub name: *const ::core::ffi::c_char,
    #[doc = "< Device iterator."]
    pub dev_iterate: rte_dev_iterate_t,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_class__bindgen_ty_1 {
    pub tqe_next: *mut rte_class,
    pub tqe_prev: *mut *mut rte_class,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_class__bindgen_ty_1"]
        [::core::mem::size_of::<rte_class__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_class__bindgen_ty_1"]
        [::core::mem::align_of::<rte_class__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_class__bindgen_ty_1::tqe_next"]
        [::core::mem::offset_of!(rte_class__bindgen_ty_1, tqe_next) - 0usize];
    ["Offset of field: rte_class__bindgen_ty_1::tqe_prev"]
        [::core::mem::offset_of!(rte_class__bindgen_ty_1, tqe_prev) - 8usize];
};
impl Default for rte_class__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_class"][::core::mem::size_of::<rte_class>() - 32usize];
    ["Alignment of rte_class"][::core::mem::align_of::<rte_class>() - 8usize];
    ["Offset of field: rte_class::next"][::core::mem::offset_of!(rte_class, next) - 0usize];
    ["Offset of field: rte_class::name"][::core::mem::offset_of!(rte_class, name) - 16usize];
    ["Offset of field: rte_class::dev_iterate"]
        [::core::mem::offset_of!(rte_class, dev_iterate) - 24usize];
};
impl Default for rte_class {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Class comparison function.\n\n# Arguments\n\n* `cls` -\nClass under test.\n* `data` -\nData to compare against.\n\n# Returns\n\n0 if the class matches the data.\n!0 if the class does not match.\n<0 if ordering is possible and the class is lower than the data.\n>0 if ordering is possible and the class is greater than the data."]
pub type rte_class_cmp_t = ::core::option::Option<
    unsafe extern "C" fn(
        cls: *const rte_class,
        data: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Class iterator to find a particular class.\nThis function compares each registered class to find one that matches\nthe data passed as parameter.\nIf the comparison function returns zero this function will stop iterating\nover any more classes. To continue a search the class of a previous search\ncan be passed via the start parameter.\n\n# Arguments\n\n* `start` -\nStarting point for the iteration.\n* `cmp` -\nComparison function.\n* `data` -\nData to pass to comparison function.\n\n# Returns\n\nA pointer to a rte_class structure or NULL in case no class matches"]
    pub fn rte_class_find(
        start: *const rte_class,
        cmp: rte_class_cmp_t,
        data: *const ::core::ffi::c_void,
    ) -> *mut rte_class;
}
unsafe extern "C" {
    #[doc = "Find the registered class for a given name."]
    pub fn rte_class_find_by_name(name: *const ::core::ffi::c_char) -> *mut rte_class;
}
unsafe extern "C" {
    #[doc = "Register a Class handle.\n\n# Arguments\n\n* `cls` -\nA pointer to a rte_class structure describing the class\nto be registered."]
    pub fn rte_class_register(cls: *mut rte_class);
}
unsafe extern "C" {
    #[doc = "Unregister a Class handle.\n\n# Arguments\n\n* `cls` -\nA pointer to a rte_class structure describing the class\nto be unregistered."]
    pub fn rte_class_unregister(cls: *mut rte_class);
}
pub mod rte_cman_mode {
    #[doc = "Congestion management modes"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Congestion based on Random Early Detection.\nhttps://en.wikipedia.org/wiki/Random_early_detection\nhttp://www.aciri.org/floyd/papers/red/red.html\n\n# See also\n\n> [`struct`] rte_cman_red_params"]
    pub const RTE_CMAN_RED: Type = 1;
}
#[doc = "RED based congestion management configuration parameters."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_cman_red_params {
    #[doc = "Minimum threshold (min_th) value\nValue expressed as percentage. Value must be in 0 to 100(inclusive)."]
    pub min_th: u8,
    #[doc = "Maximum threshold (max_th) value\nValue expressed as percentage. Value must be in 0 to 100(inclusive)."]
    pub max_th: u8,
    #[doc = "Inverse of packet marking probability maximum value (maxp = 1 / maxp_inv)"]
    pub maxp_inv: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_cman_red_params"][::core::mem::size_of::<rte_cman_red_params>() - 4usize];
    ["Alignment of rte_cman_red_params"][::core::mem::align_of::<rte_cman_red_params>() - 2usize];
    ["Offset of field: rte_cman_red_params::min_th"]
        [::core::mem::offset_of!(rte_cman_red_params, min_th) - 0usize];
    ["Offset of field: rte_cman_red_params::max_th"]
        [::core::mem::offset_of!(rte_cman_red_params, max_th) - 1usize];
    ["Offset of field: rte_cman_red_params::maxp_inv"]
        [::core::mem::offset_of!(rte_cman_red_params, maxp_inv) - 2usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_reg_name {
    pub name: [::core::ffi::c_char; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_reg_name"][::core::mem::size_of::<rte_eth_reg_name>() - 64usize];
    ["Alignment of rte_eth_reg_name"][::core::mem::align_of::<rte_eth_reg_name>() - 1usize];
    ["Offset of field: rte_eth_reg_name::name"]
        [::core::mem::offset_of!(rte_eth_reg_name, name) - 0usize];
};
impl Default for rte_eth_reg_name {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Placeholder for accessing device registers"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_reg_info {
    #[doc = "< Buffer for return registers"]
    pub data: *mut ::core::ffi::c_void,
    #[doc = "< Start register table location for access"]
    pub offset: u32,
    #[doc = "< Number of registers to fetch"]
    pub length: u32,
    #[doc = "< Size of device register"]
    pub width: u32,
    #[doc = "< Device version"]
    pub version: u32,
    #[doc = "Name of target module, filter for target subset of registers.\nThis field could affects register selection for data/length/names."]
    pub filter: *const ::core::ffi::c_char,
    #[doc = "< Registers name saver"]
    pub names: *mut rte_eth_reg_name,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_reg_info"][::core::mem::size_of::<rte_dev_reg_info>() - 40usize];
    ["Alignment of rte_dev_reg_info"][::core::mem::align_of::<rte_dev_reg_info>() - 8usize];
    ["Offset of field: rte_dev_reg_info::data"]
        [::core::mem::offset_of!(rte_dev_reg_info, data) - 0usize];
    ["Offset of field: rte_dev_reg_info::offset"]
        [::core::mem::offset_of!(rte_dev_reg_info, offset) - 8usize];
    ["Offset of field: rte_dev_reg_info::length"]
        [::core::mem::offset_of!(rte_dev_reg_info, length) - 12usize];
    ["Offset of field: rte_dev_reg_info::width"]
        [::core::mem::offset_of!(rte_dev_reg_info, width) - 16usize];
    ["Offset of field: rte_dev_reg_info::version"]
        [::core::mem::offset_of!(rte_dev_reg_info, version) - 20usize];
    ["Offset of field: rte_dev_reg_info::filter"]
        [::core::mem::offset_of!(rte_dev_reg_info, filter) - 24usize];
    ["Offset of field: rte_dev_reg_info::names"]
        [::core::mem::offset_of!(rte_dev_reg_info, names) - 32usize];
};
impl Default for rte_dev_reg_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Placeholder for accessing device EEPROM"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_eeprom_info {
    #[doc = "< Buffer for return EEPROM"]
    pub data: *mut ::core::ffi::c_void,
    #[doc = "< Start EEPROM address for access"]
    pub offset: u32,
    #[doc = "< Length of EEPROM region to access"]
    pub length: u32,
    #[doc = "< Device-specific key, such as device-id"]
    pub magic: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_eeprom_info"][::core::mem::size_of::<rte_dev_eeprom_info>() - 24usize];
    ["Alignment of rte_dev_eeprom_info"][::core::mem::align_of::<rte_dev_eeprom_info>() - 8usize];
    ["Offset of field: rte_dev_eeprom_info::data"]
        [::core::mem::offset_of!(rte_dev_eeprom_info, data) - 0usize];
    ["Offset of field: rte_dev_eeprom_info::offset"]
        [::core::mem::offset_of!(rte_dev_eeprom_info, offset) - 8usize];
    ["Offset of field: rte_dev_eeprom_info::length"]
        [::core::mem::offset_of!(rte_dev_eeprom_info, length) - 12usize];
    ["Offset of field: rte_dev_eeprom_info::magic"]
        [::core::mem::offset_of!(rte_dev_eeprom_info, magic) - 16usize];
};
impl Default for rte_dev_eeprom_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Placeholder for accessing plugin module EEPROM"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_dev_module_info {
    #[doc = "< Type of plugin module EEPROM"]
    pub type_: u32,
    #[doc = "< Length of plugin module EEPROM"]
    pub eeprom_len: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_module_info"][::core::mem::size_of::<rte_eth_dev_module_info>() - 8usize];
    ["Alignment of rte_eth_dev_module_info"]
        [::core::mem::align_of::<rte_eth_dev_module_info>() - 4usize];
    ["Offset of field: rte_eth_dev_module_info::type_"]
        [::core::mem::offset_of!(rte_eth_dev_module_info, type_) - 0usize];
    ["Offset of field: rte_eth_dev_module_info::eeprom_len"]
        [::core::mem::offset_of!(rte_eth_dev_module_info, eeprom_len) - 4usize];
};
pub mod rte_devtype {
    #[doc = "Type of generic device"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_DEVTYPE_ALLOWED: Type = 0;
    pub const RTE_DEVTYPE_BLOCKED: Type = 1;
    pub const RTE_DEVTYPE_VIRTUAL: Type = 2;
}
#[doc = "Structure that stores a device given by the user with its arguments\nA user device is a physical or a virtual device given by the user to\nthe DPDK application at startup through command line arguments.\nThe structure stores the configuration of the device, its PCI\nidentifier if it's a PCI device or the driver name if it's a virtual\ndevice."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_devargs {
    #[doc = "Next in list."]
    pub next: rte_devargs__bindgen_ty_1,
    #[doc = "Type of device."]
    pub type_: rte_devtype::Type,
    #[doc = "Device policy."]
    pub policy: rte_dev_policy::Type,
    #[doc = "Name of the device."]
    pub name: [::core::ffi::c_char; 64usize],
    pub anon1: rte_devargs__bindgen_ty_2,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::core::ffi::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::core::ffi::c_char,
    #[doc = "< raw string including bus, class and driver parts."]
    pub data: *mut ::core::ffi::c_char,
}
#[doc = "Next in list."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_devargs__bindgen_ty_1 {
    pub tqe_next: *mut rte_devargs,
    pub tqe_prev: *mut *mut rte_devargs,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs__bindgen_ty_1"]
        [::core::mem::size_of::<rte_devargs__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_devargs__bindgen_ty_1"]
        [::core::mem::align_of::<rte_devargs__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_devargs__bindgen_ty_1::tqe_next"]
        [::core::mem::offset_of!(rte_devargs__bindgen_ty_1, tqe_next) - 0usize];
    ["Offset of field: rte_devargs__bindgen_ty_1::tqe_prev"]
        [::core::mem::offset_of!(rte_devargs__bindgen_ty_1, tqe_prev) - 8usize];
};
impl Default for rte_devargs__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_devargs__bindgen_ty_2 {
    #[doc = "< legacy name."]
    pub args: *const ::core::ffi::c_char,
    #[doc = "< driver-related part of device string."]
    pub drv_str: *const ::core::ffi::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs__bindgen_ty_2"]
        [::core::mem::size_of::<rte_devargs__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_devargs__bindgen_ty_2"]
        [::core::mem::align_of::<rte_devargs__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_devargs__bindgen_ty_2::args"]
        [::core::mem::offset_of!(rte_devargs__bindgen_ty_2, args) - 0usize];
    ["Offset of field: rte_devargs__bindgen_ty_2::drv_str"]
        [::core::mem::offset_of!(rte_devargs__bindgen_ty_2, drv_str) - 0usize];
};
impl Default for rte_devargs__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs"][::core::mem::size_of::<rte_devargs>() - 136usize];
    ["Alignment of rte_devargs"][::core::mem::align_of::<rte_devargs>() - 8usize];
    ["Offset of field: rte_devargs::next"][::core::mem::offset_of!(rte_devargs, next) - 0usize];
    ["Offset of field: rte_devargs::type_"][::core::mem::offset_of!(rte_devargs, type_) - 16usize];
    ["Offset of field: rte_devargs::policy"]
        [::core::mem::offset_of!(rte_devargs, policy) - 20usize];
    ["Offset of field: rte_devargs::name"][::core::mem::offset_of!(rte_devargs, name) - 24usize];
    ["Offset of field: rte_devargs::bus"][::core::mem::offset_of!(rte_devargs, bus) - 96usize];
    ["Offset of field: rte_devargs::cls"][::core::mem::offset_of!(rte_devargs, cls) - 104usize];
    ["Offset of field: rte_devargs::bus_str"]
        [::core::mem::offset_of!(rte_devargs, bus_str) - 112usize];
    ["Offset of field: rte_devargs::cls_str"]
        [::core::mem::offset_of!(rte_devargs, cls_str) - 120usize];
    ["Offset of field: rte_devargs::data"][::core::mem::offset_of!(rte_devargs, data) - 128usize];
};
impl Default for rte_devargs {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Parse a device string.\nVerify that a bus is capable of handling the device passed\nin argument. Store which bus will handle the device, its name\nand the eventual device parameters.\nThe syntax is:\nbus:device_identifier,arg1=val1,arg2=val2\nwhere \"bus:\" is the bus name followed by any character separator.\nThe bus name is optional. If no bus name is specified, each bus\nwill attempt to recognize the device identifier. The first one\nto succeed will be used.\nExamples:\npci:0000:05.00.0,arg=val\n05.00.0,arg=val\nvdev:net_ring0\n\n# Arguments\n\n* `da` -\nThe devargs structure holding the device information.\n* `dev` -\nString describing a device.\n\n# Returns\n\n- 0 on success.\n- Negative errno on error."]
    pub fn rte_devargs_parse(
        da: *mut rte_devargs,
        dev: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Parse a device string.\nVerify that a bus is capable of handling the device passed\nin argument. Store which bus will handle the device, its name\nand the eventual device parameters.\nThe device string is built with a printf-like syntax.\nThe syntax is:\nbus:device_identifier,arg1=val1,arg2=val2\nwhere \"bus:\" is the bus name followed by any character separator.\nThe bus name is optional. If no bus name is specified, each bus\nwill attempt to recognize the device identifier. The first one\nto succeed will be used.\nExamples:\npci:0000:05.00.0,arg=val\n05.00.0,arg=val\nvdev:net_ring0\n\n# Arguments\n\n* `da` -\nThe devargs structure holding the device information.\n* `format` -\nFormat string describing a device.\n\n# Returns\n\n- 0 on success.\n- Negative errno on error."]
    pub fn rte_devargs_parsef(
        da: *mut rte_devargs,
        format: *const ::core::ffi::c_char,
        ...
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Free resources in devargs.\n\n# Arguments\n\n* `da` -\nThe devargs structure holding the device information."]
    pub fn rte_devargs_reset(da: *mut rte_devargs);
}
unsafe extern "C" {
    #[doc = "Insert an rte_devargs in the global list.\n\n# Arguments\n\n* `da` -\nThe devargs structure to insert.\nIf a devargs for the same device is already inserted,\nit will be updated and returned. It means *da pointer can change.\n\n# Returns\n\n- 0 on success\n- Negative on error."]
    pub fn rte_devargs_insert(da: *mut *mut rte_devargs) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a device to the user device list\nSee rte_devargs_parse() for details.\n\n# Arguments\n\n* `devtype` -\nThe type of the device.\n* `devargs_str` -\nThe arguments as given by the user.\n\n# Returns\n\n- 0 on success\n- A negative value on error"]
    pub fn rte_devargs_add(
        devtype: rte_devtype::Type,
        devargs_str: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a device from the user device list.\nIts resources are freed.\nIf the devargs cannot be found, nothing happens.\n\n# Arguments\n\n* `devargs` -\nThe instance or a copy of devargs to remove.\n\n# Returns\n\n0 on success.\n<0 on error.\n>0 if the devargs was not within the user device list."]
    pub fn rte_devargs_remove(devargs: *mut rte_devargs) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Count the number of user devices of a specified type\n\n# Arguments\n\n* `devtype` -\nThe type of the devices to counted.\n\n# Returns\n\nThe number of devices."]
    pub fn rte_devargs_type_count(devtype: rte_devtype::Type) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "This function dumps the list of user device and their arguments.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_devargs_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Find next rte_devargs matching the provided bus name.\n\n# Arguments\n\n* `busname` -\nLimit the iteration to devargs related to buses\nmatching this name.\nWill return any next rte_devargs if NULL.\n* `start` -\nStarting iteration point. The iteration will start at\nthe first rte_devargs if NULL.\n\n# Returns\n\nNext rte_devargs entry matching the requested bus,\nNULL if there is none."]
    pub fn rte_devargs_next(
        busname: *const ::core::ffi::c_char,
        start: *const rte_devargs,
    ) -> *mut rte_devargs;
}
#[doc = "DTLS Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_dtls_hdr {
    #[doc = "Content type of DTLS packet. Defined as RTE_DTLS_TYPE_*."]
    pub type_: u8,
    #[doc = "DTLS Version defined as RTE_DTLS_VERSION*."]
    pub version: rte_be16_t,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 8usize]>,
    #[doc = "The length (in bytes) of the following DTLS packet."]
    pub length: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dtls_hdr"][::core::mem::size_of::<rte_dtls_hdr>() - 13usize];
    ["Alignment of rte_dtls_hdr"][::core::mem::align_of::<rte_dtls_hdr>() - 1usize];
    ["Offset of field: rte_dtls_hdr::type_"][::core::mem::offset_of!(rte_dtls_hdr, type_) - 0usize];
    ["Offset of field: rte_dtls_hdr::version"]
        [::core::mem::offset_of!(rte_dtls_hdr, version) - 1usize];
    ["Offset of field: rte_dtls_hdr::length"]
        [::core::mem::offset_of!(rte_dtls_hdr, length) - 11usize];
};
impl rte_dtls_hdr {
    #[inline]
    pub fn sequence_number(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 48u8) as u64) }
    }
    #[inline]
    pub fn set_sequence_number(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 48u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sequence_number_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                48u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_sequence_number_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                48u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn epoch(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(48usize, 16u8) as u64) }
    }
    #[inline]
    pub fn set_epoch(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(48usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn epoch_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                48usize,
                16u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_epoch_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                48usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(sequence_number: u64, epoch: u64) -> __BindgenBitfieldUnit<[u8; 8usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 8usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 48u8, {
            let sequence_number: u64 = unsafe { ::core::mem::transmute(sequence_number) };
            sequence_number as u64
        });
        __bindgen_bitfield_unit.set(48usize, 16u8, {
            let epoch: u64 = unsafe { ::core::mem::transmute(epoch) };
            epoch as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "eCPRI Common Header"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ecpri_common_hdr {
    pub anon1: rte_ecpri_common_hdr__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ecpri_common_hdr__bindgen_ty_1 {
    #[doc = "< 4B common header in BE"]
    pub u32_: rte_be32_t,
    pub anon1: rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
};
impl rte_ecpri_common_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn size(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_size(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn size_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_size_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn type_(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_type(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn type__raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_type_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn c(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_c(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn c_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_c_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(25usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_res(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(25usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                25usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_res_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                25usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn revision(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(28usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_revision(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(28usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn revision_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                28usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_revision_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                28usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        size: u32,
        type_: u32,
        c: u32,
        res: u32,
        revision: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let size: u32 = unsafe { ::core::mem::transmute(size) };
            size as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let type_: u32 = unsafe { ::core::mem::transmute(type_) };
            type_ as u64
        });
        __bindgen_bitfield_unit.set(24usize, 1u8, {
            let c: u32 = unsafe { ::core::mem::transmute(c) };
            c as u64
        });
        __bindgen_bitfield_unit.set(25usize, 3u8, {
            let res: u32 = unsafe { ::core::mem::transmute(res) };
            res as u64
        });
        __bindgen_bitfield_unit.set(28usize, 4u8, {
            let revision: u32 = unsafe { ::core::mem::transmute(revision) };
            revision as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_common_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ecpri_common_hdr__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ecpri_common_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ecpri_common_hdr__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ecpri_common_hdr__bindgen_ty_1::u32_"]
        [::core::mem::offset_of!(rte_ecpri_common_hdr__bindgen_ty_1, u32_) - 0usize];
};
impl Default for rte_ecpri_common_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_common_hdr"][::core::mem::size_of::<rte_ecpri_common_hdr>() - 4usize];
    ["Alignment of rte_ecpri_common_hdr"][::core::mem::align_of::<rte_ecpri_common_hdr>() - 4usize];
};
impl Default for rte_ecpri_common_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "eCPRI Message Header of Type #0: IQ Data"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_iq_data {
    #[doc = "< Physical channel ID"]
    pub pc_id: rte_be16_t,
    #[doc = "< Sequence ID"]
    pub seq_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_iq_data"][::core::mem::size_of::<rte_ecpri_msg_iq_data>() - 4usize];
    ["Alignment of rte_ecpri_msg_iq_data"]
        [::core::mem::align_of::<rte_ecpri_msg_iq_data>() - 2usize];
    ["Offset of field: rte_ecpri_msg_iq_data::pc_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_iq_data, pc_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_iq_data::seq_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_iq_data, seq_id) - 2usize];
};
#[doc = "eCPRI Message Header of Type #1: Bit Sequence"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_bit_seq {
    #[doc = "< Physical channel ID"]
    pub pc_id: rte_be16_t,
    #[doc = "< Sequence ID"]
    pub seq_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_bit_seq"][::core::mem::size_of::<rte_ecpri_msg_bit_seq>() - 4usize];
    ["Alignment of rte_ecpri_msg_bit_seq"]
        [::core::mem::align_of::<rte_ecpri_msg_bit_seq>() - 2usize];
    ["Offset of field: rte_ecpri_msg_bit_seq::pc_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_bit_seq, pc_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_bit_seq::seq_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_bit_seq, seq_id) - 2usize];
};
#[doc = "eCPRI Message Header of Type #2: Real-Time Control Data"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_rtc_ctrl {
    #[doc = "< Real-Time Control Data ID"]
    pub rtc_id: rte_be16_t,
    #[doc = "< Sequence ID"]
    pub seq_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_rtc_ctrl"][::core::mem::size_of::<rte_ecpri_msg_rtc_ctrl>() - 4usize];
    ["Alignment of rte_ecpri_msg_rtc_ctrl"]
        [::core::mem::align_of::<rte_ecpri_msg_rtc_ctrl>() - 2usize];
    ["Offset of field: rte_ecpri_msg_rtc_ctrl::rtc_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_rtc_ctrl, rtc_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_rtc_ctrl::seq_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_rtc_ctrl, seq_id) - 2usize];
};
#[doc = "eCPRI Message Header of Type #3: Generic Data Transfer"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_gen_data {
    #[doc = "< Physical channel ID"]
    pub pc_id: rte_be32_t,
    #[doc = "< Sequence ID"]
    pub seq_id: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_gen_data"][::core::mem::size_of::<rte_ecpri_msg_gen_data>() - 8usize];
    ["Alignment of rte_ecpri_msg_gen_data"]
        [::core::mem::align_of::<rte_ecpri_msg_gen_data>() - 4usize];
    ["Offset of field: rte_ecpri_msg_gen_data::pc_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_gen_data, pc_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_gen_data::seq_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_gen_data, seq_id) - 4usize];
};
#[doc = "eCPRI Message Header of Type #4: Remote Memory Access"]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_rm_access {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "< 48-bits address"]
    pub addr: [u8; 6usize],
    #[doc = "< number of bytes"]
    pub length: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_rm_access"]
        [::core::mem::size_of::<rte_ecpri_msg_rm_access>() - 12usize];
    ["Alignment of rte_ecpri_msg_rm_access"]
        [::core::mem::align_of::<rte_ecpri_msg_rm_access>() - 4usize];
    ["Offset of field: rte_ecpri_msg_rm_access::addr"]
        [::core::mem::offset_of!(rte_ecpri_msg_rm_access, addr) - 4usize];
    ["Offset of field: rte_ecpri_msg_rm_access::length"]
        [::core::mem::offset_of!(rte_ecpri_msg_rm_access, length) - 10usize];
};
impl rte_ecpri_msg_rm_access {
    #[inline]
    pub fn ele_id(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_ele_id(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ele_id_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ele_id_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rr(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_rr(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rr_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rr_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rw(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(20usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_rw(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(20usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rw_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                20usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rw_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                20usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rma_id(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_rma_id(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rma_id_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rma_id_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ele_id: u32,
        rr: u32,
        rw: u32,
        rma_id: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let ele_id: u32 = unsafe { ::core::mem::transmute(ele_id) };
            ele_id as u64
        });
        __bindgen_bitfield_unit.set(16usize, 4u8, {
            let rr: u32 = unsafe { ::core::mem::transmute(rr) };
            rr as u64
        });
        __bindgen_bitfield_unit.set(20usize, 4u8, {
            let rw: u32 = unsafe { ::core::mem::transmute(rw) };
            rw as u64
        });
        __bindgen_bitfield_unit.set(24usize, 8u8, {
            let rma_id: u32 = unsafe { ::core::mem::transmute(rma_id) };
            rma_id as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "eCPRI Message Header of Type #5: One-Way Delay Measurement"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_delay_measure {
    #[doc = "< Measurement ID"]
    pub msr_id: u8,
    #[doc = "< Action Type"]
    pub act_type: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_delay_measure"]
        [::core::mem::size_of::<rte_ecpri_msg_delay_measure>() - 2usize];
    ["Alignment of rte_ecpri_msg_delay_measure"]
        [::core::mem::align_of::<rte_ecpri_msg_delay_measure>() - 1usize];
    ["Offset of field: rte_ecpri_msg_delay_measure::msr_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_delay_measure, msr_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_delay_measure::act_type"]
        [::core::mem::offset_of!(rte_ecpri_msg_delay_measure, act_type) - 1usize];
};
#[doc = "eCPRI Message Header of Type #6: Remote Reset"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_remote_reset {
    #[doc = "< Reset ID"]
    pub rst_id: rte_be16_t,
    #[doc = "< Reset Code Op"]
    pub rst_op: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_remote_reset"]
        [::core::mem::size_of::<rte_ecpri_msg_remote_reset>() - 4usize];
    ["Alignment of rte_ecpri_msg_remote_reset"]
        [::core::mem::align_of::<rte_ecpri_msg_remote_reset>() - 2usize];
    ["Offset of field: rte_ecpri_msg_remote_reset::rst_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_remote_reset, rst_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_remote_reset::rst_op"]
        [::core::mem::offset_of!(rte_ecpri_msg_remote_reset, rst_op) - 2usize];
};
#[doc = "eCPRI Message Header of Type #7: Event Indication"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ecpri_msg_event_ind {
    #[doc = "< Event ID"]
    pub evt_id: u8,
    #[doc = "< Event Type"]
    pub evt_type: u8,
    #[doc = "< Sequence Number"]
    pub seq: u8,
    #[doc = "< Number of Faults/Notif"]
    pub number: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_msg_event_ind"][::core::mem::size_of::<rte_ecpri_msg_event_ind>() - 4usize];
    ["Alignment of rte_ecpri_msg_event_ind"]
        [::core::mem::align_of::<rte_ecpri_msg_event_ind>() - 1usize];
    ["Offset of field: rte_ecpri_msg_event_ind::evt_id"]
        [::core::mem::offset_of!(rte_ecpri_msg_event_ind, evt_id) - 0usize];
    ["Offset of field: rte_ecpri_msg_event_ind::evt_type"]
        [::core::mem::offset_of!(rte_ecpri_msg_event_ind, evt_type) - 1usize];
    ["Offset of field: rte_ecpri_msg_event_ind::seq"]
        [::core::mem::offset_of!(rte_ecpri_msg_event_ind, seq) - 2usize];
    ["Offset of field: rte_ecpri_msg_event_ind::number"]
        [::core::mem::offset_of!(rte_ecpri_msg_event_ind, number) - 3usize];
};
#[doc = "eCPRI Combined Message Header Format: Common Header + Message Types"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ecpri_combined_msg_hdr {
    pub common: rte_ecpri_common_hdr,
    pub anon1: rte_ecpri_combined_msg_hdr__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ecpri_combined_msg_hdr__bindgen_ty_1 {
    pub type0: rte_ecpri_msg_iq_data,
    pub type1: rte_ecpri_msg_bit_seq,
    pub type2: rte_ecpri_msg_rtc_ctrl,
    pub type3: rte_ecpri_msg_gen_data,
    pub type4: rte_ecpri_msg_rm_access,
    pub type5: rte_ecpri_msg_delay_measure,
    pub type6: rte_ecpri_msg_remote_reset,
    pub type7: rte_ecpri_msg_event_ind,
    pub dummy: [rte_be32_t; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_combined_msg_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ecpri_combined_msg_hdr__bindgen_ty_1>() - 12usize];
    ["Alignment of rte_ecpri_combined_msg_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ecpri_combined_msg_hdr__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type0"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type0) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type1"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type1) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type2"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type2) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type3"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type3) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type4"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type4) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type5"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type5) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type6"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type6) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::type7"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, type7) - 0usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr__bindgen_ty_1::dummy"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr__bindgen_ty_1, dummy) - 0usize];
};
impl Default for rte_ecpri_combined_msg_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ecpri_combined_msg_hdr"]
        [::core::mem::size_of::<rte_ecpri_combined_msg_hdr>() - 16usize];
    ["Alignment of rte_ecpri_combined_msg_hdr"]
        [::core::mem::align_of::<rte_ecpri_combined_msg_hdr>() - 4usize];
    ["Offset of field: rte_ecpri_combined_msg_hdr::common"]
        [::core::mem::offset_of!(rte_ecpri_combined_msg_hdr, common) - 0usize];
};
impl Default for rte_ecpri_combined_msg_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Function which returns a printable string describing a particular\nerror code. For non-RTE-specific error codes, this function returns\nthe value from the libc strerror function.\n\n# Arguments\n\n* `errnum` -\nThe error number to be looked up - generally the value of rte_errno\n\n# Returns\n\nA pointer to a thread-local string containing the text describing\nthe error."]
    pub fn rte_strerror(errnum: ::core::ffi::c_int) -> *const ::core::ffi::c_char;
}
pub mod _bindgen_ty_4 {
    #[doc = "Error types"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Start numbering above std errno vals"]
    pub const RTE_MIN_ERRNO: Type = 1000;
    #[doc = "< Operation not allowed in secondary processes"]
    pub const E_RTE_SECONDARY: Type = 1001;
    #[doc = "< Missing rte_config"]
    pub const E_RTE_NO_CONFIG: Type = 1002;
    #[doc = "< Max RTE error number"]
    pub const RTE_MAX_ERRNO: Type = 1003;
}
#[doc = "ESP Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_esp_hdr {
    #[doc = "< Security Parameters Index"]
    pub spi: rte_be32_t,
    #[doc = "< packet sequence number"]
    pub seq: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_esp_hdr"][::core::mem::size_of::<rte_esp_hdr>() - 8usize];
    ["Alignment of rte_esp_hdr"][::core::mem::align_of::<rte_esp_hdr>() - 1usize];
    ["Offset of field: rte_esp_hdr::spi"][::core::mem::offset_of!(rte_esp_hdr, spi) - 0usize];
    ["Offset of field: rte_esp_hdr::seq"][::core::mem::offset_of!(rte_esp_hdr, seq) - 4usize];
};
#[doc = "ESP Trailer"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_esp_tail {
    #[doc = "< number of pad bytes (0-255)"]
    pub pad_len: u8,
    #[doc = "< IPv4 or IPv6 or next layer header"]
    pub next_proto: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_esp_tail"][::core::mem::size_of::<rte_esp_tail>() - 2usize];
    ["Alignment of rte_esp_tail"][::core::mem::align_of::<rte_esp_tail>() - 1usize];
    ["Offset of field: rte_esp_tail::pad_len"]
        [::core::mem::offset_of!(rte_esp_tail, pad_len) - 0usize];
    ["Offset of field: rte_esp_tail::next_proto"]
        [::core::mem::offset_of!(rte_esp_tail, next_proto) - 1usize];
};
#[doc = "ICMP base header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_icmp_base_hdr {
    pub type_: u8,
    pub code: u8,
    pub checksum: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_icmp_base_hdr"][::core::mem::size_of::<rte_icmp_base_hdr>() - 4usize];
    ["Alignment of rte_icmp_base_hdr"][::core::mem::align_of::<rte_icmp_base_hdr>() - 1usize];
    ["Offset of field: rte_icmp_base_hdr::type_"]
        [::core::mem::offset_of!(rte_icmp_base_hdr, type_) - 0usize];
    ["Offset of field: rte_icmp_base_hdr::code"]
        [::core::mem::offset_of!(rte_icmp_base_hdr, code) - 1usize];
    ["Offset of field: rte_icmp_base_hdr::checksum"]
        [::core::mem::offset_of!(rte_icmp_base_hdr, checksum) - 2usize];
};
#[doc = "ICMP echo header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_icmp_echo_hdr {
    pub base: rte_icmp_base_hdr,
    pub identifier: rte_be16_t,
    pub sequence: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_icmp_echo_hdr"][::core::mem::size_of::<rte_icmp_echo_hdr>() - 8usize];
    ["Alignment of rte_icmp_echo_hdr"][::core::mem::align_of::<rte_icmp_echo_hdr>() - 1usize];
    ["Offset of field: rte_icmp_echo_hdr::base"]
        [::core::mem::offset_of!(rte_icmp_echo_hdr, base) - 0usize];
    ["Offset of field: rte_icmp_echo_hdr::identifier"]
        [::core::mem::offset_of!(rte_icmp_echo_hdr, identifier) - 4usize];
    ["Offset of field: rte_icmp_echo_hdr::sequence"]
        [::core::mem::offset_of!(rte_icmp_echo_hdr, sequence) - 6usize];
};
#[doc = "ICMP Header\n\n# See also\n\n> [`rte_icmp_echo_hdr`] which is similar."]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_icmp_hdr {
    #[doc = "ICMP packet type."]
    pub icmp_type: u8,
    #[doc = "ICMP packet code."]
    pub icmp_code: u8,
    #[doc = "ICMP packet checksum."]
    pub icmp_cksum: rte_be16_t,
    #[doc = "ICMP packet identifier."]
    pub icmp_ident: rte_be16_t,
    #[doc = "ICMP packet sequence number."]
    pub icmp_seq_nb: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_icmp_hdr"][::core::mem::size_of::<rte_icmp_hdr>() - 8usize];
    ["Alignment of rte_icmp_hdr"][::core::mem::align_of::<rte_icmp_hdr>() - 1usize];
    ["Offset of field: rte_icmp_hdr::icmp_type"]
        [::core::mem::offset_of!(rte_icmp_hdr, icmp_type) - 0usize];
    ["Offset of field: rte_icmp_hdr::icmp_code"]
        [::core::mem::offset_of!(rte_icmp_hdr, icmp_code) - 1usize];
    ["Offset of field: rte_icmp_hdr::icmp_cksum"]
        [::core::mem::offset_of!(rte_icmp_hdr, icmp_cksum) - 2usize];
    ["Offset of field: rte_icmp_hdr::icmp_ident"]
        [::core::mem::offset_of!(rte_icmp_hdr, icmp_ident) - 4usize];
    ["Offset of field: rte_icmp_hdr::icmp_seq_nb"]
        [::core::mem::offset_of!(rte_icmp_hdr, icmp_seq_nb) - 6usize];
};
unsafe extern "C" {
    #[doc = "Process the non-complemented checksum of a buffer.\n\n# Arguments\n\n* `buf` -\nPointer to the buffer.\n* `len` -\nLength of the buffer.\n\n# Returns\n\nThe non-complemented checksum."]
    #[link_name = "rte_raw_cksum_w"]
    pub fn rte_raw_cksum(buf: *const ::core::ffi::c_void, len: usize) -> u16;
}
unsafe extern "C" {
    #[doc = "Compute the raw (non complemented) checksum of a packet.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `off` -\nThe offset in bytes to start the checksum.\n* `len` -\nThe length in bytes of the data to checksum.\n* `cksum` -\nA pointer to the checksum, filled on success.\n\n# Returns\n\n0 on success, -1 on error (bad length or offset)."]
    #[link_name = "rte_raw_cksum_mbuf_w"]
    pub fn rte_raw_cksum_mbuf(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        cksum: *mut u16,
    ) -> ::core::ffi::c_int;
}
#[doc = "IPv4 Header"]
#[repr(C, packed(2))]
#[derive(Copy, Clone)]
pub struct rte_ipv4_hdr {
    pub anon1: rte_ipv4_hdr__bindgen_ty_1,
    #[doc = "< type of service"]
    pub type_of_service: u8,
    #[doc = "< length of packet"]
    pub total_length: rte_be16_t,
    #[doc = "< packet ID"]
    pub packet_id: rte_be16_t,
    #[doc = "< fragmentation offset"]
    pub fragment_offset: rte_be16_t,
    #[doc = "< time to live"]
    pub time_to_live: u8,
    #[doc = "< protocol ID"]
    pub next_proto_id: u8,
    #[doc = "< header checksum"]
    pub hdr_checksum: rte_be16_t,
    #[doc = "< source address"]
    pub src_addr: rte_be32_t,
    #[doc = "< destination address"]
    pub dst_addr: rte_be32_t,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv4_hdr__bindgen_ty_1 {
    #[doc = "< version and header length"]
    pub version_ihl: u8,
    pub anon1: rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
};
impl rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn ihl(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_ihl(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ihl_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ihl_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn version(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_version(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn version_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_version_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(ihl: u8, version: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let ihl: u8 = unsafe { ::core::mem::transmute(ihl) };
            ihl as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let version: u8 = unsafe { ::core::mem::transmute(version) };
            version as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv4_hdr__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_ipv4_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv4_hdr__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_ipv4_hdr__bindgen_ty_1::version_ihl"]
        [::core::mem::offset_of!(rte_ipv4_hdr__bindgen_ty_1, version_ihl) - 0usize];
};
impl Default for rte_ipv4_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr"][::core::mem::size_of::<rte_ipv4_hdr>() - 20usize];
    ["Alignment of rte_ipv4_hdr"][::core::mem::align_of::<rte_ipv4_hdr>() - 2usize];
    ["Offset of field: rte_ipv4_hdr::type_of_service"]
        [::core::mem::offset_of!(rte_ipv4_hdr, type_of_service) - 1usize];
    ["Offset of field: rte_ipv4_hdr::total_length"]
        [::core::mem::offset_of!(rte_ipv4_hdr, total_length) - 2usize];
    ["Offset of field: rte_ipv4_hdr::packet_id"]
        [::core::mem::offset_of!(rte_ipv4_hdr, packet_id) - 4usize];
    ["Offset of field: rte_ipv4_hdr::fragment_offset"]
        [::core::mem::offset_of!(rte_ipv4_hdr, fragment_offset) - 6usize];
    ["Offset of field: rte_ipv4_hdr::time_to_live"]
        [::core::mem::offset_of!(rte_ipv4_hdr, time_to_live) - 8usize];
    ["Offset of field: rte_ipv4_hdr::next_proto_id"]
        [::core::mem::offset_of!(rte_ipv4_hdr, next_proto_id) - 9usize];
    ["Offset of field: rte_ipv4_hdr::hdr_checksum"]
        [::core::mem::offset_of!(rte_ipv4_hdr, hdr_checksum) - 10usize];
    ["Offset of field: rte_ipv4_hdr::src_addr"]
        [::core::mem::offset_of!(rte_ipv4_hdr, src_addr) - 12usize];
    ["Offset of field: rte_ipv4_hdr::dst_addr"]
        [::core::mem::offset_of!(rte_ipv4_hdr, dst_addr) - 16usize];
};
impl Default for rte_ipv4_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Get the length of an IPv4 header.\n\n# Arguments\n\n* `ipv4_hdr` -\nPointer to the IPv4 header.\n\n# Returns\n\nThe length of the IPv4 header (with options if present) in bytes."]
    #[link_name = "rte_ipv4_hdr_len_w"]
    pub fn rte_ipv4_hdr_len(ipv4_hdr: *const rte_ipv4_hdr) -> u8;
}
unsafe extern "C" {
    #[doc = "Process the IPv4 checksum of an IPv4 header.\nThe checksum field must be set to 0 by the caller.\n\n# Arguments\n\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n\n# Returns\n\nThe complemented checksum to set in the IP packet."]
    #[link_name = "rte_ipv4_cksum_w"]
    pub fn rte_ipv4_cksum(ipv4_hdr: *const rte_ipv4_hdr) -> u16;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nProcess the IPv4 checksum of an IPv4 header without any extensions.\nThe checksum field does NOT have to be set by the caller, the field\nis skipped by the calculation.\n\n# Arguments\n\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n\n# Returns\n\nThe complemented checksum to set in the IP packet."]
    #[link_name = "rte_ipv4_cksum_simple_w"]
    pub fn rte_ipv4_cksum_simple(ipv4_hdr: *const rte_ipv4_hdr) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the pseudo-header checksum of an IPv4 header.\nThe checksum field must be set to 0 by the caller.\nDepending on the ol_flags, the pseudo-header checksum expected by the\ndrivers is not the same. For instance, when TSO is enabled, the IP\npayload length must not be included in the packet.\nWhen ol_flags is 0, it computes the standard pseudo-header checksum.\n\n# Arguments\n\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n* `ol_flags` -\nThe ol_flags of the associated mbuf.\n\n# Returns\n\nThe non-complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv4_phdr_cksum_w"]
    pub fn rte_ipv4_phdr_cksum(ipv4_hdr: *const rte_ipv4_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv4 UDP or TCP checksum.\nThe layer 4 checksum must be set to 0 in the L4 header by the caller.\n\n# Arguments\n\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n* `l4_hdr` -\nThe pointer to the beginning of the L4 header.\n\n# Returns\n\nThe complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv4_udptcp_cksum_w"]
    pub fn rte_ipv4_udptcp_cksum(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Compute the IPv4 UDP/TCP checksum of a packet.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n* `l4_off` -\nThe offset in bytes to start L4 checksum.\n\n# Returns\n\nThe complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv4_udptcp_cksum_mbuf_w"]
    pub fn rte_ipv4_udptcp_cksum_mbuf(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Validate the IPv4 UDP or TCP checksum.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0\n(i.e. no checksum).\n\n# Arguments\n\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n* `l4_hdr` -\nThe pointer to the beginning of the L4 header.\n\n# Returns\n\nReturn 0 if the checksum is correct, else -1."]
    #[link_name = "rte_ipv4_udptcp_cksum_verify_w"]
    pub fn rte_ipv4_udptcp_cksum_verify(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Verify the IPv4 UDP/TCP checksum of a packet.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0\n(i.e. no checksum).\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `ipv4_hdr` -\nThe pointer to the contiguous IPv4 header.\n* `l4_off` -\nThe offset in bytes to start L4 checksum.\n\n# Returns\n\nReturn 0 if the checksum is correct, else -1."]
    #[link_name = "rte_ipv4_udptcp_cksum_mbuf_verify_w"]
    pub fn rte_ipv4_udptcp_cksum_mbuf_verify(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> ::core::ffi::c_int;
}
#[doc = "IPv6 Address"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv6_addr {
    pub a: [u8; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_addr"][::core::mem::size_of::<rte_ipv6_addr>() - 16usize];
    ["Alignment of rte_ipv6_addr"][::core::mem::align_of::<rte_ipv6_addr>() - 1usize];
    ["Offset of field: rte_ipv6_addr::a"][::core::mem::offset_of!(rte_ipv6_addr, a) - 0usize];
};
unsafe extern "C" {
    #[doc = "Check if two IPv6 Addresses are equal.\n\n# Arguments\n\n* `a` -\nThe first address.\n* `b` -\nThe second address.\n\n# Returns\n\ntrue if both addresses are identical."]
    #[link_name = "rte_ipv6_addr_eq_w"]
    pub fn rte_ipv6_addr_eq(a: *const rte_ipv6_addr, b: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Mask an IPv6 address using the specified depth.\nLeave untouched one bit per unit in the depth variable and set the rest to 0.\n\n# Arguments\n\n* `ip` [in]  -\nThe address to mask.\n* `depth` [out]  -\nAll bits starting from this bit number will be set to zero."]
    #[link_name = "rte_ipv6_addr_mask_w"]
    pub fn rte_ipv6_addr_mask(ip: *mut rte_ipv6_addr, depth: u8);
}
unsafe extern "C" {
    #[doc = "Check if two IPv6 addresses belong to the same network prefix.\n\n# Arguments\n\n* `a` -\nThe first address or network.\n* `b` -\nThe second address or network.\n* `depth` -\nThe network prefix length.\n\n# Returns\n\n`true` if the first `depth` bits of both addresses are identical."]
    #[link_name = "rte_ipv6_addr_eq_prefix_w"]
    pub fn rte_ipv6_addr_eq_prefix(
        a: *const rte_ipv6_addr,
        b: *const rte_ipv6_addr,
        depth: u8,
    ) -> bool;
}
unsafe extern "C" {
    #[doc = "Get the depth of a given IPv6 address mask.\n\n# Arguments\n\n* `mask` -\nThe address mask.\n\n# Returns\n\nThe number of consecutive bits set to 1 starting from the beginning of the mask."]
    #[link_name = "rte_ipv6_mask_depth_w"]
    pub fn rte_ipv6_mask_depth(mask: *const rte_ipv6_addr) -> u8;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is unspecified as defined in RFC 4291, section 2.5.2.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is the unspecified address (all zeroes)."]
    #[link_name = "rte_ipv6_addr_is_unspec_w"]
    pub fn rte_ipv6_addr_is_unspec(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is the loopback address as defined in RFC 4291,\nsection 2.5.3.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is the loopback address (all zeroes except the last bit)."]
    #[link_name = "rte_ipv6_addr_is_loopback_w"]
    pub fn rte_ipv6_addr_is_loopback(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is link-local as defined in RFC 4291, section 2.5.6.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is a link-local address."]
    #[link_name = "rte_ipv6_addr_is_linklocal_w"]
    pub fn rte_ipv6_addr_is_linklocal(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is site-local as defined in RFC 4291, section 2.5.7.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is a site-local address."]
    #[link_name = "rte_ipv6_addr_is_sitelocal_w"]
    pub fn rte_ipv6_addr_is_sitelocal(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is an IPv4-compatible address as defined in RFC 4291,\nsection 2.5.5.1.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is an IPv4-compatible address."]
    #[link_name = "rte_ipv6_addr_is_v4compat_w"]
    pub fn rte_ipv6_addr_is_v4compat(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is an IPv4-mapped address as defined in RFC 4291,\nsection 2.5.5.2.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is an IPv4-mapped address."]
    #[link_name = "rte_ipv6_addr_is_v4mapped_w"]
    pub fn rte_ipv6_addr_is_v4mapped(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    #[doc = "Check if an IPv6 address is multicast as defined in RFC 4291, section 2.7.\n\n# Arguments\n\n* `ip` -\nThe address to check.\n\n# Returns\n\n`true` if the address is multicast."]
    #[link_name = "rte_ipv6_addr_is_mcast_w"]
    pub fn rte_ipv6_addr_is_mcast(ip: *const rte_ipv6_addr) -> bool;
}
pub mod rte_ipv6_mc_scope {
    #[doc = "IPv6 multicast scope values as defined in RFC 4291, section 2.7."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Invalid multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_NONE: Type = 0;
    #[doc = "Interface-local multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_IFACELOCAL: Type = 1;
    #[doc = "Link-local multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_LINKLOCAL: Type = 2;
    #[doc = "Site-local multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_SITELOCAL: Type = 5;
    #[doc = "Organizational-local multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_ORGLOCAL: Type = 8;
    #[doc = "Global multicast scope."]
    pub const RTE_IPV6_MC_SCOPE_GLOBAL: Type = 14;
}
unsafe extern "C" {
    #[doc = "Extract the IPv6 multicast scope value as defined in RFC 4291, section 2.7.\n\n# Arguments\n\n* `ip` -\nThe address from which to get the multicast scope.\n\n# Returns\n\nThe multicast scope of the address, or #RTE_IPV6_MC_SCOPE_NONE if the\naddress is not multicast."]
    #[link_name = "rte_ipv6_mc_scope_w"]
    pub fn rte_ipv6_mc_scope(ip: *const rte_ipv6_addr) -> rte_ipv6_mc_scope::Type;
}
unsafe extern "C" {
    #[doc = "Generate a link-local IPv6 address from an Ethernet address as specified in\nRFC 2464, section 5.\n\n# Arguments\n\n* `ip` [out]  -\nThe link-local IPv6 address to generate.\n* `mac` [in]  -\nAn Ethernet address."]
    #[link_name = "rte_ipv6_llocal_from_ethernet_w"]
    pub fn rte_ipv6_llocal_from_ethernet(ip: *mut rte_ipv6_addr, mac: *const rte_ether_addr);
}
unsafe extern "C" {
    #[doc = "Convert a unicast or anycast IPv6 address to a solicited-node multicast\naddress as defined in RFC 4291, section 2.7.1.\n\n# Arguments\n\n* `sol` [out]  -\nThe IPv6 solicited-node multicast address to generate.\n* `ip` [in]  -\nA unicast or anycast address."]
    #[link_name = "rte_ipv6_solnode_from_addr_w"]
    pub fn rte_ipv6_solnode_from_addr(sol: *mut rte_ipv6_addr, ip: *const rte_ipv6_addr);
}
unsafe extern "C" {
    #[doc = "Generate a multicast Ethernet address from a multicast IPv6 address as defined\nin RFC 2464, section 7.\n\n# Arguments\n\n* `mac` [out]  -\nThe multicast Ethernet address to generate.\n* `ip` [in]  -\nA multicast IPv6 address."]
    #[link_name = "rte_ether_mcast_from_ipv6_w"]
    pub fn rte_ether_mcast_from_ipv6(mac: *mut rte_ether_addr, ip: *const rte_ipv6_addr);
}
#[doc = "IPv6 Header"]
#[repr(C, packed(2))]
#[derive(Copy, Clone)]
pub struct rte_ipv6_hdr {
    pub anon1: rte_ipv6_hdr__bindgen_ty_1,
    #[doc = "< IP payload size, including ext. headers"]
    pub payload_len: rte_be16_t,
    #[doc = "< Protocol, next header."]
    pub proto: u8,
    #[doc = "< Hop limits."]
    pub hop_limits: u8,
    #[doc = "< IP address of source host."]
    pub src_addr: rte_ipv6_addr,
    #[doc = "< IP address of destination host(s)."]
    pub dst_addr: rte_ipv6_addr,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv6_hdr__bindgen_ty_1 {
    #[doc = "< IP version, traffic class & flow label."]
    pub vtc_flow: rte_be32_t,
    pub anon1: rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
};
impl rte_ipv6_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn flow_label(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 20u8) as u32) }
    }
    #[inline]
    pub fn set_flow_label(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 20u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flow_label_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                20u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_flow_label_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                20u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ecn(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(20usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_ecn(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(20usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ecn_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                20usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ecn_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                20usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ds(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(22usize, 6u8) as u32) }
    }
    #[inline]
    pub fn set_ds(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(22usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ds_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                22usize,
                6u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ds_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                22usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn version(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(28usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_version(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(28usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn version_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                28usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_version_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                28usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        flow_label: u32,
        ecn: u32,
        ds: u32,
        version: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 20u8, {
            let flow_label: u32 = unsafe { ::core::mem::transmute(flow_label) };
            flow_label as u64
        });
        __bindgen_bitfield_unit.set(20usize, 2u8, {
            let ecn: u32 = unsafe { ::core::mem::transmute(ecn) };
            ecn as u64
        });
        __bindgen_bitfield_unit.set(22usize, 6u8, {
            let ds: u32 = unsafe { ::core::mem::transmute(ds) };
            ds as u64
        });
        __bindgen_bitfield_unit.set(28usize, 4u8, {
            let version: u32 = unsafe { ::core::mem::transmute(version) };
            version as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_hdr__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_hdr__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ipv6_hdr__bindgen_ty_1::vtc_flow"]
        [::core::mem::offset_of!(rte_ipv6_hdr__bindgen_ty_1, vtc_flow) - 0usize];
};
impl Default for rte_ipv6_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_hdr"][::core::mem::size_of::<rte_ipv6_hdr>() - 40usize];
    ["Alignment of rte_ipv6_hdr"][::core::mem::align_of::<rte_ipv6_hdr>() - 2usize];
    ["Offset of field: rte_ipv6_hdr::payload_len"]
        [::core::mem::offset_of!(rte_ipv6_hdr, payload_len) - 4usize];
    ["Offset of field: rte_ipv6_hdr::proto"][::core::mem::offset_of!(rte_ipv6_hdr, proto) - 6usize];
    ["Offset of field: rte_ipv6_hdr::hop_limits"]
        [::core::mem::offset_of!(rte_ipv6_hdr, hop_limits) - 7usize];
    ["Offset of field: rte_ipv6_hdr::src_addr"]
        [::core::mem::offset_of!(rte_ipv6_hdr, src_addr) - 8usize];
    ["Offset of field: rte_ipv6_hdr::dst_addr"]
        [::core::mem::offset_of!(rte_ipv6_hdr, dst_addr) - 24usize];
};
impl Default for rte_ipv6_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Check that the IPv6 header version field is valid according to RFC 8200 section 3.\n\n# Arguments\n\n* `ip` -\nThe IPv6 header.\n\n# Returns\n\n`0` if the version field is valid. `-EINVAL` otherwise."]
    #[link_name = "rte_ipv6_check_version_w"]
    pub fn rte_ipv6_check_version(ip: *const rte_ipv6_hdr) -> ::core::ffi::c_int;
}
#[doc = "IPv6 Routing Extension Header"]
#[repr(C, packed(2))]
#[derive(Copy, Clone)]
pub struct rte_ipv6_routing_ext {
    #[doc = "< Protocol, next header."]
    pub next_hdr: u8,
    #[doc = "< Header length."]
    pub hdr_len: u8,
    #[doc = "< Extension header type."]
    pub type_: u8,
    #[doc = "< Valid segments number."]
    pub segments_left: u8,
    pub anon1: rte_ipv6_routing_ext__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv6_routing_ext__bindgen_ty_1 {
    #[doc = "< Packet control data per type."]
    pub flags: rte_be32_t,
    pub anon1: rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< The last_entry field of SRH"]
    pub last_entry: u8,
    #[doc = "< Packet flag."]
    pub flag: u8,
    #[doc = "< Packet tag."]
    pub tag: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1::last_entry"][::core::mem::offset_of!(
        rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1,
        last_entry
    ) - 0usize];
    ["Offset of field: rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1::flag"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1, flag) - 1usize];
    ["Offset of field: rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1::tag"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext__bindgen_ty_1__bindgen_ty_1, tag) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_routing_ext__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_routing_ext__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_routing_ext__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_routing_ext__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ipv6_routing_ext__bindgen_ty_1::flags"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext__bindgen_ty_1, flags) - 0usize];
};
impl Default for rte_ipv6_routing_ext__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_routing_ext"][::core::mem::size_of::<rte_ipv6_routing_ext>() - 8usize];
    ["Alignment of rte_ipv6_routing_ext"][::core::mem::align_of::<rte_ipv6_routing_ext>() - 2usize];
    ["Offset of field: rte_ipv6_routing_ext::next_hdr"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext, next_hdr) - 0usize];
    ["Offset of field: rte_ipv6_routing_ext::hdr_len"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext, hdr_len) - 1usize];
    ["Offset of field: rte_ipv6_routing_ext::type_"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext, type_) - 2usize];
    ["Offset of field: rte_ipv6_routing_ext::segments_left"]
        [::core::mem::offset_of!(rte_ipv6_routing_ext, segments_left) - 3usize];
};
impl Default for rte_ipv6_routing_ext {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Process the pseudo-header checksum of an IPv6 header.\nDepending on the ol_flags, the pseudo-header checksum expected by the\ndrivers is not the same. For instance, when TSO is enabled, the IPv6\npayload length must not be included in the packet.\nWhen ol_flags is 0, it computes the standard pseudo-header checksum.\n\n# Arguments\n\n* `ipv6_hdr` -\nThe pointer to the contiguous IPv6 header.\n* `ol_flags` -\nThe ol_flags of the associated mbuf.\n\n# Returns\n\nThe non-complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv6_phdr_cksum_w"]
    pub fn rte_ipv6_phdr_cksum(ipv6_hdr: *const rte_ipv6_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv6 UDP or TCP checksum.\nThe IPv6 header must not be followed by extension headers. The layer 4\nchecksum must be set to 0 in the L4 header by the caller.\n\n# Arguments\n\n* `ipv6_hdr` -\nThe pointer to the contiguous IPv6 header.\n* `l4_hdr` -\nThe pointer to the beginning of the L4 header.\n\n# Returns\n\nThe complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv6_udptcp_cksum_w"]
    pub fn rte_ipv6_udptcp_cksum(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv6 UDP or TCP checksum of a packet.\nThe IPv6 header must not be followed by extension headers. The layer 4\nchecksum must be set to 0 in the L4 header by the caller.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `ipv6_hdr` -\nThe pointer to the contiguous IPv6 header.\n* `l4_off` -\nThe offset in bytes to start L4 checksum.\n\n# Returns\n\nThe complemented checksum to set in the L4 header."]
    #[link_name = "rte_ipv6_udptcp_cksum_mbuf_w"]
    pub fn rte_ipv6_udptcp_cksum_mbuf(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Validate the IPv6 UDP or TCP checksum.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0:\nthis is either invalid or means no checksum in some situations. See 8.1\n(Upper-Layer Checksums) in RFC 8200.\n\n# Arguments\n\n* `ipv6_hdr` -\nThe pointer to the contiguous IPv6 header.\n* `l4_hdr` -\nThe pointer to the beginning of the L4 header.\n\n# Returns\n\nReturn 0 if the checksum is correct, else -1."]
    #[link_name = "rte_ipv6_udptcp_cksum_verify_w"]
    pub fn rte_ipv6_udptcp_cksum_verify(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Validate the IPv6 UDP or TCP checksum of a packet.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0:\nthis is either invalid or means no checksum in some situations. See 8.1\n(Upper-Layer Checksums) in RFC 8200.\n\n# Arguments\n\n* `m` -\nThe pointer to the mbuf.\n* `ipv6_hdr` -\nThe pointer to the contiguous IPv6 header.\n* `l4_off` -\nThe offset in bytes to start L4 checksum.\n\n# Returns\n\nReturn 0 if the checksum is correct, else -1."]
    #[link_name = "rte_ipv6_udptcp_cksum_mbuf_verify_w"]
    pub fn rte_ipv6_udptcp_cksum_mbuf_verify(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> ::core::ffi::c_int;
}
#[repr(C, packed(2))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv6_fragment_ext {
    #[doc = "< Next header type"]
    pub next_header: u8,
    #[doc = "< Reserved"]
    pub reserved: u8,
    #[doc = "< All fragmentation data"]
    pub frag_data: rte_be16_t,
    #[doc = "< Packet ID"]
    pub id: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_fragment_ext"][::core::mem::size_of::<rte_ipv6_fragment_ext>() - 8usize];
    ["Alignment of rte_ipv6_fragment_ext"]
        [::core::mem::align_of::<rte_ipv6_fragment_ext>() - 2usize];
    ["Offset of field: rte_ipv6_fragment_ext::next_header"]
        [::core::mem::offset_of!(rte_ipv6_fragment_ext, next_header) - 0usize];
    ["Offset of field: rte_ipv6_fragment_ext::reserved"]
        [::core::mem::offset_of!(rte_ipv6_fragment_ext, reserved) - 1usize];
    ["Offset of field: rte_ipv6_fragment_ext::frag_data"]
        [::core::mem::offset_of!(rte_ipv6_fragment_ext, frag_data) - 2usize];
    ["Offset of field: rte_ipv6_fragment_ext::id"]
        [::core::mem::offset_of!(rte_ipv6_fragment_ext, id) - 4usize];
};
unsafe extern "C" {
    #[doc = "Parse next IPv6 header extension\nThis function checks if proto number is an IPv6 extensions and parses its\ndata if so, providing information on next header and extension length.\n\n# Arguments\n\n* `p` -\nPointer to an extension raw data.\n* `proto` -\nProtocol number extracted from the \"next header\" field from\nthe IPv6 header or the previous extension.\n* `ext_len` -\nExtension data length.\n\n# Returns\n\nnext protocol number if proto is an IPv6 extension, -EINVAL otherwise"]
    #[link_name = "rte_ipv6_get_next_ext_w"]
    pub fn rte_ipv6_get_next_ext(
        p: *const u8,
        proto: ::core::ffi::c_int,
        ext_len: *mut usize,
    ) -> ::core::ffi::c_int;
}
#[doc = "SCTP Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_sctp_hdr {
    #[doc = "< Source port."]
    pub src_port: rte_be16_t,
    #[doc = "< Destin port."]
    pub dst_port: rte_be16_t,
    #[doc = "< Validation tag."]
    pub tag: rte_be32_t,
    #[doc = "< Checksum."]
    pub cksum: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_sctp_hdr"][::core::mem::size_of::<rte_sctp_hdr>() - 12usize];
    ["Alignment of rte_sctp_hdr"][::core::mem::align_of::<rte_sctp_hdr>() - 1usize];
    ["Offset of field: rte_sctp_hdr::src_port"]
        [::core::mem::offset_of!(rte_sctp_hdr, src_port) - 0usize];
    ["Offset of field: rte_sctp_hdr::dst_port"]
        [::core::mem::offset_of!(rte_sctp_hdr, dst_port) - 2usize];
    ["Offset of field: rte_sctp_hdr::tag"][::core::mem::offset_of!(rte_sctp_hdr, tag) - 4usize];
    ["Offset of field: rte_sctp_hdr::cksum"][::core::mem::offset_of!(rte_sctp_hdr, cksum) - 8usize];
};
#[doc = "TCP Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tcp_hdr {
    #[doc = "< TCP source port."]
    pub src_port: rte_be16_t,
    #[doc = "< TCP destination port."]
    pub dst_port: rte_be16_t,
    #[doc = "< TX data sequence number."]
    pub sent_seq: rte_be32_t,
    #[doc = "< RX data acknowledgment sequence number."]
    pub recv_ack: rte_be32_t,
    #[doc = "< Data offset."]
    pub data_off: u8,
    #[doc = "< TCP flags"]
    pub tcp_flags: u8,
    #[doc = "< RX flow control window."]
    pub rx_win: rte_be16_t,
    #[doc = "< TCP checksum."]
    pub cksum: rte_be16_t,
    #[doc = "< TCP urgent pointer, if any."]
    pub tcp_urp: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tcp_hdr"][::core::mem::size_of::<rte_tcp_hdr>() - 20usize];
    ["Alignment of rte_tcp_hdr"][::core::mem::align_of::<rte_tcp_hdr>() - 1usize];
    ["Offset of field: rte_tcp_hdr::src_port"]
        [::core::mem::offset_of!(rte_tcp_hdr, src_port) - 0usize];
    ["Offset of field: rte_tcp_hdr::dst_port"]
        [::core::mem::offset_of!(rte_tcp_hdr, dst_port) - 2usize];
    ["Offset of field: rte_tcp_hdr::sent_seq"]
        [::core::mem::offset_of!(rte_tcp_hdr, sent_seq) - 4usize];
    ["Offset of field: rte_tcp_hdr::recv_ack"]
        [::core::mem::offset_of!(rte_tcp_hdr, recv_ack) - 8usize];
    ["Offset of field: rte_tcp_hdr::data_off"]
        [::core::mem::offset_of!(rte_tcp_hdr, data_off) - 12usize];
    ["Offset of field: rte_tcp_hdr::tcp_flags"]
        [::core::mem::offset_of!(rte_tcp_hdr, tcp_flags) - 13usize];
    ["Offset of field: rte_tcp_hdr::rx_win"]
        [::core::mem::offset_of!(rte_tcp_hdr, rx_win) - 14usize];
    ["Offset of field: rte_tcp_hdr::cksum"][::core::mem::offset_of!(rte_tcp_hdr, cksum) - 16usize];
    ["Offset of field: rte_tcp_hdr::tcp_urp"]
        [::core::mem::offset_of!(rte_tcp_hdr, tcp_urp) - 18usize];
};
#[doc = "UDP Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_udp_hdr {
    #[doc = "< UDP source port."]
    pub src_port: rte_be16_t,
    #[doc = "< UDP destination port."]
    pub dst_port: rte_be16_t,
    #[doc = "< UDP datagram length"]
    pub dgram_len: rte_be16_t,
    #[doc = "< UDP datagram checksum"]
    pub dgram_cksum: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_udp_hdr"][::core::mem::size_of::<rte_udp_hdr>() - 8usize];
    ["Alignment of rte_udp_hdr"][::core::mem::align_of::<rte_udp_hdr>() - 1usize];
    ["Offset of field: rte_udp_hdr::src_port"]
        [::core::mem::offset_of!(rte_udp_hdr, src_port) - 0usize];
    ["Offset of field: rte_udp_hdr::dst_port"]
        [::core::mem::offset_of!(rte_udp_hdr, dst_port) - 2usize];
    ["Offset of field: rte_udp_hdr::dgram_len"]
        [::core::mem::offset_of!(rte_udp_hdr, dgram_len) - 4usize];
    ["Offset of field: rte_udp_hdr::dgram_cksum"]
        [::core::mem::offset_of!(rte_udp_hdr, dgram_cksum) - 6usize];
};
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_vxlan_hdr {
    pub anon1: rte_vxlan_hdr__bindgen_ty_1,
    pub anon2: rte_vxlan_hdr__bindgen_ty_2,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_1 {
    #[doc = "< flags (8 bits) + extensions (24 bits)."]
    pub vx_flags: rte_be32_t,
    pub anon1: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub anon1: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    pub anon2: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Default is I bit, others are extensions."]
    pub flags: u8,
    pub anon1: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 1usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<
            rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 1usize];
};
impl rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn flag_o(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_o(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_o_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_o_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_b(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_b(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_b_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_b_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_p(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_p(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_p_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_p_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_i(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_i(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_i_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_i_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_ver(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_flag_ver(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_ver_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_ver_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_rsvd(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_rsvd(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_rsvd_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_rsvd_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_g(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_g(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_g_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_g_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        flag_o: u8,
        flag_b: u8,
        flag_p: u8,
        flag_i: u8,
        flag_ver: u8,
        flag_rsvd: u8,
        flag_g: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let flag_o: u8 = unsafe { ::core::mem::transmute(flag_o) };
            flag_o as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let flag_b: u8 = unsafe { ::core::mem::transmute(flag_b) };
            flag_b as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let flag_p: u8 = unsafe { ::core::mem::transmute(flag_p) };
            flag_p as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let flag_i: u8 = unsafe { ::core::mem::transmute(flag_i) };
            flag_i as u64
        });
        __bindgen_bitfield_unit.set(4usize, 2u8, {
            let flag_ver: u8 = unsafe { ::core::mem::transmute(flag_ver) };
            flag_ver as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let flag_rsvd: u8 = unsafe { ::core::mem::transmute(flag_rsvd) };
            flag_rsvd as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let flag_g: u8 = unsafe { ::core::mem::transmute(flag_g) };
            flag_g as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"][::core::mem::size_of::<
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 1usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"][::core::mem::align_of::<
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 1usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::flags"][::core::mem::offset_of!(
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        flags
    ) - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "Reserved for extensions."]
    pub rsvd0: [u8; 3usize],
    pub anon1: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub anon1: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 { # [doc = "< GBP Identifier."] pub policy_id : u16 , pub anon1 : rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , }
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    #[doc = "Reserved."]
    pub rsvd0_gpe: u8,
    #[doc = "< GPE Next protocol."]
    pub proto: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: size_of :: < rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 2usize] ;
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: align_of :: < rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::rsvd0_gpe"] [:: core :: mem :: offset_of ! (rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , rsvd0_gpe) - 0usize] ;
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::proto"] [:: core :: mem :: offset_of ! (rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , proto) - 1usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        >() - 2usize];
    [
        "Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1",
    ][::core::mem::align_of::<
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    >() - 2usize];
    [
        "Offset of field: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::policy_id",
    ][::core::mem::offset_of!(
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        policy_id
    ) - 0usize];
};
impl Default
    for rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1
{
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        >() - 3usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::align_of::<
            rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        >() - 1usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    #[inline]
    pub fn rsvd0_gbp3(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 3u8) as u8) }
    }
    #[inline]
    pub fn set_rsvd0_gbp3(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rsvd0_gbp3_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                3u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rsvd0_gbp3_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_a(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_a(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_a_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_a_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rsvd0_gbp2(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_rsvd0_gbp2(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rsvd0_gbp2_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rsvd0_gbp2_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn flag_d(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_flag_d(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn flag_d_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_flag_d_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rsvd0_gbp1(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_rsvd0_gbp1(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rsvd0_gbp1_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rsvd0_gbp1_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        rsvd0_gbp3: u8,
        flag_a: u8,
        rsvd0_gbp2: u8,
        flag_d: u8,
        rsvd0_gbp1: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 3u8, {
            let rsvd0_gbp3: u8 = unsafe { ::core::mem::transmute(rsvd0_gbp3) };
            rsvd0_gbp3 as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let flag_a: u8 = unsafe { ::core::mem::transmute(flag_a) };
            flag_a as u64
        });
        __bindgen_bitfield_unit.set(4usize, 2u8, {
            let rsvd0_gbp2: u8 = unsafe { ::core::mem::transmute(rsvd0_gbp2) };
            rsvd0_gbp2 as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let flag_d: u8 = unsafe { ::core::mem::transmute(flag_d) };
            flag_d as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let rsvd0_gbp1: u8 = unsafe { ::core::mem::transmute(rsvd0_gbp1) };
            rsvd0_gbp1 as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2"][::core::mem::size_of::<
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2,
    >() - 3usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2"][::core::mem::align_of::<
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2,
    >() - 1usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2::rsvd0"][::core::mem::offset_of!(
        rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2,
        rsvd0
    ) - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_vxlan_hdr__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_vxlan_hdr__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_1::vx_flags"]
        [::core::mem::offset_of!(rte_vxlan_hdr__bindgen_ty_1, vx_flags) - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_2 {
    #[doc = "< VNI (24 bits) + reserved (8 bits)."]
    pub vx_vni: rte_be32_t,
    pub anon1: rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1 {
    #[doc = "< VXLAN Identifier."]
    pub vni: [u8; 3usize],
    pub anon1: rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Reserved."]
    pub rsvd1: u8,
    #[doc = "< Reserved."]
    pub last_rsvd: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"][::core::mem::size_of::<
        rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    >() - 1usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"][::core::mem::align_of::<
        rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    >() - 1usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::rsvd1"][::core::mem::offset_of!(
        rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        rsvd1
    ) - 0usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::last_rsvd"][::core::mem::offset_of!(
        rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        last_rsvd
    )
        - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::size_of::<rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::align_of::<rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1::vni"]
        [::core::mem::offset_of!(rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1, vni) - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_2__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr__bindgen_ty_2"]
        [::core::mem::size_of::<rte_vxlan_hdr__bindgen_ty_2>() - 4usize];
    ["Alignment of rte_vxlan_hdr__bindgen_ty_2"]
        [::core::mem::align_of::<rte_vxlan_hdr__bindgen_ty_2>() - 4usize];
    ["Offset of field: rte_vxlan_hdr__bindgen_ty_2::vx_vni"]
        [::core::mem::offset_of!(rte_vxlan_hdr__bindgen_ty_2, vx_vni) - 0usize];
};
impl Default for rte_vxlan_hdr__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_hdr"][::core::mem::size_of::<rte_vxlan_hdr>() - 8usize];
    ["Alignment of rte_vxlan_hdr"][::core::mem::align_of::<rte_vxlan_hdr>() - 1usize];
};
impl Default for rte_vxlan_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_vxlan_gpe_hdr {
    pub anon1: rte_vxlan_gpe_hdr__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_vxlan_gpe_hdr__bindgen_ty_1 {
    pub anon1: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1,
    pub anon2: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< flag (8)."]
    pub vx_flags: u8,
    #[doc = "< Reserved (16)."]
    pub reserved: [u8; 2usize],
    #[doc = "< next-protocol (8)."]
    pub protocol: u8,
    #[doc = "< VNI (24) + Reserved (8)."]
    pub vx_vni: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1::vx_flags"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1, vx_flags) - 0usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1::reserved"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1, reserved) - 1usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1::protocol"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1, protocol) - 3usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1::vx_vni"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_1, vx_vni) - 4usize];
};
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< Flags."]
    pub flags: u8,
    #[doc = "< Reserved."]
    pub rsvd0: [u8; 2usize],
    #[doc = "< Next protocol."]
    pub proto: u8,
    #[doc = "< VXLAN identifier."]
    pub vni: [u8; 3usize],
    #[doc = "< Reserved."]
    pub rsvd1: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2>() - 1usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2::flags"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2, flags) - 0usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2::rsvd0"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2, rsvd0) - 1usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2::proto"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2, proto) - 3usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2::vni"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2, vni) - 4usize];
    ["Offset of field: rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2::rsvd1"]
        [::core::mem::offset_of!(rte_vxlan_gpe_hdr__bindgen_ty_1__bindgen_ty_2, rsvd1) - 7usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_gpe_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_vxlan_gpe_hdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_vxlan_gpe_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_vxlan_gpe_hdr__bindgen_ty_1>() - 4usize];
};
impl Default for rte_vxlan_gpe_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vxlan_gpe_hdr"][::core::mem::size_of::<rte_vxlan_gpe_hdr>() - 8usize];
    ["Alignment of rte_vxlan_gpe_hdr"][::core::mem::align_of::<rte_vxlan_gpe_hdr>() - 1usize];
};
impl Default for rte_vxlan_gpe_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "higig2 frc header."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_higig2_frc {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 8usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_higig2_frc"][::core::mem::size_of::<rte_higig2_frc>() - 8usize];
    ["Alignment of rte_higig2_frc"][::core::mem::align_of::<rte_higig2_frc>() - 4usize];
};
impl rte_higig2_frc {
    #[inline]
    pub fn ksop(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_ksop(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ksop_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ksop_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tc(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_tc(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tc_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_tc_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn mcst(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(12usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_mcst(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(12usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn mcst_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                12usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_mcst_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                12usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn resv(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(13usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_resv(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(13usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn resv_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                13usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_resv_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                13usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dst_modid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_dst_modid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dst_modid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_dst_modid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dst_pid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_dst_pid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dst_pid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_dst_pid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn src_modid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(32usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_src_modid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(32usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn src_modid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                32usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_src_modid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                32usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn src_pid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(40usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_src_pid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(40usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn src_pid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                40usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_src_pid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                40usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn lbid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(48usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_lbid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(48usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn lbid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                48usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_lbid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                48usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ppd_type(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(56usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_ppd_type(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(56usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ppd_type_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                56usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ppd_type_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                56usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn resv1(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(59usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_resv1(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(59usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn resv1_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                59usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_resv1_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                59usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dp(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(62usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_dp(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(62usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dp_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                62usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_dp_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                62usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ksop: u32,
        tc: u32,
        mcst: u32,
        resv: u32,
        dst_modid: u32,
        dst_pid: u32,
        src_modid: u32,
        src_pid: u32,
        lbid: u32,
        ppd_type: u32,
        resv1: u32,
        dp: u32,
    ) -> __BindgenBitfieldUnit<[u8; 8usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 8usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 8u8, {
            let ksop: u32 = unsafe { ::core::mem::transmute(ksop) };
            ksop as u64
        });
        __bindgen_bitfield_unit.set(8usize, 4u8, {
            let tc: u32 = unsafe { ::core::mem::transmute(tc) };
            tc as u64
        });
        __bindgen_bitfield_unit.set(12usize, 1u8, {
            let mcst: u32 = unsafe { ::core::mem::transmute(mcst) };
            mcst as u64
        });
        __bindgen_bitfield_unit.set(13usize, 3u8, {
            let resv: u32 = unsafe { ::core::mem::transmute(resv) };
            resv as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let dst_modid: u32 = unsafe { ::core::mem::transmute(dst_modid) };
            dst_modid as u64
        });
        __bindgen_bitfield_unit.set(24usize, 8u8, {
            let dst_pid: u32 = unsafe { ::core::mem::transmute(dst_pid) };
            dst_pid as u64
        });
        __bindgen_bitfield_unit.set(32usize, 8u8, {
            let src_modid: u32 = unsafe { ::core::mem::transmute(src_modid) };
            src_modid as u64
        });
        __bindgen_bitfield_unit.set(40usize, 8u8, {
            let src_pid: u32 = unsafe { ::core::mem::transmute(src_pid) };
            src_pid as u64
        });
        __bindgen_bitfield_unit.set(48usize, 8u8, {
            let lbid: u32 = unsafe { ::core::mem::transmute(lbid) };
            lbid as u64
        });
        __bindgen_bitfield_unit.set(56usize, 3u8, {
            let ppd_type: u32 = unsafe { ::core::mem::transmute(ppd_type) };
            ppd_type as u64
        });
        __bindgen_bitfield_unit.set(59usize, 3u8, {
            let resv1: u32 = unsafe { ::core::mem::transmute(resv1) };
            resv1 as u64
        });
        __bindgen_bitfield_unit.set(62usize, 2u8, {
            let dp: u32 = unsafe { ::core::mem::transmute(dp) };
            dp as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "higig2 ppt type0 header"]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_higig2_ppt_type0 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 8usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_higig2_ppt_type0"][::core::mem::size_of::<rte_higig2_ppt_type0>() - 8usize];
    ["Alignment of rte_higig2_ppt_type0"][::core::mem::align_of::<rte_higig2_ppt_type0>() - 4usize];
};
impl rte_higig2_ppt_type0 {
    #[inline]
    pub fn mirror(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_mirror(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn mirror_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_mirror_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn mirror_done(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_mirror_done(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn mirror_done_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_mirror_done_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn mirror_only(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_mirror_only(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn mirror_only_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_mirror_only_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ingress_tagged(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress_tagged(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_tagged_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_tagged_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dst_tgid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_dst_tgid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dst_tgid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_dst_tgid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dst_t(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_dst_t(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dst_t_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_dst_t_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn vc_label2(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_vc_label2(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn vc_label2_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_vc_label2_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn label_present(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(12usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_label_present(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(12usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn label_present_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                12usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_label_present_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                12usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(13usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_l3(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(13usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                13usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_l3_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                13usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(14usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_res(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(14usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                14usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_res_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                14usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn vc_label1(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_vc_label1(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn vc_label1_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_vc_label1_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn vc_label0(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_vc_label0(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn vc_label0_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_vc_label0_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn vid_high(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(32usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_vid_high(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(32usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn vid_high_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                32usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_vid_high_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                32usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn vid_low(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(40usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_vid_low(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(40usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn vid_low_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                40usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_vid_low_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                40usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn opc(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(48usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_opc(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(48usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn opc_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                48usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_opc_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                48usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res1(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(51usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_res1(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(51usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res1_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                51usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_res1_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                51usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn srce_t(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(53usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_srce_t(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(53usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn srce_t_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                53usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_srce_t_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                53usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn pf(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(54usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_pf(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(54usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn pf_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                54usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_pf_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                54usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res2(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(56usize, 5u8) as u32) }
    }
    #[inline]
    pub fn set_res2(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(56usize, 5u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res2_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                56usize,
                5u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_res2_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                56usize,
                5u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hdr_ext_length(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(61usize, 3u8) as u32) }
    }
    #[inline]
    pub fn set_hdr_ext_length(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(61usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hdr_ext_length_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                61usize,
                3u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_hdr_ext_length_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                61usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        mirror: u32,
        mirror_done: u32,
        mirror_only: u32,
        ingress_tagged: u32,
        dst_tgid: u32,
        dst_t: u32,
        vc_label2: u32,
        label_present: u32,
        l3: u32,
        res: u32,
        vc_label1: u32,
        vc_label0: u32,
        vid_high: u32,
        vid_low: u32,
        opc: u32,
        res1: u32,
        srce_t: u32,
        pf: u32,
        res2: u32,
        hdr_ext_length: u32,
    ) -> __BindgenBitfieldUnit<[u8; 8usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 8usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let mirror: u32 = unsafe { ::core::mem::transmute(mirror) };
            mirror as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let mirror_done: u32 = unsafe { ::core::mem::transmute(mirror_done) };
            mirror_done as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let mirror_only: u32 = unsafe { ::core::mem::transmute(mirror_only) };
            mirror_only as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let ingress_tagged: u32 = unsafe { ::core::mem::transmute(ingress_tagged) };
            ingress_tagged as u64
        });
        __bindgen_bitfield_unit.set(4usize, 3u8, {
            let dst_tgid: u32 = unsafe { ::core::mem::transmute(dst_tgid) };
            dst_tgid as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let dst_t: u32 = unsafe { ::core::mem::transmute(dst_t) };
            dst_t as u64
        });
        __bindgen_bitfield_unit.set(8usize, 4u8, {
            let vc_label2: u32 = unsafe { ::core::mem::transmute(vc_label2) };
            vc_label2 as u64
        });
        __bindgen_bitfield_unit.set(12usize, 1u8, {
            let label_present: u32 = unsafe { ::core::mem::transmute(label_present) };
            label_present as u64
        });
        __bindgen_bitfield_unit.set(13usize, 1u8, {
            let l3: u32 = unsafe { ::core::mem::transmute(l3) };
            l3 as u64
        });
        __bindgen_bitfield_unit.set(14usize, 2u8, {
            let res: u32 = unsafe { ::core::mem::transmute(res) };
            res as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let vc_label1: u32 = unsafe { ::core::mem::transmute(vc_label1) };
            vc_label1 as u64
        });
        __bindgen_bitfield_unit.set(24usize, 8u8, {
            let vc_label0: u32 = unsafe { ::core::mem::transmute(vc_label0) };
            vc_label0 as u64
        });
        __bindgen_bitfield_unit.set(32usize, 8u8, {
            let vid_high: u32 = unsafe { ::core::mem::transmute(vid_high) };
            vid_high as u64
        });
        __bindgen_bitfield_unit.set(40usize, 8u8, {
            let vid_low: u32 = unsafe { ::core::mem::transmute(vid_low) };
            vid_low as u64
        });
        __bindgen_bitfield_unit.set(48usize, 3u8, {
            let opc: u32 = unsafe { ::core::mem::transmute(opc) };
            opc as u64
        });
        __bindgen_bitfield_unit.set(51usize, 2u8, {
            let res1: u32 = unsafe { ::core::mem::transmute(res1) };
            res1 as u64
        });
        __bindgen_bitfield_unit.set(53usize, 1u8, {
            let srce_t: u32 = unsafe { ::core::mem::transmute(srce_t) };
            srce_t as u64
        });
        __bindgen_bitfield_unit.set(54usize, 2u8, {
            let pf: u32 = unsafe { ::core::mem::transmute(pf) };
            pf as u64
        });
        __bindgen_bitfield_unit.set(56usize, 5u8, {
            let res2: u32 = unsafe { ::core::mem::transmute(res2) };
            res2 as u64
        });
        __bindgen_bitfield_unit.set(61usize, 3u8, {
            let hdr_ext_length: u32 = unsafe { ::core::mem::transmute(hdr_ext_length) };
            hdr_ext_length as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "higig2 ppt type1 header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_higig2_ppt_type1 {
    pub classification: rte_be16_t,
    pub resv: rte_be16_t,
    pub vid: rte_be16_t,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_higig2_ppt_type1"][::core::mem::size_of::<rte_higig2_ppt_type1>() - 8usize];
    ["Alignment of rte_higig2_ppt_type1"][::core::mem::align_of::<rte_higig2_ppt_type1>() - 2usize];
    ["Offset of field: rte_higig2_ppt_type1::classification"]
        [::core::mem::offset_of!(rte_higig2_ppt_type1, classification) - 0usize];
    ["Offset of field: rte_higig2_ppt_type1::resv"]
        [::core::mem::offset_of!(rte_higig2_ppt_type1, resv) - 2usize];
    ["Offset of field: rte_higig2_ppt_type1::vid"]
        [::core::mem::offset_of!(rte_higig2_ppt_type1, vid) - 4usize];
};
impl rte_higig2_ppt_type1 {
    #[inline]
    pub fn opcode(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 3u8) as u16) }
    }
    #[inline]
    pub fn set_opcode(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn opcode_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                3u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_opcode_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn resv1(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 2u8) as u16) }
    }
    #[inline]
    pub fn set_resv1(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn resv1_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                2u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_resv1_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn src_t(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_src_t(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn src_t_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_src_t_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn pfm(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 2u8) as u16) }
    }
    #[inline]
    pub fn set_pfm(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn pfm_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                2u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_pfm_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn resv2(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 5u8) as u16) }
    }
    #[inline]
    pub fn set_resv2(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 5u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn resv2_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                5u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_resv2_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                5u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hdr_ext_len(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(13usize, 3u8) as u16) }
    }
    #[inline]
    pub fn set_hdr_ext_len(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(13usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hdr_ext_len_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                13usize,
                3u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_hdr_ext_len_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                13usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        opcode: u16,
        resv1: u16,
        src_t: u16,
        pfm: u16,
        resv2: u16,
        hdr_ext_len: u16,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 3u8, {
            let opcode: u16 = unsafe { ::core::mem::transmute(opcode) };
            opcode as u64
        });
        __bindgen_bitfield_unit.set(3usize, 2u8, {
            let resv1: u16 = unsafe { ::core::mem::transmute(resv1) };
            resv1 as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let src_t: u16 = unsafe { ::core::mem::transmute(src_t) };
            src_t as u64
        });
        __bindgen_bitfield_unit.set(6usize, 2u8, {
            let pfm: u16 = unsafe { ::core::mem::transmute(pfm) };
            pfm as u64
        });
        __bindgen_bitfield_unit.set(8usize, 5u8, {
            let resv2: u16 = unsafe { ::core::mem::transmute(resv2) };
            resv2 as u64
        });
        __bindgen_bitfield_unit.set(13usize, 3u8, {
            let hdr_ext_len: u16 = unsafe { ::core::mem::transmute(hdr_ext_len) };
            hdr_ext_len as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "higig2 header"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_higig2_hdr {
    pub fcr: rte_higig2_frc,
    pub anon1: rte_higig2_hdr__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_higig2_hdr__bindgen_ty_1 {
    pub ppt0: rte_higig2_ppt_type0,
    pub ppt1: rte_higig2_ppt_type1,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_higig2_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_higig2_hdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_higig2_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_higig2_hdr__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_higig2_hdr__bindgen_ty_1::ppt0"]
        [::core::mem::offset_of!(rte_higig2_hdr__bindgen_ty_1, ppt0) - 0usize];
    ["Offset of field: rte_higig2_hdr__bindgen_ty_1::ppt1"]
        [::core::mem::offset_of!(rte_higig2_hdr__bindgen_ty_1, ppt1) - 0usize];
};
impl Default for rte_higig2_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_higig2_hdr"][::core::mem::size_of::<rte_higig2_hdr>() - 16usize];
    ["Alignment of rte_higig2_hdr"][::core::mem::align_of::<rte_higig2_hdr>() - 4usize];
    ["Offset of field: rte_higig2_hdr::fcr"][::core::mem::offset_of!(rte_higig2_hdr, fcr) - 0usize];
};
impl Default for rte_higig2_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Structure describing the parameters of a mbuf dynamic field."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_dynfield {
    #[doc = "< Name of the field."]
    pub name: [::core::ffi::c_char; 64usize],
    #[doc = "< The number of bytes to reserve."]
    pub size: usize,
    #[doc = "< The alignment constraint (power of 2)."]
    pub align: usize,
    #[doc = "< Reserved for future use, must be 0."]
    pub flags: ::core::ffi::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_dynfield"][::core::mem::size_of::<rte_mbuf_dynfield>() - 88usize];
    ["Alignment of rte_mbuf_dynfield"][::core::mem::align_of::<rte_mbuf_dynfield>() - 8usize];
    ["Offset of field: rte_mbuf_dynfield::name"]
        [::core::mem::offset_of!(rte_mbuf_dynfield, name) - 0usize];
    ["Offset of field: rte_mbuf_dynfield::size"]
        [::core::mem::offset_of!(rte_mbuf_dynfield, size) - 64usize];
    ["Offset of field: rte_mbuf_dynfield::align"]
        [::core::mem::offset_of!(rte_mbuf_dynfield, align) - 72usize];
    ["Offset of field: rte_mbuf_dynfield::flags"]
        [::core::mem::offset_of!(rte_mbuf_dynfield, flags) - 80usize];
};
impl Default for rte_mbuf_dynfield {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Structure describing the parameters of a mbuf dynamic flag."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_dynflag {
    #[doc = "< Name of the dynamic flag."]
    pub name: [::core::ffi::c_char; 64usize],
    #[doc = "< Reserved for future use, must be 0."]
    pub flags: ::core::ffi::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_dynflag"][::core::mem::size_of::<rte_mbuf_dynflag>() - 68usize];
    ["Alignment of rte_mbuf_dynflag"][::core::mem::align_of::<rte_mbuf_dynflag>() - 4usize];
    ["Offset of field: rte_mbuf_dynflag::name"]
        [::core::mem::offset_of!(rte_mbuf_dynflag, name) - 0usize];
    ["Offset of field: rte_mbuf_dynflag::flags"]
        [::core::mem::offset_of!(rte_mbuf_dynflag, flags) - 64usize];
};
impl Default for rte_mbuf_dynflag {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Register space for a dynamic field in the mbuf structure.\nIf the field is already registered (same name and parameters), its\noffset is returned.\n\n# Arguments\n\n* `params` -\nA structure containing the requested parameters (name, size,\nalignment constraint and flags).\n\n# Returns\n\nThe offset in the mbuf structure, or -1 on error.\nPossible values for rte_errno:\n- EINVAL: invalid parameters (size, align, or flags).\n- EEXIST: this name is already register with different parameters.\n- EPERM: called from a secondary process.\n- ENOENT: not enough room in mbuf.\n- ENOMEM: allocation failure.\n- ENAMETOOLONG: name does not ends with \\0. "]
    pub fn rte_mbuf_dynfield_register(params: *const rte_mbuf_dynfield) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register space for a dynamic field in the mbuf structure at offset.\nIf the field is already registered (same name, parameters and offset),\nthe offset is returned.\n\n# Arguments\n\n* `params` -\nA structure containing the requested parameters (name, size,\nalignment constraint and flags).\n* `offset` -\nThe requested offset. Ignored if SIZE_MAX is passed.\n\n# Returns\n\nThe offset in the mbuf structure, or -1 on error.\nPossible values for rte_errno:\n- EINVAL: invalid parameters (size, align, flags, or offset).\n- EEXIST: this name is already register with different parameters.\n- EBUSY: the requested offset cannot be used.\n- EPERM: called from a secondary process.\n- ENOENT: not enough room in mbuf.\n- ENOMEM: allocation failure.\n- ENAMETOOLONG: name does not ends with \\0. "]
    pub fn rte_mbuf_dynfield_register_offset(
        params: *const rte_mbuf_dynfield,
        offset: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Lookup for a registered dynamic mbuf field.\n\n# Arguments\n\n* `name` -\nA string identifying the dynamic field.\n* `params` -\nIf not NULL, and if the lookup is successful, the structure is\nfilled with the parameters of the dynamic field.\n\n# Returns\n\nThe offset of this field in the mbuf structure, or -1 on error.\nPossible values for rte_errno:\n- ENOENT: no dynamic field matches this name."]
    pub fn rte_mbuf_dynfield_lookup(
        name: *const ::core::ffi::c_char,
        params: *mut rte_mbuf_dynfield,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register a dynamic flag in the mbuf structure.\nIf the flag is already registered (same name and parameters), its\nbitnum is returned.\n\n# Arguments\n\n* `params` -\nA structure containing the requested parameters of the dynamic\nflag (name and options).\n\n# Returns\n\nThe number of the reserved bit, or -1 on error.\nPossible values for rte_errno:\n- EINVAL: invalid parameters (size, align, or flags).\n- EEXIST: this name is already register with different parameters.\n- EPERM: called from a secondary process.\n- ENOENT: no more flag available.\n- ENOMEM: allocation failure.\n- ENAMETOOLONG: name is longer than RTE_MBUF_DYN_NAMESIZE - 1."]
    pub fn rte_mbuf_dynflag_register(params: *const rte_mbuf_dynflag) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register a dynamic flag in the mbuf structure specifying bitnum.\nIf the flag is already registered (same name, parameters and bitnum),\nthe bitnum is returned.\n\n# Arguments\n\n* `params` -\nA structure containing the requested parameters of the dynamic\nflag (name and options).\n* `bitnum` -\nThe requested bitnum. Ignored if UINT_MAX is passed.\n\n# Returns\n\nThe number of the reserved bit, or -1 on error.\nPossible values for rte_errno:\n- EINVAL: invalid parameters (size, align, or flags).\n- EEXIST: this name is already register with different parameters.\n- EBUSY: the requested bitnum cannot be used.\n- EPERM: called from a secondary process.\n- ENOENT: no more flag available.\n- ENOMEM: allocation failure.\n- ENAMETOOLONG: name is longer than RTE_MBUF_DYN_NAMESIZE - 1."]
    pub fn rte_mbuf_dynflag_register_bitnum(
        params: *const rte_mbuf_dynflag,
        bitnum: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Lookup for a registered dynamic mbuf flag.\n\n# Arguments\n\n* `name` -\nA string identifying the dynamic flag.\n* `params` -\nIf not NULL, and if the lookup is successful, the structure is\nfilled with the parameters of the dynamic flag.\n\n# Returns\n\nThe offset of this flag in the mbuf structure, or -1 on error.\nPossible values for rte_errno:\n- ENOENT: no dynamic flag matches this name."]
    pub fn rte_mbuf_dynflag_lookup(
        name: *const ::core::ffi::c_char,
        params: *mut rte_mbuf_dynflag,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump the status of dynamic fields and flags.\n\n# Arguments\n\n* `out` -\nThe stream where the status is displayed."]
    pub fn rte_mbuf_dyn_dump(out: *mut FILE);
}
pub type rte_mbuf_timestamp_t = u64;
unsafe extern "C" {
    #[doc = "Register dynamic mbuf field and flag for Rx timestamp.\n\n# Arguments\n\n* `field_offset` -\nPointer to the offset of the registered mbuf field, can be NULL.\nThe same field is shared for Rx and Tx timestamp.\n* `rx_flag` -\nPointer to the mask of the registered offload flag, can be NULL.\n\n# Returns\n\n0 on success, -1 otherwise.\nPossible values for rte_errno:\n- EEXIST: already registered with different parameters.\n- EPERM: called from a secondary process.\n- ENOENT: no more field or flag available.\n- ENOMEM: allocation failure."]
    pub fn rte_mbuf_dyn_rx_timestamp_register(
        field_offset: *mut ::core::ffi::c_int,
        rx_flag: *mut u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register dynamic mbuf field and flag for Tx timestamp.\n\n# Arguments\n\n* `field_offset` -\nPointer to the offset of the registered mbuf field, can be NULL.\nThe same field is shared for Rx and Tx timestamp.\n* `tx_flag` -\nPointer to the mask of the registered offload flag, can be NULL.\n\n# Returns\n\n0 on success, -1 otherwise.\nPossible values for rte_errno:\n- EEXIST: already registered with different parameters.\n- EPERM: called from a secondary process.\n- ENOENT: no more field or flag available.\n- ENOMEM: allocation failure."]
    pub fn rte_mbuf_dyn_tx_timestamp_register(
        field_offset: *mut ::core::ffi::c_int,
        tx_flag: *mut u64,
    ) -> ::core::ffi::c_int;
}
pub mod rte_color {
    #[doc = "Color"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Green"]
    pub const RTE_COLOR_GREEN: Type = 0;
    #[doc = "< Yellow"]
    pub const RTE_COLOR_YELLOW: Type = 1;
    #[doc = "< Red"]
    pub const RTE_COLOR_RED: Type = 2;
    #[doc = "< Number of colors"]
    pub const RTE_COLORS: Type = 3;
}
#[doc = "srTCM parameters per metered traffic flow. The CIR, CBS and EBS parameters only\ncount bytes of IP packets and do not include link specific headers. At least one of\nthe CBS or EBS parameters has to be greater than zero."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_srtcm_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Committed Burst Size (CBS).  Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Excess Burst Size (EBS).  Measured in bytes."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm_params"][::core::mem::size_of::<rte_meter_srtcm_params>() - 24usize];
    ["Alignment of rte_meter_srtcm_params"]
        [::core::mem::align_of::<rte_meter_srtcm_params>() - 8usize];
    ["Offset of field: rte_meter_srtcm_params::cir"]
        [::core::mem::offset_of!(rte_meter_srtcm_params, cir) - 0usize];
    ["Offset of field: rte_meter_srtcm_params::cbs"]
        [::core::mem::offset_of!(rte_meter_srtcm_params, cbs) - 8usize];
    ["Offset of field: rte_meter_srtcm_params::ebs"]
        [::core::mem::offset_of!(rte_meter_srtcm_params, ebs) - 16usize];
};
#[doc = "trTCM parameters per metered traffic flow. The CIR, PIR, CBS and PBS parameters\nonly count bytes of IP packets and do not include link specific headers. PIR has to\nbe greater than or equal to CIR. Both CBS or EBS have to be greater than zero."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Peak Information Rate (PIR). Measured in bytes per second."]
    pub pir: u64,
    #[doc = "< Committed Burst Size (CBS). Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Peak Burst Size (PBS). Measured in bytes."]
    pub pbs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_params"][::core::mem::size_of::<rte_meter_trtcm_params>() - 32usize];
    ["Alignment of rte_meter_trtcm_params"]
        [::core::mem::align_of::<rte_meter_trtcm_params>() - 8usize];
    ["Offset of field: rte_meter_trtcm_params::cir"]
        [::core::mem::offset_of!(rte_meter_trtcm_params, cir) - 0usize];
    ["Offset of field: rte_meter_trtcm_params::pir"]
        [::core::mem::offset_of!(rte_meter_trtcm_params, pir) - 8usize];
    ["Offset of field: rte_meter_trtcm_params::cbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_params, cbs) - 16usize];
    ["Offset of field: rte_meter_trtcm_params::pbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_params, pbs) - 24usize];
};
#[doc = "trTCM parameters per metered traffic flow. The CIR, EIR, CBS and EBS\nparameters only count bytes of IP packets and do not include link specific\nheaders. The CBS and EBS need to be greater than zero if CIR and EIR are\nnone-zero respectively."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Excess Information Rate (EIR). Measured in bytes per second."]
    pub eir: u64,
    #[doc = "< Committed Burst Size (CBS). Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Excess Burst Size (EBS). Measured in bytes."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115_params"]
        [::core::mem::size_of::<rte_meter_trtcm_rfc4115_params>() - 32usize];
    ["Alignment of rte_meter_trtcm_rfc4115_params"]
        [::core::mem::align_of::<rte_meter_trtcm_rfc4115_params>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::cir"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_params, cir) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::eir"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_params, eir) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::cbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_params, cbs) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::ebs"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_params, ebs) - 24usize];
};
unsafe extern "C" {
    #[doc = "srTCM profile configuration\n\n# Arguments\n\n* `p` -\nPointer to pre-allocated srTCM profile data structure\n* `params` -\nsrTCM profile parameters\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_srtcm_profile_config(
        p: *mut rte_meter_srtcm_profile,
        params: *mut rte_meter_srtcm_params,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "trTCM profile configuration\n\n# Arguments\n\n* `p` -\nPointer to pre-allocated trTCM profile data structure\n* `params` -\ntrTCM profile parameters\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_profile_config(
        p: *mut rte_meter_trtcm_profile,
        params: *mut rte_meter_trtcm_params,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "trTCM RFC 4115 profile configuration\n\n# Arguments\n\n* `p` -\nPointer to pre-allocated trTCM profile data structure\n* `params` -\ntrTCM profile parameters\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_rfc4115_profile_config(
        p: *mut rte_meter_trtcm_rfc4115_profile,
        params: *mut rte_meter_trtcm_rfc4115_params,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "srTCM configuration per metered traffic flow\n\n# Arguments\n\n* `m` -\nPointer to pre-allocated srTCM data structure\n* `p` -\nsrTCM profile. Needs to be valid.\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_srtcm_config(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "trTCM configuration per metered traffic flow\n\n# Arguments\n\n* `m` -\nPointer to pre-allocated trTCM data structure\n* `p` -\ntrTCM profile. Needs to be valid.\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_config(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "trTCM RFC 4115 configuration per metered traffic flow\n\n# Arguments\n\n* `m` -\nPointer to pre-allocated trTCM data structure\n* `p` -\ntrTCM profile. Needs to be valid.\n\n# Returns\n\n0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_rfc4115_config(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "srTCM color blind traffic metering\n\n# Arguments\n\n* `m` -\nHandle to srTCM instance\n* `p` -\nsrTCM profile specified at srTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_srtcm_color_blind_check_w"]
    pub fn rte_meter_srtcm_color_blind_check(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    #[doc = "srTCM color aware traffic metering\n\n# Arguments\n\n* `m` -\nHandle to srTCM instance\n* `p` -\nsrTCM profile specified at srTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n* `pkt_color` -\nInput color of the current IP packet\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_srtcm_color_aware_check_w"]
    pub fn rte_meter_srtcm_color_aware_check(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    #[doc = "trTCM color blind traffic metering\n\n# Arguments\n\n* `m` -\nHandle to trTCM instance\n* `p` -\ntrTCM profile specified at trTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_trtcm_color_blind_check_w"]
    pub fn rte_meter_trtcm_color_blind_check(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    #[doc = "trTCM color aware traffic metering\n\n# Arguments\n\n* `m` -\nHandle to trTCM instance\n* `p` -\ntrTCM profile specified at trTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n* `pkt_color` -\nInput color of the current IP packet\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_trtcm_color_aware_check_w"]
    pub fn rte_meter_trtcm_color_aware_check(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    #[doc = "trTCM RFC4115 color blind traffic metering\n\n# Arguments\n\n* `m` -\nHandle to trTCM instance\n* `p` -\ntrTCM profile specified at trTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_trtcm_rfc4115_color_blind_check_w"]
    pub fn rte_meter_trtcm_rfc4115_color_blind_check(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    #[doc = "trTCM RFC4115 color aware traffic metering\n\n# Arguments\n\n* `m` -\nHandle to trTCM instance\n* `p` -\ntrTCM profile specified at trTCM object creation time\n* `time` -\nCurrent CPU time stamp (measured in CPU cycles)\n* `pkt_len` -\nLength of the current IP packet (measured in bytes)\n* `pkt_color` -\nInput color of the current IP packet\n\n# Returns\n\nColor assigned to the current IP packet"]
    #[link_name = "rte_meter_trtcm_rfc4115_color_aware_check_w"]
    pub fn rte_meter_trtcm_rfc4115_color_aware_check(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
#[doc = "Internal data structure storing the srTCM configuration profile. Typically\nshared by multiple srTCM objects."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_srtcm_profile {
    pub cbs: u64,
    pub ebs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm_profile"]
        [::core::mem::size_of::<rte_meter_srtcm_profile>() - 32usize];
    ["Alignment of rte_meter_srtcm_profile"]
        [::core::mem::align_of::<rte_meter_srtcm_profile>() - 8usize];
    ["Offset of field: rte_meter_srtcm_profile::cbs"]
        [::core::mem::offset_of!(rte_meter_srtcm_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_srtcm_profile::ebs"]
        [::core::mem::offset_of!(rte_meter_srtcm_profile, ebs) - 8usize];
    ["Offset of field: rte_meter_srtcm_profile::cir_period"]
        [::core::mem::offset_of!(rte_meter_srtcm_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_srtcm_profile::cir_bytes_per_period"]
        [::core::mem::offset_of!(rte_meter_srtcm_profile, cir_bytes_per_period) - 24usize];
};
#[doc = "Internal data structure storing the srTCM run-time context per metered traffic flow."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_srtcm {
    #[doc = "Time of latest update of C and E token buckets"]
    pub time: u64,
    #[doc = "Number of bytes currently available in the committed (C) token bucket"]
    pub tc: u64,
    #[doc = "Number of bytes currently available in the excess (E) token bucket"]
    pub te: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm"][::core::mem::size_of::<rte_meter_srtcm>() - 24usize];
    ["Alignment of rte_meter_srtcm"][::core::mem::align_of::<rte_meter_srtcm>() - 8usize];
    ["Offset of field: rte_meter_srtcm::time"]
        [::core::mem::offset_of!(rte_meter_srtcm, time) - 0usize];
    ["Offset of field: rte_meter_srtcm::tc"][::core::mem::offset_of!(rte_meter_srtcm, tc) - 8usize];
    ["Offset of field: rte_meter_srtcm::te"]
        [::core::mem::offset_of!(rte_meter_srtcm, te) - 16usize];
};
#[doc = "Internal data structure storing the trTCM configuration profile. Typically\nshared by multiple trTCM objects."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm_profile {
    pub cbs: u64,
    pub pbs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
    pub pir_period: u64,
    pub pir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_profile"]
        [::core::mem::size_of::<rte_meter_trtcm_profile>() - 48usize];
    ["Alignment of rte_meter_trtcm_profile"]
        [::core::mem::align_of::<rte_meter_trtcm_profile>() - 8usize];
    ["Offset of field: rte_meter_trtcm_profile::cbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_trtcm_profile::pbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, pbs) - 8usize];
    ["Offset of field: rte_meter_trtcm_profile::cir_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_trtcm_profile::cir_bytes_per_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, cir_bytes_per_period) - 24usize];
    ["Offset of field: rte_meter_trtcm_profile::pir_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, pir_period) - 32usize];
    ["Offset of field: rte_meter_trtcm_profile::pir_bytes_per_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_profile, pir_bytes_per_period) - 40usize];
};
#[doc = "Internal data structure storing the trTCM run-time context per metered traffic flow."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm {
    pub time_tc: u64,
    pub time_tp: u64,
    pub tc: u64,
    pub tp: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm"][::core::mem::size_of::<rte_meter_trtcm>() - 32usize];
    ["Alignment of rte_meter_trtcm"][::core::mem::align_of::<rte_meter_trtcm>() - 8usize];
    ["Offset of field: rte_meter_trtcm::time_tc"]
        [::core::mem::offset_of!(rte_meter_trtcm, time_tc) - 0usize];
    ["Offset of field: rte_meter_trtcm::time_tp"]
        [::core::mem::offset_of!(rte_meter_trtcm, time_tp) - 8usize];
    ["Offset of field: rte_meter_trtcm::tc"]
        [::core::mem::offset_of!(rte_meter_trtcm, tc) - 16usize];
    ["Offset of field: rte_meter_trtcm::tp"]
        [::core::mem::offset_of!(rte_meter_trtcm, tp) - 24usize];
};
#[doc = "Internal data structure storing the trTCM RFC4115 configuration profile.\nTypically shared by multiple trTCM objects."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115_profile {
    pub cbs: u64,
    pub ebs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
    pub eir_period: u64,
    pub eir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115_profile"]
        [::core::mem::size_of::<rte_meter_trtcm_rfc4115_profile>() - 48usize];
    ["Alignment of rte_meter_trtcm_rfc4115_profile"]
        [::core::mem::align_of::<rte_meter_trtcm_rfc4115_profile>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cbs"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::ebs"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, ebs) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cir_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cir_bytes_per_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cir_bytes_per_period) - 24usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::eir_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, eir_period) - 32usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::eir_bytes_per_period"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, eir_bytes_per_period) - 40usize];
};
#[doc = "Internal data structure storing the trTCM RFC4115 run-time context per\nmetered traffic flow."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115 {
    pub time_tc: u64,
    pub time_te: u64,
    pub tc: u64,
    pub te: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115"]
        [::core::mem::size_of::<rte_meter_trtcm_rfc4115>() - 32usize];
    ["Alignment of rte_meter_trtcm_rfc4115"]
        [::core::mem::align_of::<rte_meter_trtcm_rfc4115>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::time_tc"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115, time_tc) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::time_te"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115, time_te) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::tc"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115, tc) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::te"]
        [::core::mem::offset_of!(rte_meter_trtcm_rfc4115, te) - 24usize];
};
#[doc = "Simplified GTP protocol header.\nContains 8-bit header info, 8-bit message type,\n16-bit payload length after mandatory header, 32-bit TEID.\nNo optional fields and next extension header."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_gtp_hdr {
    pub anon1: rte_gtp_hdr__bindgen_ty_1,
    #[doc = "< GTP message type"]
    pub msg_type: u8,
    #[doc = "< Total payload length"]
    pub plen: rte_be16_t,
    #[doc = "< Tunnel endpoint ID"]
    pub teid: rte_be32_t,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_gtp_hdr__bindgen_ty_1 {
    #[doc = "< GTP header info"]
    pub gtp_hdr_info: u8,
    pub anon1: rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
};
impl rte_gtp_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn pn(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_pn(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn pn_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_pn_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn s(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_s(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn s_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_s_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn e(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_e(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn e_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_e_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res1(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_res1(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res1_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_res1_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn pt(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_pt(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn pt_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_pt_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ver(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 3u8) as u8) }
    }
    #[inline]
    pub fn set_ver(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ver_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                3u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ver_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        pn: u8,
        s: u8,
        e: u8,
        res1: u8,
        pt: u8,
        ver: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let pn: u8 = unsafe { ::core::mem::transmute(pn) };
            pn as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let s: u8 = unsafe { ::core::mem::transmute(s) };
            s as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let e: u8 = unsafe { ::core::mem::transmute(e) };
            e as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let res1: u8 = unsafe { ::core::mem::transmute(res1) };
            res1 as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let pt: u8 = unsafe { ::core::mem::transmute(pt) };
            pt as u64
        });
        __bindgen_bitfield_unit.set(5usize, 3u8, {
            let ver: u8 = unsafe { ::core::mem::transmute(ver) };
            ver as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_gtp_hdr__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_gtp_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_gtp_hdr__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_gtp_hdr__bindgen_ty_1::gtp_hdr_info"]
        [::core::mem::offset_of!(rte_gtp_hdr__bindgen_ty_1, gtp_hdr_info) - 0usize];
};
impl Default for rte_gtp_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_hdr"][::core::mem::size_of::<rte_gtp_hdr>() - 8usize];
    ["Alignment of rte_gtp_hdr"][::core::mem::align_of::<rte_gtp_hdr>() - 1usize];
    ["Offset of field: rte_gtp_hdr::msg_type"]
        [::core::mem::offset_of!(rte_gtp_hdr, msg_type) - 1usize];
    ["Offset of field: rte_gtp_hdr::plen"][::core::mem::offset_of!(rte_gtp_hdr, plen) - 2usize];
    ["Offset of field: rte_gtp_hdr::teid"][::core::mem::offset_of!(rte_gtp_hdr, teid) - 4usize];
};
impl Default for rte_gtp_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Optional word of GTP header, present if any of E, S, PN is set."]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gtp_hdr_ext_word {
    #[doc = "< Sequence Number."]
    pub sqn: rte_be16_t,
    #[doc = "< N-PDU number."]
    pub npdu: u8,
    #[doc = "< Next Extension Header Type."]
    pub next_ext: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_hdr_ext_word"][::core::mem::size_of::<rte_gtp_hdr_ext_word>() - 4usize];
    ["Alignment of rte_gtp_hdr_ext_word"][::core::mem::align_of::<rte_gtp_hdr_ext_word>() - 1usize];
    ["Offset of field: rte_gtp_hdr_ext_word::sqn"]
        [::core::mem::offset_of!(rte_gtp_hdr_ext_word, sqn) - 0usize];
    ["Offset of field: rte_gtp_hdr_ext_word::npdu"]
        [::core::mem::offset_of!(rte_gtp_hdr_ext_word, npdu) - 2usize];
    ["Offset of field: rte_gtp_hdr_ext_word::next_ext"]
        [::core::mem::offset_of!(rte_gtp_hdr_ext_word, next_ext) - 3usize];
};
#[doc = "Optional extension for GTP with next_ext set to 0x85\ndefined based on RFC 38415-g30."]
#[repr(C)]
#[repr(align(1))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gtp_psc_generic_hdr {
    pub _bindgen_opaque_blob: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_psc_generic_hdr"][::core::mem::size_of::<rte_gtp_psc_generic_hdr>() - 3usize];
    ["Alignment of rte_gtp_psc_generic_hdr"]
        [::core::mem::align_of::<rte_gtp_psc_generic_hdr>() - 1usize];
};
#[doc = "Optional extension for GTP with next_ext set to 0x85\ntype0 defined based on RFC 38415-g30"]
#[repr(C, packed)]
pub struct rte_gtp_psc_type0_hdr {
    #[doc = "< PDU ext hdr len in multiples of 4 bytes"]
    pub ext_hdr_len: u8,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    #[doc = "< variable length data fields"]
    pub data: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_psc_type0_hdr"][::core::mem::size_of::<rte_gtp_psc_type0_hdr>() - 3usize];
    ["Alignment of rte_gtp_psc_type0_hdr"]
        [::core::mem::align_of::<rte_gtp_psc_type0_hdr>() - 1usize];
    ["Offset of field: rte_gtp_psc_type0_hdr::ext_hdr_len"]
        [::core::mem::offset_of!(rte_gtp_psc_type0_hdr, ext_hdr_len) - 0usize];
    ["Offset of field: rte_gtp_psc_type0_hdr::data"]
        [::core::mem::offset_of!(rte_gtp_psc_type0_hdr, data) - 3usize];
};
impl Default for rte_gtp_psc_type0_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_gtp_psc_type0_hdr {
    #[inline]
    pub fn spare_dl1(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_spare_dl1(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn spare_dl1_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_spare_dl1_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn snp(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_snp(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn snp_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_snp_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn qmp(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_qmp(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn qmp_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_qmp_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn type_(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn type__raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn qfi(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_qfi(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn qfi_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_qfi_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rqi(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(14usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_rqi(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(14usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rqi_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                14usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rqi_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                14usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ppp(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(15usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_ppp(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(15usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ppp_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                15usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ppp_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                15usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        spare_dl1: u8,
        snp: u8,
        qmp: u8,
        type_: u8,
        qfi: u8,
        rqi: u8,
        ppp: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 2u8, {
            let spare_dl1: u8 = unsafe { ::core::mem::transmute(spare_dl1) };
            spare_dl1 as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let snp: u8 = unsafe { ::core::mem::transmute(snp) };
            snp as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let qmp: u8 = unsafe { ::core::mem::transmute(qmp) };
            qmp as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let type_: u8 = unsafe { ::core::mem::transmute(type_) };
            type_ as u64
        });
        __bindgen_bitfield_unit.set(8usize, 6u8, {
            let qfi: u8 = unsafe { ::core::mem::transmute(qfi) };
            qfi as u64
        });
        __bindgen_bitfield_unit.set(14usize, 1u8, {
            let rqi: u8 = unsafe { ::core::mem::transmute(rqi) };
            rqi as u64
        });
        __bindgen_bitfield_unit.set(15usize, 1u8, {
            let ppp: u8 = unsafe { ::core::mem::transmute(ppp) };
            ppp as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "Optional extension for GTP with next_ext set to 0x85\ntype1 defined based on RFC 38415-g30"]
#[repr(C, packed)]
pub struct rte_gtp_psc_type1_hdr {
    #[doc = "< PDU ext hdr len in multiples of 4 bytes"]
    pub ext_hdr_len: u8,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    #[doc = "< variable length data fields"]
    pub data: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gtp_psc_type1_hdr"][::core::mem::size_of::<rte_gtp_psc_type1_hdr>() - 3usize];
    ["Alignment of rte_gtp_psc_type1_hdr"]
        [::core::mem::align_of::<rte_gtp_psc_type1_hdr>() - 1usize];
    ["Offset of field: rte_gtp_psc_type1_hdr::ext_hdr_len"]
        [::core::mem::offset_of!(rte_gtp_psc_type1_hdr, ext_hdr_len) - 0usize];
    ["Offset of field: rte_gtp_psc_type1_hdr::data"]
        [::core::mem::offset_of!(rte_gtp_psc_type1_hdr, data) - 3usize];
};
impl Default for rte_gtp_psc_type1_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_gtp_psc_type1_hdr {
    #[inline]
    pub fn snp(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_snp(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn snp_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_snp_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ul_delay_ind(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_ul_delay_ind(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ul_delay_ind_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ul_delay_ind_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn dl_delay_ind(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_dl_delay_ind(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn dl_delay_ind_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_dl_delay_ind_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn qmp(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_qmp(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn qmp_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_qmp_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn type_(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn type__raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn qfi(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_qfi(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn qfi_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_qfi_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn spare_ul2(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(14usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_spare_ul2(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(14usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn spare_ul2_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                14usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_spare_ul2_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                14usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn n_delay_ind(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(15usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_n_delay_ind(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(15usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn n_delay_ind_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                15usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_n_delay_ind_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                15usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        snp: u8,
        ul_delay_ind: u8,
        dl_delay_ind: u8,
        qmp: u8,
        type_: u8,
        qfi: u8,
        spare_ul2: u8,
        n_delay_ind: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let snp: u8 = unsafe { ::core::mem::transmute(snp) };
            snp as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let ul_delay_ind: u8 = unsafe { ::core::mem::transmute(ul_delay_ind) };
            ul_delay_ind as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let dl_delay_ind: u8 = unsafe { ::core::mem::transmute(dl_delay_ind) };
            dl_delay_ind as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let qmp: u8 = unsafe { ::core::mem::transmute(qmp) };
            qmp as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let type_: u8 = unsafe { ::core::mem::transmute(type_) };
            type_ as u64
        });
        __bindgen_bitfield_unit.set(8usize, 6u8, {
            let qfi: u8 = unsafe { ::core::mem::transmute(qfi) };
            qfi as u64
        });
        __bindgen_bitfield_unit.set(14usize, 1u8, {
            let spare_ul2: u8 = unsafe { ::core::mem::transmute(spare_ul2) };
            spare_ul2 as u64
        });
        __bindgen_bitfield_unit.set(15usize, 1u8, {
            let n_delay_ind: u8 = unsafe { ::core::mem::transmute(n_delay_ind) };
            n_delay_ind as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "L2TPv2 Common Header"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_l2tpv2_common_hdr {
    pub anon1: rte_l2tpv2_common_hdr__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_l2tpv2_common_hdr__bindgen_ty_1 {
    #[doc = "header flags and protocol version"]
    pub flags_version: rte_be16_t,
    pub anon1: rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Alignment of rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1>() - 2usize];
};
impl rte_l2tpv2_common_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn ver(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u16) }
    }
    #[inline]
    pub fn set_ver(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ver_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_ver_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res3(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u16) }
    }
    #[inline]
    pub fn set_res3(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res3_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res3_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn p(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_p(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn p_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_p_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn o(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(9usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_o(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(9usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn o_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                9usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_o_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                9usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res2(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(10usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_res2(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(10usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res2_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                10usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res2_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                10usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn s(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(11usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_s(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(11usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn s_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                11usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_s_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                11usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res1(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(12usize, 2u8) as u16) }
    }
    #[inline]
    pub fn set_res1(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(12usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res1_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                12usize,
                2u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res1_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                12usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(14usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_l(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(14usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                14usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_l_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                14usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn t(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(15usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_t(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(15usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn t_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                15usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_t_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                15usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ver: u16,
        res3: u16,
        p: u16,
        o: u16,
        res2: u16,
        s: u16,
        res1: u16,
        l: u16,
        t: u16,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let ver: u16 = unsafe { ::core::mem::transmute(ver) };
            ver as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let res3: u16 = unsafe { ::core::mem::transmute(res3) };
            res3 as u64
        });
        __bindgen_bitfield_unit.set(8usize, 1u8, {
            let p: u16 = unsafe { ::core::mem::transmute(p) };
            p as u64
        });
        __bindgen_bitfield_unit.set(9usize, 1u8, {
            let o: u16 = unsafe { ::core::mem::transmute(o) };
            o as u64
        });
        __bindgen_bitfield_unit.set(10usize, 1u8, {
            let res2: u16 = unsafe { ::core::mem::transmute(res2) };
            res2 as u64
        });
        __bindgen_bitfield_unit.set(11usize, 1u8, {
            let s: u16 = unsafe { ::core::mem::transmute(s) };
            s as u64
        });
        __bindgen_bitfield_unit.set(12usize, 2u8, {
            let res1: u16 = unsafe { ::core::mem::transmute(res1) };
            res1 as u64
        });
        __bindgen_bitfield_unit.set(14usize, 1u8, {
            let l: u16 = unsafe { ::core::mem::transmute(l) };
            l as u64
        });
        __bindgen_bitfield_unit.set(15usize, 1u8, {
            let t: u16 = unsafe { ::core::mem::transmute(t) };
            t as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_common_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_l2tpv2_common_hdr__bindgen_ty_1>() - 2usize];
    ["Alignment of rte_l2tpv2_common_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_l2tpv2_common_hdr__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_l2tpv2_common_hdr__bindgen_ty_1::flags_version"]
        [::core::mem::offset_of!(rte_l2tpv2_common_hdr__bindgen_ty_1, flags_version) - 0usize];
};
impl Default for rte_l2tpv2_common_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_common_hdr"][::core::mem::size_of::<rte_l2tpv2_common_hdr>() - 2usize];
    ["Alignment of rte_l2tpv2_common_hdr"]
        [::core::mem::align_of::<rte_l2tpv2_common_hdr>() - 2usize];
};
impl Default for rte_l2tpv2_common_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "L2TPv2 message Header contains all options(length, ns, nr,\noffset size, offset padding)."]
#[repr(C, packed)]
#[derive(Debug, Copy, Clone)]
pub struct rte_l2tpv2_msg_with_all_options {
    #[doc = "< length(16)"]
    pub length: rte_be16_t,
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< Ns(16)"]
    pub ns: rte_be16_t,
    #[doc = "< Nr(16)"]
    pub nr: rte_be16_t,
    #[doc = "< offset size(16)"]
    pub offset_size: rte_be16_t,
    #[doc = "< offset padding(variable length)"]
    pub offset_padding: *mut u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_with_all_options"]
        [::core::mem::size_of::<rte_l2tpv2_msg_with_all_options>() - 20usize];
    ["Alignment of rte_l2tpv2_msg_with_all_options"]
        [::core::mem::align_of::<rte_l2tpv2_msg_with_all_options>() - 1usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::length"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, length) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, tunnel_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, session_id) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::ns"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, ns) - 6usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::nr"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, nr) - 8usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::offset_size"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, offset_size) - 10usize];
    ["Offset of field: rte_l2tpv2_msg_with_all_options::offset_padding"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_all_options, offset_padding) - 12usize];
};
impl Default for rte_l2tpv2_msg_with_all_options {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "L2TPv2 message Header contains all options except length(ns, nr,\noffset size, offset padding)."]
#[repr(C, packed)]
#[derive(Debug, Copy, Clone)]
pub struct rte_l2tpv2_msg_without_length {
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< Ns(16)"]
    pub ns: rte_be16_t,
    #[doc = "< Nr(16)"]
    pub nr: rte_be16_t,
    #[doc = "< offset size(16)"]
    pub offset_size: rte_be16_t,
    #[doc = "< offset padding(variable length)"]
    pub offset_padding: *mut u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_without_length"]
        [::core::mem::size_of::<rte_l2tpv2_msg_without_length>() - 18usize];
    ["Alignment of rte_l2tpv2_msg_without_length"]
        [::core::mem::align_of::<rte_l2tpv2_msg_without_length>() - 1usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, tunnel_id) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, session_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::ns"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, ns) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::nr"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, nr) - 6usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::offset_size"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, offset_size) - 8usize];
    ["Offset of field: rte_l2tpv2_msg_without_length::offset_padding"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_length, offset_padding) - 10usize];
};
impl Default for rte_l2tpv2_msg_without_length {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "L2TPv2 message Header contains all options except ns_nr(length,\noffset size, offset padding).\nNs and Nr MUST be together."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_l2tpv2_msg_without_ns_nr {
    #[doc = "< length(16)"]
    pub length: rte_be16_t,
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< offset size(16)"]
    pub offset_size: rte_be16_t,
    #[doc = "< offset padding(variable length)"]
    pub offset_padding: *mut u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_without_ns_nr"]
        [::core::mem::size_of::<rte_l2tpv2_msg_without_ns_nr>() - 16usize];
    ["Alignment of rte_l2tpv2_msg_without_ns_nr"]
        [::core::mem::align_of::<rte_l2tpv2_msg_without_ns_nr>() - 8usize];
    ["Offset of field: rte_l2tpv2_msg_without_ns_nr::length"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_ns_nr, length) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_without_ns_nr::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_ns_nr, tunnel_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_without_ns_nr::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_ns_nr, session_id) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_without_ns_nr::offset_size"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_ns_nr, offset_size) - 6usize];
    ["Offset of field: rte_l2tpv2_msg_without_ns_nr::offset_padding"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_ns_nr, offset_padding) - 8usize];
};
impl Default for rte_l2tpv2_msg_without_ns_nr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "L2TPv2 message Header contains all options except ns_nr(length, ns, nr).\noffset size and offset padding MUST be together."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_msg_without_offset {
    #[doc = "< length(16)"]
    pub length: rte_be16_t,
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< Ns(16)"]
    pub ns: rte_be16_t,
    #[doc = "< Nr(16)"]
    pub nr: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_without_offset"]
        [::core::mem::size_of::<rte_l2tpv2_msg_without_offset>() - 10usize];
    ["Alignment of rte_l2tpv2_msg_without_offset"]
        [::core::mem::align_of::<rte_l2tpv2_msg_without_offset>() - 2usize];
    ["Offset of field: rte_l2tpv2_msg_without_offset::length"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_offset, length) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_without_offset::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_offset, tunnel_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_without_offset::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_offset, session_id) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_without_offset::ns"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_offset, ns) - 6usize];
    ["Offset of field: rte_l2tpv2_msg_without_offset::nr"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_offset, nr) - 8usize];
};
#[doc = "L2TPv2 message Header contains options offset size and offset padding."]
#[repr(C, packed)]
#[derive(Debug, Copy, Clone)]
pub struct rte_l2tpv2_msg_with_offset {
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< offset size(16)"]
    pub offset_size: rte_be16_t,
    #[doc = "< offset padding(variable length)"]
    pub offset_padding: *mut u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_with_offset"]
        [::core::mem::size_of::<rte_l2tpv2_msg_with_offset>() - 14usize];
    ["Alignment of rte_l2tpv2_msg_with_offset"]
        [::core::mem::align_of::<rte_l2tpv2_msg_with_offset>() - 1usize];
    ["Offset of field: rte_l2tpv2_msg_with_offset::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_offset, tunnel_id) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_with_offset::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_offset, session_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_offset::offset_size"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_offset, offset_size) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_with_offset::offset_padding"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_offset, offset_padding) - 6usize];
};
impl Default for rte_l2tpv2_msg_with_offset {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "L2TPv2 message Header contains options ns and nr."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_msg_with_ns_nr {
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
    #[doc = "< Ns(16)"]
    pub ns: rte_be16_t,
    #[doc = "< Nr(16)"]
    pub nr: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_with_ns_nr"]
        [::core::mem::size_of::<rte_l2tpv2_msg_with_ns_nr>() - 8usize];
    ["Alignment of rte_l2tpv2_msg_with_ns_nr"]
        [::core::mem::align_of::<rte_l2tpv2_msg_with_ns_nr>() - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_ns_nr::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_ns_nr, tunnel_id) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_with_ns_nr::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_ns_nr, session_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_ns_nr::ns"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_ns_nr, ns) - 4usize];
    ["Offset of field: rte_l2tpv2_msg_with_ns_nr::nr"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_ns_nr, nr) - 6usize];
};
#[doc = "L2TPv2 message Header contains option length."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_msg_with_length {
    #[doc = "< length(16)"]
    pub length: rte_be16_t,
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_with_length"]
        [::core::mem::size_of::<rte_l2tpv2_msg_with_length>() - 6usize];
    ["Alignment of rte_l2tpv2_msg_with_length"]
        [::core::mem::align_of::<rte_l2tpv2_msg_with_length>() - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_length::length"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_length, length) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_with_length::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_length, tunnel_id) - 2usize];
    ["Offset of field: rte_l2tpv2_msg_with_length::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_with_length, session_id) - 4usize];
};
#[doc = "L2TPv2 message Header without all options."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_msg_without_all_options {
    #[doc = "< tunnel ID(16)"]
    pub tunnel_id: rte_be16_t,
    #[doc = "< session ID(16)"]
    pub session_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_msg_without_all_options"]
        [::core::mem::size_of::<rte_l2tpv2_msg_without_all_options>() - 4usize];
    ["Alignment of rte_l2tpv2_msg_without_all_options"]
        [::core::mem::align_of::<rte_l2tpv2_msg_without_all_options>() - 2usize];
    ["Offset of field: rte_l2tpv2_msg_without_all_options::tunnel_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_all_options, tunnel_id) - 0usize];
    ["Offset of field: rte_l2tpv2_msg_without_all_options::session_id"]
        [::core::mem::offset_of!(rte_l2tpv2_msg_without_all_options, session_id) - 2usize];
};
#[doc = "L2TPv2 Combined Message Header Format: Common Header + Options"]
#[repr(C)]
#[repr(align(1))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_l2tpv2_combined_msg_hdr {
    pub _bindgen_opaque_blob: [u8; 26usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_l2tpv2_combined_msg_hdr__bindgen_ty_1 {
    #[doc = "header with all options"]
    pub type0: rte_l2tpv2_msg_with_all_options,
    #[doc = "header with all options except length"]
    pub type1: rte_l2tpv2_msg_without_length,
    #[doc = "header with all options except ns/nr"]
    pub type2: rte_l2tpv2_msg_without_ns_nr,
    #[doc = "header with all options except offset"]
    pub type3: rte_l2tpv2_msg_without_offset,
    #[doc = "header with offset options"]
    pub type4: rte_l2tpv2_msg_with_offset,
    #[doc = "header with ns/nr options"]
    pub type5: rte_l2tpv2_msg_with_ns_nr,
    #[doc = "header with length option"]
    pub type6: rte_l2tpv2_msg_with_length,
    #[doc = "header without all options"]
    pub type7: rte_l2tpv2_msg_without_all_options,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_combined_msg_hdr__bindgen_ty_1"]
        [::core::mem::size_of::<rte_l2tpv2_combined_msg_hdr__bindgen_ty_1>() - 24usize];
    ["Alignment of rte_l2tpv2_combined_msg_hdr__bindgen_ty_1"]
        [::core::mem::align_of::<rte_l2tpv2_combined_msg_hdr__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type0"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type0) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type1"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type1) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type2"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type2) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type3"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type3) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type4"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type4) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type5"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type5) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type6"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type6) - 0usize];
    ["Offset of field: rte_l2tpv2_combined_msg_hdr__bindgen_ty_1::type7"]
        [::core::mem::offset_of!(rte_l2tpv2_combined_msg_hdr__bindgen_ty_1, type7) - 0usize];
};
impl Default for rte_l2tpv2_combined_msg_hdr__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_l2tpv2_combined_msg_hdr"]
        [::core::mem::size_of::<rte_l2tpv2_combined_msg_hdr>() - 26usize];
    ["Alignment of rte_l2tpv2_combined_msg_hdr"]
        [::core::mem::align_of::<rte_l2tpv2_combined_msg_hdr>() - 1usize];
};
#[doc = "PPP Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ppp_hdr {
    #[doc = "< PPP address(8)"]
    pub addr: u8,
    #[doc = "< PPP control(8)"]
    pub ctrl: u8,
    #[doc = "< PPP protocol identifier(16)"]
    pub proto_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ppp_hdr"][::core::mem::size_of::<rte_ppp_hdr>() - 4usize];
    ["Alignment of rte_ppp_hdr"][::core::mem::align_of::<rte_ppp_hdr>() - 1usize];
    ["Offset of field: rte_ppp_hdr::addr"][::core::mem::offset_of!(rte_ppp_hdr, addr) - 0usize];
    ["Offset of field: rte_ppp_hdr::ctrl"][::core::mem::offset_of!(rte_ppp_hdr, ctrl) - 1usize];
    ["Offset of field: rte_ppp_hdr::proto_id"]
        [::core::mem::offset_of!(rte_ppp_hdr, proto_id) - 2usize];
};
#[doc = "GRE Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gre_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    #[doc = "< Protocol Type"]
    pub proto: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gre_hdr"][::core::mem::size_of::<rte_gre_hdr>() - 4usize];
    ["Alignment of rte_gre_hdr"][::core::mem::align_of::<rte_gre_hdr>() - 1usize];
    ["Offset of field: rte_gre_hdr::proto"][::core::mem::offset_of!(rte_gre_hdr, proto) - 2usize];
};
impl rte_gre_hdr {
    #[inline]
    pub fn res2(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u16) }
    }
    #[inline]
    pub fn set_res2(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res2_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res2_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn s(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_s(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn s_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_s_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn k(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_k(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn k_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_k_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res1(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_res1(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res1_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res1_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn c(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_c(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn c_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_c_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ver(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 3u8) as u16) }
    }
    #[inline]
    pub fn set_ver(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ver_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                3u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_ver_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn res3(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(11usize, 5u8) as u16) }
    }
    #[inline]
    pub fn set_res3(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(11usize, 5u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn res3_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                11usize,
                5u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_res3_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                11usize,
                5u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        res2: u16,
        s: u16,
        k: u16,
        res1: u16,
        c: u16,
        ver: u16,
        res3: u16,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let res2: u16 = unsafe { ::core::mem::transmute(res2) };
            res2 as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let s: u16 = unsafe { ::core::mem::transmute(s) };
            s as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let k: u16 = unsafe { ::core::mem::transmute(k) };
            k as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let res1: u16 = unsafe { ::core::mem::transmute(res1) };
            res1 as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let c: u16 = unsafe { ::core::mem::transmute(c) };
            c as u64
        });
        __bindgen_bitfield_unit.set(8usize, 3u8, {
            let ver: u16 = unsafe { ::core::mem::transmute(ver) };
            ver as u64
        });
        __bindgen_bitfield_unit.set(11usize, 5u8, {
            let res3: u16 = unsafe { ::core::mem::transmute(res3) };
            res3 as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "Optional field checksum in GRE header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gre_hdr_opt_checksum_rsvd {
    pub checksum: rte_be16_t,
    pub reserved1: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gre_hdr_opt_checksum_rsvd"]
        [::core::mem::size_of::<rte_gre_hdr_opt_checksum_rsvd>() - 4usize];
    ["Alignment of rte_gre_hdr_opt_checksum_rsvd"]
        [::core::mem::align_of::<rte_gre_hdr_opt_checksum_rsvd>() - 1usize];
    ["Offset of field: rte_gre_hdr_opt_checksum_rsvd::checksum"]
        [::core::mem::offset_of!(rte_gre_hdr_opt_checksum_rsvd, checksum) - 0usize];
    ["Offset of field: rte_gre_hdr_opt_checksum_rsvd::reserved1"]
        [::core::mem::offset_of!(rte_gre_hdr_opt_checksum_rsvd, reserved1) - 2usize];
};
#[doc = "Optional field key in GRE header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gre_hdr_opt_key {
    pub key: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gre_hdr_opt_key"][::core::mem::size_of::<rte_gre_hdr_opt_key>() - 4usize];
    ["Alignment of rte_gre_hdr_opt_key"][::core::mem::align_of::<rte_gre_hdr_opt_key>() - 1usize];
    ["Offset of field: rte_gre_hdr_opt_key::key"]
        [::core::mem::offset_of!(rte_gre_hdr_opt_key, key) - 0usize];
};
#[doc = "Optional field sequence in GRE header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_gre_hdr_opt_sequence {
    pub sequence: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_gre_hdr_opt_sequence"]
        [::core::mem::size_of::<rte_gre_hdr_opt_sequence>() - 4usize];
    ["Alignment of rte_gre_hdr_opt_sequence"]
        [::core::mem::align_of::<rte_gre_hdr_opt_sequence>() - 1usize];
    ["Offset of field: rte_gre_hdr_opt_sequence::sequence"]
        [::core::mem::offset_of!(rte_gre_hdr_opt_sequence, sequence) - 0usize];
};
#[doc = "MACsec Header (SecTAG)"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_macsec_hdr {
    #[doc = "Tag control information and Association number of secure channel.\nVarious bits of TCI and AN are masked using RTE_MACSEC_TCI_* and RTE_MACSEC_AN_MASK."]
    pub tci_an: u8,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Packet number to support replay protection."]
    pub packet_number: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_macsec_hdr"][::core::mem::size_of::<rte_macsec_hdr>() - 6usize];
    ["Alignment of rte_macsec_hdr"][::core::mem::align_of::<rte_macsec_hdr>() - 1usize];
    ["Offset of field: rte_macsec_hdr::tci_an"]
        [::core::mem::offset_of!(rte_macsec_hdr, tci_an) - 0usize];
    ["Offset of field: rte_macsec_hdr::packet_number"]
        [::core::mem::offset_of!(rte_macsec_hdr, packet_number) - 2usize];
};
impl rte_macsec_hdr {
    #[inline]
    pub fn short_length(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_short_length(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn short_length_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_short_length_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn unused(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_unused(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn unused_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_unused_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(short_length: u8, unused: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 6u8, {
            let short_length: u8 = unsafe { ::core::mem::transmute(short_length) };
            short_length as u64
        });
        __bindgen_bitfield_unit.set(6usize, 2u8, {
            let unused: u8 = unsafe { ::core::mem::transmute(unused) };
            unused as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "MACsec SCI header (8 bytes) after the MACsec header\nwhich is present if SC bit is set in tci_an."]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_macsec_sci_hdr {
    #[doc = "< Optional secure channel ID."]
    pub sci: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_macsec_sci_hdr"][::core::mem::size_of::<rte_macsec_sci_hdr>() - 8usize];
    ["Alignment of rte_macsec_sci_hdr"][::core::mem::align_of::<rte_macsec_sci_hdr>() - 1usize];
    ["Offset of field: rte_macsec_sci_hdr::sci"]
        [::core::mem::offset_of!(rte_macsec_sci_hdr, sci) - 0usize];
};
#[doc = "InfiniBand Base Transport Header according to\nIB Specification Vol 1-Release-1.4."]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ib_bth {
    #[doc = "< Opcode."]
    pub opcode: u8,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Partition key."]
    pub pkey: rte_be16_t,
    pub _bitfield_align_2: [u8; 0],
    pub _bitfield_2: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Destination QP"]
    pub dst_qp: [u8; 3usize],
    pub _bitfield_align_3: [u8; 0],
    pub _bitfield_3: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Packet Sequence Number"]
    pub psn: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ib_bth"][::core::mem::size_of::<rte_ib_bth>() - 12usize];
    ["Alignment of rte_ib_bth"][::core::mem::align_of::<rte_ib_bth>() - 1usize];
    ["Offset of field: rte_ib_bth::opcode"][::core::mem::offset_of!(rte_ib_bth, opcode) - 0usize];
    ["Offset of field: rte_ib_bth::pkey"][::core::mem::offset_of!(rte_ib_bth, pkey) - 2usize];
    ["Offset of field: rte_ib_bth::dst_qp"][::core::mem::offset_of!(rte_ib_bth, dst_qp) - 5usize];
    ["Offset of field: rte_ib_bth::psn"][::core::mem::offset_of!(rte_ib_bth, psn) - 9usize];
};
impl rte_ib_bth {
    #[inline]
    pub fn tver(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_tver(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tver_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_tver_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn padcnt(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_padcnt(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn padcnt_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_padcnt_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn m(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_m(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn m_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_m_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn se(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_se(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn se_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_se_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        tver: u8,
        padcnt: u8,
        m: u8,
        se: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let tver: u8 = unsafe { ::core::mem::transmute(tver) };
            tver as u64
        });
        __bindgen_bitfield_unit.set(4usize, 2u8, {
            let padcnt: u8 = unsafe { ::core::mem::transmute(padcnt) };
            padcnt as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let m: u8 = unsafe { ::core::mem::transmute(m) };
            m as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let se: u8 = unsafe { ::core::mem::transmute(se) };
            se as u64
        });
        __bindgen_bitfield_unit
    }
    #[inline]
    pub fn rsvd0(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_2.get(0usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_rsvd0(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_2.set(0usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rsvd0_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_2),
                0usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rsvd0_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_2),
                0usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn b(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_2.get(6usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_b(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_2.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn b_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_2),
                6usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_b_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_2),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn f(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_2.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_f(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_2.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn f_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_2),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_f_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_2),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_2(rsvd0: u8, b: u8, f: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 6u8, {
            let rsvd0: u8 = unsafe { ::core::mem::transmute(rsvd0) };
            rsvd0 as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let b: u8 = unsafe { ::core::mem::transmute(b) };
            b as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let f: u8 = unsafe { ::core::mem::transmute(f) };
            f as u64
        });
        __bindgen_bitfield_unit
    }
    #[inline]
    pub fn rsvd1(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_3.get(0usize, 7u8) as u8) }
    }
    #[inline]
    pub fn set_rsvd1(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_3.set(0usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rsvd1_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_3),
                0usize,
                7u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_rsvd1_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_3),
                0usize,
                7u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn a(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_3.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_a(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_3.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn a_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_3),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_a_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_3),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_3(rsvd1: u8, a: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 7u8, {
            let rsvd1: u8 = unsafe { ::core::mem::transmute(rsvd1) };
            rsvd1 as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let a: u8 = unsafe { ::core::mem::transmute(a) };
            a as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "Callback definition for monitoring conditions. Callbacks with this signature\nwill be used by `rte_power_monitor()` to check if the entering of power\noptimized state should be aborted.\n\n# Arguments\n\n* `val` -\nThe value read from memory.\n* `opaque` -\nCallback-specific data.\n\n# Returns\n\n0 if entering of power optimized state should proceed\n-1 if entering of power optimized state should be aborted"]
pub type rte_power_monitor_clb_t = ::core::option::Option<
    unsafe extern "C" fn(val: u64, opaque: *const u64) -> ::core::ffi::c_int,
>;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_power_monitor_cond {
    #[doc = "< Address to monitor for changes"]
    pub addr: *mut ::core::ffi::c_void,
    #[doc = "< Data size (in bytes) that will be read from the\nmonitored memory location (`addr`). Can be 1, 2,\n4, or 8. Supplying any other value will result in\nan error."]
    pub size: u8,
    #[doc = "< Callback to be used to check if\nentering power optimized state should\nbe aborted."]
    pub fn_: rte_power_monitor_clb_t,
    pub opaque: [u64; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_power_monitor_cond"][::core::mem::size_of::<rte_power_monitor_cond>() - 56usize];
    ["Alignment of rte_power_monitor_cond"]
        [::core::mem::align_of::<rte_power_monitor_cond>() - 8usize];
    ["Offset of field: rte_power_monitor_cond::addr"]
        [::core::mem::offset_of!(rte_power_monitor_cond, addr) - 0usize];
    ["Offset of field: rte_power_monitor_cond::size"]
        [::core::mem::offset_of!(rte_power_monitor_cond, size) - 8usize];
    ["Offset of field: rte_power_monitor_cond::fn_"]
        [::core::mem::offset_of!(rte_power_monitor_cond, fn_) - 16usize];
    ["Offset of field: rte_power_monitor_cond::opaque"]
        [::core::mem::offset_of!(rte_power_monitor_cond, opaque) - 24usize];
};
impl Default for rte_power_monitor_cond {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Monitor specific address for changes. This will cause the CPU to enter an\narchitecture-defined optimized power state until either the specified\nmemory address is written to, a certain TSC timestamp is reached, or other\nreasons cause the CPU to wake up.\nAdditionally, an expected value (`pmc->val`), mask (`pmc->mask`), and data\nsize (`pmc->size`) are provided in the `pmc` power monitoring condition. If\nthe mask is non-zero, the current value pointed to by the `pmc->addr` pointer\nwill be read and compared against the expected value, and if they match, the\nentering of optimized power state will be aborted. This is intended to\nprevent the CPU from entering optimized power state and waiting on a write\nthat has already happened by the time this API is called.\n@warning It is responsibility of the user to check if this function is\nsupported at runtime using `rte_cpu_get_intrinsics_support()` API call.\n\n# Arguments\n\n* `pmc` -\nThe monitoring condition structure.\n* `tsc_timestamp` -\nMaximum TSC timestamp to wait for. Note that the wait behavior is\narchitecture-dependent.\n\n# Returns\n\n0 on success\n-EINVAL on invalid parameters\n-ENOTSUP if unsupported"]
    pub fn rte_power_monitor(
        pmc: *const rte_power_monitor_cond,
        tsc_timestamp: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Wake up a specific lcore that is in a power optimized state and is monitoring\nan address.\n> **Note** It is safe to call this function if the lcore in question is not\nsleeping. The function will have no effect.\n> **Note** This function will *not* wake up a core that is in a power optimized\nstate due to calling `rte_power_pause`.\n\n# Arguments\n\n* `lcore_id` -\nLcore ID of a sleeping thread."]
    pub fn rte_power_monitor_wakeup(lcore_id: ::core::ffi::c_uint) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enter an architecture-defined optimized power state until a certain TSC\ntimestamp is reached.\n@warning It is responsibility of the user to check if this function is\nsupported at runtime using `rte_cpu_get_intrinsics_support()` API call.\n\n# Arguments\n\n* `tsc_timestamp` -\nMaximum TSC timestamp to wait for. Note that the wait behavior is\narchitecture-dependent.\n\n# Returns\n\n0 on success\n-EINVAL on invalid parameters\n-ENOTSUP if unsupported"]
    pub fn rte_power_pause(tsc_timestamp: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Monitor a set of addresses for changes. This will cause the CPU to enter an\narchitecture-defined optimized power state until either one of the specified\nmemory addresses is written to, a certain TSC timestamp is reached, or other\nreasons cause the CPU to wake up.\nAdditionally, `expected` 64-bit values and 64-bit masks are provided. If\nmask is non-zero, the current value pointed to by the `p` pointer will be\nchecked against the expected value, and if they do not match, the entering of\noptimized power state may be aborted.\n@warning It is responsibility of the user to check if this function is\nsupported at runtime using `rte_cpu_get_intrinsics_support()` API call.\nFailing to do so may result in an illegal CPU instruction error.\n\n# Arguments\n\n* `pmc` -\nAn array of monitoring condition structures.\n* `num` -\nLength of the `pmc` array.\n* `tsc_timestamp` -\nMaximum TSC timestamp to wait for. Note that the wait behavior is\narchitecture-dependent.\n\n# Returns\n\n0 on success\n-EINVAL on invalid parameters\n-ENOTSUP if unsupported"]
    pub fn rte_power_monitor_multi(
        pmc: *const rte_power_monitor_cond,
        num: u32,
        tsc_timestamp: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[link_name = "rte_ethdev_trace_rx_burst_empty_w"]
    pub fn rte_ethdev_trace_rx_burst_empty(
        port_id: u16,
        queue_id: u16,
        pkt_tbl: *mut *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[link_name = "rte_ethdev_trace_rx_burst_nonempty_w"]
    pub fn rte_ethdev_trace_rx_burst_nonempty(
        port_id: u16,
        queue_id: u16,
        pkt_tbl: *mut *mut ::core::ffi::c_void,
        nb_rx: u16,
    );
}
unsafe extern "C" {
    #[link_name = "rte_ethdev_trace_tx_burst_w"]
    pub fn rte_ethdev_trace_tx_burst(
        port_id: u16,
        queue_id: u16,
        pkts_tbl: *mut *mut ::core::ffi::c_void,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_call_rx_callbacks_empty_w"]
    pub fn rte_eth_trace_call_rx_callbacks_empty(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut ::core::ffi::c_void,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_call_rx_callbacks_nonempty_w"]
    pub fn rte_eth_trace_call_rx_callbacks_nonempty(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut ::core::ffi::c_void,
        nb_rx: u16,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_call_tx_callbacks_w"]
    pub fn rte_eth_trace_call_tx_callbacks(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut ::core::ffi::c_void,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_tx_buffer_drop_callback_w"]
    pub fn rte_eth_trace_tx_buffer_drop_callback(pkts: *mut *mut ::core::ffi::c_void, unsent: u16);
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_tx_buffer_count_callback_w"]
    pub fn rte_eth_trace_tx_buffer_count_callback(
        pkts: *mut *mut ::core::ffi::c_void,
        unsent: u16,
        count: u64,
    );
}
unsafe extern "C" {
    #[link_name = "rte_eth_trace_tx_queue_count_w"]
    pub fn rte_eth_trace_tx_queue_count(port_id: u16, queue_id: u16, rc: ::core::ffi::c_int);
}
unsafe extern "C" {
    pub static mut rte_eth_dev_logtype: ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initializes a device iterator.\nThis iterator allows accessing a list of devices matching some devargs.\n\n# Arguments\n\n* `iter` -\nDevice iterator handle initialized by the function.\nThe fields bus_str and cls_str might be dynamically allocated,\nand could be freed by calling rte_eth_iterator_cleanup().\n* `devargs` -\nDevice description string.\n\n# Returns\n\n0 on successful initialization, negative otherwise."]
    pub fn rte_eth_iterator_init(
        iter: *mut rte_dev_iterator,
        devargs: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Iterates on devices with devargs filter.\nThe ownership is not checked.\nThe next port ID is returned, and the iterator is updated.\n\n# Arguments\n\n* `iter` -\nDevice iterator handle initialized by rte_eth_iterator_init().\nSome fields bus_str and cls_str might be freed when no more port is found,\nby calling rte_eth_iterator_cleanup().\n\n# Returns\n\nA port ID if found, RTE_MAX_ETHPORTS otherwise."]
    pub fn rte_eth_iterator_next(iter: *mut rte_dev_iterator) -> u16;
}
unsafe extern "C" {
    #[doc = "Free some allocated fields of the iterator.\nThis function is automatically called by rte_eth_iterator_next()\non the last iteration (i.e. when no more matching port is found).\nIt is safe to call this function twice; it will do nothing more.\n\n# Arguments\n\n* `iter` -\nDevice iterator handle initialized by rte_eth_iterator_init().\nThe fields bus_str and cls_str are freed if needed."]
    pub fn rte_eth_iterator_cleanup(iter: *mut rte_dev_iterator);
}
#[doc = "A structure used to retrieve statistics for an Ethernet port.\nNot all statistics fields in struct rte_eth_stats are supported\nby any type of network interface card (NIC). If any statistics\nfield is not supported, its value is 0.\nAll byte-related statistics do not include Ethernet FCS regardless\nof whether these bytes have been delivered to the application\n(see RTE_ETH_RX_OFFLOAD_KEEP_CRC)."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_stats {
    #[doc = "< Total number of successfully received packets."]
    pub ipackets: u64,
    #[doc = "< Total number of successfully transmitted packets."]
    pub opackets: u64,
    #[doc = "< Total number of successfully received bytes."]
    pub ibytes: u64,
    #[doc = "< Total number of successfully transmitted bytes."]
    pub obytes: u64,
    #[doc = "Total of Rx packets dropped by the HW,\nbecause there are no available buffer (i.e. Rx queues are full)."]
    pub imissed: u64,
    #[doc = "< Total number of erroneous received packets."]
    pub ierrors: u64,
    #[doc = "< Total number of failed transmitted packets."]
    pub oerrors: u64,
    #[doc = "< Total number of Rx mbuf allocation failures."]
    pub rx_nombuf: u64,
    #[doc = "Queue stats are limited to max 256 queues */\n/** Total number of queue Rx packets."]
    pub q_ipackets: [u64; 16usize],
    #[doc = "Total number of queue Tx packets."]
    pub q_opackets: [u64; 16usize],
    #[doc = "Total number of successfully received queue bytes."]
    pub q_ibytes: [u64; 16usize],
    #[doc = "Total number of successfully transmitted queue bytes."]
    pub q_obytes: [u64; 16usize],
    #[doc = "Total number of queue packets received that are dropped."]
    pub q_errors: [u64; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_stats"][::core::mem::size_of::<rte_eth_stats>() - 704usize];
    ["Alignment of rte_eth_stats"][::core::mem::align_of::<rte_eth_stats>() - 8usize];
    ["Offset of field: rte_eth_stats::ipackets"]
        [::core::mem::offset_of!(rte_eth_stats, ipackets) - 0usize];
    ["Offset of field: rte_eth_stats::opackets"]
        [::core::mem::offset_of!(rte_eth_stats, opackets) - 8usize];
    ["Offset of field: rte_eth_stats::ibytes"]
        [::core::mem::offset_of!(rte_eth_stats, ibytes) - 16usize];
    ["Offset of field: rte_eth_stats::obytes"]
        [::core::mem::offset_of!(rte_eth_stats, obytes) - 24usize];
    ["Offset of field: rte_eth_stats::imissed"]
        [::core::mem::offset_of!(rte_eth_stats, imissed) - 32usize];
    ["Offset of field: rte_eth_stats::ierrors"]
        [::core::mem::offset_of!(rte_eth_stats, ierrors) - 40usize];
    ["Offset of field: rte_eth_stats::oerrors"]
        [::core::mem::offset_of!(rte_eth_stats, oerrors) - 48usize];
    ["Offset of field: rte_eth_stats::rx_nombuf"]
        [::core::mem::offset_of!(rte_eth_stats, rx_nombuf) - 56usize];
    ["Offset of field: rte_eth_stats::q_ipackets"]
        [::core::mem::offset_of!(rte_eth_stats, q_ipackets) - 64usize];
    ["Offset of field: rte_eth_stats::q_opackets"]
        [::core::mem::offset_of!(rte_eth_stats, q_opackets) - 192usize];
    ["Offset of field: rte_eth_stats::q_ibytes"]
        [::core::mem::offset_of!(rte_eth_stats, q_ibytes) - 320usize];
    ["Offset of field: rte_eth_stats::q_obytes"]
        [::core::mem::offset_of!(rte_eth_stats, q_obytes) - 448usize];
    ["Offset of field: rte_eth_stats::q_errors"]
        [::core::mem::offset_of!(rte_eth_stats, q_errors) - 576usize];
};
#[doc = "A structure used to retrieve link-level information of an Ethernet port."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_link {
    pub anon1: rte_eth_link__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_link__bindgen_ty_1 {
    #[doc = "< used for atomic64 read/write"]
    pub val64: u64,
    pub anon1: rte_eth_link__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_link__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< RTE_ETH_SPEED_NUM_"]
    pub link_speed: u32,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_link__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_eth_link__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_link__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_eth_link__bindgen_ty_1__bindgen_ty_1::link_speed"]
        [::core::mem::offset_of!(rte_eth_link__bindgen_ty_1__bindgen_ty_1, link_speed) - 0usize];
};
impl rte_eth_link__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn link_duplex(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_duplex(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_duplex_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_duplex_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn link_autoneg(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_autoneg(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_autoneg_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_autoneg_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn link_status(&self) -> u16 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_status(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_status_raw(this: *const Self) -> u16 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_status_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        link_duplex: u16,
        link_autoneg: u16,
        link_status: u16,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let link_duplex: u16 = unsafe { ::core::mem::transmute(link_duplex) };
            link_duplex as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let link_autoneg: u16 = unsafe { ::core::mem::transmute(link_autoneg) };
            link_autoneg as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let link_status: u16 = unsafe { ::core::mem::transmute(link_status) };
            link_status as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_link__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_eth_link__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_link__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_link__bindgen_ty_1::val64"]
        [::core::mem::offset_of!(rte_eth_link__bindgen_ty_1, val64) - 0usize];
};
impl Default for rte_eth_link__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link"][::core::mem::size_of::<rte_eth_link>() - 8usize];
    ["Alignment of rte_eth_link"][::core::mem::align_of::<rte_eth_link>() - 8usize];
};
impl Default for rte_eth_link {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to get and set lanes capabilities per link speed."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_speed_lanes_capa {
    pub speed: u32,
    pub capa: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_speed_lanes_capa"]
        [::core::mem::size_of::<rte_eth_speed_lanes_capa>() - 8usize];
    ["Alignment of rte_eth_speed_lanes_capa"]
        [::core::mem::align_of::<rte_eth_speed_lanes_capa>() - 4usize];
    ["Offset of field: rte_eth_speed_lanes_capa::speed"]
        [::core::mem::offset_of!(rte_eth_speed_lanes_capa, speed) - 0usize];
    ["Offset of field: rte_eth_speed_lanes_capa::capa"]
        [::core::mem::offset_of!(rte_eth_speed_lanes_capa, capa) - 4usize];
};
#[doc = "A structure used to configure the ring threshold registers of an Rx/Tx\nqueue for an Ethernet port."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_thresh {
    #[doc = "< Ring prefetch threshold."]
    pub pthresh: u8,
    #[doc = "< Ring host threshold."]
    pub hthresh: u8,
    #[doc = "< Ring writeback threshold."]
    pub wthresh: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_thresh"][::core::mem::size_of::<rte_eth_thresh>() - 3usize];
    ["Alignment of rte_eth_thresh"][::core::mem::align_of::<rte_eth_thresh>() - 1usize];
    ["Offset of field: rte_eth_thresh::pthresh"]
        [::core::mem::offset_of!(rte_eth_thresh, pthresh) - 0usize];
    ["Offset of field: rte_eth_thresh::hthresh"]
        [::core::mem::offset_of!(rte_eth_thresh, hthresh) - 1usize];
    ["Offset of field: rte_eth_thresh::wthresh"]
        [::core::mem::offset_of!(rte_eth_thresh, wthresh) - 2usize];
};
pub mod rte_eth_rx_mq_mode {
    #[doc = "A set of values to identify what method is to be used to route\npackets to multiple queues."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "None of DCB, RSS or VMDq mode"]
    pub const RTE_ETH_MQ_RX_NONE: Type = 0;
    #[doc = "For Rx side, only RSS is on"]
    pub const RTE_ETH_MQ_RX_RSS: Type = 1;
    #[doc = "For Rx side,only DCB is on."]
    pub const RTE_ETH_MQ_RX_DCB: Type = 2;
    #[doc = "Both DCB and RSS enable"]
    pub const RTE_ETH_MQ_RX_DCB_RSS: Type = 3;
    #[doc = "Only VMDq, no RSS nor DCB"]
    pub const RTE_ETH_MQ_RX_VMDQ_ONLY: Type = 4;
    #[doc = "RSS mode with VMDq"]
    pub const RTE_ETH_MQ_RX_VMDQ_RSS: Type = 5;
    #[doc = "Use VMDq+DCB to route traffic to queues"]
    pub const RTE_ETH_MQ_RX_VMDQ_DCB: Type = 6;
    #[doc = "Enable both VMDq and DCB in VMDq"]
    pub const RTE_ETH_MQ_RX_VMDQ_DCB_RSS: Type = 7;
}
pub mod rte_eth_tx_mq_mode {
    #[doc = "A set of values to identify what method is to be used to transmit\npackets using multi-TCs."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< It is in neither DCB nor VT mode."]
    pub const RTE_ETH_MQ_TX_NONE: Type = 0;
    #[doc = "< For Tx side,only DCB is on."]
    pub const RTE_ETH_MQ_TX_DCB: Type = 1;
    #[doc = "< For Tx side,both DCB and VT is on."]
    pub const RTE_ETH_MQ_TX_VMDQ_DCB: Type = 2;
    #[doc = "< Only VT on, no DCB"]
    pub const RTE_ETH_MQ_TX_VMDQ_ONLY: Type = 3;
}
#[doc = "A structure used to configure the Rx features of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxmode {
    #[doc = "The multi-queue packet distribution mode to be used, e.g. RSS."]
    pub mq_mode: rte_eth_rx_mq_mode::Type,
    #[doc = "< Requested MTU."]
    pub mtu: u32,
    #[doc = "Maximum allowed size of LRO aggregated packet."]
    pub max_lro_pkt_size: u32,
    #[doc = "Per-port Rx offloads to be set using RTE_ETH_RX_OFFLOAD_* flags.\nOnly offloads set on rx_offload_capa field on rte_eth_dev_info\nstructure are allowed to be set."]
    pub offloads: u64,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::core::ffi::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxmode"][::core::mem::size_of::<rte_eth_rxmode>() - 56usize];
    ["Alignment of rte_eth_rxmode"][::core::mem::align_of::<rte_eth_rxmode>() - 8usize];
    ["Offset of field: rte_eth_rxmode::mq_mode"]
        [::core::mem::offset_of!(rte_eth_rxmode, mq_mode) - 0usize];
    ["Offset of field: rte_eth_rxmode::mtu"][::core::mem::offset_of!(rte_eth_rxmode, mtu) - 4usize];
    ["Offset of field: rte_eth_rxmode::max_lro_pkt_size"]
        [::core::mem::offset_of!(rte_eth_rxmode, max_lro_pkt_size) - 8usize];
    ["Offset of field: rte_eth_rxmode::offloads"]
        [::core::mem::offset_of!(rte_eth_rxmode, offloads) - 16usize];
    ["Offset of field: rte_eth_rxmode::reserved_64s"]
        [::core::mem::offset_of!(rte_eth_rxmode, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_rxmode::reserved_ptrs"]
        [::core::mem::offset_of!(rte_eth_rxmode, reserved_ptrs) - 40usize];
};
impl Default for rte_eth_rxmode {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_vlan_type {
    #[doc = "VLAN types to indicate if it is for single VLAN, inner VLAN or outer VLAN.\nNote that single VLAN is treated the same as inner VLAN."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_VLAN_TYPE_UNKNOWN: Type = 0;
    #[doc = "< Inner VLAN."]
    pub const RTE_ETH_VLAN_TYPE_INNER: Type = 1;
    #[doc = "< Single VLAN, or outer VLAN."]
    pub const RTE_ETH_VLAN_TYPE_OUTER: Type = 2;
    pub const RTE_ETH_VLAN_TYPE_MAX: Type = 3;
}
#[doc = "A structure used to describe a VLAN filter.\nIf the bit corresponding to a VID is set, such VID is on."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_vlan_filter_conf {
    pub ids: [u64; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_vlan_filter_conf"][::core::mem::size_of::<rte_vlan_filter_conf>() - 512usize];
    ["Alignment of rte_vlan_filter_conf"][::core::mem::align_of::<rte_vlan_filter_conf>() - 8usize];
    ["Offset of field: rte_vlan_filter_conf::ids"]
        [::core::mem::offset_of!(rte_vlan_filter_conf, ids) - 0usize];
};
impl Default for rte_vlan_filter_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_hash_function {
    #[doc = "Hash function types."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "DEFAULT means driver decides which hash algorithm to pick."]
    pub const RTE_ETH_HASH_FUNCTION_DEFAULT: Type = 0;
    #[doc = "< Toeplitz"]
    pub const RTE_ETH_HASH_FUNCTION_TOEPLITZ: Type = 1;
    #[doc = "< Simple XOR"]
    pub const RTE_ETH_HASH_FUNCTION_SIMPLE_XOR: Type = 2;
    #[doc = "Symmetric Toeplitz: src, dst will be replaced by\nxor(src, dst). For the case with src/dst only,\nsrc or dst address will xor with zero pair."]
    pub const RTE_ETH_HASH_FUNCTION_SYMMETRIC_TOEPLITZ: Type = 3;
    #[doc = "Symmetric Toeplitz: L3 and L4 fields are sorted prior to\nthe hash function.\nIf src_ip > dst_ip, swap src_ip and dst_ip.\nIf src_port > dst_port, swap src_port and dst_port."]
    pub const RTE_ETH_HASH_FUNCTION_SYMMETRIC_TOEPLITZ_SORT: Type = 4;
    #[doc = "Symmetric Toeplitz: L3 and L4 fields are sorted prior to\nthe hash function.\nIf src_ip > dst_ip, swap src_ip and dst_ip.\nIf src_port > dst_port, swap src_port and dst_port."]
    pub const RTE_ETH_HASH_FUNCTION_MAX: Type = 5;
}
#[doc = "A structure used to configure the Receive Side Scaling (RSS) feature\nof an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rss_conf {
    #[doc = "In rte_eth_dev_rss_hash_conf_get(), the *rss_key_len* should be\ngreater than or equal to the *hash_key_size* which get from\nrte_eth_dev_info_get() API. And the *rss_key* should contain at least\n*hash_key_size* bytes. If not meet these requirements, the query\nresult is unreliable even if the operation returns success.\nIn rte_eth_dev_rss_hash_update() or rte_eth_dev_configure(), if\n*rss_key* is not NULL, the *rss_key_len* indicates the length of the\n*rss_key* in bytes and it should be equal to *hash_key_size*.\nIf *rss_key* is NULL, drivers are free to use a random or a default key."]
    pub rss_key: *mut u8,
    #[doc = "< hash key length in bytes."]
    pub rss_key_len: u8,
    #[doc = "Indicates the type of packets or the specific part of packets to\nwhich RSS hashing is to be applied."]
    pub rss_hf: u64,
    #[doc = "< Hash algorithm."]
    pub algorithm: rte_eth_hash_function::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rss_conf"][::core::mem::size_of::<rte_eth_rss_conf>() - 32usize];
    ["Alignment of rte_eth_rss_conf"][::core::mem::align_of::<rte_eth_rss_conf>() - 8usize];
    ["Offset of field: rte_eth_rss_conf::rss_key"]
        [::core::mem::offset_of!(rte_eth_rss_conf, rss_key) - 0usize];
    ["Offset of field: rte_eth_rss_conf::rss_key_len"]
        [::core::mem::offset_of!(rte_eth_rss_conf, rss_key_len) - 8usize];
    ["Offset of field: rte_eth_rss_conf::rss_hf"]
        [::core::mem::offset_of!(rte_eth_rss_conf, rss_hf) - 16usize];
    ["Offset of field: rte_eth_rss_conf::algorithm"]
        [::core::mem::offset_of!(rte_eth_rss_conf, algorithm) - 24usize];
};
impl Default for rte_eth_rss_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "For input set change of hash filter, if SRC_ONLY and DST_ONLY of\nthe same level are used simultaneously, it is the same case as\nnone of them are added.\n\n# Arguments\n\n* `rss_hf` -\nRSS types with SRC/DST_ONLY.\n\n# Returns\n\nRSS types."]
    #[link_name = "rte_eth_rss_hf_refine_w"]
    pub fn rte_eth_rss_hf_refine(rss_hf: u64) -> u64;
}
#[doc = "A structure used to configure 64 entries of Redirection Table of the\nReceive Side Scaling (RSS) feature of an Ethernet port. To configure\nmore than 64 entries supported by hardware, an array of this structure\nis needed."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rss_reta_entry64 {
    #[doc = "Mask bits indicate which entries need to be updated/queried."]
    pub mask: u64,
    #[doc = "Group of 64 redirection table entries."]
    pub reta: [u16; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rss_reta_entry64"]
        [::core::mem::size_of::<rte_eth_rss_reta_entry64>() - 136usize];
    ["Alignment of rte_eth_rss_reta_entry64"]
        [::core::mem::align_of::<rte_eth_rss_reta_entry64>() - 8usize];
    ["Offset of field: rte_eth_rss_reta_entry64::mask"]
        [::core::mem::offset_of!(rte_eth_rss_reta_entry64, mask) - 0usize];
    ["Offset of field: rte_eth_rss_reta_entry64::reta"]
        [::core::mem::offset_of!(rte_eth_rss_reta_entry64, reta) - 8usize];
};
impl Default for rte_eth_rss_reta_entry64 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_nb_tcs {
    #[doc = "This enum indicates the possible number of traffic classes\nin DCB configurations"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< 4 TCs with DCB."]
    pub const RTE_ETH_4_TCS: Type = 4;
    #[doc = "< 8 TCs with DCB."]
    pub const RTE_ETH_8_TCS: Type = 8;
}
pub mod rte_eth_nb_pools {
    #[doc = "This enum indicates the possible number of queue pools\nin VMDq configurations."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< 8 VMDq pools."]
    pub const RTE_ETH_8_POOLS: Type = 8;
    #[doc = "< 16 VMDq pools."]
    pub const RTE_ETH_16_POOLS: Type = 16;
    #[doc = "< 32 VMDq pools."]
    pub const RTE_ETH_32_POOLS: Type = 32;
    #[doc = "< 64 VMDq pools."]
    pub const RTE_ETH_64_POOLS: Type = 64;
}
#[doc = "This structure may be extended in future."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_rx_conf {
    #[doc = "< Possible DCB TCs, 4 or 8 TCs"]
    pub nb_tcs: rte_eth_nb_tcs::Type,
    #[doc = "Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_rx_conf"][::core::mem::size_of::<rte_eth_dcb_rx_conf>() - 12usize];
    ["Alignment of rte_eth_dcb_rx_conf"][::core::mem::align_of::<rte_eth_dcb_rx_conf>() - 4usize];
    ["Offset of field: rte_eth_dcb_rx_conf::nb_tcs"]
        [::core::mem::offset_of!(rte_eth_dcb_rx_conf, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_rx_conf::dcb_tc"]
        [::core::mem::offset_of!(rte_eth_dcb_rx_conf, dcb_tc) - 4usize];
};
impl Default for rte_eth_dcb_rx_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_tx_conf {
    #[doc = "< With DCB, 16 or 32 pools."]
    pub nb_queue_pools: rte_eth_nb_pools::Type,
    #[doc = "Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_tx_conf"]
        [::core::mem::size_of::<rte_eth_vmdq_dcb_tx_conf>() - 12usize];
    ["Alignment of rte_eth_vmdq_dcb_tx_conf"]
        [::core::mem::align_of::<rte_eth_vmdq_dcb_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_vmdq_dcb_tx_conf::nb_queue_pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_tx_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_tx_conf::dcb_tc"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_tx_conf, dcb_tc) - 4usize];
};
impl Default for rte_eth_vmdq_dcb_tx_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tx_conf {
    #[doc = "< Possible DCB TCs, 4 or 8 TCs."]
    pub nb_tcs: rte_eth_nb_tcs::Type,
    #[doc = "Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tx_conf"][::core::mem::size_of::<rte_eth_dcb_tx_conf>() - 12usize];
    ["Alignment of rte_eth_dcb_tx_conf"][::core::mem::align_of::<rte_eth_dcb_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_dcb_tx_conf::nb_tcs"]
        [::core::mem::offset_of!(rte_eth_dcb_tx_conf, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_tx_conf::dcb_tc"]
        [::core::mem::offset_of!(rte_eth_dcb_tx_conf, dcb_tc) - 4usize];
};
impl Default for rte_eth_dcb_tx_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_tx_conf {
    #[doc = "< VMDq mode, 64 pools."]
    pub nb_queue_pools: rte_eth_nb_pools::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_tx_conf"][::core::mem::size_of::<rte_eth_vmdq_tx_conf>() - 4usize];
    ["Alignment of rte_eth_vmdq_tx_conf"][::core::mem::align_of::<rte_eth_vmdq_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_vmdq_tx_conf::nb_queue_pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_tx_conf, nb_queue_pools) - 0usize];
};
impl Default for rte_eth_vmdq_tx_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure the VMDq+DCB feature\nof an Ethernet port.\nUsing this feature, packets are routed to a pool of queues, based\non the VLAN ID in the VLAN tag, and then to a specific queue within\nthat pool, using the user priority VLAN tag field.\nA default pool may be used, if desired, to route all traffic which\ndoes not match the VLAN filter rules."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_conf {
    #[doc = "< With DCB, 16 or 32 pools"]
    pub nb_queue_pools: rte_eth_nb_pools::Type,
    #[doc = "< If non-zero, use a default pool"]
    pub enable_default_pool: u8,
    #[doc = "< The default pool, if applicable"]
    pub default_pool: u8,
    #[doc = "< We can have up to 64 filters/mappings"]
    pub nb_pool_maps: u8,
    #[doc = "< VMDq VLAN pool maps."]
    pub pool_map: [rte_eth_vmdq_dcb_conf__bindgen_ty_1; 64usize],
    #[doc = "Selects a queue in a pool"]
    pub dcb_tc: [u8; 8usize],
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_conf__bindgen_ty_1 {
    #[doc = "< The VLAN ID of the received frame"]
    pub vlan_id: u16,
    #[doc = "< Bitmask of pools for packet Rx"]
    pub pools: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_conf__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_vmdq_dcb_conf__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_eth_vmdq_dcb_conf__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_vmdq_dcb_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf__bindgen_ty_1::vlan_id"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf__bindgen_ty_1, vlan_id) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf__bindgen_ty_1::pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf__bindgen_ty_1, pools) - 8usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_conf"][::core::mem::size_of::<rte_eth_vmdq_dcb_conf>() - 1040usize];
    ["Alignment of rte_eth_vmdq_dcb_conf"]
        [::core::mem::align_of::<rte_eth_vmdq_dcb_conf>() - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::nb_queue_pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::enable_default_pool"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, enable_default_pool) - 4usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::default_pool"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, default_pool) - 5usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::nb_pool_maps"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, nb_pool_maps) - 6usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::pool_map"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, pool_map) - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::dcb_tc"]
        [::core::mem::offset_of!(rte_eth_vmdq_dcb_conf, dcb_tc) - 1032usize];
};
impl Default for rte_eth_vmdq_dcb_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure the VMDq feature of an Ethernet port when\nnot combined with the DCB feature.\nUsing this feature, packets are routed to a pool of queues. By default,\nthe pool selection is based on the MAC address, the VLAN ID in the\nVLAN tag as specified in the pool_map array.\nPassing the RTE_ETH_VMDQ_ACCEPT_UNTAG in the rx_mode field allows pool\nselection using only the MAC address. MAC address to pool mapping is done\nusing the rte_eth_dev_mac_addr_add function, with the pool parameter\ncorresponding to the pool ID.\nQueue selection within the selected pool will be done using RSS when\nit is enabled or revert to the first queue of the pool if not.\nA default pool may be used, if desired, to route all traffic which\ndoes not match the VLAN filter rules or any pool MAC address."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_rx_conf {
    #[doc = "< VMDq only mode, 8 or 64 pools"]
    pub nb_queue_pools: rte_eth_nb_pools::Type,
    #[doc = "< If non-zero, use a default pool"]
    pub enable_default_pool: u8,
    #[doc = "< The default pool, if applicable"]
    pub default_pool: u8,
    #[doc = "< Enable VT loop back"]
    pub enable_loop_back: u8,
    #[doc = "< We can have up to 64 filters/mappings"]
    pub nb_pool_maps: u8,
    #[doc = "< Flags from RTE_ETH_VMDQ_ACCEPT_*"]
    pub rx_mode: u32,
    #[doc = "< VMDq VLAN pool maps."]
    pub pool_map: [rte_eth_vmdq_rx_conf__bindgen_ty_1; 64usize],
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_vmdq_rx_conf__bindgen_ty_1 {
    #[doc = "< The VLAN ID of the received frame"]
    pub vlan_id: u16,
    #[doc = "< Bitmask of pools for packet Rx"]
    pub pools: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_rx_conf__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_vmdq_rx_conf__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_eth_vmdq_rx_conf__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_vmdq_rx_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf__bindgen_ty_1::vlan_id"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf__bindgen_ty_1, vlan_id) - 0usize];
    ["Offset of field: rte_eth_vmdq_rx_conf__bindgen_ty_1::pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf__bindgen_ty_1, pools) - 8usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_rx_conf"][::core::mem::size_of::<rte_eth_vmdq_rx_conf>() - 1040usize];
    ["Alignment of rte_eth_vmdq_rx_conf"][::core::mem::align_of::<rte_eth_vmdq_rx_conf>() - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::nb_queue_pools"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::enable_default_pool"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, enable_default_pool) - 4usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::default_pool"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, default_pool) - 5usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::enable_loop_back"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, enable_loop_back) - 6usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::nb_pool_maps"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, nb_pool_maps) - 7usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::rx_mode"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, rx_mode) - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::pool_map"]
        [::core::mem::offset_of!(rte_eth_vmdq_rx_conf, pool_map) - 16usize];
};
impl Default for rte_eth_vmdq_rx_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure the Tx features of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txmode {
    #[doc = "< Tx multi-queues mode."]
    pub mq_mode: rte_eth_tx_mq_mode::Type,
    #[doc = "Per-port Tx offloads to be set using RTE_ETH_TX_OFFLOAD_* flags.\nOnly offloads set on tx_offload_capa field on rte_eth_dev_info\nstructure are allowed to be set."]
    pub offloads: u64,
    pub pvid: u16,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::core::ffi::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txmode"][::core::mem::size_of::<rte_eth_txmode>() - 56usize];
    ["Alignment of rte_eth_txmode"][::core::mem::align_of::<rte_eth_txmode>() - 8usize];
    ["Offset of field: rte_eth_txmode::mq_mode"]
        [::core::mem::offset_of!(rte_eth_txmode, mq_mode) - 0usize];
    ["Offset of field: rte_eth_txmode::offloads"]
        [::core::mem::offset_of!(rte_eth_txmode, offloads) - 8usize];
    ["Offset of field: rte_eth_txmode::pvid"]
        [::core::mem::offset_of!(rte_eth_txmode, pvid) - 16usize];
    ["Offset of field: rte_eth_txmode::reserved_64s"]
        [::core::mem::offset_of!(rte_eth_txmode, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_txmode::reserved_ptrs"]
        [::core::mem::offset_of!(rte_eth_txmode, reserved_ptrs) - 40usize];
};
impl Default for rte_eth_txmode {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_eth_txmode {
    #[inline]
    pub fn hw_vlan_reject_tagged(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_reject_tagged(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_reject_tagged_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_reject_tagged_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hw_vlan_reject_untagged(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_reject_untagged(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_reject_untagged_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_reject_untagged_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hw_vlan_insert_pvid(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_insert_pvid(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_insert_pvid_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_insert_pvid_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        hw_vlan_reject_tagged: u8,
        hw_vlan_reject_untagged: u8,
        hw_vlan_insert_pvid: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let hw_vlan_reject_tagged: u8 =
                unsafe { ::core::mem::transmute(hw_vlan_reject_tagged) };
            hw_vlan_reject_tagged as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let hw_vlan_reject_untagged: u8 =
                unsafe { ::core::mem::transmute(hw_vlan_reject_untagged) };
            hw_vlan_reject_untagged as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let hw_vlan_insert_pvid: u8 = unsafe { ::core::mem::transmute(hw_vlan_insert_pvid) };
            hw_vlan_insert_pvid as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nA structure used to configure an Rx packet segment to split.\nIf RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT flag is set in offloads field,\nthe PMD will split the received packets into multiple segments\naccording to the specification in the description array:\n- The first network buffer will be allocated from the memory pool,\nspecified in the first array element, the second buffer, from the\npool in the second element, and so on.\n- The proto_hdrs in the elements define the split position of\nreceived packets.\n- The offsets from the segment description elements specify\nthe data offset from the buffer beginning except the first mbuf.\nThe first segment offset is added with RTE_PKTMBUF_HEADROOM.\n- The lengths in the elements define the maximal data amount\nbeing received to each segment. The receiving starts with filling\nup the first mbuf data buffer up to specified length. If the\nthere are data remaining (packet is longer than buffer in the first\nmbuf) the following data will be pushed to the next segment\nup to its own length, and so on.\n- If the length in the segment description element is zero\nthe actual buffer size will be deduced from the appropriate\nmemory pool properties.\n- If there is not enough elements to describe the buffer for entire\npacket of maximal length the following parameters will be used\nfor the all remaining segments:\n- pool from the last valid element\n- the buffer size from this pool\n- zero offset\n- Length based buffer split:\n- mp, length, offset should be configured.\n- The proto_hdr field must be 0.\n- Protocol header based buffer split:\n- mp, offset, proto_hdr should be configured.\n- The length field must be 0.\n- The proto_hdr field in the last segment should be 0.\n- When protocol header split is enabled, NIC may receive packets\nwhich do not match all the protocol headers within the Rx segments.\nAt this point, NIC will have two possible split behaviors according to\nmatching results, one is exact match, another is longest match.\nThe split result of NIC must belong to one of them.\nThe exact match means NIC only do split when the packets exactly match all\nthe protocol headers in the segments.\nOtherwise, the whole packet will be put into the last valid mempool.\nThe longest match means NIC will do split until packets mismatch\nthe protocol header in the segments.\nThe rest will be put into the last valid pool."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxseg_split {
    #[doc = "< Memory pool to allocate segment from."]
    pub mp: *mut rte_mempool,
    #[doc = "< Segment data length, configures split point."]
    pub length: u16,
    #[doc = "< Data offset from beginning of mbuf data buffer."]
    pub offset: u16,
    #[doc = "proto_hdr defines a bit mask of the protocol sequence as RTE_PTYPE_*.\nThe last RTE_PTYPE* in the mask indicates the split position.\nIf one protocol header is defined to split packets into two segments,\nfor non-tunneling packets, the complete protocol sequence should be defined.\nFor tunneling packets, for simplicity, only the tunnel and inner part of\ncomplete protocol sequence is required.\nIf several protocol headers are defined to split packets into multi-segments,\nthe repeated parts of adjacent segments should be omitted."]
    pub proto_hdr: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg_split"][::core::mem::size_of::<rte_eth_rxseg_split>() - 16usize];
    ["Alignment of rte_eth_rxseg_split"][::core::mem::align_of::<rte_eth_rxseg_split>() - 8usize];
    ["Offset of field: rte_eth_rxseg_split::mp"]
        [::core::mem::offset_of!(rte_eth_rxseg_split, mp) - 0usize];
    ["Offset of field: rte_eth_rxseg_split::length"]
        [::core::mem::offset_of!(rte_eth_rxseg_split, length) - 8usize];
    ["Offset of field: rte_eth_rxseg_split::offset"]
        [::core::mem::offset_of!(rte_eth_rxseg_split, offset) - 10usize];
    ["Offset of field: rte_eth_rxseg_split::proto_hdr"]
        [::core::mem::offset_of!(rte_eth_rxseg_split, proto_hdr) - 12usize];
};
impl Default for rte_eth_rxseg_split {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nA common structure used to describe Rx packet segment properties."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_rxseg {
    #[doc = "The settings for buffer split offload."]
    pub split: rte_eth_rxseg_split,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg"][::core::mem::size_of::<rte_eth_rxseg>() - 16usize];
    ["Alignment of rte_eth_rxseg"][::core::mem::align_of::<rte_eth_rxseg>() - 8usize];
    ["Offset of field: rte_eth_rxseg::split"]
        [::core::mem::offset_of!(rte_eth_rxseg, split) - 0usize];
};
impl Default for rte_eth_rxseg {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure an Rx ring of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxconf {
    #[doc = "< Rx ring threshold registers."]
    pub rx_thresh: rte_eth_thresh,
    #[doc = "< Drives the freeing of Rx descriptors."]
    pub rx_free_thresh: u16,
    #[doc = "< Drop packets if no descriptors are available."]
    pub rx_drop_en: u8,
    #[doc = "< Do not start queue with rte_eth_dev_start()."]
    pub rx_deferred_start: u8,
    #[doc = "< Number of descriptions in rx_seg array."]
    pub rx_nseg: u16,
    #[doc = "Share group index in Rx domain and switch domain.\nNon-zero value to enable Rx queue share, zero value disable share.\nPMD is responsible for Rx queue consistency checks to avoid member\nport's configuration contradict to each other."]
    pub share_group: u16,
    #[doc = "< Shared Rx queue ID in group"]
    pub share_qid: u16,
    #[doc = "Per-queue Rx offloads to be set using RTE_ETH_RX_OFFLOAD_* flags.\nOnly offloads set on rx_queue_offload_capa or rx_offload_capa\nfields on rte_eth_dev_info structure are allowed to be set."]
    pub offloads: u64,
    #[doc = "Points to the array of segment descriptions for an entire packet.\nArray elements are properties for consecutive Rx segments.\nThe supported capabilities of receiving segmentation is reported\nin rte_eth_dev_info.rx_seg_capa field."]
    pub rx_seg: *mut rte_eth_rxseg,
    #[doc = "Array of mempools to allocate Rx buffers from.\nThis provides support for multiple mbuf pools per Rx queue.\nThe capability is reported in device info via positive\nmax_rx_mempools.\nIt could be useful for more efficient usage of memory when an\napplication creates different mempools to steer the specific\nsize of the packet.\nIf many mempools are specified, packets received using Rx\nburst may belong to any provided mempool. From ethdev user point\nof view it is undefined how PMD/NIC chooses mempool for a packet.\nIf Rx scatter is enabled, a packet may be delivered using a chain\nof mbufs obtained from single mempool or multiple mempools based\non the NIC implementation."]
    pub rx_mempools: *mut *mut rte_mempool,
    pub rx_nmempool: u16,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::core::ffi::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxconf"][::core::mem::size_of::<rte_eth_rxconf>() - 80usize];
    ["Alignment of rte_eth_rxconf"][::core::mem::align_of::<rte_eth_rxconf>() - 8usize];
    ["Offset of field: rte_eth_rxconf::rx_thresh"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_thresh) - 0usize];
    ["Offset of field: rte_eth_rxconf::rx_free_thresh"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_free_thresh) - 4usize];
    ["Offset of field: rte_eth_rxconf::rx_drop_en"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_drop_en) - 6usize];
    ["Offset of field: rte_eth_rxconf::rx_deferred_start"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_deferred_start) - 7usize];
    ["Offset of field: rte_eth_rxconf::rx_nseg"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_nseg) - 8usize];
    ["Offset of field: rte_eth_rxconf::share_group"]
        [::core::mem::offset_of!(rte_eth_rxconf, share_group) - 10usize];
    ["Offset of field: rte_eth_rxconf::share_qid"]
        [::core::mem::offset_of!(rte_eth_rxconf, share_qid) - 12usize];
    ["Offset of field: rte_eth_rxconf::offloads"]
        [::core::mem::offset_of!(rte_eth_rxconf, offloads) - 16usize];
    ["Offset of field: rte_eth_rxconf::rx_seg"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_seg) - 24usize];
    ["Offset of field: rte_eth_rxconf::rx_mempools"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_mempools) - 32usize];
    ["Offset of field: rte_eth_rxconf::rx_nmempool"]
        [::core::mem::offset_of!(rte_eth_rxconf, rx_nmempool) - 40usize];
    ["Offset of field: rte_eth_rxconf::reserved_64s"]
        [::core::mem::offset_of!(rte_eth_rxconf, reserved_64s) - 48usize];
    ["Offset of field: rte_eth_rxconf::reserved_ptrs"]
        [::core::mem::offset_of!(rte_eth_rxconf, reserved_ptrs) - 64usize];
};
impl Default for rte_eth_rxconf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure a Tx ring of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txconf {
    #[doc = "< Tx ring threshold registers."]
    pub tx_thresh: rte_eth_thresh,
    #[doc = "< Drives the setting of RS bit on TXDs."]
    pub tx_rs_thresh: u16,
    #[doc = "< Start freeing Tx buffers if there are\nless free descriptors than this value."]
    pub tx_free_thresh: u16,
    #[doc = "< Do not start queue with rte_eth_dev_start()."]
    pub tx_deferred_start: u8,
    #[doc = "Per-queue Tx offloads to be set  using RTE_ETH_TX_OFFLOAD_* flags.\nOnly offloads set on tx_queue_offload_capa or tx_offload_capa\nfields on rte_eth_dev_info structure are allowed to be set."]
    pub offloads: u64,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::core::ffi::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txconf"][::core::mem::size_of::<rte_eth_txconf>() - 56usize];
    ["Alignment of rte_eth_txconf"][::core::mem::align_of::<rte_eth_txconf>() - 8usize];
    ["Offset of field: rte_eth_txconf::tx_thresh"]
        [::core::mem::offset_of!(rte_eth_txconf, tx_thresh) - 0usize];
    ["Offset of field: rte_eth_txconf::tx_rs_thresh"]
        [::core::mem::offset_of!(rte_eth_txconf, tx_rs_thresh) - 4usize];
    ["Offset of field: rte_eth_txconf::tx_free_thresh"]
        [::core::mem::offset_of!(rte_eth_txconf, tx_free_thresh) - 6usize];
    ["Offset of field: rte_eth_txconf::tx_deferred_start"]
        [::core::mem::offset_of!(rte_eth_txconf, tx_deferred_start) - 8usize];
    ["Offset of field: rte_eth_txconf::offloads"]
        [::core::mem::offset_of!(rte_eth_txconf, offloads) - 16usize];
    ["Offset of field: rte_eth_txconf::reserved_64s"]
        [::core::mem::offset_of!(rte_eth_txconf, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_txconf::reserved_ptrs"]
        [::core::mem::offset_of!(rte_eth_txconf, reserved_ptrs) - 40usize];
};
impl Default for rte_eth_txconf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to return the Tx or Rx hairpin queue capabilities."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_hairpin_queue_cap {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_queue_cap"]
        [::core::mem::size_of::<rte_eth_hairpin_queue_cap>() - 4usize];
    ["Alignment of rte_eth_hairpin_queue_cap"]
        [::core::mem::align_of::<rte_eth_hairpin_queue_cap>() - 4usize];
};
impl rte_eth_hairpin_queue_cap {
    #[inline]
    pub fn locked_device_memory(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_locked_device_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn locked_device_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_locked_device_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rte_memory(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rte_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rte_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rte_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 30u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 30u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                30u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                30u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        locked_device_memory: u32,
        rte_memory: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let locked_device_memory: u32 = unsafe { ::core::mem::transmute(locked_device_memory) };
            locked_device_memory as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let rte_memory: u32 = unsafe { ::core::mem::transmute(rte_memory) };
            rte_memory as u64
        });
        __bindgen_bitfield_unit.set(2usize, 30u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to return the hairpin capabilities that are supported."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_hairpin_cap {
    #[doc = "The max number of hairpin queues (different bindings)."]
    pub max_nb_queues: u16,
    #[doc = "Max number of Rx queues to be connected to one Tx queue."]
    pub max_rx_2_tx: u16,
    #[doc = "Max number of Tx queues to be connected to one Rx queue."]
    pub max_tx_2_rx: u16,
    #[doc = "< The max num of descriptors."]
    pub max_nb_desc: u16,
    #[doc = "< Rx hairpin queue capabilities."]
    pub rx_cap: rte_eth_hairpin_queue_cap,
    #[doc = "< Tx hairpin queue capabilities."]
    pub tx_cap: rte_eth_hairpin_queue_cap,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_cap"][::core::mem::size_of::<rte_eth_hairpin_cap>() - 16usize];
    ["Alignment of rte_eth_hairpin_cap"][::core::mem::align_of::<rte_eth_hairpin_cap>() - 4usize];
    ["Offset of field: rte_eth_hairpin_cap::max_nb_queues"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, max_nb_queues) - 0usize];
    ["Offset of field: rte_eth_hairpin_cap::max_rx_2_tx"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, max_rx_2_tx) - 2usize];
    ["Offset of field: rte_eth_hairpin_cap::max_tx_2_rx"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, max_tx_2_rx) - 4usize];
    ["Offset of field: rte_eth_hairpin_cap::max_nb_desc"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, max_nb_desc) - 6usize];
    ["Offset of field: rte_eth_hairpin_cap::rx_cap"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, rx_cap) - 8usize];
    ["Offset of field: rte_eth_hairpin_cap::tx_cap"]
        [::core::mem::offset_of!(rte_eth_hairpin_cap, tx_cap) - 12usize];
};
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to hold hairpin peer data."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_hairpin_peer {
    #[doc = "< Peer port."]
    pub port: u16,
    #[doc = "< Peer queue."]
    pub queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_peer"][::core::mem::size_of::<rte_eth_hairpin_peer>() - 4usize];
    ["Alignment of rte_eth_hairpin_peer"][::core::mem::align_of::<rte_eth_hairpin_peer>() - 2usize];
    ["Offset of field: rte_eth_hairpin_peer::port"]
        [::core::mem::offset_of!(rte_eth_hairpin_peer, port) - 0usize];
    ["Offset of field: rte_eth_hairpin_peer::queue"]
        [::core::mem::offset_of!(rte_eth_hairpin_peer, queue) - 2usize];
};
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to configure hairpin binding."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_hairpin_conf {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    pub peers: [rte_eth_hairpin_peer; 32usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_conf"][::core::mem::size_of::<rte_eth_hairpin_conf>() - 132usize];
    ["Alignment of rte_eth_hairpin_conf"][::core::mem::align_of::<rte_eth_hairpin_conf>() - 4usize];
    ["Offset of field: rte_eth_hairpin_conf::peers"]
        [::core::mem::offset_of!(rte_eth_hairpin_conf, peers) - 4usize];
};
impl rte_eth_hairpin_conf {
    #[inline]
    pub fn peer_count(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_peer_count(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn peer_count_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_peer_count_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tx_explicit(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_tx_explicit(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tx_explicit_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_tx_explicit_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn manual_bind(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(17usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_manual_bind(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(17usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn manual_bind_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                17usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_manual_bind_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                17usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn use_locked_device_memory(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(18usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_use_locked_device_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(18usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn use_locked_device_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                18usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_use_locked_device_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                18usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn use_rte_memory(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(19usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_use_rte_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(19usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn use_rte_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                19usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_use_rte_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                19usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn force_memory(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(20usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_force_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(20usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn force_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                20usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_force_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                20usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(21usize, 11u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(21usize, 11u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                21usize,
                11u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                21usize,
                11u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        peer_count: u32,
        tx_explicit: u32,
        manual_bind: u32,
        use_locked_device_memory: u32,
        use_rte_memory: u32,
        force_memory: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let peer_count: u32 = unsafe { ::core::mem::transmute(peer_count) };
            peer_count as u64
        });
        __bindgen_bitfield_unit.set(16usize, 1u8, {
            let tx_explicit: u32 = unsafe { ::core::mem::transmute(tx_explicit) };
            tx_explicit as u64
        });
        __bindgen_bitfield_unit.set(17usize, 1u8, {
            let manual_bind: u32 = unsafe { ::core::mem::transmute(manual_bind) };
            manual_bind as u64
        });
        __bindgen_bitfield_unit.set(18usize, 1u8, {
            let use_locked_device_memory: u32 =
                unsafe { ::core::mem::transmute(use_locked_device_memory) };
            use_locked_device_memory as u64
        });
        __bindgen_bitfield_unit.set(19usize, 1u8, {
            let use_rte_memory: u32 = unsafe { ::core::mem::transmute(use_rte_memory) };
            use_rte_memory as u64
        });
        __bindgen_bitfield_unit.set(20usize, 1u8, {
            let force_memory: u32 = unsafe { ::core::mem::transmute(force_memory) };
            force_memory as u64
        });
        __bindgen_bitfield_unit.set(21usize, 11u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "A structure contains information about HW descriptor ring limitations."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_desc_lim {
    #[doc = "< Max allowed number of descriptors."]
    pub nb_max: u16,
    #[doc = "< Min allowed number of descriptors."]
    pub nb_min: u16,
    #[doc = "< Number of descriptors should be aligned to."]
    pub nb_align: u16,
    #[doc = "Max allowed number of segments per whole packet.\n- For TSO packet this is the total number of data descriptors allowed\nby device.\n\n# See also\n\n> [`nb_mtu_seg_max`]"]
    pub nb_seg_max: u16,
    #[doc = "Max number of segments per one MTU.\n- For non-TSO packet, this is the maximum allowed number of segments\nin a single transmit packet.\n- For TSO packet each segment within the TSO may span up to this\nvalue.\n\n# See also\n\n> [`nb_seg_max`]"]
    pub nb_mtu_seg_max: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_desc_lim"][::core::mem::size_of::<rte_eth_desc_lim>() - 10usize];
    ["Alignment of rte_eth_desc_lim"][::core::mem::align_of::<rte_eth_desc_lim>() - 2usize];
    ["Offset of field: rte_eth_desc_lim::nb_max"]
        [::core::mem::offset_of!(rte_eth_desc_lim, nb_max) - 0usize];
    ["Offset of field: rte_eth_desc_lim::nb_min"]
        [::core::mem::offset_of!(rte_eth_desc_lim, nb_min) - 2usize];
    ["Offset of field: rte_eth_desc_lim::nb_align"]
        [::core::mem::offset_of!(rte_eth_desc_lim, nb_align) - 4usize];
    ["Offset of field: rte_eth_desc_lim::nb_seg_max"]
        [::core::mem::offset_of!(rte_eth_desc_lim, nb_seg_max) - 6usize];
    ["Offset of field: rte_eth_desc_lim::nb_mtu_seg_max"]
        [::core::mem::offset_of!(rte_eth_desc_lim, nb_mtu_seg_max) - 8usize];
};
pub mod rte_eth_fc_mode {
    #[doc = "This enum indicates the flow control mode"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Disable flow control."]
    pub const RTE_ETH_FC_NONE: Type = 0;
    #[doc = "< Rx pause frame, enable flowctrl on Tx side."]
    pub const RTE_ETH_FC_RX_PAUSE: Type = 1;
    #[doc = "< Tx pause frame, enable flowctrl on Rx side."]
    pub const RTE_ETH_FC_TX_PAUSE: Type = 2;
    #[doc = "< Enable flow control on both side."]
    pub const RTE_ETH_FC_FULL: Type = 3;
}
#[doc = "A structure used to configure Ethernet flow control parameter.\nThese parameters will be configured into the register of the NIC.\nPlease refer to the corresponding data sheet for proper value."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fc_conf {
    #[doc = "< High threshold value to trigger XOFF"]
    pub high_water: u32,
    #[doc = "< Low threshold value to trigger XON"]
    pub low_water: u32,
    #[doc = "< Pause quota in the Pause frame"]
    pub pause_time: u16,
    #[doc = "< Is XON frame need be sent"]
    pub send_xon: u16,
    #[doc = "< Link flow control mode"]
    pub mode: rte_eth_fc_mode::Type,
    #[doc = "< Forward MAC control frames"]
    pub mac_ctrl_frame_fwd: u8,
    #[doc = "< Use Pause autoneg"]
    pub autoneg: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fc_conf"][::core::mem::size_of::<rte_eth_fc_conf>() - 20usize];
    ["Alignment of rte_eth_fc_conf"][::core::mem::align_of::<rte_eth_fc_conf>() - 4usize];
    ["Offset of field: rte_eth_fc_conf::high_water"]
        [::core::mem::offset_of!(rte_eth_fc_conf, high_water) - 0usize];
    ["Offset of field: rte_eth_fc_conf::low_water"]
        [::core::mem::offset_of!(rte_eth_fc_conf, low_water) - 4usize];
    ["Offset of field: rte_eth_fc_conf::pause_time"]
        [::core::mem::offset_of!(rte_eth_fc_conf, pause_time) - 8usize];
    ["Offset of field: rte_eth_fc_conf::send_xon"]
        [::core::mem::offset_of!(rte_eth_fc_conf, send_xon) - 10usize];
    ["Offset of field: rte_eth_fc_conf::mode"]
        [::core::mem::offset_of!(rte_eth_fc_conf, mode) - 12usize];
    ["Offset of field: rte_eth_fc_conf::mac_ctrl_frame_fwd"]
        [::core::mem::offset_of!(rte_eth_fc_conf, mac_ctrl_frame_fwd) - 16usize];
    ["Offset of field: rte_eth_fc_conf::autoneg"]
        [::core::mem::offset_of!(rte_eth_fc_conf, autoneg) - 17usize];
};
impl Default for rte_eth_fc_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure Ethernet priority flow control parameter.\nThese parameters will be configured into the register of the NIC.\nPlease refer to the corresponding data sheet for proper value."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_conf {
    #[doc = "< General flow control parameter."]
    pub fc: rte_eth_fc_conf,
    #[doc = "< VLAN User Priority."]
    pub priority: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_conf"][::core::mem::size_of::<rte_eth_pfc_conf>() - 24usize];
    ["Alignment of rte_eth_pfc_conf"][::core::mem::align_of::<rte_eth_pfc_conf>() - 4usize];
    ["Offset of field: rte_eth_pfc_conf::fc"]
        [::core::mem::offset_of!(rte_eth_pfc_conf, fc) - 0usize];
    ["Offset of field: rte_eth_pfc_conf::priority"]
        [::core::mem::offset_of!(rte_eth_pfc_conf, priority) - 20usize];
};
impl Default for rte_eth_pfc_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to retrieve information of queue based PFC."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_info {
    #[doc = "Maximum supported traffic class as per PFC (802.1Qbb) specification."]
    pub tc_max: u8,
    #[doc = "PFC queue mode capabilities."]
    pub mode_capa: rte_eth_fc_mode::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_info"][::core::mem::size_of::<rte_eth_pfc_queue_info>() - 8usize];
    ["Alignment of rte_eth_pfc_queue_info"]
        [::core::mem::align_of::<rte_eth_pfc_queue_info>() - 4usize];
    ["Offset of field: rte_eth_pfc_queue_info::tc_max"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_info, tc_max) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_info::mode_capa"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_info, mode_capa) - 4usize];
};
impl Default for rte_eth_pfc_queue_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nA structure used to configure Ethernet priority flow control parameters for\nethdev queues.\nrte_eth_pfc_queue_conf::rx_pause structure shall be used to configure given\ntx_qid with corresponding tc. When ethdev device receives PFC frame with\nrte_eth_pfc_queue_conf::rx_pause::tc, traffic will be paused on\nrte_eth_pfc_queue_conf::rx_pause::tx_qid for that tc.\nrte_eth_pfc_queue_conf::tx_pause structure shall be used to configure given\nrx_qid. When rx_qid is congested, PFC frames are generated with\nrte_eth_pfc_queue_conf::rx_pause::tc and\nrte_eth_pfc_queue_conf::rx_pause::pause_time to the peer."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf {
    #[doc = "< Link flow control mode"]
    pub mode: rte_eth_fc_mode::Type,
    #[doc = "Valid when (mode == FC_RX_PAUSE || mode == FC_FULL)"]
    pub rx_pause: rte_eth_pfc_queue_conf__bindgen_ty_1,
    #[doc = "Valid when (mode == FC_TX_PAUSE || mode == FC_FULL)"]
    pub tx_pause: rte_eth_pfc_queue_conf__bindgen_ty_2,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf__bindgen_ty_1 {
    #[doc = "< Tx queue ID"]
    pub tx_qid: u16,
    #[doc = "Traffic class as per PFC (802.1Qbb) spec. The value must be\nin the range [0, rte_eth_pfc_queue_info::tx_max - 1]"]
    pub tc: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_pfc_queue_conf__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_pfc_queue_conf__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_pfc_queue_conf__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_1::tx_qid"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_1, tx_qid) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_1::tc"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_1, tc) - 2usize];
};
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf__bindgen_ty_2 {
    #[doc = "< Pause quota in the Pause frame"]
    pub pause_time: u16,
    #[doc = "< Rx queue ID"]
    pub rx_qid: u16,
    #[doc = "Traffic class as per PFC (802.1Qbb) spec. The value must be\nin the range [0, rte_eth_pfc_queue_info::tx_max - 1]"]
    pub tc: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf__bindgen_ty_2"]
        [::core::mem::size_of::<rte_eth_pfc_queue_conf__bindgen_ty_2>() - 6usize];
    ["Alignment of rte_eth_pfc_queue_conf__bindgen_ty_2"]
        [::core::mem::align_of::<rte_eth_pfc_queue_conf__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::pause_time"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, pause_time) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::rx_qid"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, rx_qid) - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::tc"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, tc) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf"][::core::mem::size_of::<rte_eth_pfc_queue_conf>() - 16usize];
    ["Alignment of rte_eth_pfc_queue_conf"]
        [::core::mem::align_of::<rte_eth_pfc_queue_conf>() - 4usize];
    ["Offset of field: rte_eth_pfc_queue_conf::mode"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf, mode) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf::rx_pause"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf, rx_pause) - 4usize];
    ["Offset of field: rte_eth_pfc_queue_conf::tx_pause"]
        [::core::mem::offset_of!(rte_eth_pfc_queue_conf, tx_pause) - 8usize];
};
impl Default for rte_eth_pfc_queue_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_tunnel_type {
    #[doc = "Tunnel type for device-specific classifier configuration.\n\n# See also\n\n> [`rte_eth_udp_tunnel`]"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_TUNNEL_TYPE_NONE: Type = 0;
    pub const RTE_ETH_TUNNEL_TYPE_VXLAN: Type = 1;
    pub const RTE_ETH_TUNNEL_TYPE_GENEVE: Type = 2;
    pub const RTE_ETH_TUNNEL_TYPE_TEREDO: Type = 3;
    pub const RTE_ETH_TUNNEL_TYPE_NVGRE: Type = 4;
    pub const RTE_ETH_TUNNEL_TYPE_IP_IN_GRE: Type = 5;
    pub const RTE_ETH_L2_TUNNEL_TYPE_E_TAG: Type = 6;
    pub const RTE_ETH_TUNNEL_TYPE_VXLAN_GPE: Type = 7;
    pub const RTE_ETH_TUNNEL_TYPE_ECPRI: Type = 8;
    pub const RTE_ETH_TUNNEL_TYPE_MAX: Type = 9;
}
#[doc = "UDP tunneling configuration.\nUsed to configure the classifier of a device,\nassociating an UDP port with a type of tunnel.\nSome NICs may need such configuration to properly parse a tunnel\nwith any standard or custom UDP port."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_udp_tunnel {
    #[doc = "< UDP port used for the tunnel."]
    pub udp_port: u16,
    #[doc = "< Tunnel type. # See also\n\n> [`rte_eth_tunnel_type`]"]
    pub prot_type: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_udp_tunnel"][::core::mem::size_of::<rte_eth_udp_tunnel>() - 4usize];
    ["Alignment of rte_eth_udp_tunnel"][::core::mem::align_of::<rte_eth_udp_tunnel>() - 2usize];
    ["Offset of field: rte_eth_udp_tunnel::udp_port"]
        [::core::mem::offset_of!(rte_eth_udp_tunnel, udp_port) - 0usize];
    ["Offset of field: rte_eth_udp_tunnel::prot_type"]
        [::core::mem::offset_of!(rte_eth_udp_tunnel, prot_type) - 2usize];
};
#[doc = "A structure used to enable/disable specific device interrupts."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_intr_conf {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_intr_conf"][::core::mem::size_of::<rte_eth_intr_conf>() - 4usize];
    ["Alignment of rte_eth_intr_conf"][::core::mem::align_of::<rte_eth_intr_conf>() - 4usize];
};
impl rte_eth_intr_conf {
    #[inline]
    pub fn lsc(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_lsc(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn lsc_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_lsc_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rxq(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rxq(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rxq_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rxq_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rmv(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rmv(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rmv_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rmv_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(lsc: u32, rxq: u32, rmv: u32) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let lsc: u32 = unsafe { ::core::mem::transmute(lsc) };
            lsc as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let rxq: u32 = unsafe { ::core::mem::transmute(rxq) };
            rxq as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let rmv: u32 = unsafe { ::core::mem::transmute(rmv) };
            rmv as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "A structure used to configure an Ethernet port.\nDepending upon the Rx multi-queue mode, extra advanced\nconfiguration settings may be needed."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_conf {
    #[doc = "< bitmap of RTE_ETH_LINK_SPEED_XXX of speeds to be\nused. RTE_ETH_LINK_SPEED_FIXED disables link\nautonegotiation, and a unique speed shall be\nset. Otherwise, the bitmap defines the set of\nspeeds to be advertised. If the special value\nRTE_ETH_LINK_SPEED_AUTONEG (0) is used, all speeds\nsupported are advertised."]
    pub link_speeds: u32,
    #[doc = "< Port Rx configuration."]
    pub rxmode: rte_eth_rxmode,
    #[doc = "< Port Tx configuration."]
    pub txmode: rte_eth_txmode,
    #[doc = "< Loopback operation mode. By default the value\nis 0, meaning the loopback mode is disabled.\nRead the datasheet of given Ethernet controller\nfor details. The possible values of this field\nare defined in implementation of each driver."]
    pub lpbk_mode: u32,
    #[doc = "< Port Rx filtering configuration."]
    pub rx_adv_conf: rte_eth_conf__bindgen_ty_1,
    #[doc = "< Port Tx DCB configuration (union)."]
    pub tx_adv_conf: rte_eth_conf__bindgen_ty_2,
    #[doc = "Currently,Priority Flow Control(PFC) are supported,if DCB with PFC\nis needed,and the variable must be set RTE_ETH_DCB_PFC_SUPPORT."]
    pub dcb_capability_en: u32,
    #[doc = "< Interrupt mode configuration."]
    pub intr_conf: rte_eth_intr_conf,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_conf__bindgen_ty_1 {
    #[doc = "< Port RSS configuration"]
    pub rss_conf: rte_eth_rss_conf,
    #[doc = "Port VMDq+DCB configuration."]
    pub vmdq_dcb_conf: rte_eth_vmdq_dcb_conf,
    #[doc = "Port DCB Rx configuration."]
    pub dcb_rx_conf: rte_eth_dcb_rx_conf,
    #[doc = "Port VMDq Rx configuration."]
    pub vmdq_rx_conf: rte_eth_vmdq_rx_conf,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_conf__bindgen_ty_1>() - 2128usize];
    ["Alignment of rte_eth_conf__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::rss_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_1, rss_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::vmdq_dcb_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_1, vmdq_dcb_conf) - 32usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::dcb_rx_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_1, dcb_rx_conf) - 1072usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::vmdq_rx_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_1, vmdq_rx_conf) - 1088usize];
};
impl Default for rte_eth_conf__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_conf__bindgen_ty_2 {
    #[doc = "Port VMDq+DCB Tx configuration."]
    pub vmdq_dcb_tx_conf: rte_eth_vmdq_dcb_tx_conf,
    #[doc = "Port DCB Tx configuration."]
    pub dcb_tx_conf: rte_eth_dcb_tx_conf,
    #[doc = "Port VMDq Tx configuration."]
    pub vmdq_tx_conf: rte_eth_vmdq_tx_conf,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf__bindgen_ty_2"]
        [::core::mem::size_of::<rte_eth_conf__bindgen_ty_2>() - 12usize];
    ["Alignment of rte_eth_conf__bindgen_ty_2"]
        [::core::mem::align_of::<rte_eth_conf__bindgen_ty_2>() - 4usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::vmdq_dcb_tx_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_2, vmdq_dcb_tx_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::dcb_tx_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_2, dcb_tx_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::vmdq_tx_conf"]
        [::core::mem::offset_of!(rte_eth_conf__bindgen_ty_2, vmdq_tx_conf) - 0usize];
};
impl Default for rte_eth_conf__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf"][::core::mem::size_of::<rte_eth_conf>() - 2280usize];
    ["Alignment of rte_eth_conf"][::core::mem::align_of::<rte_eth_conf>() - 8usize];
    ["Offset of field: rte_eth_conf::link_speeds"]
        [::core::mem::offset_of!(rte_eth_conf, link_speeds) - 0usize];
    ["Offset of field: rte_eth_conf::rxmode"]
        [::core::mem::offset_of!(rte_eth_conf, rxmode) - 8usize];
    ["Offset of field: rte_eth_conf::txmode"]
        [::core::mem::offset_of!(rte_eth_conf, txmode) - 64usize];
    ["Offset of field: rte_eth_conf::lpbk_mode"]
        [::core::mem::offset_of!(rte_eth_conf, lpbk_mode) - 120usize];
    ["Offset of field: rte_eth_conf::rx_adv_conf"]
        [::core::mem::offset_of!(rte_eth_conf, rx_adv_conf) - 128usize];
    ["Offset of field: rte_eth_conf::tx_adv_conf"]
        [::core::mem::offset_of!(rte_eth_conf, tx_adv_conf) - 2256usize];
    ["Offset of field: rte_eth_conf::dcb_capability_en"]
        [::core::mem::offset_of!(rte_eth_conf, dcb_capability_en) - 2268usize];
    ["Offset of field: rte_eth_conf::intr_conf"]
        [::core::mem::offset_of!(rte_eth_conf, intr_conf) - 2272usize];
};
impl Default for rte_eth_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Preferred Rx/Tx port parameters.\nThere are separate instances of this structure for transmission\nand reception respectively."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_dev_portconf {
    #[doc = "< Device-preferred burst size"]
    pub burst_size: u16,
    #[doc = "< Device-preferred size of queue rings"]
    pub ring_size: u16,
    #[doc = "< Device-preferred number of queues"]
    pub nb_queues: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_portconf"][::core::mem::size_of::<rte_eth_dev_portconf>() - 6usize];
    ["Alignment of rte_eth_dev_portconf"][::core::mem::align_of::<rte_eth_dev_portconf>() - 2usize];
    ["Offset of field: rte_eth_dev_portconf::burst_size"]
        [::core::mem::offset_of!(rte_eth_dev_portconf, burst_size) - 0usize];
    ["Offset of field: rte_eth_dev_portconf::ring_size"]
        [::core::mem::offset_of!(rte_eth_dev_portconf, ring_size) - 2usize];
    ["Offset of field: rte_eth_dev_portconf::nb_queues"]
        [::core::mem::offset_of!(rte_eth_dev_portconf, nb_queues) - 4usize];
};
#[doc = "Ethernet device associated switch information"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_switch_info {
    #[doc = "< switch name"]
    pub name: *const ::core::ffi::c_char,
    #[doc = "< switch domain ID"]
    pub domain_id: u16,
    #[doc = "Mapping to the devices physical switch port as enumerated from the\nperspective of the embedded interconnect/switch. For SR-IOV enabled\ndevice this may correspond to the VF_ID of each virtual function,\nbut each driver should explicitly define the mapping of switch\nport identifier to that physical interconnect/switch"]
    pub port_id: u16,
    #[doc = "Shared Rx queue sub-domain boundary. Only ports in same Rx domain\nand switch domain can share Rx queue. Valid only if device advertised\nRTE_ETH_DEV_CAPA_RXQ_SHARE capability."]
    pub rx_domain: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_switch_info"][::core::mem::size_of::<rte_eth_switch_info>() - 16usize];
    ["Alignment of rte_eth_switch_info"][::core::mem::align_of::<rte_eth_switch_info>() - 8usize];
    ["Offset of field: rte_eth_switch_info::name"]
        [::core::mem::offset_of!(rte_eth_switch_info, name) - 0usize];
    ["Offset of field: rte_eth_switch_info::domain_id"]
        [::core::mem::offset_of!(rte_eth_switch_info, domain_id) - 8usize];
    ["Offset of field: rte_eth_switch_info::port_id"]
        [::core::mem::offset_of!(rte_eth_switch_info, port_id) - 10usize];
    ["Offset of field: rte_eth_switch_info::rx_domain"]
        [::core::mem::offset_of!(rte_eth_switch_info, rx_domain) - 12usize];
};
impl Default for rte_eth_switch_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nEthernet device Rx buffer segmentation capabilities."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_rxseg_capa {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Maximum amount of segments to split."]
    pub max_nseg: u16,
    #[doc = "< Reserved field."]
    pub reserved: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg_capa"][::core::mem::size_of::<rte_eth_rxseg_capa>() - 8usize];
    ["Alignment of rte_eth_rxseg_capa"][::core::mem::align_of::<rte_eth_rxseg_capa>() - 4usize];
    ["Offset of field: rte_eth_rxseg_capa::max_nseg"]
        [::core::mem::offset_of!(rte_eth_rxseg_capa, max_nseg) - 2usize];
    ["Offset of field: rte_eth_rxseg_capa::reserved"]
        [::core::mem::offset_of!(rte_eth_rxseg_capa, reserved) - 4usize];
};
impl rte_eth_rxseg_capa {
    #[inline]
    pub fn multi_pools(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_multi_pools(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn multi_pools_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_multi_pools_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn offset_allowed(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_offset_allowed(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn offset_allowed_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_offset_allowed_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn offset_align_log2(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_offset_align_log2(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn offset_align_log2_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_offset_align_log2_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        multi_pools: u32,
        offset_allowed: u32,
        offset_align_log2: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let multi_pools: u32 = unsafe { ::core::mem::transmute(multi_pools) };
            multi_pools as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let offset_allowed: u32 = unsafe { ::core::mem::transmute(offset_allowed) };
            offset_allowed as u64
        });
        __bindgen_bitfield_unit.set(2usize, 4u8, {
            let offset_align_log2: u32 = unsafe { ::core::mem::transmute(offset_align_log2) };
            offset_align_log2 as u64
        });
        __bindgen_bitfield_unit
    }
}
pub mod rte_eth_representor_type {
    #[doc = "Ethernet device representor port type."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< not a representor."]
    pub const RTE_ETH_REPRESENTOR_NONE: Type = 0;
    #[doc = "< representor of Virtual Function."]
    pub const RTE_ETH_REPRESENTOR_VF: Type = 1;
    #[doc = "< representor of Sub Function."]
    pub const RTE_ETH_REPRESENTOR_SF: Type = 2;
    #[doc = "< representor of Physical Function."]
    pub const RTE_ETH_REPRESENTOR_PF: Type = 3;
}
pub mod rte_eth_err_handle_mode {
    #[doc = "@warning **EXPERIMENTAL:** this enumeration may change without prior notice.\nEthernet device error handling mode."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "No error handling modes are supported."]
    pub const RTE_ETH_ERROR_HANDLE_MODE_NONE: Type = 0;
    #[doc = "Passive error handling, after the PMD detects that a reset is required,\nthe PMD reports # See also\n\n> [`RTE_ETH_EVENT_INTR_RESET`] event,\nand the application invokes > [`rte_eth_dev_reset`] to recover the port."]
    pub const RTE_ETH_ERROR_HANDLE_MODE_PASSIVE: Type = 1;
    #[doc = "Proactive error handling, after the PMD detects that a reset is required,\nthe PMD reports # See also\n\n> [`RTE_ETH_EVENT_ERR_RECOVERING`] event,\ndo recovery internally, and finally reports the recovery result event\n(> [`RTE_ETH_EVENT_RECOVERY_*).`]"]
    pub const RTE_ETH_ERROR_HANDLE_MODE_PROACTIVE: Type = 2;
}
#[doc = "A structure used to retrieve the contextual information of\nan Ethernet device, such as the controlling driver of the\ndevice, etc..."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_info {
    #[doc = "< Generic device information"]
    pub device: *mut rte_device,
    #[doc = "< Device Driver name."]
    pub driver_name: *const ::core::ffi::c_char,
    #[doc = "< Index to bound host interface, or 0 if none.\nUse if_indextoname() to translate into an interface name."]
    pub if_index: ::core::ffi::c_uint,
    #[doc = "< Minimum MTU allowed"]
    pub min_mtu: u16,
    #[doc = "< Maximum MTU allowed"]
    pub max_mtu: u16,
    #[doc = "< Device flags"]
    pub dev_flags: *const u32,
    #[doc = "Minimum Rx buffer size per descriptor supported by HW."]
    pub min_rx_bufsize: u32,
    #[doc = "Maximum Rx buffer size per descriptor supported by HW.\nThe value is not enforced, information only to application to\noptimize mbuf size.\nIts value is UINT32_MAX when not specified by the driver."]
    pub max_rx_bufsize: u32,
    #[doc = "< Maximum configurable length of Rx pkt."]
    pub max_rx_pktlen: u32,
    #[doc = "Maximum configurable size of LRO aggregated packet."]
    pub max_lro_pkt_size: u32,
    #[doc = "< Maximum number of Rx queues."]
    pub max_rx_queues: u16,
    #[doc = "< Maximum number of Tx queues."]
    pub max_tx_queues: u16,
    #[doc = "< Maximum number of MAC addresses."]
    pub max_mac_addrs: u32,
    #[doc = "Maximum number of hash MAC addresses for MTA and UTA."]
    pub max_hash_mac_addrs: u32,
    #[doc = "< Maximum number of VFs."]
    pub max_vfs: u16,
    #[doc = "< Maximum number of VMDq pools."]
    pub max_vmdq_pools: u16,
    #[doc = "< Segmentation capability."]
    pub rx_seg_capa: rte_eth_rxseg_capa,
    #[doc = "All Rx offload capabilities including all per-queue ones"]
    pub rx_offload_capa: u64,
    #[doc = "All Tx offload capabilities including all per-queue ones"]
    pub tx_offload_capa: u64,
    #[doc = "Device per-queue Rx offload capabilities."]
    pub rx_queue_offload_capa: u64,
    #[doc = "Device per-queue Tx offload capabilities."]
    pub tx_queue_offload_capa: u64,
    #[doc = "Device redirection table size, the total number of entries."]
    pub reta_size: u16,
    #[doc = "< Hash key size in bytes"]
    pub hash_key_size: u8,
    pub rss_algo_capa: u32,
    #[doc = "RSS hash algorithms capabilities */\n/** Bit mask of RSS offloads, the bit offset also means flow type"]
    pub flow_type_rss_offloads: u64,
    #[doc = "< Default Rx configuration"]
    pub default_rxconf: rte_eth_rxconf,
    #[doc = "< Default Tx configuration"]
    pub default_txconf: rte_eth_txconf,
    #[doc = "< First queue ID for VMDq pools."]
    pub vmdq_queue_base: u16,
    #[doc = "< Queue number for VMDq pools."]
    pub vmdq_queue_num: u16,
    #[doc = "< First ID of VMDq pools."]
    pub vmdq_pool_base: u16,
    #[doc = "< Rx descriptors limits"]
    pub rx_desc_lim: rte_eth_desc_lim,
    #[doc = "< Tx descriptors limits"]
    pub tx_desc_lim: rte_eth_desc_lim,
    #[doc = "< Supported speeds bitmap (RTE_ETH_LINK_SPEED_)."]
    pub speed_capa: u32,
    #[doc = "< Number of Rx queues."]
    pub nb_rx_queues: u16,
    #[doc = "< Number of Tx queues."]
    pub nb_tx_queues: u16,
    #[doc = "Maximum number of Rx mempools supported per Rx queue.\nValue greater than 0 means that the driver supports Rx queue\nmempools specification via rx_conf->rx_mempools."]
    pub max_rx_mempools: u16,
    #[doc = "Rx parameter recommendations"]
    pub default_rxportconf: rte_eth_dev_portconf,
    #[doc = "Tx parameter recommendations"]
    pub default_txportconf: rte_eth_dev_portconf,
    #[doc = "Generic device capabilities (RTE_ETH_DEV_CAPA_)."]
    pub dev_capa: u64,
    #[doc = "Switching information for ports on a device with a\nembedded managed interconnect/switch."]
    pub switch_info: rte_eth_switch_info,
    #[doc = "Supported error handling mode."]
    pub err_handle_mode: rte_eth_err_handle_mode::Type,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::core::ffi::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_info"][::core::mem::size_of::<rte_eth_dev_info>() - 376usize];
    ["Alignment of rte_eth_dev_info"][::core::mem::align_of::<rte_eth_dev_info>() - 8usize];
    ["Offset of field: rte_eth_dev_info::device"]
        [::core::mem::offset_of!(rte_eth_dev_info, device) - 0usize];
    ["Offset of field: rte_eth_dev_info::driver_name"]
        [::core::mem::offset_of!(rte_eth_dev_info, driver_name) - 8usize];
    ["Offset of field: rte_eth_dev_info::if_index"]
        [::core::mem::offset_of!(rte_eth_dev_info, if_index) - 16usize];
    ["Offset of field: rte_eth_dev_info::min_mtu"]
        [::core::mem::offset_of!(rte_eth_dev_info, min_mtu) - 20usize];
    ["Offset of field: rte_eth_dev_info::max_mtu"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_mtu) - 22usize];
    ["Offset of field: rte_eth_dev_info::dev_flags"]
        [::core::mem::offset_of!(rte_eth_dev_info, dev_flags) - 24usize];
    ["Offset of field: rte_eth_dev_info::min_rx_bufsize"]
        [::core::mem::offset_of!(rte_eth_dev_info, min_rx_bufsize) - 32usize];
    ["Offset of field: rte_eth_dev_info::max_rx_bufsize"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_rx_bufsize) - 36usize];
    ["Offset of field: rte_eth_dev_info::max_rx_pktlen"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_rx_pktlen) - 40usize];
    ["Offset of field: rte_eth_dev_info::max_lro_pkt_size"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_lro_pkt_size) - 44usize];
    ["Offset of field: rte_eth_dev_info::max_rx_queues"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_rx_queues) - 48usize];
    ["Offset of field: rte_eth_dev_info::max_tx_queues"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_tx_queues) - 50usize];
    ["Offset of field: rte_eth_dev_info::max_mac_addrs"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_mac_addrs) - 52usize];
    ["Offset of field: rte_eth_dev_info::max_hash_mac_addrs"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_hash_mac_addrs) - 56usize];
    ["Offset of field: rte_eth_dev_info::max_vfs"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_vfs) - 60usize];
    ["Offset of field: rte_eth_dev_info::max_vmdq_pools"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_vmdq_pools) - 62usize];
    ["Offset of field: rte_eth_dev_info::rx_seg_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, rx_seg_capa) - 64usize];
    ["Offset of field: rte_eth_dev_info::rx_offload_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, rx_offload_capa) - 72usize];
    ["Offset of field: rte_eth_dev_info::tx_offload_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, tx_offload_capa) - 80usize];
    ["Offset of field: rte_eth_dev_info::rx_queue_offload_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, rx_queue_offload_capa) - 88usize];
    ["Offset of field: rte_eth_dev_info::tx_queue_offload_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, tx_queue_offload_capa) - 96usize];
    ["Offset of field: rte_eth_dev_info::reta_size"]
        [::core::mem::offset_of!(rte_eth_dev_info, reta_size) - 104usize];
    ["Offset of field: rte_eth_dev_info::hash_key_size"]
        [::core::mem::offset_of!(rte_eth_dev_info, hash_key_size) - 106usize];
    ["Offset of field: rte_eth_dev_info::rss_algo_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, rss_algo_capa) - 108usize];
    ["Offset of field: rte_eth_dev_info::flow_type_rss_offloads"]
        [::core::mem::offset_of!(rte_eth_dev_info, flow_type_rss_offloads) - 112usize];
    ["Offset of field: rte_eth_dev_info::default_rxconf"]
        [::core::mem::offset_of!(rte_eth_dev_info, default_rxconf) - 120usize];
    ["Offset of field: rte_eth_dev_info::default_txconf"]
        [::core::mem::offset_of!(rte_eth_dev_info, default_txconf) - 200usize];
    ["Offset of field: rte_eth_dev_info::vmdq_queue_base"]
        [::core::mem::offset_of!(rte_eth_dev_info, vmdq_queue_base) - 256usize];
    ["Offset of field: rte_eth_dev_info::vmdq_queue_num"]
        [::core::mem::offset_of!(rte_eth_dev_info, vmdq_queue_num) - 258usize];
    ["Offset of field: rte_eth_dev_info::vmdq_pool_base"]
        [::core::mem::offset_of!(rte_eth_dev_info, vmdq_pool_base) - 260usize];
    ["Offset of field: rte_eth_dev_info::rx_desc_lim"]
        [::core::mem::offset_of!(rte_eth_dev_info, rx_desc_lim) - 262usize];
    ["Offset of field: rte_eth_dev_info::tx_desc_lim"]
        [::core::mem::offset_of!(rte_eth_dev_info, tx_desc_lim) - 272usize];
    ["Offset of field: rte_eth_dev_info::speed_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, speed_capa) - 284usize];
    ["Offset of field: rte_eth_dev_info::nb_rx_queues"]
        [::core::mem::offset_of!(rte_eth_dev_info, nb_rx_queues) - 288usize];
    ["Offset of field: rte_eth_dev_info::nb_tx_queues"]
        [::core::mem::offset_of!(rte_eth_dev_info, nb_tx_queues) - 290usize];
    ["Offset of field: rte_eth_dev_info::max_rx_mempools"]
        [::core::mem::offset_of!(rte_eth_dev_info, max_rx_mempools) - 292usize];
    ["Offset of field: rte_eth_dev_info::default_rxportconf"]
        [::core::mem::offset_of!(rte_eth_dev_info, default_rxportconf) - 294usize];
    ["Offset of field: rte_eth_dev_info::default_txportconf"]
        [::core::mem::offset_of!(rte_eth_dev_info, default_txportconf) - 300usize];
    ["Offset of field: rte_eth_dev_info::dev_capa"]
        [::core::mem::offset_of!(rte_eth_dev_info, dev_capa) - 312usize];
    ["Offset of field: rte_eth_dev_info::switch_info"]
        [::core::mem::offset_of!(rte_eth_dev_info, switch_info) - 320usize];
    ["Offset of field: rte_eth_dev_info::err_handle_mode"]
        [::core::mem::offset_of!(rte_eth_dev_info, err_handle_mode) - 336usize];
    ["Offset of field: rte_eth_dev_info::reserved_64s"]
        [::core::mem::offset_of!(rte_eth_dev_info, reserved_64s) - 344usize];
    ["Offset of field: rte_eth_dev_info::reserved_ptrs"]
        [::core::mem::offset_of!(rte_eth_dev_info, reserved_ptrs) - 360usize];
};
impl Default for rte_eth_dev_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Ethernet device Rx queue information structure.\nUsed to retrieve information about configured queue."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxq_info {
    #[doc = "< mempool used by that queue."]
    pub mp: *mut rte_mempool,
    #[doc = "< queue config parameters."]
    pub conf: rte_eth_rxconf,
    #[doc = "< scattered packets Rx supported."]
    pub scattered_rx: u8,
    #[doc = "< one of RTE_ETH_QUEUE_STATE_*."]
    pub queue_state: u8,
    #[doc = "< configured number of RXDs."]
    pub nb_desc: u16,
    #[doc = "< hardware receive buffer size."]
    pub rx_buf_size: u16,
    #[doc = "Available Rx descriptors threshold defined as percentage\nof Rx queue size. If number of available descriptors is lower,\nthe event RTE_ETH_EVENT_RX_AVAIL_THESH is generated.\nValue 0 means that the threshold monitoring is disabled."]
    pub avail_thresh: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxq_info"][::core::mem::size_of::<rte_eth_rxq_info>() - 128usize];
    ["Alignment of rte_eth_rxq_info"][::core::mem::align_of::<rte_eth_rxq_info>() - 64usize];
    ["Offset of field: rte_eth_rxq_info::mp"]
        [::core::mem::offset_of!(rte_eth_rxq_info, mp) - 0usize];
    ["Offset of field: rte_eth_rxq_info::conf"]
        [::core::mem::offset_of!(rte_eth_rxq_info, conf) - 8usize];
    ["Offset of field: rte_eth_rxq_info::scattered_rx"]
        [::core::mem::offset_of!(rte_eth_rxq_info, scattered_rx) - 88usize];
    ["Offset of field: rte_eth_rxq_info::queue_state"]
        [::core::mem::offset_of!(rte_eth_rxq_info, queue_state) - 89usize];
    ["Offset of field: rte_eth_rxq_info::nb_desc"]
        [::core::mem::offset_of!(rte_eth_rxq_info, nb_desc) - 90usize];
    ["Offset of field: rte_eth_rxq_info::rx_buf_size"]
        [::core::mem::offset_of!(rte_eth_rxq_info, rx_buf_size) - 92usize];
    ["Offset of field: rte_eth_rxq_info::avail_thresh"]
        [::core::mem::offset_of!(rte_eth_rxq_info, avail_thresh) - 94usize];
};
impl Default for rte_eth_rxq_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Ethernet device Tx queue information structure.\nUsed to retrieve information about configured queue."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txq_info {
    #[doc = "< queue config parameters."]
    pub conf: rte_eth_txconf,
    #[doc = "< configured number of TXDs."]
    pub nb_desc: u16,
    #[doc = "< one of RTE_ETH_QUEUE_STATE_*."]
    pub queue_state: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txq_info"][::core::mem::size_of::<rte_eth_txq_info>() - 64usize];
    ["Alignment of rte_eth_txq_info"][::core::mem::align_of::<rte_eth_txq_info>() - 64usize];
    ["Offset of field: rte_eth_txq_info::conf"]
        [::core::mem::offset_of!(rte_eth_txq_info, conf) - 0usize];
    ["Offset of field: rte_eth_txq_info::nb_desc"]
        [::core::mem::offset_of!(rte_eth_txq_info, nb_desc) - 56usize];
    ["Offset of field: rte_eth_txq_info::queue_state"]
        [::core::mem::offset_of!(rte_eth_txq_info, queue_state) - 58usize];
};
impl Default for rte_eth_txq_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nEthernet device Rx queue information structure for recycling mbufs.\nUsed to retrieve Rx queue information when Tx queue reusing mbufs and moving\nthem into Rx mbuf ring."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_recycle_rxq_info {
    #[doc = "< mbuf ring of Rx queue."]
    pub mbuf_ring: *mut *mut rte_mbuf,
    #[doc = "< mempool of Rx queue."]
    pub mp: *mut rte_mempool,
    #[doc = "< head of Rx queue refilling mbufs."]
    pub refill_head: *mut u16,
    #[doc = "< tail of Rx queue receiving pkts."]
    pub receive_tail: *mut u16,
    #[doc = "< configured number of mbuf ring size."]
    pub mbuf_ring_size: u16,
    #[doc = "Requirement on mbuf refilling batch size of Rx mbuf ring.\nFor some PMD drivers, the number of Rx mbuf ring refilling mbufs\nshould be aligned with mbuf ring size, in order to simplify\nring wrapping around.\nValue 0 means that PMD drivers have no requirement for this."]
    pub refill_requirement: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_recycle_rxq_info"]
        [::core::mem::size_of::<rte_eth_recycle_rxq_info>() - 64usize];
    ["Alignment of rte_eth_recycle_rxq_info"]
        [::core::mem::align_of::<rte_eth_recycle_rxq_info>() - 64usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mbuf_ring"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, mbuf_ring) - 0usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mp"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, mp) - 8usize];
    ["Offset of field: rte_eth_recycle_rxq_info::refill_head"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, refill_head) - 16usize];
    ["Offset of field: rte_eth_recycle_rxq_info::receive_tail"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, receive_tail) - 24usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mbuf_ring_size"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, mbuf_ring_size) - 32usize];
    ["Offset of field: rte_eth_recycle_rxq_info::refill_requirement"]
        [::core::mem::offset_of!(rte_eth_recycle_rxq_info, refill_requirement) - 34usize];
};
impl Default for rte_eth_recycle_rxq_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Ethernet device Rx/Tx queue packet burst mode information structure.\nUsed to retrieve information about packet burst mode setting."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_burst_mode {
    #[doc = "< The ORed values of RTE_ETH_BURST_FLAG_xxx"]
    pub flags: u64,
    #[doc = "< burst mode information"]
    pub info: [::core::ffi::c_char; 1024usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_burst_mode"][::core::mem::size_of::<rte_eth_burst_mode>() - 1032usize];
    ["Alignment of rte_eth_burst_mode"][::core::mem::align_of::<rte_eth_burst_mode>() - 8usize];
    ["Offset of field: rte_eth_burst_mode::flags"]
        [::core::mem::offset_of!(rte_eth_burst_mode, flags) - 0usize];
    ["Offset of field: rte_eth_burst_mode::info"]
        [::core::mem::offset_of!(rte_eth_burst_mode, info) - 8usize];
};
impl Default for rte_eth_burst_mode {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "An Ethernet device extended statistic structure\nThis structure is used by rte_eth_xstats_get() to provide\nstatistics that are not provided in the generic *rte_eth_stats*\nstructure.\nIt maps a name ID, corresponding to an index in the array returned\nby rte_eth_xstats_get_names(), to a statistic value."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_xstat {
    #[doc = "< The index in xstats name array."]
    pub id: u64,
    #[doc = "< The statistic counter value."]
    pub value: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_xstat"][::core::mem::size_of::<rte_eth_xstat>() - 16usize];
    ["Alignment of rte_eth_xstat"][::core::mem::align_of::<rte_eth_xstat>() - 8usize];
    ["Offset of field: rte_eth_xstat::id"][::core::mem::offset_of!(rte_eth_xstat, id) - 0usize];
    ["Offset of field: rte_eth_xstat::value"]
        [::core::mem::offset_of!(rte_eth_xstat, value) - 8usize];
};
#[doc = "A name element for extended statistics.\nAn array of this structure is returned by rte_eth_xstats_get_names().\nIt lists the names of extended statistics for a PMD. The *rte_eth_xstat*\nstructure references these names by their array index.\nThe xstats should follow a common naming scheme.\nSome names are standardized in rte_stats_strings.\nExamples:\n- rx_missed_errors\n- tx_q3_bytes\n- tx_size_128_to_255_packets"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_xstat_name {
    #[doc = "< The statistic name."]
    pub name: [::core::ffi::c_char; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_xstat_name"][::core::mem::size_of::<rte_eth_xstat_name>() - 64usize];
    ["Alignment of rte_eth_xstat_name"][::core::mem::align_of::<rte_eth_xstat_name>() - 1usize];
    ["Offset of field: rte_eth_xstat_name::name"]
        [::core::mem::offset_of!(rte_eth_xstat_name, name) - 0usize];
};
impl Default for rte_eth_xstat_name {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to get the information of queue and\nTC mapping on both Tx and Rx paths."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping {
    pub tc_rxq: [[rte_eth_dcb_tc_queue_mapping__bindgen_ty_1; 8usize]; 64usize],
    pub tc_txq: [[rte_eth_dcb_tc_queue_mapping__bindgen_ty_2; 8usize]; 64usize],
}
#[doc = "Rx queues assigned to tc per Pool"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping__bindgen_ty_1 {
    pub base: u16,
    pub nb_queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_1::base"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_1, base) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_1::nb_queue"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_1, nb_queue) - 2usize];
};
#[doc = "Rx queues assigned to tc per Pool"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping__bindgen_ty_2 {
    pub base: u16,
    pub nb_queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping__bindgen_ty_2"]
        [::core::mem::size_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_2>() - 4usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping__bindgen_ty_2"]
        [::core::mem::align_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_2::base"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_2, base) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_2::nb_queue"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_2, nb_queue) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping"]
        [::core::mem::size_of::<rte_eth_dcb_tc_queue_mapping>() - 4096usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping"]
        [::core::mem::align_of::<rte_eth_dcb_tc_queue_mapping>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping::tc_rxq"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping, tc_rxq) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping::tc_txq"]
        [::core::mem::offset_of!(rte_eth_dcb_tc_queue_mapping, tc_txq) - 2048usize];
};
impl Default for rte_eth_dcb_tc_queue_mapping {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to get the information of DCB.\nIt includes TC UP mapping and queue TC mapping."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_info {
    #[doc = "< number of TCs"]
    pub nb_tcs: u8,
    #[doc = "< Priority to tc"]
    pub prio_tc: [u8; 8usize],
    #[doc = "< Tx BW percentage for each TC"]
    pub tc_bws: [u8; 8usize],
    #[doc = "Rx queues assigned to tc"]
    pub tc_queue: rte_eth_dcb_tc_queue_mapping,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_info"][::core::mem::size_of::<rte_eth_dcb_info>() - 4114usize];
    ["Alignment of rte_eth_dcb_info"][::core::mem::align_of::<rte_eth_dcb_info>() - 2usize];
    ["Offset of field: rte_eth_dcb_info::nb_tcs"]
        [::core::mem::offset_of!(rte_eth_dcb_info, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_info::prio_tc"]
        [::core::mem::offset_of!(rte_eth_dcb_info, prio_tc) - 1usize];
    ["Offset of field: rte_eth_dcb_info::tc_bws"]
        [::core::mem::offset_of!(rte_eth_dcb_info, tc_bws) - 9usize];
    ["Offset of field: rte_eth_dcb_info::tc_queue"]
        [::core::mem::offset_of!(rte_eth_dcb_info, tc_queue) - 18usize];
};
impl Default for rte_eth_dcb_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_fec_mode {
    #[doc = "This enum indicates the possible Forward Error Correction (FEC) modes\nof an ethdev port."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< FEC is off"]
    pub const RTE_ETH_FEC_NOFEC: Type = 0;
    #[doc = "< FEC autonegotiation modes"]
    pub const RTE_ETH_FEC_AUTO: Type = 1;
    #[doc = "< FEC using common algorithm"]
    pub const RTE_ETH_FEC_BASER: Type = 2;
    #[doc = "< FEC using RS algorithm"]
    pub const RTE_ETH_FEC_RS: Type = 3;
    #[doc = "< FEC using LLRS algorithm"]
    pub const RTE_ETH_FEC_LLRS: Type = 4;
}
#[doc = "A structure used to get capabilities per link speed"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_fec_capa {
    #[doc = "< Link speed (see RTE_ETH_SPEED_NUM_*)"]
    pub speed: u32,
    #[doc = "< FEC capabilities bitmask"]
    pub capa: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fec_capa"][::core::mem::size_of::<rte_eth_fec_capa>() - 8usize];
    ["Alignment of rte_eth_fec_capa"][::core::mem::align_of::<rte_eth_fec_capa>() - 4usize];
    ["Offset of field: rte_eth_fec_capa::speed"]
        [::core::mem::offset_of!(rte_eth_fec_capa, speed) - 0usize];
    ["Offset of field: rte_eth_fec_capa::capa"]
        [::core::mem::offset_of!(rte_eth_fec_capa, capa) - 4usize];
};
#[doc = "Function type used for Rx packet processing packet callbacks.\nThe callback function is called on Rx with a burst of packets that have\nbeen received on the given port and queue.\n\n# Arguments\n\n* `port_id` -\nThe Ethernet port on which Rx is being performed.\n* `queue` -\nThe queue on the Ethernet port which is being used to receive the packets.\n* `pkts` -\nThe burst of packets that have just been received.\n* `nb_pkts` -\nThe number of packets in the burst pointed to by \"pkts\".\n* `max_pkts` -\nThe max number of packets that can be stored in the \"pkts\" array.\n* `user_param` -\nThe arbitrary user parameter passed in by the application when the callback\nwas originally configured.\n\n# Returns\n\nThe number of packets returned to the user."]
pub type rte_rx_callback_fn = ::core::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        queue: u16,
        pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        max_pkts: u16,
        user_param: *mut ::core::ffi::c_void,
    ) -> u16,
>;
#[doc = "Function type used for Tx packet processing packet callbacks.\nThe callback function is called on Tx with a burst of packets immediately\nbefore the packets are put onto the hardware queue for transmission.\n\n# Arguments\n\n* `port_id` -\nThe Ethernet port on which Tx is being performed.\n* `queue` -\nThe queue on the Ethernet port which is being used to transmit the packets.\n* `pkts` -\nThe burst of packets that are about to be transmitted.\n* `nb_pkts` -\nThe number of packets in the burst pointed to by \"pkts\".\n* `user_param` -\nThe arbitrary user parameter passed in by the application when the callback\nwas originally configured.\n\n# Returns\n\nThe number of packets to be written to the NIC."]
pub type rte_tx_callback_fn = ::core::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        queue: u16,
        pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        user_param: *mut ::core::ffi::c_void,
    ) -> u16,
>;
pub mod rte_eth_dev_state {
    #[doc = "Possible states of an ethdev port."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Device is unused before being probed."]
    pub const RTE_ETH_DEV_UNUSED: Type = 0;
    #[doc = "Device is attached when allocated in probing."]
    pub const RTE_ETH_DEV_ATTACHED: Type = 1;
    #[doc = "Device is in removed state when plug-out is detected."]
    pub const RTE_ETH_DEV_REMOVED: Type = 2;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_dev_sriov {
    #[doc = "< SRIOV is active with 16, 32 or 64 pools"]
    pub active: u8,
    #[doc = "< Rx queue number per pool"]
    pub nb_q_per_pool: u8,
    #[doc = "< Default pool num used for PF"]
    pub def_vmdq_idx: u16,
    #[doc = "< Default pool queue start reg index"]
    pub def_pool_q_idx: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_sriov"][::core::mem::size_of::<rte_eth_dev_sriov>() - 6usize];
    ["Alignment of rte_eth_dev_sriov"][::core::mem::align_of::<rte_eth_dev_sriov>() - 2usize];
    ["Offset of field: rte_eth_dev_sriov::active"]
        [::core::mem::offset_of!(rte_eth_dev_sriov, active) - 0usize];
    ["Offset of field: rte_eth_dev_sriov::nb_q_per_pool"]
        [::core::mem::offset_of!(rte_eth_dev_sriov, nb_q_per_pool) - 1usize];
    ["Offset of field: rte_eth_dev_sriov::def_vmdq_idx"]
        [::core::mem::offset_of!(rte_eth_dev_sriov, def_vmdq_idx) - 2usize];
    ["Offset of field: rte_eth_dev_sriov::def_pool_q_idx"]
        [::core::mem::offset_of!(rte_eth_dev_sriov, def_pool_q_idx) - 4usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_owner {
    #[doc = "< The owner unique identifier."]
    pub id: u64,
    #[doc = "< The owner name."]
    pub name: [::core::ffi::c_char; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_owner"][::core::mem::size_of::<rte_eth_dev_owner>() - 72usize];
    ["Alignment of rte_eth_dev_owner"][::core::mem::align_of::<rte_eth_dev_owner>() - 8usize];
    ["Offset of field: rte_eth_dev_owner::id"]
        [::core::mem::offset_of!(rte_eth_dev_owner, id) - 0usize];
    ["Offset of field: rte_eth_dev_owner::name"]
        [::core::mem::offset_of!(rte_eth_dev_owner, name) - 8usize];
};
impl Default for rte_eth_dev_owner {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Iterates over valid ethdev ports owned by a specific owner.\n\n# Arguments\n\n* `port_id` -\nThe ID of the next possible valid owned port.\n* `owner_id` -\nThe owner identifier.\nRTE_ETH_DEV_NO_OWNER means iterate over all valid ownerless ports.\n\n# Returns\n\nNext valid port ID owned by owner_id, RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_owned_by(port_id: u16, owner_id: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Iterates over valid ethdev ports.\n\n# Arguments\n\n* `port_id` -\nThe ID of the next possible valid port.\n\n# Returns\n\nNext valid port ID, RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next(port_id: u16) -> u16;
}
unsafe extern "C" {
    #[doc = "Iterates over ethdev ports of a specified device.\n\n# Arguments\n\n* `port_id_start` -\nThe ID of the next possible valid port.\n* `parent` -\nThe generic device behind the ports to iterate.\n\n# Returns\n\nNext port ID of the device, possibly port_id_start,\nRTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_of(port_id_start: u16, parent: *const rte_device) -> u16;
}
unsafe extern "C" {
    #[doc = "Iterates over sibling ethdev ports (i.e. sharing the same rte_device).\n\n# Arguments\n\n* `port_id_start` -\nThe ID of the next possible valid sibling port.\n* `ref_port_id` -\nThe ID of a reference port to compare rte_device with.\n\n# Returns\n\nNext sibling port ID, possibly port_id_start or ref_port_id itself,\nRTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_sibling(port_id_start: u16, ref_port_id: u16) -> u16;
}
unsafe extern "C" {
    #[doc = "Get a new unique owner identifier.\nAn owner identifier is used to owns Ethernet devices by only one DPDK entity\nto avoid multiple management of device by different entities.\n\n# Arguments\n\n* `owner_id` -\nOwner identifier pointer.\n\n# Returns\n\nNegative errno value on error, 0 on success."]
    pub fn rte_eth_dev_owner_new(owner_id: *mut u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set an Ethernet device owner.\n\n# Arguments\n\n* `port_id` -\nThe identifier of the port to own.\n* `owner` -\nThe owner pointer.\n\n# Returns\n\nNegative errno value on error, 0 on success."]
    pub fn rte_eth_dev_owner_set(
        port_id: u16,
        owner: *const rte_eth_dev_owner,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unset Ethernet device owner to make the device ownerless.\n\n# Arguments\n\n* `port_id` -\nThe identifier of port to make ownerless.\n* `owner_id` -\nThe owner identifier.\n\n# Returns\n\n0 on success, negative errno value on error."]
    pub fn rte_eth_dev_owner_unset(port_id: u16, owner_id: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove owner from all Ethernet devices owned by a specific owner.\n\n# Arguments\n\n* `owner_id` -\nThe owner identifier.\n\n# Returns\n\n0 on success, negative errno value on error."]
    pub fn rte_eth_dev_owner_delete(owner_id: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the owner of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier.\n* `owner` -\nThe owner structure pointer to fill.\n\n# Returns\n\n0 on success, negative errno value on error.."]
    pub fn rte_eth_dev_owner_get(port_id: u16, owner: *mut rte_eth_dev_owner)
    -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the number of ports which are usable for the application.\nThese devices must be iterated by using the macro\n``RTE_ETH_FOREACH_DEV`` or ``RTE_ETH_FOREACH_DEV_OWNED_BY``\nto deal with non-contiguous ranges of devices.\n\n# Returns\n\nThe count of available Ethernet devices."]
    pub fn rte_eth_dev_count_avail() -> u16;
}
unsafe extern "C" {
    #[doc = "Get the total number of ports which are allocated.\nSome devices may not be available for the application.\n\n# Returns\n\nThe total count of Ethernet devices."]
    pub fn rte_eth_dev_count_total() -> u16;
}
unsafe extern "C" {
    #[doc = "Convert a numerical speed in Mbps to a bitmap flag that can be used in\nthe bitmap link_speeds of the struct rte_eth_conf\n\n# Arguments\n\n* `speed` -\nNumerical speed value in Mbps\n* `duplex` -\nRTE_ETH_LINK_[HALF/FULL]_DUPLEX (only for 10/100M speeds)\n\n# Returns\n\n0 if the speed cannot be mapped"]
    pub fn rte_eth_speed_bitflag(speed: u32, duplex: ::core::ffi::c_int) -> u32;
}
unsafe extern "C" {
    #[doc = "Get RTE_ETH_RX_OFFLOAD_* flag name.\n\n# Arguments\n\n* `offload` -\nOffload flag.\n\n# Returns\n\nOffload name or 'UNKNOWN' if the flag cannot be recognised."]
    pub fn rte_eth_dev_rx_offload_name(offload: u64) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get RTE_ETH_TX_OFFLOAD_* flag name.\n\n# Arguments\n\n* `offload` -\nOffload flag.\n\n# Returns\n\nOffload name or 'UNKNOWN' if the flag cannot be recognised."]
    pub fn rte_eth_dev_tx_offload_name(offload: u64) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nGet RTE_ETH_DEV_CAPA_* flag name.\n\n# Arguments\n\n* `capability` -\nCapability flag.\n\n# Returns\n\nCapability name or 'UNKNOWN' if the flag cannot be recognized."]
    pub fn rte_eth_dev_capability_name(capability: u64) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Configure an Ethernet device.\nThis function must be invoked first before any other function in the\nEthernet API. This function can also be re-invoked when a device is in the\nstopped state.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device to configure.\n* `nb_rx_queue` -\nThe number of receive queues to set up for the Ethernet device.\n* `nb_tx_queue` -\nThe number of transmit queues to set up for the Ethernet device.\n* `eth_conf` -\nThe pointer to the configuration data to be used for the Ethernet device.\nThe *rte_eth_conf* structure includes:\n-  the hardware offload features to activate, with dedicated fields for\neach statically configurable offload hardware feature provided by\nEthernet devices, such as IP checksum or VLAN tag stripping for\nexample.\nThe Rx offload bitfield API is obsolete and will be deprecated.\nApplications should set the ignore_bitfield_offloads bit on *rxmode*\nstructure and use offloads field to set per-port offloads instead.\n-  Any offloading set in eth_conf->[rt]xmode.offloads must be within\nthe [rt]x_offload_capa returned from rte_eth_dev_info_get().\nAny type of device supported offloading set in the input argument\neth_conf->[rt]xmode.offloads to rte_eth_dev_configure() is enabled\non all queues and it can't be disabled in rte_eth_[rt]x_queue_setup()\n-  the Receive Side Scaling (RSS) configuration when using multiple Rx\nqueues per port. Any RSS hash function set in eth_conf->rss_conf.rss_hf\nmust be within the flow_type_rss_offloads provided by drivers via\nrte_eth_dev_info_get() API.\nEmbedding all configuration information in a single data structure\nis the more flexible method that allows the addition of new features\nwithout changing the syntax of the API.\n\n# Returns\n\n- 0: Success, device configured.\n- <0: Error code returned by the driver configuration function."]
    pub fn rte_eth_dev_configure(
        port_id: u16,
        nb_rx_queue: u16,
        nb_tx_queue: u16,
        eth_conf: *const rte_eth_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet device was physically removed.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n1 when the Ethernet device is removed, otherwise 0."]
    pub fn rte_eth_dev_is_removed(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Allocate and set up a receive queue for an Ethernet device.\nThe function allocates a contiguous block of memory for *nb_rx_desc*\nreceive descriptors from a memory zone associated with *socket_id*\nand initializes each receive descriptor with a network buffer allocated\nfrom the memory pool *mb_pool*.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rx_queue_id` -\nThe index of the receive queue to set up.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `nb_rx_desc` -\nThe number of receive descriptors to allocate for the receive ring.\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in case of NUMA.\nThe value can be *SOCKET_ID_ANY* if there is no NUMA constraint for\nthe DMA memory allocated for the receive descriptors of the ring.\n* `rx_conf` -\nThe pointer to the configuration data to be used for the receive queue.\nNULL value is allowed, in which case default Rx configuration\nwill be used.\nThe *rx_conf* structure contains an *rx_thresh* structure with the values\nof the Prefetch, Host, and Write-Back threshold registers of the receive\nring.\nIn addition it contains the hardware offloads features to activate using\nthe RTE_ETH_RX_OFFLOAD_* flags.\nIf an offloading set in rx_conf->offloads\nhasn't been set in the input argument eth_conf->rxmode.offloads\nto rte_eth_dev_configure(), it is a new added offloading, it must be\nper-queue type and it is enabled for the queue.\nNo need to repeat any bit in rx_conf->offloads which has already been\nenabled in rte_eth_dev_configure() at port level. An offloading enabled\nat port level can't be disabled at queue level.\nThe configuration structure also contains the pointer to the array\nof the receiving buffer segment descriptions, see rx_seg and rx_nseg\nfields, this extended configuration might be used by split offloads like\nRTE_ETH_RX_OFFLOAD_BUFFER_SPLIT. If mb_pool is not NULL,\nthe extended configuration fields must be set to NULL and zero.\n* `mb_pool` -\nThe pointer to the memory pool from which to allocate *rte_mbuf* network\nmemory buffers to populate each descriptor of the receive ring. There are\ntwo options to provide Rx buffer configuration:\n- single pool:\nmb_pool is not NULL, rx_conf.rx_nseg is 0.\n- multiple segments description:\nmb_pool is NULL, rx_conf.rx_seg is not NULL, rx_conf.rx_nseg is not 0.\nTaken only if flag RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT is set in offloads.\n\n# Returns\n\n- 0: Success, receive queue correctly set up.\n- -EIO: if device is removed.\n- -ENODEV: if *port_id* is invalid.\n- -EINVAL: The memory pool pointer is null or the size of network buffers\nwhich can be allocated from this memory pool does not fit the various\nbuffer sizes allowed by the device controller.\n- -ENOMEM: Unable to allocate the receive ring descriptors or to\nallocate network memory buffers from the memory pool when\ninitializing receive descriptors."]
    pub fn rte_eth_rx_queue_setup(
        port_id: u16,
        rx_queue_id: u16,
        nb_rx_desc: u16,
        socket_id: ::core::ffi::c_uint,
        rx_conf: *const rte_eth_rxconf,
        mb_pool: *mut rte_mempool,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nAllocate and set up a hairpin receive queue for an Ethernet device.\nThe function set up the selected queue to be used in hairpin.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rx_queue_id` -\nThe index of the receive queue to set up.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `nb_rx_desc` -\nThe number of receive descriptors to allocate for the receive ring.\n0 means the PMD will use default value.\n* `conf` -\nThe pointer to the hairpin configuration.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENOMEM) if unable to allocate the resources."]
    pub fn rte_eth_rx_hairpin_queue_setup(
        port_id: u16,
        rx_queue_id: u16,
        nb_rx_desc: u16,
        conf: *const rte_eth_hairpin_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Allocate and set up a transmit queue for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `tx_queue_id` -\nThe index of the transmit queue to set up.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `nb_tx_desc` -\nThe number of transmit descriptors to allocate for the transmit ring.\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in case of NUMA.\nIts value can be *SOCKET_ID_ANY* if there is no NUMA constraint for\nthe DMA memory allocated for the transmit descriptors of the ring.\n* `tx_conf` -\nThe pointer to the configuration data to be used for the transmit queue.\nNULL value is allowed, in which case default Tx configuration\nwill be used.\nThe *tx_conf* structure contains the following data:\n- The *tx_thresh* structure with the values of the Prefetch, Host, and\nWrite-Back threshold registers of the transmit ring.\nWhen setting Write-Back threshold to the value greater then zero,\n*tx_rs_thresh* value should be explicitly set to one.\n- The *tx_free_thresh* value indicates the [minimum] number of network\nbuffers that must be pending in the transmit ring to trigger their\n[implicit] freeing by the driver transmit function.\n- The *tx_rs_thresh* value indicates the [minimum] number of transmit\ndescriptors that must be pending in the transmit ring before setting the\nRS bit on a descriptor by the driver transmit function.\nThe *tx_rs_thresh* value should be less or equal then\n*tx_free_thresh* value, and both of them should be less then\n*nb_tx_desc* - 3.\n- The *offloads* member contains Tx offloads to be enabled.\nIf an offloading set in tx_conf->offloads\nhasn't been set in the input argument eth_conf->txmode.offloads\nto rte_eth_dev_configure(), it is a new added offloading, it must be\nper-queue type and it is enabled for the queue.\nNo need to repeat any bit in tx_conf->offloads which has already been\nenabled in rte_eth_dev_configure() at port level. An offloading enabled\nat port level can't be disabled at queue level.\nNote that setting *tx_free_thresh* or *tx_rs_thresh* value to 0 forces\nthe transmit function to use default values.\n\n# Returns\n\n- 0: Success, the transmit queue is correctly set up.\n- -ENOMEM: Unable to allocate the transmit ring descriptors."]
    pub fn rte_eth_tx_queue_setup(
        port_id: u16,
        tx_queue_id: u16,
        nb_tx_desc: u16,
        socket_id: ::core::ffi::c_uint,
        tx_conf: *const rte_eth_txconf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nAllocate and set up a transmit hairpin queue for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `tx_queue_id` -\nThe index of the transmit queue to set up.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `nb_tx_desc` -\nThe number of transmit descriptors to allocate for the transmit ring.\n0 to set default PMD value.\n* `conf` -\nThe hairpin configuration.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENOMEM) if unable to allocate the resources."]
    pub fn rte_eth_tx_hairpin_queue_setup(
        port_id: u16,
        tx_queue_id: u16,
        nb_tx_desc: u16,
        conf: *const rte_eth_hairpin_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nGet all the hairpin peer Rx / Tx ports of the current port.\nThe caller should ensure that the array is large enough to save the ports\nlist.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `peer_ports` -\nPointer to the array to store the peer ports list.\n* `len` -\nLength of the array to store the port identifiers.\n* `direction` -\nCurrent port to peer port direction\npositive - current used as Tx to get all peer Rx ports.\nzero - current used as Rx to get all peer Tx ports.\n\n# Returns\n\n- (0 or positive) actual peer ports number.\n- (-EINVAL) if bad parameter.\n- (-ENODEV) if *port_id* invalid\n- (-ENOTSUP) if hardware doesn't support.\n- Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_get_peer_ports(
        port_id: u16,
        peer_ports: *mut u16,
        len: usize,
        direction: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nBind all hairpin Tx queues of one port to the Rx queues of the peer port.\nIt is only allowed to call this function after all hairpin queues are\nconfigured properly and the devices are in started state.\n\n# Arguments\n\n* `tx_port` -\nThe identifier of the Tx port.\n* `rx_port` -\nThe identifier of peer Rx port.\nRTE_MAX_ETHPORTS is allowed for the traversal of all devices.\nRx port ID could have the same value as Tx port ID.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if Tx port ID is invalid.\n- (-EBUSY) if device is not in started state.\n- (-ENOTSUP) if hardware doesn't support.\n- Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_bind(tx_port: u16, rx_port: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nUnbind all hairpin Tx queues of one port from the Rx queues of the peer port.\nThis should be called before closing the Tx or Rx devices, if the bind\nfunction is called before.\nAfter unbinding the hairpin ports pair, it is allowed to bind them again.\nChanging queues configuration should be after stopping the device(s).\n\n# Arguments\n\n* `tx_port` -\nThe identifier of the Tx port.\n* `rx_port` -\nThe identifier of peer Rx port.\nRTE_MAX_ETHPORTS is allowed for traversal of all devices.\nRx port ID could have the same value as Tx port ID.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if Tx port ID is invalid.\n- (-EBUSY) if device is in stopped state.\n- (-ENOTSUP) if hardware doesn't support.\n- Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_unbind(tx_port: u16, rx_port: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nGet the number of aggregated ports of the DPDK port (specified with port_id).\nIt is used when multiple ports are aggregated into a single one.\nFor the regular physical port doesn't have aggregated ports,\nthe number of aggregated ports is reported as 0.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (>=0) the number of aggregated port if success."]
    pub fn rte_eth_dev_count_aggr_ports(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nMap a Tx queue with an aggregated port of the DPDK port (specified with port_id).\nWhen multiple ports are aggregated into a single one,\nit allows to choose which port to use for Tx via a queue.\nThe application should use rte_eth_dev_map_aggr_tx_affinity()\nafter rte_eth_dev_configure(), rte_eth_tx_queue_setup(), and\nbefore rte_eth_dev_start().\n\n# Arguments\n\n* `port_id` -\nThe identifier of the port used in rte_eth_tx_burst().\n* `tx_queue_id` -\nThe index of the transmit queue used in rte_eth_tx_burst().\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `affinity` -\nThe number of the aggregated port.\nValue 0 means no affinity and traffic could be routed to any aggregated port.\nThe first aggregated port is number 1 and so on.\nThe maximum number is given by rte_eth_dev_count_aggr_ports().\n\n# Returns\n\nZero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_map_aggr_tx_affinity(
        port_id: u16,
        tx_queue_id: u16,
        affinity: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the NUMA socket to which an Ethernet device is connected\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n\n# Returns\n\n- The NUMA socket ID which the Ethernet device is connected to.\n- -1 (which translates to SOCKET_ID_ANY) if the socket could not be\ndetermined. rte_errno is then set to:\n- EINVAL is the port_id is invalid,\n- 0 is the socket could not be determined,"]
    pub fn rte_eth_dev_socket_id(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if port_id of device is attached\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n\n# Returns\n\n- 0 if port is out of range or not attached\n- 1 if device is attached"]
    pub fn rte_eth_dev_is_valid_port(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice.\nCheck if Rx queue is valid.\nIf the queue has been setup, it is considered valid.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue.\n\n# Returns\n\n- -ENODEV: if port_id is invalid.\n- -EINVAL: if queue_id is out of range or queue has not been setup.\n- 0 if Rx queue is valid."]
    pub fn rte_eth_rx_queue_is_valid(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice.\nCheck if Tx queue is valid.\nIf the queue has been setup, it is considered valid.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue.\n\n# Returns\n\n- -ENODEV: if port_id is invalid.\n- -EINVAL: if queue_id is out of range or queue has not been setup.\n- 0 if Tx queue is valid."]
    pub fn rte_eth_tx_queue_is_valid(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Start specified Rx queue of a port. It is used when rx_deferred_start\nflag of the specified queue is true.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n* `rx_queue_id` -\nThe index of the Rx queue to update the ring.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- 0: Success, the receive queue is started.\n- -ENODEV: if *port_id* is invalid.\n- -EINVAL: The queue_id out of range or belong to hairpin.\n- -EIO: if device is removed.\n- -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_rx_queue_start(port_id: u16, rx_queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Stop specified Rx queue of a port\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n* `rx_queue_id` -\nThe index of the Rx queue to update the ring.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- 0: Success, the receive queue is stopped.\n- -ENODEV: if *port_id* is invalid.\n- -EINVAL: The queue_id out of range or belong to hairpin.\n- -EIO: if device is removed.\n- -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_rx_queue_stop(port_id: u16, rx_queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Start Tx for specified queue of a port. It is used when tx_deferred_start\nflag of the specified queue is true.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n* `tx_queue_id` -\nThe index of the Tx queue to update the ring.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- 0: Success, the transmit queue is started.\n- -ENODEV: if *port_id* is invalid.\n- -EINVAL: The queue_id out of range or belong to hairpin.\n- -EIO: if device is removed.\n- -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_tx_queue_start(port_id: u16, tx_queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Stop specified Tx queue of a port\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device\n* `tx_queue_id` -\nThe index of the Tx queue to update the ring.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- 0: Success, the transmit queue is stopped.\n- -ENODEV: if *port_id* is invalid.\n- -EINVAL: The queue_id out of range or belong to hairpin.\n- -EIO: if device is removed.\n- -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_tx_queue_stop(port_id: u16, tx_queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Start an Ethernet device.\nThe device start step is the last one and consists of setting the configured\noffload features and in starting the transmit and the receive units of the\ndevice.\nDevice RTE_ETH_DEV_NOLIVE_MAC_ADDR flag causes MAC address to be set before\nPMD port start callback function is invoked.\nAll device queues (except form deferred start queues) status should be\n`RTE_ETH_QUEUE_STATE_STARTED` after start.\nOn success, all basic functions exported by the Ethernet API (link status,\nreceive/transmit, and so on) can be invoked.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- 0: Success, Ethernet device started.\n- -EAGAIN: If start operation must be retried.\n- <0: Error code of the driver device start function."]
    pub fn rte_eth_dev_start(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Stop an Ethernet device. The device can be restarted with a call to\nrte_eth_dev_start()\nAll device queues status should be `RTE_ETH_QUEUE_STATE_STOPPED` after stop.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- 0: Success, Ethernet device stopped.\n- -EBUSY: If stopping the port is not allowed in current state.\n- <0: Error code of the driver device stop function."]
    pub fn rte_eth_dev_stop(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Link up an Ethernet device.\nSet device link up will re-enable the device Rx/Tx\nfunctionality after it is previously set device linked down.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- 0: Success, Ethernet device linked up.\n- <0: Error code of the driver device link up function."]
    pub fn rte_eth_dev_set_link_up(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Link down an Ethernet device.\nThe device Rx/Tx functionality will be disabled if success,\nand it can be re-enabled with a call to\nrte_eth_dev_set_link_up()\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device."]
    pub fn rte_eth_dev_set_link_down(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Close a stopped Ethernet device. The device cannot be restarted!\nThe function frees all port resources.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- Zero if the port is closed successfully.\n- Negative if something went wrong."]
    pub fn rte_eth_dev_close(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Reset a Ethernet device and keep its port ID.\nWhen a port has to be reset passively, the DPDK application can invoke\nthis function. For example when a PF is reset, all its VFs should also\nbe reset. Normally a DPDK application can invoke this function when\nRTE_ETH_EVENT_INTR_RESET event is detected, but can also use it to start\na port reset in other circumstances.\nWhen this function is called, it first stops the port and then calls the\nPMD specific dev_uninit( ) and dev_init( ) to return the port to initial\nstate, in which no Tx and Rx queues are setup, as if the port has been\nreset and not started. The port keeps the port ID it had before the\nfunction call.\nAfter calling rte_eth_dev_reset( ), the application should use\nrte_eth_dev_configure( ), rte_eth_rx_queue_setup( ),\nrte_eth_tx_queue_setup( ), and rte_eth_dev_start( )\nto reconfigure the device as appropriate.\nNote: To avoid unexpected behavior, the application should stop calling\nTx and Rx functions before calling rte_eth_dev_reset( ). For thread\nsafety, all these controlling functions should be called from the same\nthread.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-ENOTSUP) if hardware doesn't support this function.\n- (-EPERM) if not ran from the primary process.\n- (-EIO) if re-initialisation failed or device is removed.\n- (-ENOMEM) if the reset failed due to OOM.\n- (-EAGAIN) if the reset temporarily failed and should be retried later."]
    pub fn rte_eth_dev_reset(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable receipt in promiscuous mode for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for promiscuous_enable() does not exist\nfor the device.\n- (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_promiscuous_enable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable receipt in promiscuous mode for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for promiscuous_disable() does not exist\nfor the device.\n- (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_promiscuous_disable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the value of promiscuous mode for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (1) if promiscuous is enabled\n- (0) if promiscuous is disabled.\n- (-1) on error"]
    pub fn rte_eth_promiscuous_get(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable the receipt of any multicast frame by an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for allmulticast_enable() does not exist\nfor the device.\n- (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_allmulticast_enable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable the receipt of all multicast frames by an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for allmulticast_disable() does not exist\nfor the device.\n- (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_allmulticast_disable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return the value of allmulticast mode for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (1) if allmulticast is enabled\n- (0) if allmulticast is disabled.\n- (-1) on error"]
    pub fn rte_eth_allmulticast_get(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the link status (up/down), the duplex mode (half/full),\nthe negotiation (auto/fixed), and if available, the speed (Mbps).\nIt might need to wait up to 9 seconds.\n\n# See also\n\n> [`rte_eth_link_get_nowait.`]\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `link` -\nLink information written back.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if the function is not supported in PMD.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_link_get(port_id: u16, link: *mut rte_eth_link) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the link status (up/down), the duplex mode (half/full),\nthe negotiation (auto/fixed), and if available, the speed (Mbps).\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `link` -\nLink information written back.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if the function is not supported in PMD.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_link_get_nowait(port_id: u16, link: *mut rte_eth_link) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nThe function converts a link_speed to a string. It handles all special\nvalues like unknown or none speed.\n\n# Arguments\n\n* `link_speed` -\nlink_speed of rte_eth_link struct\n\n# Returns\n\nLink speed in textual format. It's pointer to immutable memory.\nNo free is required."]
    pub fn rte_eth_link_speed_to_str(link_speed: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nThe function converts a rte_eth_link struct representing a link status to\na string.\n\n# Arguments\n\n* `str` -\nA pointer to a string to be filled with textual representation of\ndevice status. At least RTE_ETH_LINK_MAX_STR_LEN bytes should be allocated to\nstore default link status text.\n* `len` -\nLength of available memory at 'str' string.\n* `eth_link` -\nLink status returned by rte_eth_link_get function\n\n# Returns\n\nNumber of bytes written to str array or -EINVAL if bad parameter."]
    pub fn rte_eth_link_to_str(
        str_: *mut ::core::ffi::c_char,
        len: usize,
        eth_link: *const rte_eth_link,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nGet Active lanes.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `lanes` -\nDriver updates lanes with the number of active lanes.\nOn a supported NIC on link up, lanes will be a non-zero value irrespective whether the\nlink is Autonegotiated or Fixed speed. No information is displayed for error.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\nthat operation.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid."]
    pub fn rte_eth_speed_lanes_get(port_id: u16, lanes: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nSet speed lanes supported by the NIC.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `speed_lanes` -\nA non-zero number of speed lanes, that will be applied to the ethernet PHY\nalong with the fixed speed configuration. Driver returns error if the user\nlanes is not in speeds capability list.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\nthat operation.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if *lanes* count not in speeds capability list."]
    pub fn rte_eth_speed_lanes_set(port_id: u16, speed_lanes: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nGet speed lanes supported by the NIC.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `speed_lanes_capa` -\nAn array of supported speed and its supported lanes.\n* `num` -\nSize of the speed_lanes_capa array. The size is equal to the supported speeds list size.\nValue of num is derived by calling this api with speed_lanes_capa=NULL and num=0\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\nthat operation.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if *speed_lanes* invalid"]
    pub fn rte_eth_speed_lanes_get_capability(
        port_id: u16,
        speed_lanes_capa: *mut rte_eth_speed_lanes_capa,
        num: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the general I/O statistics of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `stats` -\nA pointer to a structure of type *rte_eth_stats* to be filled with\nthe values of device counters for the following set of statistics:\n- *ipackets* with the total of successfully received packets.\n- *opackets* with the total of successfully transmitted packets.\n- *ibytes*   with the total of successfully received bytes.\n- *obytes*   with the total of successfully transmitted bytes.\n- *ierrors*  with the total of erroneous received packets.\n- *oerrors*  with the total of failed transmitted packets.\n\n# Returns\n\nZero if successful. Non-zero otherwise."]
    pub fn rte_eth_stats_get(port_id: u16, stats: *mut rte_eth_stats) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Reset the general I/O statistics of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if device notified to reset stats.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (<0): Error code of the driver stats reset function."]
    pub fn rte_eth_stats_reset(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve names of extended statistics of an Ethernet device.\nThere is an assumption that 'xstat_names' and 'xstats' arrays are matched\nby array index:\nxstats_names[i].name => xstats[i].value\nAnd the array index is same with id field of 'struct rte_eth_xstat':\nxstats[i].id == i\nThis assumption makes key-value pair matching less flexible but simpler.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `xstats_names` -\nAn rte_eth_xstat_name array of at least *size* elements to\nbe filled. If set to NULL, the function returns the required number\nof elements.\n* `size` -\nThe size of the xstats_names array (number of elements).\n\n# Returns\n\n- A positive value lower or equal to size: success. The return value\nis the number of entries filled in the stats table.\n- A positive value higher than size: error, the given statistics table\nis too small. The return value corresponds to the size that should\nbe given to succeed. The entries in the table are not valid and\nshall not be used by the caller.\n- A negative value on error (invalid port ID)."]
    pub fn rte_eth_xstats_get_names(
        port_id: u16,
        xstats_names: *mut rte_eth_xstat_name,
        size: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve extended statistics of an Ethernet device.\nThere is an assumption that 'xstat_names' and 'xstats' arrays are matched\nby array index:\nxstats_names[i].name => xstats[i].value\nAnd the array index is same with id field of 'struct rte_eth_xstat':\nxstats[i].id == i\nThis assumption makes key-value pair matching less flexible but simpler.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `xstats` -\nA pointer to a table of structure of type *rte_eth_xstat*\nto be filled with device statistics ids and values.\nThis parameter can be set to NULL if and only if n is 0.\n* `n` -\nThe size of the xstats array (number of elements).\nIf lower than the required number of elements, the function returns\nthe required number of elements.\nIf equal to zero, the xstats must be NULL, the function returns the\nrequired number of elements.\n\n# Returns\n\n- A positive value lower or equal to n: success. The return value\nis the number of entries filled in the stats table.\n- A positive value higher than n: error, the given statistics table\nis too small. The return value corresponds to the size that should\nbe given to succeed. The entries in the table are not valid and\nshall not be used by the caller.\n- A negative value on error (invalid port ID)."]
    pub fn rte_eth_xstats_get(
        port_id: u16,
        xstats: *mut rte_eth_xstat,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve names of extended statistics of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `xstats_names` -\nArray to be filled in with names of requested device statistics.\nMust not be NULL if `ids` are specified (not NULL).\n* `size` -\nNumber of elements in `xstats_names` array (if not NULL) and in\n`ids` array (if not NULL). Must be 0 if both array pointers are NULL.\n* `ids` -\nIDs array given by app to retrieve specific statistics. May be NULL to\nretrieve names of all available statistics or, if `xstats_names` is\nNULL as well, just the number of available statistics.\n\n# Returns\n\n- A positive value lower or equal to size: success. The return value\nis the number of entries filled in the stats table.\n- A positive value higher than size: success. The given statistics table\nis too small. The return value corresponds to the size that should\nbe given to succeed. The entries in the table are not valid and\nshall not be used by the caller.\n- A negative value on error."]
    pub fn rte_eth_xstats_get_names_by_id(
        port_id: u16,
        xstats_names: *mut rte_eth_xstat_name,
        size: ::core::ffi::c_uint,
        ids: *mut u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve extended statistics of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `ids` -\nIDs array given by app to retrieve specific statistics. May be NULL to\nretrieve all available statistics or, if `values` is NULL as well,\njust the number of available statistics.\n* `values` -\nArray to be filled in with requested device statistics.\nMust not be NULL if ids are specified (not NULL).\n* `size` -\nNumber of elements in `values` array (if not NULL) and in `ids`\narray (if not NULL). Must be 0 if both array pointers are NULL.\n\n# Returns\n\n- A positive value lower or equal to size: success. The return value\nis the number of entries filled in the stats table.\n- A positive value higher than size: success: The given statistics table\nis too small. The return value corresponds to the size that should\nbe given to succeed. The entries in the table are not valid and\nshall not be used by the caller.\n- A negative value on error."]
    pub fn rte_eth_xstats_get_by_id(
        port_id: u16,
        ids: *const u64,
        values: *mut u64,
        size: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Gets the ID of a statistic from its name.\nThis function searches for the statistics using string compares, and\nas such should not be used on the fast-path. For fast-path retrieval of\nspecific statistics, store the ID as provided in *id* from this function,\nand pass the ID to rte_eth_xstats_get()\n\n# Arguments\n\n* `port_id` - The port to look up statistics from\n* `xstat_name` - The name of the statistic to return\n* `id` [out]  - A pointer to an app-supplied uint64_t which should be\nset to the ID of the stat if the stat exists.\n\n# Returns\n\n0 on success\n-ENODEV for invalid port_id,\n-EIO if device is removed,\n-EINVAL if the xstat_name doesn't exist in port_id\n-ENOMEM if bad parameter."]
    pub fn rte_eth_xstats_get_id_by_name(
        port_id: u16,
        xstat_name: *const ::core::ffi::c_char,
        id: *mut u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable/Disable the xstat counter of the given id.\n\n# Arguments\n\n* `port_id` - The port to look up statistics from\n* `id` - The ID of the counter to enable\n* `on_off` - The state to set the counter to.\n\n# Returns\n\n- (0) on success\n- (-EEXIST) counter already enabled\n- (-ENOTSUP) enable/disable is not implemented\n- (-EINVAL) xstat id is invalid\n- (-EPERM) enabling this counter is not permitted\n- (-ENOSPC) no resources"]
    pub fn rte_eth_xstats_set_counter(
        port_id: u16,
        id: u64,
        on_off: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Query the state of the xstat counter.\n\n# Arguments\n\n* `port_id` - The port to look up statistics from\n* `id` - The ID of the counter to query\n\n# Returns\n\n- (0) xstat is enabled\n- (1) xstat is disabled\n- (-ENOTSUP) enable/disabling is not implemented\n- (-EINVAL) xstat id is invalid"]
    pub fn rte_eth_xstats_query_state(port_id: u16, id: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Reset extended statistics of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if device notified to reset extended stats.\n- (-ENOTSUP) if pmd doesn't support both\nextended stats and basic stats reset.\n- (-ENODEV) if *port_id* invalid.\n- (<0): Error code of the driver xstats reset function."]
    pub fn rte_eth_xstats_reset(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set a mapping for the specified transmit queue to the specified per-queue\nstatistics counter.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `tx_queue_id` -\nThe index of the transmit queue for which a queue stats mapping is required.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `stat_idx` -\nThe per-queue packet statistics functionality number that the transmit\nqueue is to be assigned.\nThe value must be in the range [0, RTE_ETHDEV_QUEUE_STAT_CNTRS - 1].\nMax RTE_ETHDEV_QUEUE_STAT_CNTRS being 256.\n\n# Returns\n\nZero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_set_tx_queue_stats_mapping(
        port_id: u16,
        tx_queue_id: u16,
        stat_idx: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set a mapping for the specified receive queue to the specified per-queue\nstatistics counter.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rx_queue_id` -\nThe index of the receive queue for which a queue stats mapping is required.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `stat_idx` -\nThe per-queue packet statistics functionality number that the receive\nqueue is to be assigned.\nThe value must be in the range [0, RTE_ETHDEV_QUEUE_STAT_CNTRS - 1].\nMax RTE_ETHDEV_QUEUE_STAT_CNTRS being 256.\n\n# Returns\n\nZero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_set_rx_queue_stats_mapping(
        port_id: u16,
        rx_queue_id: u16,
        stat_idx: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the Ethernet address of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mac_addr` -\nA pointer to a structure of type *ether_addr* to be filled with\nthe Ethernet address of the Ethernet device.\n\n# Returns\n\n- (0) if successful\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_macaddr_get(port_id: u16, mac_addr: *mut rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nRetrieve the Ethernet addresses of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `ma` -\nA pointer to an array of structures of type *ether_addr* to be filled with\nthe Ethernet addresses of the Ethernet device.\n* `num` -\nNumber of elements in the `ma` array.\nNote that  rte_eth_dev_info::max_mac_addrs can be used to retrieve\nmax number of Ethernet addresses for given port.\n\n# Returns\n\n- number of retrieved addresses if successful\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_macaddrs_get(
        port_id: u16,
        ma: *mut rte_ether_addr,
        num: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the contextual information of an Ethernet device.\nThis function returns the Ethernet device information based\non the values stored internally in the device specific data.\nFor example: number of queues, descriptor limits, device\ncapabilities and offload flags.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `dev_info` -\nA pointer to a structure of type *rte_eth_dev_info* to be filled with\nthe contextual information of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for dev_infos_get() does not exist for the device.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_info_get(
        port_id: u16,
        dev_info: *mut rte_eth_dev_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRetrieve the configuration of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `dev_conf` -\nLocation for Ethernet device configuration to be filled in.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_conf_get(port_id: u16, dev_conf: *mut rte_eth_conf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the firmware version of a device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `fw_version` -\nA pointer to a string array storing the firmware version of a device,\nthe string includes terminating null. This pointer is allocated by caller.\n* `fw_size` -\nThe size of the string array pointed by fw_version, which should be\nlarge enough to store firmware version of the device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if operation is not supported.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if bad parameter.\n- (>0) if *fw_size* is not enough to store firmware version, return\nthe size of the non truncated string."]
    pub fn rte_eth_dev_fw_version_get(
        port_id: u16,
        fw_version: *mut ::core::ffi::c_char,
        fw_size: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the supported packet types of an Ethernet device.\nWhen a packet type is announced as supported, it *must* be recognized by\nthe PMD. For instance, if RTE_PTYPE_L2_ETHER, RTE_PTYPE_L2_ETHER_VLAN\nand RTE_PTYPE_L3_IPV4 are announced, the PMD must return the following\npacket types for these packets:\n- Ether/IPv4              -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4\n- Ether/VLAN/IPv4         -> RTE_PTYPE_L2_ETHER_VLAN | RTE_PTYPE_L3_IPV4\n- Ether/[anything else]   -> RTE_PTYPE_L2_ETHER\n- Ether/VLAN/[anything else] -> RTE_PTYPE_L2_ETHER_VLAN\nWhen a packet is received by a PMD, the most precise type must be\nreturned among the ones supported. However a PMD is allowed to set\npacket type that is not in the supported list, at the condition that it\nis more precise. Therefore, a PMD announcing no supported packet types\ncan still set a matching packet type in a received packet.\n> **Note** Better to invoke this API after the device is already started or Rx burst\nfunction is decided, to obtain correct supported ptypes.\n> **Note** if a given PMD does not report what ptypes it supports, then the supported\nptype count is reported as 0.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `ptype_mask` -\nA hint of what kind of packet type which the caller is interested in.\n* `ptypes` -\nAn array pointer to store adequate packet types, allocated by caller.\n* `num` -\nSize of the array pointed by param ptypes.\n\n# Returns\n\n- (>=0) Number of supported ptypes. If the number of types exceeds num,\nonly num entries will be filled into the ptypes array, but the full\ncount of supported ptypes will be returned.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_supported_ptypes(
        port_id: u16,
        ptype_mask: u32,
        ptypes: *mut u32,
        num: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Inform Ethernet device about reduced range of packet types to handle.\nApplication can use this function to set only specific ptypes that it's\ninterested. This information can be used by the PMD to optimize Rx path.\nThe function accepts an array `set_ptypes` allocated by the caller to\nstore the packet types set by the driver, the last element of the array\nis set to RTE_PTYPE_UNKNOWN. The size of the `set_ptype` array should be\n`rte_eth_dev_get_supported_ptypes() + 1` else it might only be filled\npartially.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `ptype_mask` -\nThe ptype family that application is interested in should be bitwise OR of\nRTE_PTYPE_*_MASK or 0.\n* `set_ptypes` -\nAn array pointer to store set packet types, allocated by caller. The\nfunction marks the end of array with RTE_PTYPE_UNKNOWN.\n* `num` -\nSize of the array pointed by param ptypes.\nShould be rte_eth_dev_get_supported_ptypes() + 1 to accommodate the\nset ptypes.\n\n# Returns\n\n- (0) if Success.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if *ptype_mask* is invalid (or) set_ptypes is NULL and\nnum > 0."]
    pub fn rte_eth_dev_set_ptypes(
        port_id: u16,
        ptype_mask: u32,
        set_ptypes: *mut u32,
        num: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the MTU of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mtu` -\nA pointer to a uint16_t where the retrieved MTU is to be stored.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_mtu(port_id: u16, mtu: *mut u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Change the MTU of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mtu` -\nA uint16_t for the MTU to be applied.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if operation is not supported.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if *mtu* invalid, validation of mtu can occur within\nrte_eth_dev_set_mtu if dev_infos_get is supported by the device or\nwhen the mtu is set using dev->dev_ops->mtu_set.\n- (-EBUSY) if operation is not allowed when the port is running"]
    pub fn rte_eth_dev_set_mtu(port_id: u16, mtu: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable/Disable hardware filtering by an Ethernet device of received\nVLAN packets tagged with a given VLAN Tag Identifier.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `vlan_id` -\nThe VLAN Tag Identifier whose filtering must be enabled or disabled.\n* `on` -\nIf > 0, enable VLAN filtering of VLAN packets tagged with *vlan_id*.\nOtherwise, disable VLAN filtering of VLAN packets tagged with *vlan_id*.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware-assisted VLAN filtering not configured.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-ENOSYS) if VLAN filtering on *port_id* disabled.\n- (-EINVAL) if *vlan_id* > 4095."]
    pub fn rte_eth_dev_vlan_filter(
        port_id: u16,
        vlan_id: u16,
        on: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable/Disable hardware VLAN Strip by a Rx queue of an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rx_queue_id` -\nThe index of the receive queue for which a queue stats mapping is required.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `on` -\nIf 1, Enable VLAN Stripping of the receive queue of the Ethernet port.\nIf 0, Disable VLAN Stripping of the receive queue of the Ethernet port.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware-assisted VLAN stripping not configured.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if *rx_queue_id* invalid."]
    pub fn rte_eth_dev_set_vlan_strip_on_queue(
        port_id: u16,
        rx_queue_id: u16,
        on: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the Outer VLAN Ether Type by an Ethernet device, it can be inserted to\nthe VLAN header.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `vlan_type` -\nThe VLAN type.\n* `tag_type` -\nThe Tag Protocol ID\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware-assisted VLAN TPID setup is not supported.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_set_vlan_ether_type(
        port_id: u16,
        vlan_type: rte_vlan_type::Type,
        tag_type: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set VLAN offload configuration on an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `offload_mask` -\nThe VLAN Offload bit mask can be mixed use with \"OR\"\nRTE_ETH_VLAN_STRIP_OFFLOAD\nRTE_ETH_VLAN_FILTER_OFFLOAD\nRTE_ETH_VLAN_EXTEND_OFFLOAD\nRTE_ETH_QINQ_STRIP_OFFLOAD\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware-assisted VLAN filtering not configured.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_set_vlan_offload(
        port_id: u16,
        offload_mask: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read VLAN Offload configuration from an Ethernet device\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (>0) if successful. Bit mask to indicate\nRTE_ETH_VLAN_STRIP_OFFLOAD\nRTE_ETH_VLAN_FILTER_OFFLOAD\nRTE_ETH_VLAN_EXTEND_OFFLOAD\nRTE_ETH_QINQ_STRIP_OFFLOAD\n- (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_dev_get_vlan_offload(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set port based Tx VLAN insertion on or off.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `pvid` -\nPort based Tx VLAN identifier together with user priority.\n* `on` -\nTurn on or off the port based Tx VLAN insertion.\n\n# Returns\n\n- (0) if successful.\n- negative if failed."]
    pub fn rte_eth_dev_set_vlan_pvid(
        port_id: u16,
        pvid: u16,
        on: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSet Rx queue available descriptors threshold.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue.\n* `avail_thresh` -\nThe available descriptors threshold is percentage of Rx queue size\nwhich describes the availability of Rx queue for hardware.\nIf the Rx queue availability is below it,\nthe event RTE_ETH_EVENT_RX_AVAIL_THRESH is triggered.\n[1-99] to set a new available descriptors threshold.\n0 to disable threshold monitoring.\n\n# Returns\n\n- 0 if successful.\n- (-ENODEV) if `port_id` is invalid.\n- (-EINVAL) if bad parameter.\n- (-ENOTSUP) if available Rx descriptors threshold is not supported.\n- (-EIO) if device is removed."]
    pub fn rte_eth_rx_avail_thresh_set(
        port_id: u16,
        queue_id: u16,
        avail_thresh: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nFind Rx queue with RTE_ETH_EVENT_RX_AVAIL_THRESH event pending.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` [inout]  -\nOn input starting Rx queue index to search from.\nIf the queue_id is bigger than maximum queue ID of the port,\nsearch is started from 0. So that application can keep calling\nthis function to handle all pending events with a simple increment\nof queue_id on the next call.\nOn output if return value is 1, Rx queue index with the event pending.\n* `avail_thresh` [out]  -\nLocation for available descriptors threshold of the found Rx queue.\n\n# Returns\n\n- 1 if an Rx queue with pending event is found.\n- 0 if no Rx queue with pending event is found.\n- (-ENODEV) if `port_id` is invalid.\n- (-EINVAL) if bad parameter (e.g. `queue_id` is NULL).\n- (-ENOTSUP) if operation is not supported.\n- (-EIO) if device is removed."]
    pub fn rte_eth_rx_avail_thresh_query(
        port_id: u16,
        queue_id: *mut u16,
        avail_thresh: *mut u8,
    ) -> ::core::ffi::c_int;
}
pub type buffer_tx_error_fn = ::core::option::Option<
    unsafe extern "C" fn(
        unsent: *mut *mut rte_mbuf,
        count: u16,
        userdata: *mut ::core::ffi::c_void,
    ),
>;
#[doc = "Structure used to buffer packets for future Tx\nUsed by APIs rte_eth_tx_buffer and rte_eth_tx_buffer_flush"]
#[repr(C)]
#[derive(Debug)]
pub struct rte_eth_dev_tx_buffer {
    pub error_callback: buffer_tx_error_fn,
    pub error_userdata: *mut ::core::ffi::c_void,
    #[doc = "< Size of buffer for buffered Tx"]
    pub size: u16,
    #[doc = "< Number of packets in the array"]
    pub length: u16,
    #[doc = "Pending packets to be sent on explicit flush or when full"]
    pub pkts: __IncompleteArrayField<*mut rte_mbuf>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_tx_buffer"][::core::mem::size_of::<rte_eth_dev_tx_buffer>() - 24usize];
    ["Alignment of rte_eth_dev_tx_buffer"]
        [::core::mem::align_of::<rte_eth_dev_tx_buffer>() - 8usize];
    ["Offset of field: rte_eth_dev_tx_buffer::error_callback"]
        [::core::mem::offset_of!(rte_eth_dev_tx_buffer, error_callback) - 0usize];
    ["Offset of field: rte_eth_dev_tx_buffer::error_userdata"]
        [::core::mem::offset_of!(rte_eth_dev_tx_buffer, error_userdata) - 8usize];
    ["Offset of field: rte_eth_dev_tx_buffer::size"]
        [::core::mem::offset_of!(rte_eth_dev_tx_buffer, size) - 16usize];
    ["Offset of field: rte_eth_dev_tx_buffer::length"]
        [::core::mem::offset_of!(rte_eth_dev_tx_buffer, length) - 18usize];
    ["Offset of field: rte_eth_dev_tx_buffer::pkts"]
        [::core::mem::offset_of!(rte_eth_dev_tx_buffer, pkts) - 24usize];
};
impl Default for rte_eth_dev_tx_buffer {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Initialize default values for buffered transmitting\n\n# Arguments\n\n* `buffer` -\nTx buffer to be initialized.\n* `size` -\nBuffer size\n\n# Returns\n\n0 if no error"]
    pub fn rte_eth_tx_buffer_init(
        buffer: *mut rte_eth_dev_tx_buffer,
        size: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Configure a callback for buffered packets which cannot be sent\nRegister a specific callback to be called when an attempt is made to send\nall packets buffered on an Ethernet port, but not all packets can\nsuccessfully be sent. The callback registered here will be called only\nfrom calls to rte_eth_tx_buffer() and rte_eth_tx_buffer_flush() APIs.\nThe default callback configured for each queue by default just frees the\npackets back to the calling mempool. If additional behaviour is required,\nfor example, to count dropped packets, or to retry transmission of packets\nwhich cannot be sent, this function should be used to register a suitable\ncallback function to implement the desired behaviour.\nThe example callback \"rte_eth_tx_buffer_count_callback()\" is also\nprovided as reference.\n\n# Arguments\n\n* `buffer` -\nThe port identifier of the Ethernet device.\n* `callback` -\nThe function to be used as the callback.\n* `userdata` -\nArbitrary parameter to be passed to the callback function\n\n# Returns\n\n0 on success, or -EINVAL if bad parameter"]
    pub fn rte_eth_tx_buffer_set_err_callback(
        buffer: *mut rte_eth_dev_tx_buffer,
        callback: buffer_tx_error_fn,
        userdata: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Callback function for silently dropping unsent buffered packets.\nThis function can be passed to rte_eth_tx_buffer_set_err_callback() to\nadjust the default behavior when buffered packets cannot be sent. This\nfunction drops any unsent packets silently and is used by Tx buffered\noperations as default behavior.\nNOTE: this function should not be called directly, instead it should be used\nas a callback for packet buffering.\nNOTE: when configuring this function as a callback with\nrte_eth_tx_buffer_set_err_callback(), the final, userdata parameter\nshould point to an uint64_t value.\n\n# Arguments\n\n* `pkts` -\nThe previously buffered packets which could not be sent\n* `unsent` -\nThe number of unsent packets in the pkts array\n* `userdata` -\nNot used"]
    pub fn rte_eth_tx_buffer_drop_callback(
        pkts: *mut *mut rte_mbuf,
        unsent: u16,
        userdata: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[doc = "Callback function for tracking unsent buffered packets.\nThis function can be passed to rte_eth_tx_buffer_set_err_callback() to\nadjust the default behavior when buffered packets cannot be sent. This\nfunction drops any unsent packets, but also updates a user-supplied counter\nto track the overall number of packets dropped. The counter should be an\nuint64_t variable.\nNOTE: this function should not be called directly, instead it should be used\nas a callback for packet buffering.\nNOTE: when configuring this function as a callback with\nrte_eth_tx_buffer_set_err_callback(), the final, userdata parameter\nshould point to an uint64_t value.\n\n# Arguments\n\n* `pkts` -\nThe previously buffered packets which could not be sent\n* `unsent` -\nThe number of unsent packets in the pkts array\n* `userdata` -\nPointer to an uint64_t value, which will be incremented by unsent"]
    pub fn rte_eth_tx_buffer_count_callback(
        pkts: *mut *mut rte_mbuf,
        unsent: u16,
        userdata: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[doc = "Request the driver to free mbufs currently cached by the driver. The\ndriver will only free the mbuf if it is no longer in use. It is the\napplication's responsibility to ensure rte_eth_tx_buffer_flush(..) is\ncalled if needed.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue through which output packets must be\nsent.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `free_cnt` -\nMaximum number of packets to free. Use 0 to indicate all possible packets\nshould be freed. Note that a packet may be using multiple mbufs.\n\n# Returns\n\nFailure: < 0\n-ENODEV: Invalid interface\n-EIO: device is removed\n-ENOTSUP: Driver does not support function\nSuccess: >= 0\n0-n: Number of packets freed. More packets may still remain in ring that\nare in use."]
    pub fn rte_eth_tx_done_cleanup(
        port_id: u16,
        queue_id: u16,
        free_cnt: u32,
    ) -> ::core::ffi::c_int;
}
pub mod rte_eth_event_macsec_subtype {
    #[doc = "Subtypes for MACsec offload event ([`RTE_ETH_EVENT_MACSEC)`]\nraised by Ethernet device."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Notifies unknown MACsec subevent."]
    pub const RTE_ETH_SUBEVENT_MACSEC_UNKNOWN: Type = 0;
    #[doc = "Subevent of RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR sectag validation events\nValidation check: SecTag.TCI.V = 1"]
    pub const RTE_ETH_SUBEVENT_MACSEC_RX_SECTAG_V_EQ1: Type = 1;
    #[doc = "Subevent of RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR sectag validation events\nValidation check: SecTag.TCI.E = 0 && SecTag.TCI.C = 1"]
    pub const RTE_ETH_SUBEVENT_MACSEC_RX_SECTAG_E_EQ0_C_EQ1: Type = 2;
    #[doc = "Subevent of RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR sectag validation events\nValidation check: SecTag.SL >= 'd48"]
    pub const RTE_ETH_SUBEVENT_MACSEC_RX_SECTAG_SL_GTE48: Type = 3;
    #[doc = "Subevent of RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR sectag validation events\nValidation check: SecTag.TCI.ES = 1 && SecTag.TCI.SC = 1"]
    pub const RTE_ETH_SUBEVENT_MACSEC_RX_SECTAG_ES_EQ1_SC_EQ1: Type = 4;
    #[doc = "Subevent of RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR sectag validation events\nValidation check: SecTag.TCI.SC = 1 && SecTag.TCI.SCB = 1"]
    pub const RTE_ETH_SUBEVENT_MACSEC_RX_SECTAG_SC_EQ1_SCB_EQ1: Type = 5;
}
pub mod rte_eth_event_macsec_type {
    #[doc = "Event types for MACsec offload event ([`RTE_ETH_EVENT_MACSEC)`]\nraised by eth device."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Notifies unknown MACsec event."]
    pub const RTE_ETH_EVENT_MACSEC_UNKNOWN: Type = 0;
    #[doc = "Notifies Sectag validation failure events."]
    pub const RTE_ETH_EVENT_MACSEC_SECTAG_VAL_ERR: Type = 1;
    #[doc = "Notifies Rx SA hard expiry events."]
    pub const RTE_ETH_EVENT_MACSEC_RX_SA_PN_HARD_EXP: Type = 2;
    #[doc = "Notifies Rx SA soft expiry events."]
    pub const RTE_ETH_EVENT_MACSEC_RX_SA_PN_SOFT_EXP: Type = 3;
    #[doc = "Notifies Tx SA hard expiry events."]
    pub const RTE_ETH_EVENT_MACSEC_TX_SA_PN_HARD_EXP: Type = 4;
    #[doc = "Notifies Tx SA soft events."]
    pub const RTE_ETH_EVENT_MACSEC_TX_SA_PN_SOFT_EXP: Type = 5;
    #[doc = "Notifies Invalid SA event."]
    pub const RTE_ETH_EVENT_MACSEC_SA_NOT_VALID: Type = 6;
}
#[doc = "Descriptor for [`RTE_ETH_EVENT_MACSEC`] event.\nUsed by ethdev to send extra information of the MACsec offload event."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_event_macsec_desc {
    #[doc = "Type of RTE_ETH_EVENT_MACSEC_* event."]
    pub type_: rte_eth_event_macsec_type::Type,
    #[doc = "Type of RTE_ETH_SUBEVENT_MACSEC_* subevent."]
    pub subtype: rte_eth_event_macsec_subtype::Type,
    #[doc = "Event specific metadata.\nFor the following events, *userdata* registered\nwith the *rte_security_session* would be returned\nas metadata.\n\n# See also\n\n> [`struct`] rte_security_session_conf"]
    pub metadata: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_event_macsec_desc"]
        [::core::mem::size_of::<rte_eth_event_macsec_desc>() - 16usize];
    ["Alignment of rte_eth_event_macsec_desc"]
        [::core::mem::align_of::<rte_eth_event_macsec_desc>() - 8usize];
    ["Offset of field: rte_eth_event_macsec_desc::type_"]
        [::core::mem::offset_of!(rte_eth_event_macsec_desc, type_) - 0usize];
    ["Offset of field: rte_eth_event_macsec_desc::subtype"]
        [::core::mem::offset_of!(rte_eth_event_macsec_desc, subtype) - 4usize];
    ["Offset of field: rte_eth_event_macsec_desc::metadata"]
        [::core::mem::offset_of!(rte_eth_event_macsec_desc, metadata) - 8usize];
};
impl Default for rte_eth_event_macsec_desc {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_event_ipsec_subtype {
    #[doc = "Subtypes for IPsec offload event([`RTE_ETH_EVENT_IPSEC)`] raised by\neth device."]
    pub type Type = ::core::ffi::c_int;
    #[doc = "PMD specific error start"]
    pub const RTE_ETH_EVENT_IPSEC_PMD_ERROR_START: Type = -256;
    #[doc = "PMD specific error end"]
    pub const RTE_ETH_EVENT_IPSEC_PMD_ERROR_END: Type = -1;
    #[doc = "Unknown event type"]
    pub const RTE_ETH_EVENT_IPSEC_UNKNOWN: Type = 0;
    #[doc = "Sequence number overflow"]
    pub const RTE_ETH_EVENT_IPSEC_ESN_OVERFLOW: Type = 1;
    #[doc = "Soft time expiry of SA"]
    pub const RTE_ETH_EVENT_IPSEC_SA_TIME_EXPIRY: Type = 2;
    #[doc = "Soft byte expiry of SA determined by\n[`rte_security_ipsec_lifetime::bytes_soft_limit`]"]
    pub const RTE_ETH_EVENT_IPSEC_SA_BYTE_EXPIRY: Type = 3;
    #[doc = "Soft packet expiry of SA determined by\n[`rte_security_ipsec_lifetime::packets_soft_limit`]"]
    pub const RTE_ETH_EVENT_IPSEC_SA_PKT_EXPIRY: Type = 4;
    #[doc = "Hard byte expiry of SA determined by\n[`rte_security_ipsec_lifetime::bytes_hard_limit`]"]
    pub const RTE_ETH_EVENT_IPSEC_SA_BYTE_HARD_EXPIRY: Type = 5;
    #[doc = "Hard packet expiry of SA determined by\n[`rte_security_ipsec_lifetime::packets_hard_limit`]"]
    pub const RTE_ETH_EVENT_IPSEC_SA_PKT_HARD_EXPIRY: Type = 6;
    #[doc = "Max value of this enum"]
    pub const RTE_ETH_EVENT_IPSEC_MAX: Type = 7;
}
#[doc = "Descriptor for [`RTE_ETH_EVENT_IPSEC`] event. Used by eth dev to send extra\ninformation of the IPsec offload event."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_event_ipsec_desc {
    #[doc = "Type of RTE_ETH_EVENT_IPSEC_* event"]
    pub subtype: rte_eth_event_ipsec_subtype::Type,
    #[doc = "Event specific metadata.\nFor the following events, *userdata* registered\nwith the *rte_security_session* would be returned\nas metadata,\n- [`RTE_ETH_EVENT_IPSEC_ESN_OVERFLOW`]\n- [`RTE_ETH_EVENT_IPSEC_SA_TIME_EXPIRY`]\n- [`RTE_ETH_EVENT_IPSEC_SA_BYTE_EXPIRY`]\n- [`RTE_ETH_EVENT_IPSEC_SA_PKT_EXPIRY`]\n- [`RTE_ETH_EVENT_IPSEC_SA_BYTE_HARD_EXPIRY`]\n- [`RTE_ETH_EVENT_IPSEC_SA_PKT_HARD_EXPIRY`]\n\n# See also\n\n> [`struct`] rte_security_session_conf\n"]
    pub metadata: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_event_ipsec_desc"]
        [::core::mem::size_of::<rte_eth_event_ipsec_desc>() - 16usize];
    ["Alignment of rte_eth_event_ipsec_desc"]
        [::core::mem::align_of::<rte_eth_event_ipsec_desc>() - 8usize];
    ["Offset of field: rte_eth_event_ipsec_desc::subtype"]
        [::core::mem::offset_of!(rte_eth_event_ipsec_desc, subtype) - 0usize];
    ["Offset of field: rte_eth_event_ipsec_desc::metadata"]
        [::core::mem::offset_of!(rte_eth_event_ipsec_desc, metadata) - 8usize];
};
impl Default for rte_eth_event_ipsec_desc {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_event_type {
    #[doc = "The eth device event type for interrupt, and maybe others in the future."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< unknown event type"]
    pub const RTE_ETH_EVENT_UNKNOWN: Type = 0;
    #[doc = "< lsc interrupt event"]
    pub const RTE_ETH_EVENT_INTR_LSC: Type = 1;
    #[doc = "queue state event (enabled/disabled)"]
    pub const RTE_ETH_EVENT_QUEUE_STATE: Type = 2;
    #[doc = "reset interrupt event, sent to VF on PF reset"]
    pub const RTE_ETH_EVENT_INTR_RESET: Type = 3;
    #[doc = "< message from the VF received by PF"]
    pub const RTE_ETH_EVENT_VF_MBOX: Type = 4;
    #[doc = "< MACsec offload related event"]
    pub const RTE_ETH_EVENT_MACSEC: Type = 5;
    #[doc = "< device removal event"]
    pub const RTE_ETH_EVENT_INTR_RMV: Type = 6;
    #[doc = "The port is being probed, i.e. allocated and not yet available.\nIt is too early to check validity, query infos, and configure\nthe port. But some functions, like rte_eth_dev_socket_id() and\nrte_eth_dev_owner_*() are available to the application."]
    pub const RTE_ETH_EVENT_NEW: Type = 7;
    #[doc = "< port is released"]
    pub const RTE_ETH_EVENT_DESTROY: Type = 8;
    #[doc = "< IPsec offload related event"]
    pub const RTE_ETH_EVENT_IPSEC: Type = 9;
    #[doc = "< New aged-out flows is detected"]
    pub const RTE_ETH_EVENT_FLOW_AGED: Type = 10;
    #[doc = "Number of available Rx descriptors is smaller than the threshold.\n\n# See also\n\n> [`rte_eth_rx_avail_thresh_set()`]"]
    pub const RTE_ETH_EVENT_RX_AVAIL_THRESH: Type = 11;
    #[doc = "Port recovering from a hardware or firmware error.\nIf PMD supports proactive error recovery,\nit should trigger this event to notify application\nthat it detected an error and the recovery is being started.\nUpon receiving the event, the application should not invoke any control path API\n(such as rte_eth_dev_configure/rte_eth_dev_stop...) until receiving\nRTE_ETH_EVENT_RECOVERY_SUCCESS or RTE_ETH_EVENT_RECOVERY_FAILED event.\nThe PMD will set the data path pointers to dummy functions,\nand re-set the data path pointers to non-dummy functions\nbefore reporting RTE_ETH_EVENT_RECOVERY_SUCCESS event.\nIt means that the application cannot send or receive any packets\nduring this period.\n> **Note** Before the PMD reports the recovery result,\nthe PMD may report the RTE_ETH_EVENT_ERR_RECOVERING event again,\nbecause a larger error may occur during the recovery."]
    pub const RTE_ETH_EVENT_ERR_RECOVERING: Type = 12;
    #[doc = "Port recovers successfully from the error.\nThe PMD already re-configured the port,\nand the effect is the same as a restart operation.\na) The following operation will be retained: (alphabetically)\n- DCB configuration\n- FEC configuration\n- Flow control configuration\n- LRO configuration\n- LSC configuration\n- MTU\n- MAC address (default and those supplied by MAC address array)\n- Promiscuous and allmulticast mode\n- PTP configuration\n- Queue (Rx/Tx) settings\n- Queue statistics mappings\n- RSS configuration by rte_eth_dev_rss_xxx() family\n- Rx checksum configuration\n- Rx interrupt settings\n- Traffic management configuration\n- VLAN configuration (including filtering, tpid, strip, pvid)\n- VMDq configuration\nb) The following configuration maybe retained\nor not depending on the device capabilities:\n- flow rules\n(# See also\n\n> [`RTE_ETH_DEV_CAPA_FLOW_RULE_KEEP)`]\n- shared flow objects\n(> [`RTE_ETH_DEV_CAPA_FLOW_SHARED_OBJECT_KEEP)`]\nc) Any other configuration will not be stored\nand will need to be re-configured."]
    pub const RTE_ETH_EVENT_RECOVERY_SUCCESS: Type = 13;
    #[doc = "Port recovery failed.\nIt means that the port should not be usable anymore.\nThe application should close the port."]
    pub const RTE_ETH_EVENT_RECOVERY_FAILED: Type = 14;
    #[doc = "< max value of this enum"]
    pub const RTE_ETH_EVENT_MAX: Type = 15;
}
#[doc = "User application callback to be registered for interrupts.\nNote: there is no guarantee in the DPDK drivers that a callback won't be\ncalled in the middle of other parts of the ethdev API. For example,\nimagine that thread A calls rte_eth_dev_start() and as part of this\ncall, a RTE_ETH_EVENT_INTR_RESET event gets generated and the\nassociated callback is ran on thread A. In that example, if the\napplication protects its internal data using locks before calling\nrte_eth_dev_start(), and the callback takes a same lock, a deadlock\noccurs. Because of this, it is highly recommended NOT to take locks in\nthose callbacks."]
pub type rte_eth_dev_cb_fn = ::core::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        event: rte_eth_event_type::Type,
        cb_arg: *mut ::core::ffi::c_void,
        ret_param: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Register a callback function for port event.\n\n# Arguments\n\n* `port_id` -\nPort ID.\nRTE_ETH_ALL means register the event for all port ids.\n* `event` -\nEvent interested.\n* `cb_fn` -\nUser supplied callback function to be called.\n* `cb_arg` -\nPointer to the parameters for the registered callback.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_dev_callback_register(
        port_id: u16,
        event: rte_eth_event_type::Type,
        cb_fn: rte_eth_dev_cb_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unregister a callback function for port event.\n\n# Arguments\n\n* `port_id` -\nPort ID.\nRTE_ETH_ALL means unregister the event for all port ids.\n* `event` -\nEvent interested.\n* `cb_fn` -\nUser supplied callback function to be called.\n* `cb_arg` -\nPointer to the parameters for the registered callback. -1 means to\nremove all for the same callback address and same event.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_dev_callback_unregister(
        port_id: u16,
        event: rte_eth_event_type::Type,
        cb_fn: rte_eth_dev_cb_fn,
        cb_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "When there is no Rx packet coming in Rx Queue for a long time, we can\nsleep lcore related to Rx Queue for power saving, and enable Rx interrupt\nto be triggered when Rx packet arrives.\nThe rte_eth_dev_rx_intr_enable() function enables Rx queue\ninterrupt on specific Rx queue of a port.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support\nthat operation.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_rx_intr_enable(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "When lcore wakes up from Rx interrupt indicating packet coming, disable Rx\ninterrupt and returns to polling mode.\nThe rte_eth_dev_rx_intr_disable() function disables Rx queue\ninterrupt on specific Rx queue of a port.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support\nthat operation.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_rx_intr_disable(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Rx Interrupt control per port.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `epfd` -\nEpoll instance fd which the intr vector associated to.\nUsing RTE_EPOLL_PER_THREAD allows to use per thread epoll instance.\n* `op` -\nThe operation be performed for the vector.\nOperation type of {RTE_INTR_EVENT_ADD, RTE_INTR_EVENT_DEL}.\n* `data` -\nUser raw data.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_dev_rx_intr_ctl(
        port_id: u16,
        epfd: ::core::ffi::c_int,
        op: ::core::ffi::c_int,
        data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Rx Interrupt control per queue.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `epfd` -\nEpoll instance fd which the intr vector associated to.\nUsing RTE_EPOLL_PER_THREAD allows to use per thread epoll instance.\n* `op` -\nThe operation be performed for the vector.\nOperation type of {RTE_INTR_EVENT_ADD, RTE_INTR_EVENT_DEL}.\n* `data` -\nUser raw data.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_dev_rx_intr_ctl_q(
        port_id: u16,
        queue_id: u16,
        epfd: ::core::ffi::c_int,
        op: ::core::ffi::c_int,
        data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get interrupt fd per Rx queue.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n\n# Returns\n\n- (>=0) the interrupt fd associated to the requested Rx queue if\nsuccessful.\n- (-1) on error."]
    pub fn rte_eth_dev_rx_intr_ctl_q_get_fd(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Turn on the LED on the Ethernet device.\nThis function turns on the LED on the Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support\nthat operation.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_led_on(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Turn off the LED on the Ethernet device.\nThis function turns off the LED on the Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support\nthat operation.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed."]
    pub fn rte_eth_led_off(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nGet Forward Error Correction(FEC) capability.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `speed_fec_capa` -\nspeed_fec_capa is out only with per-speed capabilities.\nIf set to NULL, the function returns the required number\nof required array entries.\n* `num` -\na number of elements in an speed_fec_capa array.\n\n# Returns\n\n- A non-negative value lower or equal to num: success. The return value\nis the number of entries filled in the fec capa array.\n- A non-negative value higher than num: error, the given fec capa array\nis too small. The return value corresponds to the num that should\nbe given to succeed. The entries in fec capa array are not valid and\nshall not be used by the caller.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\nthat operation.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if *num* or *speed_fec_capa* invalid"]
    pub fn rte_eth_fec_get_capability(
        port_id: u16,
        speed_fec_capa: *mut rte_eth_fec_capa,
        num: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nGet current Forward Error Correction(FEC) mode.\nIf link is down and AUTO is enabled, AUTO is returned, otherwise,\nconfigured FEC mode is returned.\nIf link is up, current FEC mode is returned.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `fec_capa` -\nA bitmask with the current FEC mode.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\nthat operation.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid."]
    pub fn rte_eth_fec_get(port_id: u16, fec_capa: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nSet Forward Error Correction(FEC) mode.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `fec_capa` -\nA bitmask of allowed FEC modes.\nIf only the AUTO bit is set, the decision on which FEC\nmode to use will be made by HW/FW or driver.\nIf the AUTO bit is set with some FEC modes, only specified\nFEC modes can be set.\nIf AUTO bit is clear, specify FEC mode to be used\n(only one valid mode per speed may be set).\n\n# Returns\n\n- (0) if successful.\n- (-EINVAL) if the FEC mode is not valid.\n- (-ENOTSUP) if underlying hardware OR driver doesn't support.\n- (-EIO) if device is removed.\n- (-ENODEV)  if *port_id* invalid."]
    pub fn rte_eth_fec_set(port_id: u16, fec_capa: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get current status of the Ethernet link flow control for Ethernet device\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `fc_conf` -\nThe pointer to the structure where to store the flow control parameters.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support flow control.\n- (-ENODEV)  if *port_id* invalid.\n- (-EIO)  if device is removed.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_flow_ctrl_get(
        port_id: u16,
        fc_conf: *mut rte_eth_fc_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Configure the Ethernet link flow control for Ethernet device\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `fc_conf` -\nThe pointer to the structure of the flow control parameters.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support flow control mode.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if bad parameter\n- (-EIO)     if flow control setup failure or device is removed."]
    pub fn rte_eth_dev_flow_ctrl_set(
        port_id: u16,
        fc_conf: *mut rte_eth_fc_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Configure the Ethernet priority flow control under DCB environment\nfor Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `pfc_conf` -\nThe pointer to the structure of the priority flow control parameters.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support priority flow control mode.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if bad parameter\n- (-EIO)     if flow control setup failure or device is removed."]
    pub fn rte_eth_dev_priority_flow_ctrl_set(
        port_id: u16,
        pfc_conf: *mut rte_eth_pfc_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a MAC address to the set used for filtering incoming packets.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mac_addr` -\nThe MAC address to add.\n* `pool` -\nVMDq pool index to associate address with (if VMDq is enabled). If VMDq is\nnot enabled, this should be set to 0.\n\n# Returns\n\n- (0) if successfully added or *mac_addr* was already added.\n- (-ENOTSUP) if hardware doesn't support this feature.\n- (-ENODEV) if *port* is invalid.\n- (-EIO) if device is removed.\n- (-ENOSPC) if no more MAC addresses can be added.\n- (-EINVAL) if MAC address is invalid."]
    pub fn rte_eth_dev_mac_addr_add(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
        pool: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRetrieve the information for queue based PFC.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `pfc_queue_info` -\nA pointer to a structure of type *rte_eth_pfc_queue_info* to be filled with\nthe information about queue based PFC.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for priority_flow_ctrl_queue_info_get does not exist.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_priority_flow_ctrl_queue_info_get(
        port_id: u16,
        pfc_queue_info: *mut rte_eth_pfc_queue_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nConfigure the queue based priority flow control for a given queue\nfor Ethernet device.\n> **Note** When an ethdev port switches to queue based PFC mode, the\nunconfigured queues shall be configured by the driver with\ndefault values such as lower priority value for TC etc.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `pfc_queue_conf` -\nThe pointer to the structure of the priority flow control parameters\nfor the queue.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support queue based PFC mode.\n- (-ENODEV)  if *port_id* invalid.\n- (-EINVAL)  if bad parameter\n- (-EIO)     if flow control setup queue failure"]
    pub fn rte_eth_dev_priority_flow_ctrl_queue_configure(
        port_id: u16,
        pfc_queue_conf: *mut rte_eth_pfc_queue_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a MAC address from the internal array of addresses.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mac_addr` -\nMAC address to remove.\n\n# Returns\n\n- (0) if successful, or *mac_addr* didn't exist.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port* invalid.\n- (-EADDRINUSE) if attempting to remove the default MAC address.\n- (-EINVAL) if MAC address is invalid."]
    pub fn rte_eth_dev_mac_addr_remove(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the default MAC address.\nIt replaces the address at index 0 of the MAC address list.\nIf the address was already in the MAC address list,\nplease remove it first.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mac_addr` -\nNew default MAC address.\n\n# Returns\n\n- (0) if successful, or *mac_addr* didn't exist.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port* invalid.\n- (-EINVAL) if MAC address is invalid.\n- (-EEXIST) if MAC address was already in the address list."]
    pub fn rte_eth_dev_default_mac_addr_set(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Update Redirection Table(RETA) of Receive Side Scaling of Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `reta_conf` -\nRETA to update.\n* `reta_size` -\nRedirection table size. The table size can be queried by\nrte_eth_dev_info_get().\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_rss_reta_update(
        port_id: u16,
        reta_conf: *mut rte_eth_rss_reta_entry64,
        reta_size: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Query Redirection Table(RETA) of Receive Side Scaling of Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `reta_conf` -\nRETA to query. For each requested reta entry, corresponding bit\nin mask must be set.\n* `reta_size` -\nRedirection table size. The table size can be queried by\nrte_eth_dev_info_get().\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_rss_reta_query(
        port_id: u16,
        reta_conf: *mut rte_eth_rss_reta_entry64,
        reta_size: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Updates unicast hash table for receiving packet with the given destination\nMAC address, and the packet is routed to all VFs for which the Rx mode is\naccept packets that match the unicast hash table.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `addr` -\nUnicast MAC address.\n* `on` -\n1 - Set an unicast hash bit for receiving packets with the MAC address.\n0 - Clear an unicast hash bit.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_uc_hash_table_set(
        port_id: u16,
        addr: *mut rte_ether_addr,
        on: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Updates all unicast hash bitmaps for receiving packet with any Unicast\nEthernet MAC addresses,the packet is routed to all VFs for which the Rx\nmode is accept packets that match the unicast hash table.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `on` -\n1 - Set all unicast hash bitmaps for receiving all the Ethernet\nMAC addresses\n0 - Clear all unicast hash bitmaps\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_uc_all_hash_table_set(port_id: u16, on: u8) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the rate limitation for a queue on an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_idx` -\nThe queue ID.\n* `tx_rate` -\nThe Tx rate in Mbps. Allocated from the total port link speed.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support this feature.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_set_queue_rate_limit(
        port_id: u16,
        queue_idx: u16,
        tx_rate: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Configuration of Receive Side Scaling hash computation of Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rss_conf` -\nThe new configuration to use for RSS hash computation on the port.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if port identifier is invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_rss_hash_update(
        port_id: u16,
        rss_conf: *mut rte_eth_rss_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve current configuration of Receive Side Scaling hash computation\nof Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `rss_conf` -\nWhere to store the current RSS hash configuration of the Ethernet device.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if port identifier is invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if hardware doesn't support RSS.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_rss_hash_conf_get(
        port_id: u16,
        rss_conf: *mut rte_eth_rss_conf,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice.\nGet the name of RSS hash algorithm.\n\n# Arguments\n\n* `rss_algo` -\nHash algorithm.\n\n# Returns\n\nHash algorithm name or 'UNKNOWN' if the rss_algo cannot be recognized."]
    pub fn rte_eth_dev_rss_algo_name(
        rss_algo: rte_eth_hash_function::Type,
    ) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice.\nGet RSS hash algorithm by its name.\n\n# Arguments\n\n* `name` -\nRSS hash algorithm.\n* `algo` -\nReturn the RSS hash algorithm found, # See also\n\n> [`rte_eth_hash_function.`]\n\n# Returns\n\n- (0) if successful.\n- (-EINVAL) if not found."]
    pub fn rte_eth_find_rss_algo(
        name: *const ::core::ffi::c_char,
        algo: *mut u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add UDP tunneling port for a type of tunnel.\nSome NICs may require such configuration to properly parse a tunnel\nwith any standard or custom UDP port.\nThe packets with this UDP port will be parsed for this type of tunnel.\nThe device parser will also check the rest of the tunnel headers\nbefore classifying the packet.\nWith some devices, this API will affect packet classification, i.e.:\n- mbuf.packet_type reported on Rx\n- rte_flow rules with tunnel items\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `tunnel_udp` -\nUDP tunneling configuration.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if port identifier is invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if hardware doesn't support tunnel type."]
    pub fn rte_eth_dev_udp_tunnel_port_add(
        port_id: u16,
        tunnel_udp: *mut rte_eth_udp_tunnel,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Delete UDP tunneling port for a type of tunnel.\nThe packets with this UDP port will not be classified as this type of tunnel\nanymore if the device use such mapping for tunnel packet classification.\n\n# See also\n\n> [`rte_eth_dev_udp_tunnel_port_add`]\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `tunnel_udp` -\nUDP tunneling configuration.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if port identifier is invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if hardware doesn't support tunnel type."]
    pub fn rte_eth_dev_udp_tunnel_port_delete(
        port_id: u16,
        tunnel_udp: *mut rte_eth_udp_tunnel,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get DCB information on an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `dcb_info` -\nDCB information.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if port identifier is invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_dcb_info(
        port_id: u16,
        dcb_info: *mut rte_eth_dcb_info,
    ) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxtx_callback {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Add a callback to be called on packet Rx on a given port and queue.\nThis API configures a function to be called for each burst of\npackets received on a given NIC port queue. The return value is a pointer\nthat can be used to later remove the callback using\nrte_eth_remove_rx_callback().\nMultiple functions are called in the order that they are added.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue on the Ethernet device on which the callback is to be added.\n* `fn` -\nThe callback function\n* `user_param` -\nA generic pointer parameter which will be passed to each invocation of the\ncallback function on this port and queue. Inter-thread synchronization\nof any user data changes is the responsibility of the user.\n\n# Returns\n\nNULL on error.\nOn success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_rx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_rx_callback_fn,
        user_param: *mut ::core::ffi::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = "Add a callback that must be called first on packet Rx on a given port\nand queue.\nThis API configures a first function to be called for each burst of\npackets received on a given NIC port queue. The return value is a pointer\nthat can be used to later remove the callback using\nrte_eth_remove_rx_callback().\nMultiple functions are called in the order that they are added.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue on the Ethernet device on which the callback is to be added.\n* `fn` -\nThe callback function\n* `user_param` -\nA generic pointer parameter which will be passed to each invocation of the\ncallback function on this port and queue. Inter-thread synchronization\nof any user data changes is the responsibility of the user.\n\n# Returns\n\nNULL on error.\nOn success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_first_rx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_rx_callback_fn,
        user_param: *mut ::core::ffi::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = "Add a callback to be called on packet Tx on a given port and queue.\nThis API configures a function to be called for each burst of\npackets sent on a given NIC port queue. The return value is a pointer\nthat can be used to later remove the callback using\nrte_eth_remove_tx_callback().\nMultiple functions are called in the order that they are added.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue on the Ethernet device on which the callback is to be added.\n* `fn` -\nThe callback function\n* `user_param` -\nA generic pointer parameter which will be passed to each invocation of the\ncallback function on this port and queue. Inter-thread synchronization\nof any user data changes is the responsibility of the user.\n\n# Returns\n\nNULL on error.\nOn success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_tx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_tx_callback_fn,
        user_param: *mut ::core::ffi::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = "Remove an Rx packet callback from a given port and queue.\nThis function is used to removed callbacks that were added to a NIC port\nqueue using rte_eth_add_rx_callback().\nNote: the callback is removed from the callback list but it isn't freed\nsince the it may still be in use. The memory for the callback can be\nsubsequently freed back by the application by calling rte_free():\n- Immediately - if the port is stopped, or the user knows that no\ncallbacks are in flight e.g. if called from the thread doing Rx/Tx\non that queue.\n- After a short delay - where the delay is sufficient to allow any\nin-flight callbacks to complete. Alternately, the RCU mechanism can be\nused to detect when data plane threads have ceased referencing the\ncallback memory.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue on the Ethernet device from which the callback is to be removed.\n* `user_cb` -\nUser supplied callback created via rte_eth_add_rx_callback().\n\n# Returns\n\n- 0: Success. Callback was removed.\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: Callback support is not available.\n- -EINVAL:  The queue_id is out of range, or the callback\nis NULL or not found for the port/queue."]
    pub fn rte_eth_remove_rx_callback(
        port_id: u16,
        queue_id: u16,
        user_cb: *const rte_eth_rxtx_callback,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a Tx packet callback from a given port and queue.\nThis function is used to removed callbacks that were added to a NIC port\nqueue using rte_eth_add_tx_callback().\nNote: the callback is removed from the callback list but it isn't freed\nsince the it may still be in use. The memory for the callback can be\nsubsequently freed back by the application by calling rte_free():\n- Immediately - if the port is stopped, or the user knows that no\ncallbacks are in flight e.g. if called from the thread doing Rx/Tx\non that queue.\n- After a short delay - where the delay is sufficient to allow any\nin-flight callbacks to complete. Alternately, the RCU mechanism can be\nused to detect when data plane threads have ceased referencing the\ncallback memory.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue on the Ethernet device from which the callback is to be removed.\n* `user_cb` -\nUser supplied callback created via rte_eth_add_tx_callback().\n\n# Returns\n\n- 0: Success. Callback was removed.\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: Callback support is not available.\n- -EINVAL:  The queue_id is out of range, or the callback\nis NULL or not found for the port/queue."]
    pub fn rte_eth_remove_tx_callback(
        port_id: u16,
        queue_id: u16,
        user_cb: *const rte_eth_rxtx_callback,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve information about given port's Rx queue.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Rx queue on the Ethernet device for which information\nwill be retrieved.\n* `qinfo` -\nA pointer to a structure of type *rte_eth_rxq_info_info* to be filled with\nthe information of the Ethernet device.\n\n# Returns\n\n- 0: Success\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: routine is not supported by the device PMD.\n- -EINVAL:  The queue_id is out of range, or the queue\nis hairpin queue."]
    pub fn rte_eth_rx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        qinfo: *mut rte_eth_rxq_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve information about given port's Tx queue.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Tx queue on the Ethernet device for which information\nwill be retrieved.\n* `qinfo` -\nA pointer to a structure of type *rte_eth_txq_info_info* to be filled with\nthe information of the Ethernet device.\n\n# Returns\n\n- 0: Success\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: routine is not supported by the device PMD.\n- -EINVAL:  The queue_id is out of range, or the queue\nis hairpin queue."]
    pub fn rte_eth_tx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        qinfo: *mut rte_eth_txq_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nRetrieve information about given ports's Rx queue for recycling mbufs.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Rx queue on the Ethernet devicefor which information\nwill be retrieved.\n* `recycle_rxq_info` -\nA pointer to a structure of type *rte_eth_recycle_rxq_info* to be filled.\n\n# Returns\n\n- 0: Success\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: routine is not supported by the device PMD.\n- -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_recycle_rx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve information about the Rx packet burst mode.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Rx queue on the Ethernet device for which information\nwill be retrieved.\n* `mode` -\nA pointer to a structure of type *rte_eth_burst_mode* to be filled\nwith the information of the packet burst mode.\n\n# Returns\n\n- 0: Success\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: routine is not supported by the device PMD.\n- -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_rx_burst_mode_get(
        port_id: u16,
        queue_id: u16,
        mode: *mut rte_eth_burst_mode,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve information about the Tx packet burst mode.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Tx queue on the Ethernet device for which information\nwill be retrieved.\n* `mode` -\nA pointer to a structure of type *rte_eth_burst_mode* to be filled\nwith the information of the packet burst mode.\n\n# Returns\n\n- 0: Success\n- -ENODEV:  If *port_id* is invalid.\n- -ENOTSUP: routine is not supported by the device PMD.\n- -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_tx_burst_mode_get(
        port_id: u16,
        queue_id: u16,
        mode: *mut rte_eth_burst_mode,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRetrieve the monitor condition for a given receive queue.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe Rx queue on the Ethernet device for which information\nwill be retrieved.\n* `pmc` -\nThe pointer to power-optimized monitoring condition structure.\n\n# Returns\n\n- 0: Success.\n-ENOTSUP: Operation not supported.\n-EINVAL: Invalid parameters.\n-ENODEV: Invalid port ID."]
    pub fn rte_eth_get_monitor_addr(
        port_id: u16,
        queue_id: u16,
        pmc: *mut rte_power_monitor_cond,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve the filtered device registers (values and names) and\nregister attributes (number of registers and register size)\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nPointer to rte_dev_reg_info structure to fill in.\n- If info->filter is NULL, return info for all registers (seen as filter\nnone).\n- If info->filter is not NULL, return error if the driver does not support\nfilter. Fill the length field with filtered register number.\n- If info->data is NULL, the function fills in the width and length fields.\n- If info->data is not NULL, ethdev considers there are enough spaces to\nstore the registers, and the values of registers with the filter string\nas the module name are put into the buffer pointed at by info->data.\n- If info->names is not NULL, drivers should fill it or the ethdev fills it\nwith default names.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_reg_info_ext(
        port_id: u16,
        info: *mut rte_dev_reg_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve device registers and register attributes (number of registers and\nregister size)\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nPointer to rte_dev_reg_info structure to fill in. If info->data is\nNULL the function fills in the width and length fields. If non-NULL\nthe registers are put into the buffer pointed at by the data field.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_reg_info(
        port_id: u16,
        info: *mut rte_dev_reg_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve size of device EEPROM\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- (>=0) EEPROM size if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_eeprom_length(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve EEPROM and EEPROM attribute\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nThe template includes buffer for return EEPROM data and\nEEPROM attributes to be filled.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Program EEPROM with provided data\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nThe template includes EEPROM data for programming and\nEEPROM attributes to be filled\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_set_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRetrieve the type and size of plugin module EEPROM\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `modinfo` -\nThe type and size of plugin module EEPROM.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_module_info(
        port_id: u16,
        modinfo: *mut rte_eth_dev_module_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRetrieve the data of plugin module EEPROM\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nThe template includes the plugin module EEPROM attributes, and the\nbuffer for return plugin module EEPROM data.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_module_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the list of multicast addresses to filter on an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `mc_addr_set` -\nThe array of multicast addresses to set. Equal to NULL when the function\nis invoked to flush the set of filtered addresses.\n* `nb_mc_addr` -\nThe number of multicast addresses in the *mc_addr_set* array. Equal to 0\nwhen the function is invoked to flush the set of filtered addresses.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-ENOTSUP) if PMD of *port_id* doesn't support multicast filtering.\n- (-ENOSPC) if *port_id* has not enough multicast filtering resources.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_set_mc_addr_list(
        port_id: u16,
        mc_addr_set: *mut rte_ether_addr,
        nb_mc_addr: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable IEEE1588/802.1AS timestamping for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- 0: Success.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_enable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Disable IEEE1588/802.1AS timestamping for an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n\n# Returns\n\n- 0: Success.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_disable(port_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read an IEEE1588/802.1AS Rx timestamp from an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `timestamp` -\nPointer to the timestamp struct.\n* `flags` -\nDevice specific flags. Used to pass the Rx timesync register index to\ni40e. Unused in igb/ixgbe, pass 0 instead.\n\n# Returns\n\n- 0: Success.\n- -EINVAL: No timestamp is available.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_read_rx_timestamp(
        port_id: u16,
        timestamp: *mut timespec,
        flags: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read an IEEE1588/802.1AS Tx timestamp from an Ethernet device.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `timestamp` -\nPointer to the timestamp struct.\n\n# Returns\n\n- 0: Success.\n- -EINVAL: No timestamp is available.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_read_tx_timestamp(
        port_id: u16,
        timestamp: *mut timespec,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Adjust the timesync clock on an Ethernet device.\nThis is usually used in conjunction with other Ethdev timesync functions to\nsynchronize the device time using the IEEE1588/802.1AS protocol.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `delta` -\nThe adjustment in nanoseconds.\n\n# Returns\n\n- 0: Success.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_adjust_time(port_id: u16, delta: i64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Adjust the clock frequency on an Ethernet device.\nAdjusts the base frequency by a specified percentage of ppm (parts per\nmillion). This is usually used in conjunction with other Ethdev timesync\nfunctions to synchronize the device time using the IEEE1588/802.1AS\nprotocol.\nThe clock is subject to frequency deviation and rate of change drift due to\nthe environment. The upper layer APP calculates the frequency compensation\nvalue of the slave clock relative to the master clock via a servo algorithm\nand adjusts the device clock frequency via \"rte_eth_timesync_adjust_freq()\".\nCommonly used servo algorithms are pi/linreg/ntpshm, for implementation\nsee: https://github.com/nxp-archive/openil_linuxptp.git.\nThe adjustment value obtained by the servo algorithm is usually in\nppb (parts per billion). For consistency with the kernel driver .adjfine,\nthe tuning values are in ppm. Note that 1 ppb is approximately 65.536 scaled\nppm, see Linux kernel upstream commit 1060707e3809 (ptp: introduce helpers\nto adjust by scaled parts per million).\nIn addition, the device reference frequency is usually also the stepping\nthreshold for the servo algorithm, and the frequency up and down adjustment\nrange is limited by the device. The device clock frequency should be\nadjusted with \"rte_eth_timesync_adjust_freq()\" every time the clock is\nsynchronised. Also use rte_eth_timesync_adjust_time() to update the device\nclock only if the absolute value of the master/slave clock offset is greater than\nor equal to the step threshold.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `ppm` -\nParts per million with 16-bit fractional field\n\n# Returns\n\n- 0: Success.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_adjust_freq(port_id: u16, ppm: i64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Read the time from the timesync clock on an Ethernet device.\nThis is usually used in conjunction with other Ethdev timesync functions to\nsynchronize the device time using the IEEE1588/802.1AS protocol.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `time` -\nPointer to the timespec struct that holds the time.\n\n# Returns\n\n- 0: Success.\n- -EINVAL: Bad parameter."]
    pub fn rte_eth_timesync_read_time(port_id: u16, time: *mut timespec) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the time of the timesync clock on an Ethernet device.\nThis is usually used in conjunction with other Ethdev timesync functions to\nsynchronize the device time using the IEEE1588/802.1AS protocol.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `time` -\nPointer to the timespec struct that holds the time.\n\n# Returns\n\n- 0: Success.\n- -EINVAL: No timestamp is available.\n- -ENODEV: The port ID is invalid.\n- -EIO: if device is removed.\n- -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_write_time(port_id: u16, time: *const timespec) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nRead the current clock counter of an Ethernet device\nThis returns the current raw clock value of an Ethernet device. It is\na raw amount of ticks, with no given time reference.\nThe value returned here is from the same clock than the one\nfilling timestamp field of Rx packets when using hardware timestamp\noffload. Therefore it can be used to compute a precise conversion of\nthe device clock to the real time.\nE.g, a simple heuristic to derivate the frequency would be:\nuint64_t start, end;\nrte_eth_read_clock(port, start);\nrte_delay_ms(100);\nrte_eth_read_clock(port, end);\ndouble freq = (end - start) * 10;\nCompute a common reference with:\nuint64_t base_time_sec = current_time();\nuint64_t base_clock;\nrte_eth_read_clock(port, base_clock);\nThen, convert the raw mbuf timestamp with:\nbase_time_sec + (double)(*timestamp_dynfield(mbuf) - base_clock) / freq;\nThis simple example will not provide a very good accuracy. One must\nat least measure multiple times the frequency and do a regression.\nTo avoid deviation from the system time, the common reference can\nbe repeated from time to time. The integer division can also be\nconverted by a multiplication and a shift for better performance.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `clock` -\nPointer to the uint64_t that holds the raw clock value.\n\n# Returns\n\n- 0: Success.\n- -ENODEV: The port ID is invalid.\n- -ENOTSUP: The function is not supported by the Ethernet driver.\n- -EINVAL: if bad parameter."]
    pub fn rte_eth_read_clock(port_id: u16, clock: *mut u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the port ID from device name.\nThe device name should be specified as below:\n- PCIe address (Domain:Bus:Device.Function), for example- 0000:2:00.0\n- SoC device name, for example- fsl-gmac0\n- vdev dpdk name, for example- net_[pcap0|null0|tap0]\n\n# Arguments\n\n* `name` -\nPCI address or name of the device.\n* `port_id` -\nPointer to port identifier of the device.\n\n# Returns\n\n- (0) if successful and port_id is filled.\n- (-ENODEV or -EINVAL) on failure."]
    pub fn rte_eth_dev_get_port_by_name(
        name: *const ::core::ffi::c_char,
        port_id: *mut u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the device name from port ID.\nThe device name is specified as below:\n- PCIe address (Domain:Bus:Device.Function), for example- 0000:02:00.0\n- SoC device name, for example- fsl-gmac0\n- vdev dpdk name, for example- net_[pcap0|null0|tun0|tap0]\n\n# Arguments\n\n* `port_id` -\nPort identifier of the device.\n* `name` -\nBuffer of size RTE_ETH_NAME_MAX_LEN to store the name.\n\n# Returns\n\n- (0) if successful.\n- (-ENODEV) if *port_id* is invalid.\n- (-EINVAL) on failure."]
    pub fn rte_eth_dev_get_name_by_port(
        port_id: u16,
        name: *mut ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check that numbers of Rx and Tx descriptors satisfy descriptors limits from\nthe Ethernet device information, otherwise adjust them to boundaries.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `nb_rx_desc` -\nA pointer to a uint16_t where the number of receive\ndescriptors stored.\n* `nb_tx_desc` -\nA pointer to a uint16_t where the number of transmit\ndescriptors stored.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP, -ENODEV or -EINVAL) on failure."]
    pub fn rte_eth_dev_adjust_nb_rx_tx_desc(
        port_id: u16,
        nb_rx_desc: *mut u16,
        nb_tx_desc: *mut u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if a port supports specific mempool ops.\n\n# Arguments\n\n* `port_id` -\nPort identifier of the Ethernet device.\n* `pool` [in]  -\nThe name of the pool operations to test.\n\n# Returns\n\n- 0: best mempool ops choice for this port.\n- 1: mempool ops are supported for this port.\n- -ENOTSUP: mempool ops not supported for this port.\n- -ENODEV: Invalid port Identifier.\n- -EINVAL: Pool param is null."]
    pub fn rte_eth_dev_pool_ops_supported(
        port_id: u16,
        pool: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the security context for the Ethernet device.\n\n# Arguments\n\n* `port_id` -\nPort identifier of the Ethernet device\n\n# Returns\n\n- NULL on error.\n- pointer to security context on success."]
    pub fn rte_eth_dev_get_sec_ctx(port_id: u16) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nQuery the device hairpin capabilities.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `cap` -\nPointer to a structure that will hold the hairpin capabilities.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if hardware doesn't support.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_hairpin_capability_get(
        port_id: u16,
        cap: *mut rte_eth_hairpin_cap,
    ) -> ::core::ffi::c_int;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nEthernet device representor ID range entry"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_representor_range {
    #[doc = "< Representor type"]
    pub type_: rte_eth_representor_type::Type,
    #[doc = "< Controller index"]
    pub controller: ::core::ffi::c_int,
    #[doc = "< Physical function index"]
    pub pf: ::core::ffi::c_int,
    pub anon1: rte_eth_representor_range__bindgen_ty_1,
    #[doc = "< Representor ID start index"]
    pub id_base: u32,
    #[doc = "< Representor ID end index"]
    pub id_end: u32,
    #[doc = "< Representor name"]
    pub name: [::core::ffi::c_char; 64usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_representor_range__bindgen_ty_1 {
    #[doc = "< VF start index"]
    pub vf: ::core::ffi::c_int,
    #[doc = "< SF start index"]
    pub sf: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_range__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_representor_range__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_representor_range__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_representor_range__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_eth_representor_range__bindgen_ty_1::vf"]
        [::core::mem::offset_of!(rte_eth_representor_range__bindgen_ty_1, vf) - 0usize];
    ["Offset of field: rte_eth_representor_range__bindgen_ty_1::sf"]
        [::core::mem::offset_of!(rte_eth_representor_range__bindgen_ty_1, sf) - 0usize];
};
impl Default for rte_eth_representor_range__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_range"]
        [::core::mem::size_of::<rte_eth_representor_range>() - 88usize];
    ["Alignment of rte_eth_representor_range"]
        [::core::mem::align_of::<rte_eth_representor_range>() - 4usize];
    ["Offset of field: rte_eth_representor_range::type_"]
        [::core::mem::offset_of!(rte_eth_representor_range, type_) - 0usize];
    ["Offset of field: rte_eth_representor_range::controller"]
        [::core::mem::offset_of!(rte_eth_representor_range, controller) - 4usize];
    ["Offset of field: rte_eth_representor_range::pf"]
        [::core::mem::offset_of!(rte_eth_representor_range, pf) - 8usize];
    ["Offset of field: rte_eth_representor_range::id_base"]
        [::core::mem::offset_of!(rte_eth_representor_range, id_base) - 16usize];
    ["Offset of field: rte_eth_representor_range::id_end"]
        [::core::mem::offset_of!(rte_eth_representor_range, id_end) - 20usize];
    ["Offset of field: rte_eth_representor_range::name"]
        [::core::mem::offset_of!(rte_eth_representor_range, name) - 24usize];
};
impl Default for rte_eth_representor_range {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nEthernet device representor information"]
#[repr(C)]
pub struct rte_eth_representor_info {
    #[doc = "< Controller ID of caller device."]
    pub controller: u16,
    #[doc = "< Physical function ID of caller device."]
    pub pf: u16,
    #[doc = "< Size of the ranges array."]
    pub nb_ranges_alloc: u32,
    #[doc = "< Number of initialized ranges."]
    pub nb_ranges: u32,
    #[doc = "< Representor ID range."]
    pub ranges: __IncompleteArrayField<rte_eth_representor_range>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_info"]
        [::core::mem::size_of::<rte_eth_representor_info>() - 12usize];
    ["Alignment of rte_eth_representor_info"]
        [::core::mem::align_of::<rte_eth_representor_info>() - 4usize];
    ["Offset of field: rte_eth_representor_info::controller"]
        [::core::mem::offset_of!(rte_eth_representor_info, controller) - 0usize];
    ["Offset of field: rte_eth_representor_info::pf"]
        [::core::mem::offset_of!(rte_eth_representor_info, pf) - 2usize];
    ["Offset of field: rte_eth_representor_info::nb_ranges_alloc"]
        [::core::mem::offset_of!(rte_eth_representor_info, nb_ranges_alloc) - 4usize];
    ["Offset of field: rte_eth_representor_info::nb_ranges"]
        [::core::mem::offset_of!(rte_eth_representor_info, nb_ranges) - 8usize];
    ["Offset of field: rte_eth_representor_info::ranges"]
        [::core::mem::offset_of!(rte_eth_representor_info, ranges) - 12usize];
};
impl Default for rte_eth_representor_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Retrieve the representor info of the device.\nGet device representor info to be able to calculate a unique\nrepresentor ID. # See also\n\n> [`rte_eth_representor_id_get`] helper.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `info` -\nA pointer to a representor info structure.\nNULL to return number of range entries and allocate memory\nfor next call to store detail.\nThe number of ranges that were written into this structure\nwill be placed into its nb_ranges field. This number cannot be\nlarger than the nb_ranges_alloc that by the user before calling\nthis function. It can be smaller than the value returned by the\nfunction, however.\n\n# Returns\n\n- (-ENOTSUP) if operation is not supported.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (>=0) number of available representor range entries."]
    pub fn rte_eth_representor_info_get(
        port_id: u16,
        info: *mut rte_eth_representor_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Negotiate the NIC's ability to deliver specific kinds of metadata to the PMD.\nInvoke this API before the first rte_eth_dev_configure() invocation\nto let the PMD make preparations that are inconvenient to do later.\nThe negotiation process is as follows:\n- the application requests features intending to use at least some of them;\n- the PMD responds with the guaranteed subset of the requested feature set;\n- the application can retry negotiation with another set of features;\n- the application can pass zero to clear the negotiation result;\n- the last negotiated result takes effect upon\nthe ethdev configure and start.\n> **Note** The PMD is supposed to first consider enabling the requested feature set\nin its entirety. Only if it fails to do so, does it have the right to\nrespond with a smaller set of the originally requested features.\n> **Note** Return code (-ENOTSUP) does not necessarily mean that the requested\nfeatures are unsupported. In this case, the application should just\nassume that these features can be used without prior negotiations.\n\n# Arguments\n\n* `port_id` -\nPort (ethdev) identifier\n* `features` [inout]  -\nFeature selection buffer\n\n# Returns\n\n- (-EBUSY) if the port can't handle this in its current state;\n- (-ENOTSUP) if the method itself is not supported by the PMD;\n- (-ENODEV) if *port_id* is invalid;\n- (-EINVAL) if *features* is NULL;\n- (-EIO) if the device is removed;\n- (0) on success"]
    pub fn rte_eth_rx_metadata_negotiate(port_id: u16, features: *mut u64) -> ::core::ffi::c_int;
}
#[doc = "A structure used to get/set IP reassembly configuration. It is also used\nto get the maximum capability values that a PMD can support.\nIf rte_eth_ip_reassembly_capability_get() returns 0, IP reassembly can be\nenabled using rte_eth_ip_reassembly_conf_set() and params values lower than\ncapability params can be set in the PMD."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_ip_reassembly_params {
    #[doc = "Maximum time in ms which PMD can wait for other fragments."]
    pub timeout_ms: u32,
    #[doc = "Maximum number of fragments that can be reassembled."]
    pub max_frags: u16,
    #[doc = "Flags to enable reassembly of packet types -\nRTE_ETH_DEV_REASSEMBLY_F_xxx."]
    pub flags: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ip_reassembly_params"]
        [::core::mem::size_of::<rte_eth_ip_reassembly_params>() - 8usize];
    ["Alignment of rte_eth_ip_reassembly_params"]
        [::core::mem::align_of::<rte_eth_ip_reassembly_params>() - 4usize];
    ["Offset of field: rte_eth_ip_reassembly_params::timeout_ms"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_params, timeout_ms) - 0usize];
    ["Offset of field: rte_eth_ip_reassembly_params::max_frags"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_params, max_frags) - 4usize];
    ["Offset of field: rte_eth_ip_reassembly_params::flags"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_params, flags) - 6usize];
};
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nGet IP reassembly capabilities supported by the PMD. This is the first API\nto be called for enabling the IP reassembly offload feature. PMD will return\nthe maximum values of parameters that PMD can support and user can call\nrte_eth_ip_reassembly_conf_set() with param values lower than capability.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `capa` -\nA pointer to rte_eth_ip_reassembly_params structure.\n\n# Returns\n\n- (-ENOTSUP) if offload configuration is not supported by device.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if device is not configured or *capa* passed is NULL.\n- (0) on success."]
    pub fn rte_eth_ip_reassembly_capability_get(
        port_id: u16,
        capa: *mut rte_eth_ip_reassembly_params,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nGet IP reassembly configuration parameters currently set in PMD.\nThe API will return error if the configuration is not already\nset using rte_eth_ip_reassembly_conf_set() before calling this API or if\nthe device is not configured.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `conf` -\nA pointer to rte_eth_ip_reassembly_params structure.\n\n# Returns\n\n- (-ENOTSUP) if offload configuration is not supported by device.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if device is not configured or if *conf* passed is NULL or if\nconfiguration is not set using rte_eth_ip_reassembly_conf_set().\n- (0) on success."]
    pub fn rte_eth_ip_reassembly_conf_get(
        port_id: u16,
        conf: *mut rte_eth_ip_reassembly_params,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nSet IP reassembly configuration parameters if the PMD supports IP reassembly\noffload. User should first call rte_eth_ip_reassembly_capability_get() to\ncheck the maximum values supported by the PMD before setting the\nconfiguration. The use of this API is mandatory to enable this feature and\nshould be called before rte_eth_dev_start().\nIn datapath, PMD cannot guarantee that IP reassembly is always successful.\nHence, PMD shall register mbuf dynamic field and dynamic flag using\nrte_eth_ip_reassembly_dynfield_register() to denote incomplete IP reassembly.\nIf dynfield is not successfully registered, error will be returned and\nIP reassembly offload cannot be used.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `conf` -\nA pointer to rte_eth_ip_reassembly_params structure.\n\n# Returns\n\n- (-ENOTSUP) if offload configuration is not supported by device.\n- (-ENODEV) if *port_id* invalid.\n- (-EIO) if device is removed.\n- (-EINVAL) if device is not configured or if device is already started or\nif *conf* passed is NULL or if mbuf dynfield is not registered\nsuccessfully by the PMD.\n- (0) on success."]
    pub fn rte_eth_ip_reassembly_conf_set(
        port_id: u16,
        conf: *const rte_eth_ip_reassembly_params,
    ) -> ::core::ffi::c_int;
}
#[doc = "In case of IP reassembly offload failure, packet will be updated with\ndynamic flag - RTE_MBUF_DYNFLAG_IP_REASSEMBLY_INCOMPLETE_NAME and packets\nwill be returned without alteration.\nThe application can retrieve the attached fragments using mbuf dynamic field\nRTE_MBUF_DYNFIELD_IP_REASSEMBLY_NAME."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_ip_reassembly_dynfield_t {
    #[doc = "Next fragment packet. Application should fetch dynamic field of\neach fragment until a NULL is received and nb_frags is 0."]
    pub next_frag: *mut rte_mbuf,
    #[doc = "Time spent(in ms) by HW in waiting for further fragments."]
    pub time_spent: u16,
    #[doc = "Number of more fragments attached in mbuf dynamic fields."]
    pub nb_frags: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ip_reassembly_dynfield_t"]
        [::core::mem::size_of::<rte_eth_ip_reassembly_dynfield_t>() - 16usize];
    ["Alignment of rte_eth_ip_reassembly_dynfield_t"]
        [::core::mem::align_of::<rte_eth_ip_reassembly_dynfield_t>() - 8usize];
    ["Offset of field: rte_eth_ip_reassembly_dynfield_t::next_frag"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_dynfield_t, next_frag) - 0usize];
    ["Offset of field: rte_eth_ip_reassembly_dynfield_t::time_spent"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_dynfield_t, time_spent) - 8usize];
    ["Offset of field: rte_eth_ip_reassembly_dynfield_t::nb_frags"]
        [::core::mem::offset_of!(rte_eth_ip_reassembly_dynfield_t, nb_frags) - 10usize];
};
impl Default for rte_eth_ip_reassembly_dynfield_t {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nDump private info from device to a file. Provided data and the order depends\non the PMD.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `file` -\nA pointer to a file for output.\n\n# Returns\n\n- (0) on success.\n- (-ENODEV) if *port_id* is invalid.\n- (-EINVAL) if null file.\n- (-ENOTSUP) if the device does not support this function.\n- (-EIO) if device is removed."]
    pub fn rte_eth_dev_priv_dump(port_id: u16, file: *mut FILE) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nDump ethdev Rx descriptor info to a file.\nThis API is used for debugging, not a dataplane API.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nA Rx queue identifier on this port.\n* `offset` -\nThe offset of the descriptor starting from tail. (0 is the next\npacket to be received by the driver).\n* `num` -\nThe number of the descriptors to dump.\n* `file` -\nA pointer to a file for output.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_rx_descriptor_dump(
        port_id: u16,
        queue_id: u16,
        offset: u16,
        num: u16,
        file: *mut FILE,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nDump ethdev Tx descriptor info to a file.\nThis API is used for debugging, not a dataplane API.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nA Tx queue identifier on this port.\n* `offset` -\nThe offset of the descriptor starting from tail. (0 is the place where\nthe next packet will be send).\n* `num` -\nThe number of the descriptors to dump.\n* `file` -\nA pointer to a file for output.\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_eth_tx_descriptor_dump(
        port_id: u16,
        queue_id: u16,
        offset: u16,
        num: u16,
        file: *mut FILE,
    ) -> ::core::ffi::c_int;
}
pub mod rte_eth_cman_obj {
    #[doc = "Enumerate list of ethdev congestion management objects"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Congestion management based on Rx queue depth"]
    pub const RTE_ETH_CMAN_OBJ_RX_QUEUE: Type = 1;
    #[doc = "Congestion management based on mempool depth associated with Rx queue\n\n# See also\n\n> [`rte_eth_rx_queue_setup()`]"]
    pub const RTE_ETH_CMAN_OBJ_RX_QUEUE_MEMPOOL: Type = 2;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change, or be removed, without prior notice\nA structure used to retrieve information of ethdev congestion management."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_cman_info {
    #[doc = "Set of supported congestion management modes\n\n# See also\n\n> [`enum`] rte_cman_mode"]
    pub modes_supported: u64,
    #[doc = "Set of supported congestion management objects\n\n# See also\n\n> [`enum`] rte_eth_cman_obj"]
    pub objs_supported: u64,
    #[doc = "Reserved for future fields. Always returned as 0 when\nrte_eth_cman_info_get() is invoked"]
    pub rsvd: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_info"][::core::mem::size_of::<rte_eth_cman_info>() - 24usize];
    ["Alignment of rte_eth_cman_info"][::core::mem::align_of::<rte_eth_cman_info>() - 8usize];
    ["Offset of field: rte_eth_cman_info::modes_supported"]
        [::core::mem::offset_of!(rte_eth_cman_info, modes_supported) - 0usize];
    ["Offset of field: rte_eth_cman_info::objs_supported"]
        [::core::mem::offset_of!(rte_eth_cman_info, objs_supported) - 8usize];
    ["Offset of field: rte_eth_cman_info::rsvd"]
        [::core::mem::offset_of!(rte_eth_cman_info, rsvd) - 16usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change, or be removed, without prior notice\nA structure used to configure the ethdev congestion management."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_cman_config {
    #[doc = "Congestion management object"]
    pub obj: rte_eth_cman_obj::Type,
    #[doc = "Congestion management mode"]
    pub mode: rte_cman_mode::Type,
    pub obj_param: rte_eth_cman_config__bindgen_ty_1,
    pub mode_param: rte_eth_cman_config__bindgen_ty_2,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_cman_config__bindgen_ty_1 {
    #[doc = "Rx queue to configure congestion management.\nValid when object is RTE_ETH_CMAN_OBJ_RX_QUEUE or\nRTE_ETH_CMAN_OBJ_RX_QUEUE_MEMPOOL."]
    pub rx_queue: u16,
    #[doc = "Reserved for future fields.\nIt must be set to 0 when rte_eth_cman_config_set() is invoked\nand will be returned as 0 when rte_eth_cman_config_get() is\ninvoked."]
    pub rsvd_obj_params: [u8; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config__bindgen_ty_1"]
        [::core::mem::size_of::<rte_eth_cman_config__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_cman_config__bindgen_ty_1"]
        [::core::mem::align_of::<rte_eth_cman_config__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_1::rx_queue"]
        [::core::mem::offset_of!(rte_eth_cman_config__bindgen_ty_1, rx_queue) - 0usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_1::rsvd_obj_params"]
        [::core::mem::offset_of!(rte_eth_cman_config__bindgen_ty_1, rsvd_obj_params) - 0usize];
};
impl Default for rte_eth_cman_config__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_cman_config__bindgen_ty_2 {
    #[doc = "RED configuration parameters.\nValid when mode is RTE_CMAN_RED."]
    pub red: rte_cman_red_params,
    #[doc = "Reserved for future fields.\nIt must be set to 0 when rte_eth_cman_config_set() is invoked\nand will be returned as 0 when rte_eth_cman_config_get() is\ninvoked."]
    pub rsvd_mode_params: [u8; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config__bindgen_ty_2"]
        [::core::mem::size_of::<rte_eth_cman_config__bindgen_ty_2>() - 4usize];
    ["Alignment of rte_eth_cman_config__bindgen_ty_2"]
        [::core::mem::align_of::<rte_eth_cman_config__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_2::red"]
        [::core::mem::offset_of!(rte_eth_cman_config__bindgen_ty_2, red) - 0usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_2::rsvd_mode_params"]
        [::core::mem::offset_of!(rte_eth_cman_config__bindgen_ty_2, rsvd_mode_params) - 0usize];
};
impl Default for rte_eth_cman_config__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config"][::core::mem::size_of::<rte_eth_cman_config>() - 16usize];
    ["Alignment of rte_eth_cman_config"][::core::mem::align_of::<rte_eth_cman_config>() - 4usize];
    ["Offset of field: rte_eth_cman_config::obj"]
        [::core::mem::offset_of!(rte_eth_cman_config, obj) - 0usize];
    ["Offset of field: rte_eth_cman_config::mode"]
        [::core::mem::offset_of!(rte_eth_cman_config, mode) - 4usize];
    ["Offset of field: rte_eth_cman_config::obj_param"]
        [::core::mem::offset_of!(rte_eth_cman_config, obj_param) - 8usize];
    ["Offset of field: rte_eth_cman_config::mode_param"]
        [::core::mem::offset_of!(rte_eth_cman_config, mode_param) - 12usize];
};
impl Default for rte_eth_cman_config {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nRetrieve the information for ethdev congestion management\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `info` -\nA pointer to a structure of type *rte_eth_cman_info* to be filled with\nthe information about congestion management.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for cman_info_get does not exist.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_info_get(port_id: u16, info: *mut rte_eth_cman_info) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nInitialize the ethdev congestion management configuration structure with default values.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `config` -\nA pointer to a structure of type *rte_eth_cman_config* to be initialized\nwith default value.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for cman_config_init does not exist.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_init(
        port_id: u16,
        config: *mut rte_eth_cman_config,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nConfigure ethdev congestion management\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `config` -\nA pointer to a structure of type *rte_eth_cman_config* to be configured.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for cman_config_set does not exist.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_set(
        port_id: u16,
        config: *const rte_eth_cman_config,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nRetrieve the applied ethdev congestion management parameters for the given port.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `config` -\nA pointer to a structure of type *rte_eth_cman_config* to retrieve\ncongestion management parameters for the given object.\nApplication must fill all parameters except mode_param parameter in\nstruct rte_eth_cman_config.\n\n# Returns\n\n- (0) if successful.\n- (-ENOTSUP) if support for cman_config_get does not exist.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_get(
        port_id: u16,
        config: *mut rte_eth_cman_config,
    ) -> ::core::ffi::c_int;
}
#[doc = "@file RTE Ethernet Device internal header.\nThis header contains internal data types. But they are still part of the\npublic API because they are used by inline functions in the published API.\nApplications should not use these directly."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_callback {
    _unused: [u8; 0],
}
#[doc = "@internal Structure to keep track of registered callbacks"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_cb_list {
    pub tqh_first: *mut rte_eth_dev_callback,
    pub tqh_last: *mut *mut rte_eth_dev_callback,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_cb_list"][::core::mem::size_of::<rte_eth_dev_cb_list>() - 16usize];
    ["Alignment of rte_eth_dev_cb_list"][::core::mem::align_of::<rte_eth_dev_cb_list>() - 8usize];
    ["Offset of field: rte_eth_dev_cb_list::tqh_first"]
        [::core::mem::offset_of!(rte_eth_dev_cb_list, tqh_first) - 0usize];
    ["Offset of field: rte_eth_dev_cb_list::tqh_last"]
        [::core::mem::offset_of!(rte_eth_dev_cb_list, tqh_last) - 8usize];
};
impl Default for rte_eth_dev_cb_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev {
    _unused: [u8; 0],
}
#[doc = "@internal Retrieve input packets from a receive queue of an Ethernet device."]
pub type eth_rx_burst_t = ::core::option::Option<
    unsafe extern "C" fn(
        rxq: *mut ::core::ffi::c_void,
        rx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16,
>;
#[doc = "@internal Send output packets on a transmit queue of an Ethernet device."]
pub type eth_tx_burst_t = ::core::option::Option<
    unsafe extern "C" fn(
        txq: *mut ::core::ffi::c_void,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16,
>;
#[doc = "@internal Prepare output packets on a transmit queue of an Ethernet device."]
pub type eth_tx_prep_t = ::core::option::Option<
    unsafe extern "C" fn(
        txq: *mut ::core::ffi::c_void,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16,
>;
#[doc = "@internal Get number of used descriptors on a receive queue."]
pub type eth_rx_queue_count_t =
    ::core::option::Option<unsafe extern "C" fn(rxq: *mut ::core::ffi::c_void) -> u32>;
#[doc = "@internal Check the status of a Rx descriptor"]
pub type eth_rx_descriptor_status_t = ::core::option::Option<
    unsafe extern "C" fn(rxq: *mut ::core::ffi::c_void, offset: u16) -> ::core::ffi::c_int,
>;
#[doc = "@internal Get number of used descriptors on a transmit queue."]
pub type eth_tx_queue_count_t = ::core::option::Option<
    unsafe extern "C" fn(txq: *mut ::core::ffi::c_void) -> ::core::ffi::c_int,
>;
#[doc = "@internal Check the status of a Tx descriptor"]
pub type eth_tx_descriptor_status_t = ::core::option::Option<
    unsafe extern "C" fn(txq: *mut ::core::ffi::c_void, offset: u16) -> ::core::ffi::c_int,
>;
#[doc = "@internal Copy used mbufs from Tx mbuf ring into Rx mbuf ring"]
pub type eth_recycle_tx_mbufs_reuse_t = ::core::option::Option<
    unsafe extern "C" fn(
        txq: *mut ::core::ffi::c_void,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> u16,
>;
#[doc = "@internal Refill Rx descriptors with the recycling mbufs"]
pub type eth_recycle_rx_descriptors_refill_t =
    ::core::option::Option<unsafe extern "C" fn(rxq: *mut ::core::ffi::c_void, nb: u16)>;
#[doc = "@internal Structure used to hold opaque pointers to internal ethdev Rx/Tx\nqueues data.\nThe main purpose to expose these pointers at all - allow compiler\nto fetch this data for fast-path ethdev inline functions in advance."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_ethdev_qdata {
    #[doc = "points to array of internal queue data pointers"]
    pub data: *mut *mut ::core::ffi::c_void,
    #[doc = "points to array of queue callback data pointers"]
    pub clbk: *mut *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ethdev_qdata"][::core::mem::size_of::<rte_ethdev_qdata>() - 16usize];
    ["Alignment of rte_ethdev_qdata"][::core::mem::align_of::<rte_ethdev_qdata>() - 8usize];
    ["Offset of field: rte_ethdev_qdata::data"]
        [::core::mem::offset_of!(rte_ethdev_qdata, data) - 0usize];
    ["Offset of field: rte_ethdev_qdata::clbk"]
        [::core::mem::offset_of!(rte_ethdev_qdata, clbk) - 8usize];
};
impl Default for rte_ethdev_qdata {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@internal fast-path ethdev functions and related data are hold in a flat array.\nOne entry per ethdev.\nOn 64-bit systems contents of this structure occupy exactly two 64B lines.\nOn 32-bit systems contents of this structure fits into one 64B line."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fp_ops {
    #[doc = "@{*/ /**\nRx fast-path functions and related data.\n64-bit systems: occupies first 64B line\n/\n/** Rx queues data."]
    pub rxq: rte_ethdev_qdata,
    #[doc = "PMD receive function."]
    pub rx_pkt_burst: eth_rx_burst_t,
    #[doc = "Get the number of used Rx descriptors."]
    pub rx_queue_count: eth_rx_queue_count_t,
    #[doc = "Check the status of a Rx descriptor."]
    pub rx_descriptor_status: eth_rx_descriptor_status_t,
    #[doc = "Refill Rx descriptors with the recycling mbufs."]
    pub recycle_rx_descriptors_refill: eth_recycle_rx_descriptors_refill_t,
    pub reserved1: [usize; 2usize],
    #[doc = "@{*/ /**\nTx fast-path functions and related data.\n64-bit systems: occupies second 64B line\n/\n/** Tx queues data."]
    pub txq: rte_ethdev_qdata,
    #[doc = "PMD transmit function."]
    pub tx_pkt_burst: eth_tx_burst_t,
    #[doc = "PMD transmit prepare function."]
    pub tx_pkt_prepare: eth_tx_prep_t,
    #[doc = "Check the status of a Tx descriptor."]
    pub tx_descriptor_status: eth_tx_descriptor_status_t,
    #[doc = "Copy used mbufs from Tx mbuf ring into Rx."]
    pub recycle_tx_mbufs_reuse: eth_recycle_tx_mbufs_reuse_t,
    #[doc = "Get the number of used Tx descriptors."]
    pub tx_queue_count: eth_tx_queue_count_t,
    pub reserved2: [usize; 1usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fp_ops"][::core::mem::size_of::<rte_eth_fp_ops>() - 128usize];
    ["Alignment of rte_eth_fp_ops"][::core::mem::align_of::<rte_eth_fp_ops>() - 64usize];
    ["Offset of field: rte_eth_fp_ops::rxq"][::core::mem::offset_of!(rte_eth_fp_ops, rxq) - 0usize];
    ["Offset of field: rte_eth_fp_ops::rx_pkt_burst"]
        [::core::mem::offset_of!(rte_eth_fp_ops, rx_pkt_burst) - 16usize];
    ["Offset of field: rte_eth_fp_ops::rx_queue_count"]
        [::core::mem::offset_of!(rte_eth_fp_ops, rx_queue_count) - 24usize];
    ["Offset of field: rte_eth_fp_ops::rx_descriptor_status"]
        [::core::mem::offset_of!(rte_eth_fp_ops, rx_descriptor_status) - 32usize];
    ["Offset of field: rte_eth_fp_ops::recycle_rx_descriptors_refill"]
        [::core::mem::offset_of!(rte_eth_fp_ops, recycle_rx_descriptors_refill) - 40usize];
    ["Offset of field: rte_eth_fp_ops::reserved1"]
        [::core::mem::offset_of!(rte_eth_fp_ops, reserved1) - 48usize];
    ["Offset of field: rte_eth_fp_ops::txq"]
        [::core::mem::offset_of!(rte_eth_fp_ops, txq) - 64usize];
    ["Offset of field: rte_eth_fp_ops::tx_pkt_burst"]
        [::core::mem::offset_of!(rte_eth_fp_ops, tx_pkt_burst) - 80usize];
    ["Offset of field: rte_eth_fp_ops::tx_pkt_prepare"]
        [::core::mem::offset_of!(rte_eth_fp_ops, tx_pkt_prepare) - 88usize];
    ["Offset of field: rte_eth_fp_ops::tx_descriptor_status"]
        [::core::mem::offset_of!(rte_eth_fp_ops, tx_descriptor_status) - 96usize];
    ["Offset of field: rte_eth_fp_ops::recycle_tx_mbufs_reuse"]
        [::core::mem::offset_of!(rte_eth_fp_ops, recycle_tx_mbufs_reuse) - 104usize];
    ["Offset of field: rte_eth_fp_ops::tx_queue_count"]
        [::core::mem::offset_of!(rte_eth_fp_ops, tx_queue_count) - 112usize];
    ["Offset of field: rte_eth_fp_ops::reserved2"]
        [::core::mem::offset_of!(rte_eth_fp_ops, reserved2) - 120usize];
};
impl Default for rte_eth_fp_ops {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static mut rte_eth_fp_ops: [rte_eth_fp_ops; 32usize];
}
unsafe extern "C" {
    #[doc = "@internal Helper routine for rte_eth_rx_burst().\nShould be called at exit from PMD's rte_eth_rx_bulk implementation.\nDoes necessary post-processing - invokes Rx callbacks if any, etc.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\n* `rx_pkts` -\nThe address of an array of pointers to *rte_mbuf* structures that\nhave been retrieved from the device.\n* `nb_rx` -\nThe number of packets that were retrieved from the device.\n* `nb_pkts` -\nThe number of elements in `rx_pkts` array.\n* `opaque` -\nOpaque pointer of Rx queue callback related data.\n\n# Returns\n\nThe number of packets effectively supplied to the `rx_pkts` array."]
    pub fn rte_eth_call_rx_callbacks(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut rte_mbuf,
        nb_rx: u16,
        nb_pkts: u16,
        opaque: *mut ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Retrieve a burst of input packets from a receive queue of an Ethernet\ndevice. The retrieved packets are stored in *rte_mbuf* structures whose\npointers are supplied in the *rx_pkts* array.\nThe rte_eth_rx_burst() function loops, parsing the Rx ring of the\nreceive queue, up to *nb_pkts* packets, and for each completed Rx\ndescriptor in the ring, it performs the following operations:\n- Initialize the *rte_mbuf* data structure associated with the\nRx descriptor according to the information provided by the NIC into\nthat Rx descriptor.\n- Store the *rte_mbuf* data structure into the next entry of the\n*rx_pkts* array.\n- Replenish the Rx descriptor with a new *rte_mbuf* buffer\nallocated from the memory pool associated with the receive queue at\ninitialization time.\nWhen retrieving an input packet that was scattered by the controller\ninto multiple receive descriptors, the rte_eth_rx_burst() function\nappends the associated *rte_mbuf* buffers to the first buffer of the\npacket.\nThe rte_eth_rx_burst() function returns the number of packets\nactually retrieved, which is the number of *rte_mbuf* data structures\neffectively supplied into the *rx_pkts* array.\nA return value equal to *nb_pkts* indicates that the Rx queue contained\nat least *rx_pkts* packets, and this is likely to signify that other\nreceived packets remain in the input queue. Applications implementing\na \"retrieve as much received packets as possible\" policy can check this\nspecific case and keep invoking the rte_eth_rx_burst() function until\na value less than *nb_pkts* is returned.\nThis receive method has the following advantages:\n- It allows a run-to-completion network stack engine to retrieve and\nto immediately process received packets in a fast burst-oriented\napproach, avoiding the overhead of unnecessary intermediate packet\nqueue/dequeue operations.\n- Conversely, it also allows an asynchronous-oriented processing\nmethod to retrieve bursts of received packets and to immediately\nqueue them for further parallel processing by another logical core,\nfor instance. However, instead of having received packets being\nindividually queued by the driver, this approach allows the caller\nof the rte_eth_rx_burst() function to queue a burst of retrieved\npackets at a time and therefore dramatically reduce the cost of\nenqueue/dequeue operations per packet.\n- It allows the rte_eth_rx_burst() function of the driver to take\nadvantage of burst-oriented hardware features (CPU cache,\nprefetch instructions, and so on) to minimize the number of CPU\ncycles per packet.\nTo summarize, the proposed receive API enables many\nburst-oriented optimizations in both synchronous and asynchronous\npacket processing environments with no overhead in both cases.\n> **Note** Some drivers using vector instructions require that *nb_pkts* is\ndivisible by 4 or 8, depending on the driver implementation.\nThe rte_eth_rx_burst() function does not provide any error\nnotification to avoid the corresponding overhead. As a hint, the\nupper-level application might check the status of the device link once\nbeing systematically returned a 0 value for a given number of tries.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the receive queue from which to retrieve input packets.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `rx_pkts` -\nThe address of an array of pointers to *rte_mbuf* structures that\nmust be large enough to store *nb_pkts* pointers in it.\n* `nb_pkts` -\nThe maximum number of packets to retrieve.\nThe value must be divisible by 8 in order to work with any driver.\n\n# Returns\n\nThe number of packets actually retrieved, which is the number\nof pointers to *rte_mbuf* structures effectively supplied to the\n*rx_pkts* array."]
    #[link_name = "rte_eth_rx_burst_w"]
    pub fn rte_eth_rx_burst(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the number of used descriptors of a Rx queue\nSince it's a dataplane function, no check is performed on port_id and\nqueue_id. The caller must therefore ensure that the port is enabled\nand the queue is configured and running.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe queue ID on the specific port.\n\n# Returns\n\nThe number of used descriptors in the specific queue, or:\n- (-ENODEV) if *port_id* is invalid.\n- (-EINVAL) if *queue_id* is invalid\n- (-ENOTSUP) if the device does not support this function"]
    #[link_name = "rte_eth_rx_queue_count_w"]
    pub fn rte_eth_rx_queue_count(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check the status of a Rx descriptor in the queue\nIt should be called in a similar context than the Rx function:\n- on a dataplane core\n- not concurrently on the same queue\nSince it's a dataplane function, no check is performed on port_id and\nqueue_id. The caller must therefore ensure that the port is enabled\nand the queue is configured and running.\nNote: accessing to a random descriptor in the ring may trigger cache\nmisses and have a performance impact.\n\n# Arguments\n\n* `port_id` -\nA valid port identifier of the Ethernet device which.\n* `queue_id` -\nA valid Rx queue identifier on this port.\n* `offset` -\nThe offset of the descriptor starting from tail (0 is the next\npacket to be received by the driver).\n\n# Returns\n\n- (RTE_ETH_RX_DESC_AVAIL): Descriptor is available for the hardware to\nreceive a packet.\n- (RTE_ETH_RX_DESC_DONE): Descriptor is done, it is filled by hw, but\nnot yet processed by the driver (i.e. in the receive queue).\n- (RTE_ETH_RX_DESC_UNAVAIL): Descriptor is unavailable, either hold by\nthe driver and not yet returned to hw, or reserved by the hw.\n- (-EINVAL) bad descriptor offset.\n- (-ENOTSUP) if the device does not support this function.\n- (-ENODEV) bad port or queue (only if compiled with debug)."]
    #[link_name = "rte_eth_rx_descriptor_status_w"]
    pub fn rte_eth_rx_descriptor_status(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check the status of a Tx descriptor in the queue.\nIt should be called in a similar context than the Tx function:\n- on a dataplane core\n- not concurrently on the same queue\nSince it's a dataplane function, no check is performed on port_id and\nqueue_id. The caller must therefore ensure that the port is enabled\nand the queue is configured and running.\nNote: accessing to a random descriptor in the ring may trigger cache\nmisses and have a performance impact.\n\n# Arguments\n\n* `port_id` -\nA valid port identifier of the Ethernet device which.\n* `queue_id` -\nA valid Tx queue identifier on this port.\n* `offset` -\nThe offset of the descriptor starting from tail (0 is the place where\nthe next packet will be send).\n\n# Returns\n\n- (RTE_ETH_TX_DESC_FULL) Descriptor is being processed by the hw, i.e.\nin the transmit queue.\n- (RTE_ETH_TX_DESC_DONE) Hardware is done with this descriptor, it can\nbe reused by the driver.\n- (RTE_ETH_TX_DESC_UNAVAIL): Descriptor is unavailable, reserved by the\ndriver or the hardware.\n- (-EINVAL) bad descriptor offset.\n- (-ENOTSUP) if the device does not support this function.\n- (-ENODEV) bad port or queue (only if compiled with debug)."]
    #[link_name = "rte_eth_tx_descriptor_status_w"]
    pub fn rte_eth_tx_descriptor_status(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Helper routine for rte_eth_tx_burst().\nShould be called before entry PMD's rte_eth_tx_bulk implementation.\nDoes necessary pre-processing - invokes Tx callbacks if any, etc.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue through which output packets must be\nsent.\n* `tx_pkts` -\nThe address of an array of *nb_pkts* pointers to *rte_mbuf* structures\nwhich contain the output packets.\n* `nb_pkts` -\nThe maximum number of packets to transmit.\n\n# Returns\n\nThe number of output packets to transmit."]
    pub fn rte_eth_call_tx_callbacks(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        opaque: *mut ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Send a burst of output packets on a transmit queue of an Ethernet device.\nThe rte_eth_tx_burst() function is invoked to transmit output packets\non the output queue *queue_id* of the Ethernet device designated by its\n*port_id*.\nThe *nb_pkts* parameter is the number of packets to send which are\nsupplied in the *tx_pkts* array of *rte_mbuf* structures, each of them\nallocated from a pool created with rte_pktmbuf_pool_create().\nThe rte_eth_tx_burst() function loops, sending *nb_pkts* packets,\nup to the number of transmit descriptors available in the Tx ring of the\ntransmit queue.\nFor each packet to send, the rte_eth_tx_burst() function performs\nthe following operations:\n- Pick up the next available descriptor in the transmit ring.\n- Free the network buffer previously sent with that descriptor, if any.\n- Initialize the transmit descriptor with the information provided\nin the *rte_mbuf data structure.\nIn the case of a segmented packet composed of a list of *rte_mbuf* buffers,\nthe rte_eth_tx_burst() function uses several transmit descriptors\nof the ring.\nThe rte_eth_tx_burst() function returns the number of packets it\nactually sent. A return value equal to *nb_pkts* means that all packets\nhave been sent, and this is likely to signify that other output packets\ncould be immediately transmitted again. Applications that implement a\n\"send as many packets to transmit as possible\" policy can check this\nspecific case and keep invoking the rte_eth_tx_burst() function until\na value less than *nb_pkts* is returned.\nIt is the responsibility of the rte_eth_tx_burst() function to\ntransparently free the memory buffers of packets previously sent.\nThis feature is driven by the *tx_free_thresh* value supplied to the\nrte_eth_dev_configure() function at device configuration time.\nWhen the number of free Tx descriptors drops below this threshold, the\nrte_eth_tx_burst() function must [attempt to] free the *rte_mbuf*  buffers\nof those packets whose transmission was effectively completed.\nIf the PMD is RTE_ETH_TX_OFFLOAD_MT_LOCKFREE capable, multiple threads can\ninvoke this function concurrently on the same Tx queue without SW lock.\n\n# See also\n\n> [`rte_eth_dev_info_get,`] struct rte_eth_txconf::offloads\n> [`rte_eth_tx_prepare`] to perform some prior checks or adjustments\nfor offloads.\n> **Note** This function must not modify mbufs (including packets data)\nunless the refcnt is 1.\nAn exception is the bonding PMD, which does not have \"Tx prepare\" support,\nin this case, mbufs may be modified.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue through which output packets must be\nsent.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `tx_pkts` -\nThe address of an array of *nb_pkts* pointers to *rte_mbuf* structures\nwhich contain the output packets.\n* `nb_pkts` -\nThe maximum number of packets to transmit.\n\n# Returns\n\nThe number of output packets actually stored in transmit descriptors of\nthe transmit ring. The return value can be less than the value of the\n*tx_pkts* parameter when the transmit ring is full or has been filled up."]
    #[link_name = "rte_eth_tx_burst_w"]
    pub fn rte_eth_tx_burst(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[link_name = "rte_eth_tx_prepare_w"]
    pub fn rte_eth_tx_prepare(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Send any packets queued up for transmission on a port and HW queue\nThis causes an explicit flush of packets previously buffered via the\nrte_eth_tx_buffer() function. It returns the number of packets successfully\nsent to the NIC, and calls the error callback for any unsent packets. Unless\nexplicitly set up otherwise, the default callback simply frees the unsent\npackets back to the owning mempool.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue through which output packets must be\nsent.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `buffer` -\nBuffer of packets to be transmit.\n\n# Returns\n\nThe number of packets successfully sent to the Ethernet device. The error\ncallback is called for any packets which could not be sent."]
    #[link_name = "rte_eth_tx_buffer_flush_w"]
    pub fn rte_eth_tx_buffer_flush(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Buffer a single packet for future transmission on a port and queue\nThis function takes a single mbuf/packet and buffers it for later\ntransmission on the particular port and queue specified. Once the buffer is\nfull of packets, an attempt will be made to transmit all the buffered\npackets. In case of error, where not all packets can be transmitted, a\ncallback is called with the unsent packets as a parameter. If no callback\nis explicitly set up, the unsent packets are just freed back to the owning\nmempool. The function returns the number of packets actually sent i.e.\n0 if no buffer flush occurred, otherwise the number of packets successfully\nflushed\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the Ethernet device.\n* `queue_id` -\nThe index of the transmit queue through which output packets must be\nsent.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `buffer` -\nBuffer used to collect packets to be sent.\n* `tx_pkt` -\nPointer to the packet mbuf to be sent.\n\n# Returns\n\n0 = packet has been buffered for later transmission\nN > 0 = packet has been buffered, and the buffer was subsequently flushed,\ncausing N packets to be sent, and the error callback to be called for\nthe rest."]
    #[link_name = "rte_eth_tx_buffer_w"]
    pub fn rte_eth_tx_buffer(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
        tx_pkt: *mut rte_mbuf,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice\nRecycle used mbufs from a transmit queue of an Ethernet device, and move\nthese mbufs into a mbuf ring for a receive queue of an Ethernet device.\nThis can bypass mempool path to save CPU cycles.\nThe rte_eth_recycle_mbufs() function loops, with rte_eth_rx_burst() and\nrte_eth_tx_burst() functions, freeing Tx used mbufs and replenishing Rx\ndescriptors. The number of recycling mbufs depends on the request of Rx mbuf\nring, with the constraint of enough used mbufs from Tx mbuf ring.\nFor each recycling mbufs, the rte_eth_recycle_mbufs() function performs the\nfollowing operations:\n- Copy used *rte_mbuf* buffer pointers from Tx mbuf ring into Rx mbuf ring.\n- Replenish the Rx descriptors with the recycling *rte_mbuf* mbufs freed\nfrom the Tx mbuf ring.\nThis function spilts Rx and Tx path with different callback functions. The\ncallback function recycle_tx_mbufs_reuse is for Tx driver. The callback\nfunction recycle_rx_descriptors_refill is for Rx driver. rte_eth_recycle_mbufs()\ncan support the case that Rx Ethernet device is different from Tx Ethernet device.\nIt is the responsibility of users to select the Rx/Tx queue pair to recycle\nmbufs. Before call this function, users must call rte_eth_recycle_rxq_info_get\nfunction to retrieve selected Rx queue information.\n\n# See also\n\n> [`rte_eth_recycle_rxq_info_get,`] struct rte_eth_recycle_rxq_info\nCurrently, the rte_eth_recycle_mbufs() function can support to feed 1 Rx queue from\n2 Tx queues in the same thread. Do not pair the Rx queue and Tx queue in different\nthreads, in order to avoid memory error rewriting.\n\n# Arguments\n\n* `rx_port_id` -\nPort identifying the receive side.\n* `rx_queue_id` -\nThe index of the receive queue identifying the receive side.\nThe value must be in the range [0, nb_rx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `tx_port_id` -\nPort identifying the transmit side.\n* `tx_queue_id` -\nThe index of the transmit queue identifying the transmit side.\nThe value must be in the range [0, nb_tx_queue - 1] previously supplied\nto rte_eth_dev_configure().\n* `recycle_rxq_info` -\nA pointer to a structure of type *rte_eth_recycle_rxq_info* which contains\nthe information of the Rx queue mbuf ring.\n\n# Returns\n\nThe number of recycling mbufs."]
    #[link_name = "rte_eth_recycle_mbufs_w"]
    pub fn rte_eth_recycle_mbufs(
        rx_port_id: u16,
        rx_queue_id: u16,
        tx_port_id: u16,
        tx_queue_id: u16,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nGet supported header protocols to split on Rx.\nWhen a packet type is announced to be split,\nit *must* be supported by the PMD.\nFor instance, if eth-ipv4, eth-ipv4-udp is announced,\nthe PMD must return the following packet types for these packets:\n- Ether/IPv4             -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4\n- Ether/IPv4/UDP         -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4 | RTE_PTYPE_L4_UDP\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `ptypes` [out]  -\nAn array pointer to store supported protocol headers, allocated by caller.\nThese ptypes are composed with RTE_PTYPE_*.\n* `num` -\nSize of the array pointed by param ptypes.\n\n# Returns\n\n- (>=0) Number of supported ptypes. If the number of types exceeds num,\nonly num entries will be filled into the ptypes array,\nbut the full count of supported ptypes will be returned.\n- (-ENOTSUP) if header protocol is not supported by device.\n- (-ENODEV) if *port_id* invalid.\n- (-EINVAL) if bad parameter."]
    pub fn rte_eth_buffer_split_get_supported_hdr_ptypes(
        port_id: u16,
        ptypes: *mut u32,
        num: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change, or be removed, without prior notice.\nGet the number of used descriptors of a Tx queue.\nThis function retrieves the number of used descriptors of a transmit queue.\nApplications can use this API in the fast path to inspect Tx queue occupancy\nand take appropriate actions based on the available free descriptors.\nAn example action could be implementing Random Early Discard (RED).\nSince it's a fast-path function, no check is performed on port_id and queue_id.\nThe caller must therefore ensure that the port is enabled\nand the queue is configured and running.\n\n# Arguments\n\n* `port_id` -\nThe port identifier of the device.\n* `queue_id` -\nThe index of the transmit queue.\nThe value must be in the range [0, nb_tx_queue - 1]\npreviously supplied to rte_eth_dev_configure().\n\n# Returns\n\nThe number of used descriptors in the specific queue, or:\n- (-ENODEV) if *port_id* is invalid. Enabled only when RTE_ETHDEV_DEBUG_TX is enabled.\n- (-EINVAL) if *queue_id* is invalid. Enabled only when RTE_ETHDEV_DEBUG_TX is enabled.\n- (-ENOTSUP) if the device does not support this function.\n> **Note** This function is designed for fast-path use.\n> **Note** There is no requirement to call this function before rte_eth_tx_burst() invocation.\n> **Note** Utilize this function exclusively when the caller needs to determine\nthe used queue count across all descriptors of a Tx queue.\nIf the use case only involves checking the status of a specific descriptor slot,\nopt for rte_eth_tx_descriptor_status() instead."]
    #[link_name = "rte_eth_tx_queue_count_w"]
    pub fn rte_eth_tx_queue_count(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
#[doc = "Flow rule attributes.\nPriorities are set on a per rule based within groups.\nLower values denote higher priority, the highest priority for a flow rule\nis 0, so that a flow that matches for than one rule, the rule with the\nlowest priority value will always be matched.\nAlthough optional, applications are encouraged to group similar rules as\nmuch as possible to fully take advantage of hardware capabilities\n(e.g. optimized matching) and work around limitations (e.g. a single\npattern type possibly allowed in a given group). Applications should be\naware that groups are not linked by default, and that they must be\nexplicitly linked by the application using the JUMP action.\nPriority levels are arbitrary and up to the application, they\ndo not need to be contiguous nor start from 0, however the maximum number\nvaries between devices and may be affected by existing flow rules.\nIf a packet is matched by several rules of a given group for a given\npriority level, the outcome is undefined. It can take any path, may be\nduplicated or even cause unrecoverable errors.\nNote that support for more than a single group and priority level is not\nguaranteed.\nAt vNIC / ethdev level, flow rules can apply to inbound and / or outbound\ntraffic (ingress / egress), with respect to the vNIC / ethdev in question.\nAt embedded switch level, flow rules apply to all traffic seen by it\nunless fitting meta items are used to set concrete traffic source(s).\nSeveral pattern items and actions are valid and can be used in both\ndirections. Those valid for only one direction are described as such.\nAt least one direction must be specified.\nSpecifying both directions at once for a given rule is not recommended\nbut may be valid in a few cases."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_attr {
    #[doc = "A group is a superset of multiple rules.\nThe default group is 0 and is processed for all packets.\nRules in other groups are processed only if the group is chained\nby a jump action from a previously matched rule.\nIt means the group hierarchy is made by the flow rules,\nand the group 0 is the hierarchy root.\nNote there is no automatic dead loop protection.\n\n# See also\n\n> [`rte_flow_action_jump`]"]
    pub group: u32,
    #[doc = "< Rule priority level within group."]
    pub priority: u32,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_attr"][::core::mem::size_of::<rte_flow_attr>() - 12usize];
    ["Alignment of rte_flow_attr"][::core::mem::align_of::<rte_flow_attr>() - 4usize];
    ["Offset of field: rte_flow_attr::group"]
        [::core::mem::offset_of!(rte_flow_attr, group) - 0usize];
    ["Offset of field: rte_flow_attr::priority"]
        [::core::mem::offset_of!(rte_flow_attr, priority) - 4usize];
};
impl rte_flow_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 29u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 29u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                29u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                29u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::core::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::core::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::core::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit.set(3usize, 29u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_group_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_group_attr"][::core::mem::size_of::<rte_flow_group_attr>() - 4usize];
    ["Alignment of rte_flow_group_attr"][::core::mem::align_of::<rte_flow_group_attr>() - 4usize];
};
impl rte_flow_group_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::core::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::core::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::core::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
pub mod rte_flow_item_type {
    #[doc = "Matching pattern item types.\nPattern items fall in two categories:\n- Matching protocol headers and packet data, usually associated with a\nspecification structure. These must be stacked in the same order as the\nprotocol layers to match inside packets, starting from the lowest.\n- Matching meta-data or affecting pattern processing, often without a\nspecification structure. Since they do not match packet contents, their\nposition in the list is usually not relevant.\nSee the description of individual types for more information. Those\nmarked with [META] fall into the second category."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "[META]\nEnd marker for item lists. Prevents further processing of items,\nthereby ending the pattern.\nNo associated specification structure."]
    pub const RTE_FLOW_ITEM_TYPE_END: Type = 0;
    #[doc = "[META]\nUsed as a placeholder for convenience. It is ignored and simply\ndiscarded by PMDs.\nNo associated specification structure."]
    pub const RTE_FLOW_ITEM_TYPE_VOID: Type = 1;
    #[doc = "[META]\nInverted matching, i.e. process packets that do not match the\npattern.\nNo associated specification structure."]
    pub const RTE_FLOW_ITEM_TYPE_INVERT: Type = 2;
    #[doc = "Matches any protocol in place of the current layer, a single ANY\nmay also stand for several protocol layers.\nSee struct rte_flow_item_any."]
    pub const RTE_FLOW_ITEM_TYPE_ANY: Type = 3;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ITEM_TYPE_REPRESENTED_PORT`]\n[META]\nMatches traffic originating from (ingress) or going to (egress) a\ngiven DPDK port ID.\nSee struct rte_flow_item_port_id."]
    pub const RTE_FLOW_ITEM_TYPE_PORT_ID: Type = 4;
    #[doc = "Matches a byte string of a given length at a given offset.\nSee struct rte_flow_item_raw."]
    pub const RTE_FLOW_ITEM_TYPE_RAW: Type = 5;
    #[doc = "Matches an Ethernet header.\nSee struct rte_flow_item_eth."]
    pub const RTE_FLOW_ITEM_TYPE_ETH: Type = 6;
    #[doc = "Matches an 802.1Q/ad VLAN tag.\nSee struct rte_flow_item_vlan."]
    pub const RTE_FLOW_ITEM_TYPE_VLAN: Type = 7;
    #[doc = "Matches an IPv4 header.\nSee struct rte_flow_item_ipv4."]
    pub const RTE_FLOW_ITEM_TYPE_IPV4: Type = 8;
    #[doc = "Matches an IPv6 header.\nSee struct rte_flow_item_ipv6."]
    pub const RTE_FLOW_ITEM_TYPE_IPV6: Type = 9;
    #[doc = "Matches an ICMP header.\nSee struct rte_flow_item_icmp."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP: Type = 10;
    #[doc = "Matches a UDP header.\nSee struct rte_flow_item_udp."]
    pub const RTE_FLOW_ITEM_TYPE_UDP: Type = 11;
    #[doc = "Matches a TCP header.\nSee struct rte_flow_item_tcp."]
    pub const RTE_FLOW_ITEM_TYPE_TCP: Type = 12;
    #[doc = "Matches a SCTP header.\nSee struct rte_flow_item_sctp."]
    pub const RTE_FLOW_ITEM_TYPE_SCTP: Type = 13;
    #[doc = "Matches a VXLAN header.\nSee struct rte_flow_item_vxlan."]
    pub const RTE_FLOW_ITEM_TYPE_VXLAN: Type = 14;
    #[doc = "Matches a E_TAG header.\nSee struct rte_flow_item_e_tag."]
    pub const RTE_FLOW_ITEM_TYPE_E_TAG: Type = 15;
    #[doc = "Matches a NVGRE header.\nSee struct rte_flow_item_nvgre."]
    pub const RTE_FLOW_ITEM_TYPE_NVGRE: Type = 16;
    #[doc = "Matches a MPLS header.\nSee struct rte_flow_item_mpls."]
    pub const RTE_FLOW_ITEM_TYPE_MPLS: Type = 17;
    #[doc = "Matches a GRE header.\nSee struct rte_flow_item_gre."]
    pub const RTE_FLOW_ITEM_TYPE_GRE: Type = 18;
    #[doc = "[META]\nFuzzy pattern match, expect faster than default.\nThis is for device that support fuzzy matching option.\nUsually a fuzzy matching is fast but the cost is accuracy.\nSee struct rte_flow_item_fuzzy."]
    pub const RTE_FLOW_ITEM_TYPE_FUZZY: Type = 19;
    #[doc = "Matches a GTP header.\nConfigure flow for GTP packets.\nSee struct rte_flow_item_gtp."]
    pub const RTE_FLOW_ITEM_TYPE_GTP: Type = 20;
    #[doc = "Matches a GTP header.\nConfigure flow for GTP-C packets.\nSee struct rte_flow_item_gtp."]
    pub const RTE_FLOW_ITEM_TYPE_GTPC: Type = 21;
    #[doc = "Matches a GTP header.\nConfigure flow for GTP-U packets.\nSee struct rte_flow_item_gtp."]
    pub const RTE_FLOW_ITEM_TYPE_GTPU: Type = 22;
    #[doc = "Matches a ESP header.\nSee struct rte_flow_item_esp."]
    pub const RTE_FLOW_ITEM_TYPE_ESP: Type = 23;
    #[doc = "Matches a GENEVE header.\nSee struct rte_flow_item_geneve."]
    pub const RTE_FLOW_ITEM_TYPE_GENEVE: Type = 24;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ITEM_TYPE_VXLAN`]\nMatches a VXLAN-GPE header.\nSee struct rte_flow_item_vxlan_gpe."]
    pub const RTE_FLOW_ITEM_TYPE_VXLAN_GPE: Type = 25;
    #[doc = "Matches an ARP header for Ethernet/IPv4.\nSee struct rte_flow_item_arp_eth_ipv4."]
    pub const RTE_FLOW_ITEM_TYPE_ARP_ETH_IPV4: Type = 26;
    #[doc = "Matches the presence of any IPv6 extension header.\nSee struct rte_flow_item_ipv6_ext."]
    pub const RTE_FLOW_ITEM_TYPE_IPV6_EXT: Type = 27;
    #[doc = "Matches any ICMPv6 header.\nSee struct rte_flow_item_icmp6."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6: Type = 28;
    #[doc = "Matches an ICMPv6 neighbor discovery solicitation.\nSee struct rte_flow_item_icmp6_nd_ns."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ND_NS: Type = 29;
    #[doc = "Matches an ICMPv6 neighbor discovery advertisement.\nSee struct rte_flow_item_icmp6_nd_na."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ND_NA: Type = 30;
    #[doc = "Matches the presence of any ICMPv6 neighbor discovery option.\nSee struct rte_flow_item_icmp6_nd_opt."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT: Type = 31;
    #[doc = "Matches an ICMPv6 neighbor discovery source Ethernet link-layer\naddress option.\nSee struct rte_flow_item_icmp6_nd_opt_sla_eth."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_SLA_ETH: Type = 32;
    #[doc = "Matches an ICMPv6 neighbor discovery target Ethernet link-layer\naddress option.\nSee struct rte_flow_item_icmp6_nd_opt_tla_eth."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_TLA_ETH: Type = 33;
    #[doc = "Matches specified mark field.\nSee struct rte_flow_item_mark."]
    pub const RTE_FLOW_ITEM_TYPE_MARK: Type = 34;
    #[doc = "[META]\nMatches a metadata value.\nSee struct rte_flow_item_meta."]
    pub const RTE_FLOW_ITEM_TYPE_META: Type = 35;
    #[doc = "Matches a GRE optional key field.\nThe value should a big-endian 32bit integer.\nWhen this item present the K bit is implicitly matched as \"1\"\nin the default mask.\n`spec/mask` type:\n@code rte_be32_t * @endcode "]
    pub const RTE_FLOW_ITEM_TYPE_GRE_KEY: Type = 36;
    #[doc = "Matches a GTP extension header: PDU session container.\nConfigure flow for GTP packets with extension header type 0x85.\nSee struct rte_flow_item_gtp_psc."]
    pub const RTE_FLOW_ITEM_TYPE_GTP_PSC: Type = 37;
    #[doc = "Matches a PPPoE header.\nConfigure flow for PPPoE session packets.\nSee struct rte_flow_item_pppoe."]
    pub const RTE_FLOW_ITEM_TYPE_PPPOES: Type = 38;
    #[doc = "Matches a PPPoE header.\nConfigure flow for PPPoE discovery packets.\nSee struct rte_flow_item_pppoe."]
    pub const RTE_FLOW_ITEM_TYPE_PPPOED: Type = 39;
    #[doc = "Matches a PPPoE optional proto_id field.\nIt only applies to PPPoE session packets.\nSee struct rte_flow_item_pppoe_proto_id."]
    pub const RTE_FLOW_ITEM_TYPE_PPPOE_PROTO_ID: Type = 40;
    #[doc = "Matches Network service header (NSH).\nSee struct rte_flow_item_nsh.\n"]
    pub const RTE_FLOW_ITEM_TYPE_NSH: Type = 41;
    #[doc = "Matches Internet Group Management Protocol (IGMP).\nSee struct rte_flow_item_igmp.\n"]
    pub const RTE_FLOW_ITEM_TYPE_IGMP: Type = 42;
    #[doc = "Matches IP Authentication Header (AH).\nSee struct rte_flow_item_ah.\n"]
    pub const RTE_FLOW_ITEM_TYPE_AH: Type = 43;
    #[doc = "Matches a HIGIG header.\nsee struct rte_flow_item_higig2_hdr."]
    pub const RTE_FLOW_ITEM_TYPE_HIGIG2: Type = 44;
    #[doc = "[META]\nMatches a tag value.\nSee struct rte_flow_item_tag."]
    pub const RTE_FLOW_ITEM_TYPE_TAG: Type = 45;
    #[doc = "Matches a L2TPv3 over IP header.\nConfigure flow for L2TPv3 over IP packets.\nSee struct rte_flow_item_l2tpv3oip."]
    pub const RTE_FLOW_ITEM_TYPE_L2TPV3OIP: Type = 46;
    #[doc = "Matches PFCP Header.\nSee struct rte_flow_item_pfcp.\n"]
    pub const RTE_FLOW_ITEM_TYPE_PFCP: Type = 47;
    #[doc = "Matches eCPRI Header.\nConfigure flow for eCPRI over ETH or UDP packets.\nSee struct rte_flow_item_ecpri."]
    pub const RTE_FLOW_ITEM_TYPE_ECPRI: Type = 48;
    #[doc = "Matches the presence of IPv6 fragment extension header.\nSee struct rte_flow_item_ipv6_frag_ext."]
    pub const RTE_FLOW_ITEM_TYPE_IPV6_FRAG_EXT: Type = 49;
    #[doc = "Matches Geneve Variable Length Option\nSee struct rte_flow_item_geneve_opt"]
    pub const RTE_FLOW_ITEM_TYPE_GENEVE_OPT: Type = 50;
    #[doc = "[META]\nMatches on packet integrity.\nFor some devices application needs to enable integration checks in HW\nbefore using this item.\n\n# See also\n\n> [`struct`] rte_flow_item_integrity."]
    pub const RTE_FLOW_ITEM_TYPE_INTEGRITY: Type = 51;
    #[doc = "[META]\nMatches conntrack state.\n\n# See also\n\n> [`struct`] rte_flow_item_conntrack."]
    pub const RTE_FLOW_ITEM_TYPE_CONNTRACK: Type = 52;
    #[doc = "[META]\nMatches traffic entering the embedded switch from the given ethdev.\n\n# See also\n\n> [`struct`] rte_flow_item_ethdev"]
    pub const RTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR: Type = 53;
    #[doc = "[META]\nMatches traffic entering the embedded switch from\nthe entity represented by the given ethdev.\n\n# See also\n\n> [`struct`] rte_flow_item_ethdev"]
    pub const RTE_FLOW_ITEM_TYPE_REPRESENTED_PORT: Type = 54;
    #[doc = "Matches a configured set of fields at runtime calculated offsets\nover the generic network header with variable length and\nflexible pattern\n\n# See also\n\n> [`struct`] rte_flow_item_flex."]
    pub const RTE_FLOW_ITEM_TYPE_FLEX: Type = 55;
    #[doc = "Matches L2TPv2 Header.\nSee struct rte_flow_item_l2tpv2."]
    pub const RTE_FLOW_ITEM_TYPE_L2TPV2: Type = 56;
    #[doc = "Matches PPP Header.\nSee struct rte_flow_item_ppp."]
    pub const RTE_FLOW_ITEM_TYPE_PPP: Type = 57;
    #[doc = "Matches GRE optional fields.\nSee struct rte_flow_item_gre_opt."]
    pub const RTE_FLOW_ITEM_TYPE_GRE_OPTION: Type = 58;
    #[doc = "Matches MACsec Ethernet Header.\nSee struct rte_flow_item_macsec."]
    pub const RTE_FLOW_ITEM_TYPE_MACSEC: Type = 59;
    #[doc = "Matches Meter Color Marker.\nSee struct rte_flow_item_meter_color."]
    pub const RTE_FLOW_ITEM_TYPE_METER_COLOR: Type = 60;
    #[doc = "Matches the presence of IPv6 routing extension header.\n\n# See also\n\n> [`struct`] rte_flow_item_ipv6_routing_ext."]
    pub const RTE_FLOW_ITEM_TYPE_IPV6_ROUTING_EXT: Type = 61;
    #[doc = "Matches an ICMPv6 echo request.\n\n# See also\n\n> [`struct`] rte_flow_item_icmp6_echo."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REQUEST: Type = 62;
    #[doc = "Matches an ICMPv6 echo reply.\n\n# See also\n\n> [`struct`] rte_flow_item_icmp6_echo."]
    pub const RTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REPLY: Type = 63;
    #[doc = "Match Quota state\n\n# See also\n\n> [`struct`] rte_flow_item_quota"]
    pub const RTE_FLOW_ITEM_TYPE_QUOTA: Type = 64;
    #[doc = "Matches on the aggregated port of the received packet.\nUsed in case multiple ports are aggregated to the a DPDK port.\nFirst port is number 1.\n\n# See also\n\n> [`struct`] rte_flow_item_aggr_affinity."]
    pub const RTE_FLOW_ITEM_TYPE_AGGR_AFFINITY: Type = 65;
    #[doc = "Match Tx queue number.\nThis is valid only for egress rules.\n\n# See also\n\n> [`struct`] rte_flow_item_tx_queue"]
    pub const RTE_FLOW_ITEM_TYPE_TX_QUEUE: Type = 66;
    #[doc = "Matches an InfiniBand base transport header in RoCE packet.\n\n# See also\n\n> [`struct`] rte_flow_item_ib_bth."]
    pub const RTE_FLOW_ITEM_TYPE_IB_BTH: Type = 67;
    #[doc = "Matches the packet type as defined in rte_mbuf_ptype.\nSee struct rte_flow_item_ptype.\n"]
    pub const RTE_FLOW_ITEM_TYPE_PTYPE: Type = 68;
    #[doc = "[META]\nMatches a random value.\nThis value is not based on the packet data/headers.\nThe application shouldn't assume that this value is kept\nduring the lifetime of the packet.\n\n# See also\n\n> [`struct`] rte_flow_item_random."]
    pub const RTE_FLOW_ITEM_TYPE_RANDOM: Type = 69;
    #[doc = "Match packet with various comparison types.\nSee struct rte_flow_item_compare."]
    pub const RTE_FLOW_ITEM_TYPE_COMPARE: Type = 70;
}
pub mod rte_flow_quota_state {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQUOTA state.\n\n# See also\n\n> [`struct`] rte_flow_item_quota"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< PASS quota state"]
    pub const RTE_FLOW_QUOTA_STATE_PASS: Type = 0;
    #[doc = "< BLOCK quota state"]
    pub const RTE_FLOW_QUOTA_STATE_BLOCK: Type = 1;
}
#[doc = "RTE_FLOW_ITEM_TYPE_QUOTA\nMatches QUOTA state"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_quota {
    pub state: rte_flow_quota_state::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_quota"][::core::mem::size_of::<rte_flow_item_quota>() - 4usize];
    ["Alignment of rte_flow_item_quota"][::core::mem::align_of::<rte_flow_item_quota>() - 4usize];
    ["Offset of field: rte_flow_item_quota::state"]
        [::core::mem::offset_of!(rte_flow_item_quota, state) - 0usize];
};
impl Default for rte_flow_item_quota {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_quota_mask: rte_flow_item_quota;
}
#[doc = "RTE_FLOW_ITEM_TYPE_HIGIG2\nMatches higig2 header"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_higig2_hdr {
    pub hdr: rte_higig2_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_higig2_hdr"]
        [::core::mem::size_of::<rte_flow_item_higig2_hdr>() - 16usize];
    ["Alignment of rte_flow_item_higig2_hdr"]
        [::core::mem::align_of::<rte_flow_item_higig2_hdr>() - 4usize];
    ["Offset of field: rte_flow_item_higig2_hdr::hdr"]
        [::core::mem::offset_of!(rte_flow_item_higig2_hdr, hdr) - 0usize];
};
impl Default for rte_flow_item_higig2_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_higig2_hdr_mask: rte_flow_item_higig2_hdr;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ANY\nMatches any protocol in place of the current layer, a single ANY may also\nstand for several protocol layers.\nThis is usually specified as the first pattern item when looking for a\nprotocol anywhere in a packet.\nA zeroed mask stands for any number of layers."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_any {
    #[doc = "< Number of layers covered."]
    pub num: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_any"][::core::mem::size_of::<rte_flow_item_any>() - 4usize];
    ["Alignment of rte_flow_item_any"][::core::mem::align_of::<rte_flow_item_any>() - 4usize];
    ["Offset of field: rte_flow_item_any::num"]
        [::core::mem::offset_of!(rte_flow_item_any, num) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_any_mask: rte_flow_item_any;
}
#[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ITEM_TYPE_REPRESENTED_PORT`]\nRTE_FLOW_ITEM_TYPE_PORT_ID\nMatches traffic originating from (ingress) or going to (egress) a given\nDPDK port ID.\nNormally only supported if the port ID in question is known by the\nunderlying PMD and related to the device the flow rule is created\nagainst."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_port_id {
    #[doc = "< DPDK port ID."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_port_id"][::core::mem::size_of::<rte_flow_item_port_id>() - 4usize];
    ["Alignment of rte_flow_item_port_id"]
        [::core::mem::align_of::<rte_flow_item_port_id>() - 4usize];
    ["Offset of field: rte_flow_item_port_id::id"]
        [::core::mem::offset_of!(rte_flow_item_port_id, id) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_port_id_mask: rte_flow_item_port_id;
}
#[doc = "RTE_FLOW_ITEM_TYPE_RAW\nMatches a byte string of a given length at a given offset.\nOffset is either absolute (using the start of the packet) or relative to\nthe end of the previous matched item in the stack, in which case negative\nvalues are allowed.\nIf search is enabled, offset is used as the starting point. The search\narea can be delimited by setting limit to a nonzero value, which is the\nmaximum number of bytes after offset where the pattern may start.\nMatching a zero-length pattern is allowed, doing so resets the relative\noffset for subsequent items.\nThis type does not support ranges (struct rte_flow_item.last)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_raw {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "< Absolute or relative offset for pattern."]
    pub offset: i32,
    #[doc = "< Search area limit for start of pattern."]
    pub limit: u16,
    #[doc = "< Pattern length."]
    pub length: u16,
    #[doc = "< Byte string to look for."]
    pub pattern: *const u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_raw"][::core::mem::size_of::<rte_flow_item_raw>() - 24usize];
    ["Alignment of rte_flow_item_raw"][::core::mem::align_of::<rte_flow_item_raw>() - 8usize];
    ["Offset of field: rte_flow_item_raw::offset"]
        [::core::mem::offset_of!(rte_flow_item_raw, offset) - 4usize];
    ["Offset of field: rte_flow_item_raw::limit"]
        [::core::mem::offset_of!(rte_flow_item_raw, limit) - 8usize];
    ["Offset of field: rte_flow_item_raw::length"]
        [::core::mem::offset_of!(rte_flow_item_raw, length) - 10usize];
    ["Offset of field: rte_flow_item_raw::pattern"]
        [::core::mem::offset_of!(rte_flow_item_raw, pattern) - 16usize];
};
impl Default for rte_flow_item_raw {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_item_raw {
    #[inline]
    pub fn relative(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_relative(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn relative_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_relative_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn search(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_search(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn search_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_search_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 30u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 30u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                30u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                30u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        relative: u32,
        search: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let relative: u32 = unsafe { ::core::mem::transmute(relative) };
            relative as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let search: u32 = unsafe { ::core::mem::transmute(search) };
            search as u64
        });
        __bindgen_bitfield_unit.set(2usize, 30u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_raw_mask: rte_flow_item_raw;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ETH\nMatches an Ethernet header.\nInside `hdr` field, the sub-field `ether_type` stands either for EtherType\nor TPID, depending on whether the item is followed by a VLAN item or not. If\ntwo VLAN items follow, the sub-field refers to the outer one, which, in turn,\ncontains the inner TPID in the similar header field. The innermost VLAN item\ncontains a layer-3 EtherType. All of that follows the order seen on the wire.\nIf the field in question contains a TPID value, only tagged packets with the\nspecified TPID will match the pattern. Alternatively, it's possible to match\nany type of tagged packets by means of the field `has_vlan` rather than use\nthe EtherType/TPID field. Also, it's possible to leave the two fields unused.\nIf this is the case, both tagged and untagged packets will match the pattern."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_eth {
    pub anon1: rte_flow_item_eth__bindgen_ty_1,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_eth__bindgen_ty_1 {
    pub anon1: rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1,
    pub hdr: rte_ether_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Destination MAC."]
    pub dst: rte_ether_addr,
    #[doc = "< Source MAC."]
    pub src: rte_ether_addr,
    #[doc = "< EtherType or TPID."]
    pub type_: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1>() - 14usize];
    ["Alignment of rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1::dst"]
        [::core::mem::offset_of!(rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1, dst) - 0usize];
    ["Offset of field: rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1::src"]
        [::core::mem::offset_of!(rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1, src) - 6usize];
    ["Offset of field: rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1::type_"]
        [::core::mem::offset_of!(rte_flow_item_eth__bindgen_ty_1__bindgen_ty_1, type_) - 12usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_eth__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_eth__bindgen_ty_1>() - 14usize];
    ["Alignment of rte_flow_item_eth__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_eth__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_flow_item_eth__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_eth__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_eth__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_eth"][::core::mem::size_of::<rte_flow_item_eth>() - 20usize];
    ["Alignment of rte_flow_item_eth"][::core::mem::align_of::<rte_flow_item_eth>() - 4usize];
};
impl Default for rte_flow_item_eth {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_item_eth {
    #[inline]
    pub fn has_vlan(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_vlan(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_vlan_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_vlan_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 31u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 31u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                31u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                31u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(has_vlan: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let has_vlan: u32 = unsafe { ::core::mem::transmute(has_vlan) };
            has_vlan as u64
        });
        __bindgen_bitfield_unit.set(1usize, 31u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_eth_mask: rte_flow_item_eth;
}
#[doc = "RTE_FLOW_ITEM_TYPE_VLAN\nMatches an 802.1Q/ad VLAN tag.\nThe corresponding standard outer EtherType (TPID) values are\nRTE_ETHER_TYPE_VLAN or RTE_ETHER_TYPE_QINQ. It can be overridden by\nthe preceding pattern item.\nIf a `VLAN` item is present in the pattern, then only tagged packets will\nmatch the pattern.\nThe field `has_more_vlan` can be used to match any type of tagged packets,\ninstead of using the `eth_proto` field of `hdr.`\nIf the `eth_proto` of `hdr` and `has_more_vlan` fields are not specified,\nthen any tagged packets will match the pattern."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_vlan {
    pub anon1: rte_flow_item_vlan__bindgen_ty_1,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_vlan__bindgen_ty_1 {
    pub anon1: rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1,
    pub hdr: rte_vlan_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Tag control information."]
    pub tci: rte_be16_t,
    #[doc = "< Inner EtherType or TPID."]
    pub inner_type: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1::tci"]
        [::core::mem::offset_of!(rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1, tci) - 0usize];
    ["Offset of field: rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1::inner_type"][::core::mem::offset_of!(
        rte_flow_item_vlan__bindgen_ty_1__bindgen_ty_1,
        inner_type
    ) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vlan__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vlan__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_flow_item_vlan__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vlan__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_flow_item_vlan__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_vlan__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_vlan__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vlan"][::core::mem::size_of::<rte_flow_item_vlan>() - 8usize];
    ["Alignment of rte_flow_item_vlan"][::core::mem::align_of::<rte_flow_item_vlan>() - 4usize];
};
impl Default for rte_flow_item_vlan {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_item_vlan {
    #[inline]
    pub fn has_more_vlan(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_more_vlan(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_more_vlan_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_more_vlan_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 31u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 31u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                31u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                31u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        has_more_vlan: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let has_more_vlan: u32 = unsafe { ::core::mem::transmute(has_more_vlan) };
            has_more_vlan as u64
        });
        __bindgen_bitfield_unit.set(1usize, 31u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_vlan_mask: rte_flow_item_vlan;
}
#[doc = "RTE_FLOW_ITEM_TYPE_IPV4\nMatches an IPv4 header.\nNote: IPv4 options are handled by dedicated pattern items."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_ipv4 {
    #[doc = "< IPv4 header definition."]
    pub hdr: rte_ipv4_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ipv4"][::core::mem::size_of::<rte_flow_item_ipv4>() - 20usize];
    ["Alignment of rte_flow_item_ipv4"][::core::mem::align_of::<rte_flow_item_ipv4>() - 2usize];
    ["Offset of field: rte_flow_item_ipv4::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ipv4, hdr) - 0usize];
};
impl Default for rte_flow_item_ipv4 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_ipv4_mask: rte_flow_item_ipv4;
}
#[doc = "RTE_FLOW_ITEM_TYPE_IPV6.\nMatches an IPv6 header.\nDedicated flags indicate if header contains specific extension headers."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_ipv6 {
    #[doc = "< IPv6 header definition."]
    pub hdr: rte_ipv6_hdr,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ipv6"][::core::mem::size_of::<rte_flow_item_ipv6>() - 44usize];
    ["Alignment of rte_flow_item_ipv6"][::core::mem::align_of::<rte_flow_item_ipv6>() - 4usize];
    ["Offset of field: rte_flow_item_ipv6::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ipv6, hdr) - 0usize];
};
impl Default for rte_flow_item_ipv6 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_item_ipv6 {
    #[inline]
    pub fn has_hop_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_hop_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_hop_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_hop_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_route_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_route_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_route_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_route_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_frag_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_frag_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_frag_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_frag_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_auth_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_auth_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_auth_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_auth_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_esp_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_esp_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_esp_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_esp_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_dest_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_dest_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_dest_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_dest_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_mobil_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_mobil_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_mobil_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_mobil_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_hip_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_hip_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_hip_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_hip_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn has_shim6_ext(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_has_shim6_ext(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn has_shim6_ext_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_has_shim6_ext_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(9usize, 23u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(9usize, 23u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                9usize,
                23u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                9usize,
                23u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        has_hop_ext: u32,
        has_route_ext: u32,
        has_frag_ext: u32,
        has_auth_ext: u32,
        has_esp_ext: u32,
        has_dest_ext: u32,
        has_mobil_ext: u32,
        has_hip_ext: u32,
        has_shim6_ext: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let has_hop_ext: u32 = unsafe { ::core::mem::transmute(has_hop_ext) };
            has_hop_ext as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let has_route_ext: u32 = unsafe { ::core::mem::transmute(has_route_ext) };
            has_route_ext as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let has_frag_ext: u32 = unsafe { ::core::mem::transmute(has_frag_ext) };
            has_frag_ext as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let has_auth_ext: u32 = unsafe { ::core::mem::transmute(has_auth_ext) };
            has_auth_ext as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let has_esp_ext: u32 = unsafe { ::core::mem::transmute(has_esp_ext) };
            has_esp_ext as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let has_dest_ext: u32 = unsafe { ::core::mem::transmute(has_dest_ext) };
            has_dest_ext as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let has_mobil_ext: u32 = unsafe { ::core::mem::transmute(has_mobil_ext) };
            has_mobil_ext as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let has_hip_ext: u32 = unsafe { ::core::mem::transmute(has_hip_ext) };
            has_hip_ext as u64
        });
        __bindgen_bitfield_unit.set(8usize, 1u8, {
            let has_shim6_ext: u32 = unsafe { ::core::mem::transmute(has_shim6_ext) };
            has_shim6_ext as u64
        });
        __bindgen_bitfield_unit.set(9usize, 23u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_ipv6_mask: rte_flow_item_ipv6;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ITEM_TYPE_IPV6_ROUTING_EXT.\nMatches an IPv6 routing extension header."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_ipv6_routing_ext {
    pub hdr: rte_ipv6_routing_ext,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ipv6_routing_ext"]
        [::core::mem::size_of::<rte_flow_item_ipv6_routing_ext>() - 8usize];
    ["Alignment of rte_flow_item_ipv6_routing_ext"]
        [::core::mem::align_of::<rte_flow_item_ipv6_routing_ext>() - 2usize];
    ["Offset of field: rte_flow_item_ipv6_routing_ext::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ipv6_routing_ext, hdr) - 0usize];
};
impl Default for rte_flow_item_ipv6_routing_ext {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP.\nMatches an ICMP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp {
    #[doc = "< ICMP header definition."]
    pub hdr: rte_icmp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp"][::core::mem::size_of::<rte_flow_item_icmp>() - 8usize];
    ["Alignment of rte_flow_item_icmp"][::core::mem::align_of::<rte_flow_item_icmp>() - 1usize];
    ["Offset of field: rte_flow_item_icmp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_icmp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp_mask: rte_flow_item_icmp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_UDP.\nMatches a UDP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_udp {
    #[doc = "< UDP header definition."]
    pub hdr: rte_udp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_udp"][::core::mem::size_of::<rte_flow_item_udp>() - 8usize];
    ["Alignment of rte_flow_item_udp"][::core::mem::align_of::<rte_flow_item_udp>() - 1usize];
    ["Offset of field: rte_flow_item_udp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_udp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_udp_mask: rte_flow_item_udp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_TCP.\nMatches a TCP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_tcp {
    #[doc = "< TCP header definition."]
    pub hdr: rte_tcp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_tcp"][::core::mem::size_of::<rte_flow_item_tcp>() - 20usize];
    ["Alignment of rte_flow_item_tcp"][::core::mem::align_of::<rte_flow_item_tcp>() - 1usize];
    ["Offset of field: rte_flow_item_tcp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_tcp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_tcp_mask: rte_flow_item_tcp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_SCTP.\nMatches a SCTP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_sctp {
    #[doc = "< SCTP header definition."]
    pub hdr: rte_sctp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_sctp"][::core::mem::size_of::<rte_flow_item_sctp>() - 12usize];
    ["Alignment of rte_flow_item_sctp"][::core::mem::align_of::<rte_flow_item_sctp>() - 1usize];
    ["Offset of field: rte_flow_item_sctp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_sctp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_sctp_mask: rte_flow_item_sctp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_VXLAN.\nMatches a VXLAN header (RFC 7348),\nincluding GPE (draft-ietf-nvo3-vxlan-gpe-13.txt)\nand GBP (draft-smith-vxlan-group-policy-05.txt).\nGPE is distinguished with its UDP port.\nUDP port may be specified with ``rte_eth_dev_udp_tunnel_port_add()``."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_vxlan {
    pub anon1: rte_flow_item_vxlan__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_vxlan__bindgen_ty_1 {
    pub anon1: rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1,
    pub hdr: rte_vxlan_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Normally 0x08 (I flag)."]
    pub flags: u8,
    #[doc = "< Reserved, normally 0x000000."]
    pub rsvd0: [u8; 3usize],
    #[doc = "< VXLAN identifier."]
    pub vni: [u8; 3usize],
    #[doc = "< Reserved, normally 0x00."]
    pub rsvd1: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1::flags"]
        [::core::mem::offset_of!(rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1, flags) - 0usize];
    ["Offset of field: rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1::rsvd0"]
        [::core::mem::offset_of!(rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1, rsvd0) - 1usize];
    ["Offset of field: rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1::vni"]
        [::core::mem::offset_of!(rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1, vni) - 4usize];
    ["Offset of field: rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1::rsvd1"]
        [::core::mem::offset_of!(rte_flow_item_vxlan__bindgen_ty_1__bindgen_ty_1, rsvd1) - 7usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vxlan__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_vxlan__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vxlan__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_flow_item_vxlan__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_vxlan__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_vxlan__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan"][::core::mem::size_of::<rte_flow_item_vxlan>() - 8usize];
    ["Alignment of rte_flow_item_vxlan"][::core::mem::align_of::<rte_flow_item_vxlan>() - 1usize];
};
impl Default for rte_flow_item_vxlan {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_vxlan_mask: rte_flow_item_vxlan;
}
#[doc = "RTE_FLOW_ITEM_TYPE_E_TAG.\nMatches a E-tag header.\nThe corresponding standard outer EtherType (TPID) value is\nRTE_ETHER_TYPE_ETAG. It can be overridden by the preceding pattern item."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_e_tag {
    #[doc = "E-Tag control information (E-TCI).\nE-PCP (3b), E-DEI (1b), ingress E-CID base (12b)."]
    pub epcp_edei_in_ecid_b: rte_be16_t,
    #[doc = "Reserved (2b), GRP (2b), E-CID base (12b)."]
    pub rsvd_grp_ecid_b: rte_be16_t,
    #[doc = "< Ingress E-CID ext."]
    pub in_ecid_e: u8,
    #[doc = "< E-CID ext."]
    pub ecid_e: u8,
    #[doc = "< Inner EtherType or TPID."]
    pub inner_type: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_e_tag"][::core::mem::size_of::<rte_flow_item_e_tag>() - 8usize];
    ["Alignment of rte_flow_item_e_tag"][::core::mem::align_of::<rte_flow_item_e_tag>() - 2usize];
    ["Offset of field: rte_flow_item_e_tag::epcp_edei_in_ecid_b"]
        [::core::mem::offset_of!(rte_flow_item_e_tag, epcp_edei_in_ecid_b) - 0usize];
    ["Offset of field: rte_flow_item_e_tag::rsvd_grp_ecid_b"]
        [::core::mem::offset_of!(rte_flow_item_e_tag, rsvd_grp_ecid_b) - 2usize];
    ["Offset of field: rte_flow_item_e_tag::in_ecid_e"]
        [::core::mem::offset_of!(rte_flow_item_e_tag, in_ecid_e) - 4usize];
    ["Offset of field: rte_flow_item_e_tag::ecid_e"]
        [::core::mem::offset_of!(rte_flow_item_e_tag, ecid_e) - 5usize];
    ["Offset of field: rte_flow_item_e_tag::inner_type"]
        [::core::mem::offset_of!(rte_flow_item_e_tag, inner_type) - 6usize];
};
unsafe extern "C" {
    pub static rte_flow_item_e_tag_mask: rte_flow_item_e_tag;
}
#[doc = "RTE_FLOW_ITEM_TYPE_NVGRE.\nMatches a NVGRE header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_nvgre {
    #[doc = "Checksum (1b), undefined (1b), key bit (1b), sequence number (1b),\nreserved 0 (9b), version (3b).\nc_k_s_rsvd0_ver must have value 0x2000 according to RFC 7637."]
    pub c_k_s_rsvd0_ver: rte_be16_t,
    #[doc = "< Protocol type (0x6558)."]
    pub protocol: rte_be16_t,
    #[doc = "< Virtual subnet ID."]
    pub tni: [u8; 3usize],
    #[doc = "< Flow ID."]
    pub flow_id: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_nvgre"][::core::mem::size_of::<rte_flow_item_nvgre>() - 8usize];
    ["Alignment of rte_flow_item_nvgre"][::core::mem::align_of::<rte_flow_item_nvgre>() - 2usize];
    ["Offset of field: rte_flow_item_nvgre::c_k_s_rsvd0_ver"]
        [::core::mem::offset_of!(rte_flow_item_nvgre, c_k_s_rsvd0_ver) - 0usize];
    ["Offset of field: rte_flow_item_nvgre::protocol"]
        [::core::mem::offset_of!(rte_flow_item_nvgre, protocol) - 2usize];
    ["Offset of field: rte_flow_item_nvgre::tni"]
        [::core::mem::offset_of!(rte_flow_item_nvgre, tni) - 4usize];
    ["Offset of field: rte_flow_item_nvgre::flow_id"]
        [::core::mem::offset_of!(rte_flow_item_nvgre, flow_id) - 7usize];
};
unsafe extern "C" {
    pub static rte_flow_item_nvgre_mask: rte_flow_item_nvgre;
}
#[doc = "RTE_FLOW_ITEM_TYPE_MPLS.\nMatches a MPLS header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_mpls {
    #[doc = "Label (20b), TC (3b), Bottom of Stack (1b)."]
    pub label_tc_s: [u8; 3usize],
    pub ttl: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_mpls"][::core::mem::size_of::<rte_flow_item_mpls>() - 4usize];
    ["Alignment of rte_flow_item_mpls"][::core::mem::align_of::<rte_flow_item_mpls>() - 1usize];
    ["Offset of field: rte_flow_item_mpls::label_tc_s"]
        [::core::mem::offset_of!(rte_flow_item_mpls, label_tc_s) - 0usize];
    ["Offset of field: rte_flow_item_mpls::ttl"]
        [::core::mem::offset_of!(rte_flow_item_mpls, ttl) - 3usize];
};
unsafe extern "C" {
    pub static rte_flow_item_mpls_mask: rte_flow_item_mpls;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GRE.\nMatches a GRE header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_gre {
    #[doc = "Checksum (1b), reserved 0 (12b), version (3b).\nRefer to RFC 2784."]
    pub c_rsvd0_ver: rte_be16_t,
    #[doc = "< Protocol type."]
    pub protocol: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gre"][::core::mem::size_of::<rte_flow_item_gre>() - 4usize];
    ["Alignment of rte_flow_item_gre"][::core::mem::align_of::<rte_flow_item_gre>() - 2usize];
    ["Offset of field: rte_flow_item_gre::c_rsvd0_ver"]
        [::core::mem::offset_of!(rte_flow_item_gre, c_rsvd0_ver) - 0usize];
    ["Offset of field: rte_flow_item_gre::protocol"]
        [::core::mem::offset_of!(rte_flow_item_gre, protocol) - 2usize];
};
unsafe extern "C" {
    pub static rte_flow_item_gre_mask: rte_flow_item_gre;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GRE_OPTION.\nMatches GRE optional fields in header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_gre_opt {
    pub checksum_rsvd: rte_gre_hdr_opt_checksum_rsvd,
    pub key: rte_gre_hdr_opt_key,
    pub sequence: rte_gre_hdr_opt_sequence,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gre_opt"][::core::mem::size_of::<rte_flow_item_gre_opt>() - 12usize];
    ["Alignment of rte_flow_item_gre_opt"]
        [::core::mem::align_of::<rte_flow_item_gre_opt>() - 1usize];
    ["Offset of field: rte_flow_item_gre_opt::checksum_rsvd"]
        [::core::mem::offset_of!(rte_flow_item_gre_opt, checksum_rsvd) - 0usize];
    ["Offset of field: rte_flow_item_gre_opt::key"]
        [::core::mem::offset_of!(rte_flow_item_gre_opt, key) - 4usize];
    ["Offset of field: rte_flow_item_gre_opt::sequence"]
        [::core::mem::offset_of!(rte_flow_item_gre_opt, sequence) - 8usize];
};
#[doc = "RTE_FLOW_ITEM_TYPE_MACSEC.\nMatches MACsec header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_macsec {
    pub macsec_hdr: rte_macsec_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_macsec"][::core::mem::size_of::<rte_flow_item_macsec>() - 6usize];
    ["Alignment of rte_flow_item_macsec"][::core::mem::align_of::<rte_flow_item_macsec>() - 1usize];
    ["Offset of field: rte_flow_item_macsec::macsec_hdr"]
        [::core::mem::offset_of!(rte_flow_item_macsec, macsec_hdr) - 0usize];
};
#[doc = "RTE_FLOW_ITEM_TYPE_FUZZY\nFuzzy pattern match, expect faster than default.\nThis is for device that support fuzzy match option.\nUsually a fuzzy match is fast but the cost is accuracy.\ni.e. Signature Match only match pattern's hash value, but it is\npossible two different patterns have the same hash value.\nMatching accuracy level can be configure by threshold.\nDriver can divide the range of threshold and map to different\naccuracy levels that device support.\nThreshold 0 means perfect match (no fuzziness), while threshold\n0xffffffff means fuzziest match."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_fuzzy {
    #[doc = "< Accuracy threshold."]
    pub thresh: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_fuzzy"][::core::mem::size_of::<rte_flow_item_fuzzy>() - 4usize];
    ["Alignment of rte_flow_item_fuzzy"][::core::mem::align_of::<rte_flow_item_fuzzy>() - 4usize];
    ["Offset of field: rte_flow_item_fuzzy::thresh"]
        [::core::mem::offset_of!(rte_flow_item_fuzzy, thresh) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_fuzzy_mask: rte_flow_item_fuzzy;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GTP.\nMatches a GTPv1 header."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_gtp {
    pub anon1: rte_flow_item_gtp__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_gtp__bindgen_ty_1 {
    pub anon1: rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1,
    #[doc = "< GTP header definition."]
    pub hdr: rte_gtp_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "These are old fields kept for compatibility.\nPlease prefer hdr field below.\n/\n/**\nVersion (3b), protocol type (1b), reserved (1b),\nExtension header flag (1b),\nSequence number flag (1b),\nN-PDU number flag (1b)."]
    pub v_pt_rsv_flags: u8,
    #[doc = "< Message type."]
    pub msg_type: u8,
    #[doc = "< Message length."]
    pub msg_len: rte_be16_t,
    #[doc = "< Tunnel endpoint identifier."]
    pub teid: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1::v_pt_rsv_flags"][::core::mem::offset_of!(
        rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1,
        v_pt_rsv_flags
    ) - 0usize];
    ["Offset of field: rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1::msg_type"]
        [::core::mem::offset_of!(rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1, msg_type) - 1usize];
    ["Offset of field: rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1::msg_len"]
        [::core::mem::offset_of!(rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1, msg_len) - 2usize];
    ["Offset of field: rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1::teid"]
        [::core::mem::offset_of!(rte_flow_item_gtp__bindgen_ty_1__bindgen_ty_1, teid) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gtp__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_gtp__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_gtp__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_gtp__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_item_gtp__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_gtp__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_gtp__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gtp"][::core::mem::size_of::<rte_flow_item_gtp>() - 8usize];
    ["Alignment of rte_flow_item_gtp"][::core::mem::align_of::<rte_flow_item_gtp>() - 4usize];
};
impl Default for rte_flow_item_gtp {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_gtp_mask: rte_flow_item_gtp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ESP\nMatches an ESP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_esp {
    #[doc = "< ESP header definition."]
    pub hdr: rte_esp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_esp"][::core::mem::size_of::<rte_flow_item_esp>() - 8usize];
    ["Alignment of rte_flow_item_esp"][::core::mem::align_of::<rte_flow_item_esp>() - 1usize];
    ["Offset of field: rte_flow_item_esp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_esp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_esp_mask: rte_flow_item_esp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GENEVE.\nMatches a GENEVE header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_geneve {
    #[doc = "Version (2b), length of the options fields (6b), OAM packet (1b),\ncritical options present (1b), reserved 0 (6b)."]
    pub ver_opt_len_o_c_rsvd0: rte_be16_t,
    #[doc = "< Protocol type."]
    pub protocol: rte_be16_t,
    #[doc = "< Virtual Network Identifier."]
    pub vni: [u8; 3usize],
    #[doc = "< Reserved, normally 0x00."]
    pub rsvd1: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_geneve"][::core::mem::size_of::<rte_flow_item_geneve>() - 8usize];
    ["Alignment of rte_flow_item_geneve"][::core::mem::align_of::<rte_flow_item_geneve>() - 2usize];
    ["Offset of field: rte_flow_item_geneve::ver_opt_len_o_c_rsvd0"]
        [::core::mem::offset_of!(rte_flow_item_geneve, ver_opt_len_o_c_rsvd0) - 0usize];
    ["Offset of field: rte_flow_item_geneve::protocol"]
        [::core::mem::offset_of!(rte_flow_item_geneve, protocol) - 2usize];
    ["Offset of field: rte_flow_item_geneve::vni"]
        [::core::mem::offset_of!(rte_flow_item_geneve, vni) - 4usize];
    ["Offset of field: rte_flow_item_geneve::rsvd1"]
        [::core::mem::offset_of!(rte_flow_item_geneve, rsvd1) - 7usize];
};
unsafe extern "C" {
    pub static rte_flow_item_geneve_mask: rte_flow_item_geneve;
}
#[doc = "> **Deprecated** # See also\n\n> [`rte_flow_item_vxlan`]\nRTE_FLOW_ITEM_TYPE_VXLAN_GPE (draft-ietf-nvo3-vxlan-gpe-05).\nMatches a VXLAN-GPE header."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_vxlan_gpe {
    pub anon1: rte_flow_item_vxlan_gpe__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_vxlan_gpe__bindgen_ty_1 {
    pub anon1: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
    pub hdr: rte_vxlan_gpe_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Normally 0x0c (I and P flags)."]
    pub flags: u8,
    #[doc = "< Reserved, normally 0x0000."]
    pub rsvd0: [u8; 2usize],
    #[doc = "< Protocol type."]
    pub protocol: u8,
    #[doc = "< VXLAN identifier."]
    pub vni: [u8; 3usize],
    #[doc = "< Reserved, normally 0x00."]
    pub rsvd1: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1::flags"][::core::mem::offset_of!(
        rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
        flags
    ) - 0usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1::rsvd0"][::core::mem::offset_of!(
        rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
        rsvd0
    ) - 1usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1::protocol"][::core::mem::offset_of!(
        rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
        protocol
    ) - 3usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1::vni"][::core::mem::offset_of!(
        rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
        vni
    ) - 4usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1::rsvd1"][::core::mem::offset_of!(
        rte_flow_item_vxlan_gpe__bindgen_ty_1__bindgen_ty_1,
        rsvd1
    ) - 7usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan_gpe__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_vxlan_gpe__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_vxlan_gpe__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_vxlan_gpe__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_flow_item_vxlan_gpe__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_vxlan_gpe__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_vxlan_gpe__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_vxlan_gpe"][::core::mem::size_of::<rte_flow_item_vxlan_gpe>() - 8usize];
    ["Alignment of rte_flow_item_vxlan_gpe"]
        [::core::mem::align_of::<rte_flow_item_vxlan_gpe>() - 1usize];
};
impl Default for rte_flow_item_vxlan_gpe {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_vxlan_gpe_mask: rte_flow_item_vxlan_gpe;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ARP_ETH_IPV4\nMatches an ARP header for Ethernet/IPv4."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_arp_eth_ipv4 {
    pub anon1: rte_flow_item_arp_eth_ipv4__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_arp_eth_ipv4__bindgen_ty_1 {
    pub anon1: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
    #[doc = "< ARP header definition."]
    pub hdr: rte_arp_hdr,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< Hardware type, normally 1."]
    pub hrd: rte_be16_t,
    #[doc = "< Protocol type, normally 0x0800."]
    pub pro: rte_be16_t,
    #[doc = "< Hardware address length, normally 6."]
    pub hln: u8,
    #[doc = "< Protocol address length, normally 4."]
    pub pln: u8,
    #[doc = "< Opcode (1 for request, 2 for reply)."]
    pub op: rte_be16_t,
    #[doc = "< Sender hardware address."]
    pub sha: rte_ether_addr,
    #[doc = "< Sender IPv4 address."]
    pub spa: rte_be32_t,
    #[doc = "< Target hardware address."]
    pub tha: rte_ether_addr,
    #[doc = "< Target IPv4 address."]
    pub tpa: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1"][::core::mem::size_of::<
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
    >() - 32usize];
    ["Alignment of rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1"][::core::mem::align_of::<
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
    >() - 4usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::hrd"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        hrd
    ) - 0usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::pro"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        pro
    ) - 2usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::hln"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        hln
    ) - 4usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::pln"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        pln
    ) - 5usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::op"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        op
    ) - 6usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::sha"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        sha
    ) - 8usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::spa"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        spa
    ) - 16usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::tha"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        tha
    ) - 20usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1::tpa"][::core::mem::offset_of!(
        rte_flow_item_arp_eth_ipv4__bindgen_ty_1__bindgen_ty_1,
        tpa
    ) - 28usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_arp_eth_ipv4__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_arp_eth_ipv4__bindgen_ty_1>() - 32usize];
    ["Alignment of rte_flow_item_arp_eth_ipv4__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_arp_eth_ipv4__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_item_arp_eth_ipv4__bindgen_ty_1::hdr"]
        [::core::mem::offset_of!(rte_flow_item_arp_eth_ipv4__bindgen_ty_1, hdr) - 0usize];
};
impl Default for rte_flow_item_arp_eth_ipv4__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_arp_eth_ipv4"]
        [::core::mem::size_of::<rte_flow_item_arp_eth_ipv4>() - 32usize];
    ["Alignment of rte_flow_item_arp_eth_ipv4"]
        [::core::mem::align_of::<rte_flow_item_arp_eth_ipv4>() - 4usize];
};
impl Default for rte_flow_item_arp_eth_ipv4 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_arp_eth_ipv4_mask: rte_flow_item_arp_eth_ipv4;
}
#[doc = "RTE_FLOW_ITEM_TYPE_IPV6_EXT\nMatches the presence of any IPv6 extension header.\nNormally preceded by any of:\n- RTE_FLOW_ITEM_TYPE_IPV6\n- RTE_FLOW_ITEM_TYPE_IPV6_EXT"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ipv6_ext {
    #[doc = "< Next header."]
    pub next_hdr: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ipv6_ext"][::core::mem::size_of::<rte_flow_item_ipv6_ext>() - 1usize];
    ["Alignment of rte_flow_item_ipv6_ext"]
        [::core::mem::align_of::<rte_flow_item_ipv6_ext>() - 1usize];
    ["Offset of field: rte_flow_item_ipv6_ext::next_hdr"]
        [::core::mem::offset_of!(rte_flow_item_ipv6_ext, next_hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_ipv6_ext_mask: rte_flow_item_ipv6_ext;
}
#[doc = "RTE_FLOW_ITEM_TYPE_IPV6_FRAG_EXT\nMatches the presence of IPv6 fragment extension header.\nPreceded by any of:\n- RTE_FLOW_ITEM_TYPE_IPV6\n- RTE_FLOW_ITEM_TYPE_IPV6_EXT"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ipv6_frag_ext {
    pub hdr: rte_ipv6_fragment_ext,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ipv6_frag_ext"]
        [::core::mem::size_of::<rte_flow_item_ipv6_frag_ext>() - 8usize];
    ["Alignment of rte_flow_item_ipv6_frag_ext"]
        [::core::mem::align_of::<rte_flow_item_ipv6_frag_ext>() - 2usize];
    ["Offset of field: rte_flow_item_ipv6_frag_ext::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ipv6_frag_ext, hdr) - 0usize];
};
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6\nMatches any ICMPv6 header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6 {
    #[doc = "< ICMPv6 type."]
    pub type_: u8,
    #[doc = "< ICMPv6 code."]
    pub code: u8,
    #[doc = "< ICMPv6 checksum."]
    pub checksum: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6"][::core::mem::size_of::<rte_flow_item_icmp6>() - 4usize];
    ["Alignment of rte_flow_item_icmp6"][::core::mem::align_of::<rte_flow_item_icmp6>() - 2usize];
    ["Offset of field: rte_flow_item_icmp6::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6::code"]
        [::core::mem::offset_of!(rte_flow_item_icmp6, code) - 1usize];
    ["Offset of field: rte_flow_item_icmp6::checksum"]
        [::core::mem::offset_of!(rte_flow_item_icmp6, checksum) - 2usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_mask: rte_flow_item_icmp6;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REQUEST\nRTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REPLY\nMatches an ICMPv6 echo request or reply."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_echo {
    pub hdr: rte_icmp_echo_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_echo"]
        [::core::mem::size_of::<rte_flow_item_icmp6_echo>() - 8usize];
    ["Alignment of rte_flow_item_icmp6_echo"]
        [::core::mem::align_of::<rte_flow_item_icmp6_echo>() - 1usize];
    ["Offset of field: rte_flow_item_icmp6_echo::hdr"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_echo, hdr) - 0usize];
};
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ND_NS\nMatches an ICMPv6 neighbor discovery solicitation."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_nd_ns {
    #[doc = "< ICMPv6 type, normally 135."]
    pub type_: u8,
    #[doc = "< ICMPv6 code, normally 0."]
    pub code: u8,
    #[doc = "< ICMPv6 checksum."]
    pub checksum: rte_be16_t,
    #[doc = "< Reserved, normally 0."]
    pub reserved: rte_be32_t,
    #[doc = "< Target address."]
    pub target_addr: rte_ipv6_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_nd_ns"]
        [::core::mem::size_of::<rte_flow_item_icmp6_nd_ns>() - 24usize];
    ["Alignment of rte_flow_item_icmp6_nd_ns"]
        [::core::mem::align_of::<rte_flow_item_icmp6_nd_ns>() - 4usize];
    ["Offset of field: rte_flow_item_icmp6_nd_ns::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_ns, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6_nd_ns::code"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_ns, code) - 1usize];
    ["Offset of field: rte_flow_item_icmp6_nd_ns::checksum"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_ns, checksum) - 2usize];
    ["Offset of field: rte_flow_item_icmp6_nd_ns::reserved"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_ns, reserved) - 4usize];
    ["Offset of field: rte_flow_item_icmp6_nd_ns::target_addr"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_ns, target_addr) - 8usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_nd_ns_mask: rte_flow_item_icmp6_nd_ns;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ND_NA\nMatches an ICMPv6 neighbor discovery advertisement."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_nd_na {
    #[doc = "< ICMPv6 type, normally 136."]
    pub type_: u8,
    #[doc = "< ICMPv6 code, normally 0."]
    pub code: u8,
    #[doc = "< ICMPv6 checksum."]
    pub checksum: rte_be16_t,
    #[doc = "Route flag (1b), solicited flag (1b), override flag (1b),\nreserved (29b)."]
    pub rso_reserved: rte_be32_t,
    #[doc = "< Target address."]
    pub target_addr: rte_ipv6_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_nd_na"]
        [::core::mem::size_of::<rte_flow_item_icmp6_nd_na>() - 24usize];
    ["Alignment of rte_flow_item_icmp6_nd_na"]
        [::core::mem::align_of::<rte_flow_item_icmp6_nd_na>() - 4usize];
    ["Offset of field: rte_flow_item_icmp6_nd_na::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_na, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6_nd_na::code"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_na, code) - 1usize];
    ["Offset of field: rte_flow_item_icmp6_nd_na::checksum"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_na, checksum) - 2usize];
    ["Offset of field: rte_flow_item_icmp6_nd_na::rso_reserved"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_na, rso_reserved) - 4usize];
    ["Offset of field: rte_flow_item_icmp6_nd_na::target_addr"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_na, target_addr) - 8usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_nd_na_mask: rte_flow_item_icmp6_nd_na;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT\nMatches the presence of any ICMPv6 neighbor discovery option.\nNormally preceded by any of:\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_NA\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_NS\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_nd_opt {
    #[doc = "< ND option type."]
    pub type_: u8,
    #[doc = "< ND option length."]
    pub length: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_nd_opt"]
        [::core::mem::size_of::<rte_flow_item_icmp6_nd_opt>() - 2usize];
    ["Alignment of rte_flow_item_icmp6_nd_opt"]
        [::core::mem::align_of::<rte_flow_item_icmp6_nd_opt>() - 1usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt::length"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt, length) - 1usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_nd_opt_mask: rte_flow_item_icmp6_nd_opt;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_SLA_ETH\nMatches an ICMPv6 neighbor discovery source Ethernet link-layer address\noption.\nNormally preceded by any of:\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_NA\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_nd_opt_sla_eth {
    #[doc = "< ND option type, normally 1."]
    pub type_: u8,
    #[doc = "< ND option length, normally 1."]
    pub length: u8,
    #[doc = "< Source Ethernet LLA."]
    pub sla: rte_ether_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_nd_opt_sla_eth"]
        [::core::mem::size_of::<rte_flow_item_icmp6_nd_opt_sla_eth>() - 8usize];
    ["Alignment of rte_flow_item_icmp6_nd_opt_sla_eth"]
        [::core::mem::align_of::<rte_flow_item_icmp6_nd_opt_sla_eth>() - 2usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_sla_eth::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_sla_eth, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_sla_eth::length"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_sla_eth, length) - 1usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_sla_eth::sla"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_sla_eth, sla) - 2usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_nd_opt_sla_eth_mask: rte_flow_item_icmp6_nd_opt_sla_eth;
}
#[doc = "RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_TLA_ETH\nMatches an ICMPv6 neighbor discovery target Ethernet link-layer address\noption.\nNormally preceded by any of:\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_NS\n- RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_icmp6_nd_opt_tla_eth {
    #[doc = "< ND option type, normally 2."]
    pub type_: u8,
    #[doc = "< ND option length, normally 1."]
    pub length: u8,
    #[doc = "< Target Ethernet LLA."]
    pub tla: rte_ether_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_icmp6_nd_opt_tla_eth"]
        [::core::mem::size_of::<rte_flow_item_icmp6_nd_opt_tla_eth>() - 8usize];
    ["Alignment of rte_flow_item_icmp6_nd_opt_tla_eth"]
        [::core::mem::align_of::<rte_flow_item_icmp6_nd_opt_tla_eth>() - 2usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_tla_eth::type_"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_tla_eth, type_) - 0usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_tla_eth::length"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_tla_eth, length) - 1usize];
    ["Offset of field: rte_flow_item_icmp6_nd_opt_tla_eth::tla"]
        [::core::mem::offset_of!(rte_flow_item_icmp6_nd_opt_tla_eth, tla) - 2usize];
};
unsafe extern "C" {
    pub static rte_flow_item_icmp6_nd_opt_tla_eth_mask: rte_flow_item_icmp6_nd_opt_tla_eth;
}
#[doc = "RTE_FLOW_ITEM_TYPE_META\nMatches a specified metadata value. On egress, metadata can be set\neither by mbuf dynamic metadata field with RTE_MBUF_DYNFLAG_TX_METADATA flag\nor RTE_FLOW_ACTION_TYPE_SET_META. On ingress, RTE_FLOW_ACTION_TYPE_SET_META\nsets metadata for a packet and the metadata will be reported via mbuf\nmetadata dynamic field with RTE_MBUF_DYNFLAG_RX_METADATA flag. The dynamic\nmbuf field must be registered in advance by\nrte_flow_dynf_metadata_register()."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_meta {
    pub data: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_meta"][::core::mem::size_of::<rte_flow_item_meta>() - 4usize];
    ["Alignment of rte_flow_item_meta"][::core::mem::align_of::<rte_flow_item_meta>() - 4usize];
    ["Offset of field: rte_flow_item_meta::data"]
        [::core::mem::offset_of!(rte_flow_item_meta, data) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_meta_mask: rte_flow_item_meta;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GTP_PSC.\nMatches a GTP PDU extension header with type 0x85."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_gtp_psc {
    #[doc = "< gtp psc generic hdr."]
    pub hdr: rte_gtp_psc_generic_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_gtp_psc"][::core::mem::size_of::<rte_flow_item_gtp_psc>() - 3usize];
    ["Alignment of rte_flow_item_gtp_psc"]
        [::core::mem::align_of::<rte_flow_item_gtp_psc>() - 1usize];
    ["Offset of field: rte_flow_item_gtp_psc::hdr"]
        [::core::mem::offset_of!(rte_flow_item_gtp_psc, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_gtp_psc_mask: rte_flow_item_gtp_psc;
}
#[doc = "RTE_FLOW_ITEM_TYPE_PPPOE.\nMatches a PPPoE header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_pppoe {
    #[doc = "Version (4b), type (4b)."]
    pub version_type: u8,
    #[doc = "< Message type."]
    pub code: u8,
    #[doc = "< Session identifier."]
    pub session_id: rte_be16_t,
    #[doc = "< Payload length."]
    pub length: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_pppoe"][::core::mem::size_of::<rte_flow_item_pppoe>() - 6usize];
    ["Alignment of rte_flow_item_pppoe"][::core::mem::align_of::<rte_flow_item_pppoe>() - 2usize];
    ["Offset of field: rte_flow_item_pppoe::version_type"]
        [::core::mem::offset_of!(rte_flow_item_pppoe, version_type) - 0usize];
    ["Offset of field: rte_flow_item_pppoe::code"]
        [::core::mem::offset_of!(rte_flow_item_pppoe, code) - 1usize];
    ["Offset of field: rte_flow_item_pppoe::session_id"]
        [::core::mem::offset_of!(rte_flow_item_pppoe, session_id) - 2usize];
    ["Offset of field: rte_flow_item_pppoe::length"]
        [::core::mem::offset_of!(rte_flow_item_pppoe, length) - 4usize];
};
#[doc = "RTE_FLOW_ITEM_TYPE_PPPOE_PROTO_ID.\nMatches a PPPoE optional proto_id field.\nIt only applies to PPPoE session packets.\nNormally preceded by any of:\n- RTE_FLOW_ITEM_TYPE_PPPOE\n- RTE_FLOW_ITEM_TYPE_PPPOE_PROTO_ID"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_pppoe_proto_id {
    #[doc = "< PPP protocol identifier."]
    pub proto_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_pppoe_proto_id"]
        [::core::mem::size_of::<rte_flow_item_pppoe_proto_id>() - 2usize];
    ["Alignment of rte_flow_item_pppoe_proto_id"]
        [::core::mem::align_of::<rte_flow_item_pppoe_proto_id>() - 2usize];
    ["Offset of field: rte_flow_item_pppoe_proto_id::proto_id"]
        [::core::mem::offset_of!(rte_flow_item_pppoe_proto_id, proto_id) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_pppoe_proto_id_mask: rte_flow_item_pppoe_proto_id;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_TAG\nMatches a specified tag value at the specified index."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_tag {
    pub data: u32,
    pub index: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_tag"][::core::mem::size_of::<rte_flow_item_tag>() - 8usize];
    ["Alignment of rte_flow_item_tag"][::core::mem::align_of::<rte_flow_item_tag>() - 4usize];
    ["Offset of field: rte_flow_item_tag::data"]
        [::core::mem::offset_of!(rte_flow_item_tag, data) - 0usize];
    ["Offset of field: rte_flow_item_tag::index"]
        [::core::mem::offset_of!(rte_flow_item_tag, index) - 4usize];
};
unsafe extern "C" {
    pub static rte_flow_item_tag_mask: rte_flow_item_tag;
}
#[doc = "RTE_FLOW_ITEM_TYPE_L2TPV3OIP.\nMatches a L2TPv3 over IP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_l2tpv3oip {
    #[doc = "< Session ID."]
    pub session_id: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_l2tpv3oip"][::core::mem::size_of::<rte_flow_item_l2tpv3oip>() - 4usize];
    ["Alignment of rte_flow_item_l2tpv3oip"]
        [::core::mem::align_of::<rte_flow_item_l2tpv3oip>() - 4usize];
    ["Offset of field: rte_flow_item_l2tpv3oip::session_id"]
        [::core::mem::offset_of!(rte_flow_item_l2tpv3oip, session_id) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_l2tpv3oip_mask: rte_flow_item_l2tpv3oip;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_MARK\nMatches an arbitrary integer value which was set using the ``MARK`` action\nin a previously matched rule.\nThis item can only be specified once as a match criteria as the ``MARK``\naction can only be specified once in a flow action.\nThis value is arbitrary and application-defined. Maximum allowed value\ndepends on the underlying implementation.\nDepending on the underlying implementation the MARK item may be supported on\nthe physical device, with virtual groups in the PMD or not at all."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_mark {
    #[doc = "< Integer value to match against."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_mark"][::core::mem::size_of::<rte_flow_item_mark>() - 4usize];
    ["Alignment of rte_flow_item_mark"][::core::mem::align_of::<rte_flow_item_mark>() - 4usize];
    ["Offset of field: rte_flow_item_mark::id"]
        [::core::mem::offset_of!(rte_flow_item_mark, id) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_mark_mask: rte_flow_item_mark;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_NSH\nMatch network service header (NSH), RFC 8300"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_nsh {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 8usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_nsh"][::core::mem::size_of::<rte_flow_item_nsh>() - 8usize];
    ["Alignment of rte_flow_item_nsh"][::core::mem::align_of::<rte_flow_item_nsh>() - 4usize];
};
impl rte_flow_item_nsh {
    #[inline]
    pub fn version(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 2u8) as u32) }
    }
    #[inline]
    pub fn set_version(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn version_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                2u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_version_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn oam_pkt(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_oam_pkt(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn oam_pkt_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_oam_pkt_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ttl(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 6u8) as u32) }
    }
    #[inline]
    pub fn set_ttl(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ttl_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                6u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ttl_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn length(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(10usize, 6u8) as u32) }
    }
    #[inline]
    pub fn set_length(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(10usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn length_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                10usize,
                6u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_length_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                10usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved1(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_reserved1(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved1_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved1_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn mdtype(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(20usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_mdtype(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(20usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn mdtype_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                20usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_mdtype_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                20usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn next_proto(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_next_proto(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn next_proto_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_next_proto_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn spi(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(32usize, 24u8) as u32) }
    }
    #[inline]
    pub fn set_spi(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(32usize, 24u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn spi_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                32usize,
                24u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_spi_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                32usize,
                24u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn sindex(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(56usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_sindex(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(56usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sindex_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                56usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_sindex_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                56usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        version: u32,
        oam_pkt: u32,
        reserved: u32,
        ttl: u32,
        length: u32,
        reserved1: u32,
        mdtype: u32,
        next_proto: u32,
        spi: u32,
        sindex: u32,
    ) -> __BindgenBitfieldUnit<[u8; 8usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 8usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 2u8, {
            let version: u32 = unsafe { ::core::mem::transmute(version) };
            version as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let oam_pkt: u32 = unsafe { ::core::mem::transmute(oam_pkt) };
            oam_pkt as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit.set(4usize, 6u8, {
            let ttl: u32 = unsafe { ::core::mem::transmute(ttl) };
            ttl as u64
        });
        __bindgen_bitfield_unit.set(10usize, 6u8, {
            let length: u32 = unsafe { ::core::mem::transmute(length) };
            length as u64
        });
        __bindgen_bitfield_unit.set(16usize, 4u8, {
            let reserved1: u32 = unsafe { ::core::mem::transmute(reserved1) };
            reserved1 as u64
        });
        __bindgen_bitfield_unit.set(20usize, 4u8, {
            let mdtype: u32 = unsafe { ::core::mem::transmute(mdtype) };
            mdtype as u64
        });
        __bindgen_bitfield_unit.set(24usize, 8u8, {
            let next_proto: u32 = unsafe { ::core::mem::transmute(next_proto) };
            next_proto as u64
        });
        __bindgen_bitfield_unit.set(32usize, 24u8, {
            let spi: u32 = unsafe { ::core::mem::transmute(spi) };
            spi as u64
        });
        __bindgen_bitfield_unit.set(56usize, 8u8, {
            let sindex: u32 = unsafe { ::core::mem::transmute(sindex) };
            sindex as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_nsh_mask: rte_flow_item_nsh;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_IGMP\nMatch Internet Group Management Protocol (IGMP), RFC 2236"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_igmp {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    pub group_addr: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_igmp"][::core::mem::size_of::<rte_flow_item_igmp>() - 8usize];
    ["Alignment of rte_flow_item_igmp"][::core::mem::align_of::<rte_flow_item_igmp>() - 4usize];
    ["Offset of field: rte_flow_item_igmp::group_addr"]
        [::core::mem::offset_of!(rte_flow_item_igmp, group_addr) - 4usize];
};
impl rte_flow_item_igmp {
    #[inline]
    pub fn type_(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_type(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn type__raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_type_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn max_resp_time(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_max_resp_time(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn max_resp_time_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_max_resp_time_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn checksum(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_checksum(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn checksum_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_checksum_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        type_: u32,
        max_resp_time: u32,
        checksum: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 8u8, {
            let type_: u32 = unsafe { ::core::mem::transmute(type_) };
            type_ as u64
        });
        __bindgen_bitfield_unit.set(8usize, 8u8, {
            let max_resp_time: u32 = unsafe { ::core::mem::transmute(max_resp_time) };
            max_resp_time as u64
        });
        __bindgen_bitfield_unit.set(16usize, 16u8, {
            let checksum: u32 = unsafe { ::core::mem::transmute(checksum) };
            checksum as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_igmp_mask: rte_flow_item_igmp;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_AH\nMatch IP Authentication Header (AH), RFC 4302"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ah {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    pub spi: u32,
    pub seq_num: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ah"][::core::mem::size_of::<rte_flow_item_ah>() - 12usize];
    ["Alignment of rte_flow_item_ah"][::core::mem::align_of::<rte_flow_item_ah>() - 4usize];
    ["Offset of field: rte_flow_item_ah::spi"]
        [::core::mem::offset_of!(rte_flow_item_ah, spi) - 4usize];
    ["Offset of field: rte_flow_item_ah::seq_num"]
        [::core::mem::offset_of!(rte_flow_item_ah, seq_num) - 8usize];
};
impl rte_flow_item_ah {
    #[inline]
    pub fn next_hdr(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_next_hdr(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn next_hdr_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_next_hdr_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn payload_len(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_payload_len(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn payload_len_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_payload_len_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        next_hdr: u32,
        payload_len: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 8u8, {
            let next_hdr: u32 = unsafe { ::core::mem::transmute(next_hdr) };
            next_hdr as u64
        });
        __bindgen_bitfield_unit.set(8usize, 8u8, {
            let payload_len: u32 = unsafe { ::core::mem::transmute(payload_len) };
            payload_len as u64
        });
        __bindgen_bitfield_unit.set(16usize, 16u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static rte_flow_item_ah_mask: rte_flow_item_ah;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_PFCP\nMatch PFCP Header"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_pfcp {
    pub s_field: u8,
    pub msg_type: u8,
    pub msg_len: rte_be16_t,
    pub seid: rte_be64_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_pfcp"][::core::mem::size_of::<rte_flow_item_pfcp>() - 16usize];
    ["Alignment of rte_flow_item_pfcp"][::core::mem::align_of::<rte_flow_item_pfcp>() - 8usize];
    ["Offset of field: rte_flow_item_pfcp::s_field"]
        [::core::mem::offset_of!(rte_flow_item_pfcp, s_field) - 0usize];
    ["Offset of field: rte_flow_item_pfcp::msg_type"]
        [::core::mem::offset_of!(rte_flow_item_pfcp, msg_type) - 1usize];
    ["Offset of field: rte_flow_item_pfcp::msg_len"]
        [::core::mem::offset_of!(rte_flow_item_pfcp, msg_len) - 2usize];
    ["Offset of field: rte_flow_item_pfcp::seid"]
        [::core::mem::offset_of!(rte_flow_item_pfcp, seid) - 8usize];
};
unsafe extern "C" {
    pub static rte_flow_item_pfcp_mask: rte_flow_item_pfcp;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_ECPRI\nMatch eCPRI Header"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_ecpri {
    pub hdr: rte_ecpri_combined_msg_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ecpri"][::core::mem::size_of::<rte_flow_item_ecpri>() - 16usize];
    ["Alignment of rte_flow_item_ecpri"][::core::mem::align_of::<rte_flow_item_ecpri>() - 4usize];
    ["Offset of field: rte_flow_item_ecpri::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ecpri, hdr) - 0usize];
};
impl Default for rte_flow_item_ecpri {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_ecpri_mask: rte_flow_item_ecpri;
}
#[doc = "RTE_FLOW_ITEM_TYPE_GENEVE_OPT\nMatches a GENEVE Variable Length Option"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_geneve_opt {
    pub option_class: rte_be16_t,
    pub option_type: u8,
    pub option_len: u8,
    pub data: *mut u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_geneve_opt"]
        [::core::mem::size_of::<rte_flow_item_geneve_opt>() - 16usize];
    ["Alignment of rte_flow_item_geneve_opt"]
        [::core::mem::align_of::<rte_flow_item_geneve_opt>() - 8usize];
    ["Offset of field: rte_flow_item_geneve_opt::option_class"]
        [::core::mem::offset_of!(rte_flow_item_geneve_opt, option_class) - 0usize];
    ["Offset of field: rte_flow_item_geneve_opt::option_type"]
        [::core::mem::offset_of!(rte_flow_item_geneve_opt, option_type) - 2usize];
    ["Offset of field: rte_flow_item_geneve_opt::option_len"]
        [::core::mem::offset_of!(rte_flow_item_geneve_opt, option_len) - 3usize];
    ["Offset of field: rte_flow_item_geneve_opt::data"]
        [::core::mem::offset_of!(rte_flow_item_geneve_opt, data) - 8usize];
};
impl Default for rte_flow_item_geneve_opt {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_geneve_opt_mask: rte_flow_item_geneve_opt;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_INTEGRITY\nMatch on packet integrity check result."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_integrity {
    #[doc = "Tunnel encapsulation level the item should apply to.\n\n# See also\n\n> [`rte_flow_action_rss`]"]
    pub level: u32,
    pub anon1: rte_flow_item_integrity__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_item_integrity__bindgen_ty_1 {
    pub anon1: rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1,
    pub value: u64,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u64; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 8usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1>() - 8usize];
};
impl rte_flow_item_integrity__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn packet_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_packet_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn packet_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_packet_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l2_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l2_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l2_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l3_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l3_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l4_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l4_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l2_crc_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l2_crc_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_crc_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l2_crc_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ipv4_csum_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_ipv4_csum_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ipv4_csum_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_ipv4_csum_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_csum_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l4_csum_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_csum_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l4_csum_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_len_ok(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u64) }
    }
    #[inline]
    pub fn set_l3_len_ok(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_len_ok_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l3_len_ok_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u64 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 56u8) as u64) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 56u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u64 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 8usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                56u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 8usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                56u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        packet_ok: u64,
        l2_ok: u64,
        l3_ok: u64,
        l4_ok: u64,
        l2_crc_ok: u64,
        ipv4_csum_ok: u64,
        l4_csum_ok: u64,
        l3_len_ok: u64,
        reserved: u64,
    ) -> __BindgenBitfieldUnit<[u8; 8usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 8usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let packet_ok: u64 = unsafe { ::core::mem::transmute(packet_ok) };
            packet_ok as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let l2_ok: u64 = unsafe { ::core::mem::transmute(l2_ok) };
            l2_ok as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let l3_ok: u64 = unsafe { ::core::mem::transmute(l3_ok) };
            l3_ok as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let l4_ok: u64 = unsafe { ::core::mem::transmute(l4_ok) };
            l4_ok as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let l2_crc_ok: u64 = unsafe { ::core::mem::transmute(l2_crc_ok) };
            l2_crc_ok as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let ipv4_csum_ok: u64 = unsafe { ::core::mem::transmute(ipv4_csum_ok) };
            ipv4_csum_ok as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let l4_csum_ok: u64 = unsafe { ::core::mem::transmute(l4_csum_ok) };
            l4_csum_ok as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let l3_len_ok: u64 = unsafe { ::core::mem::transmute(l3_len_ok) };
            l3_len_ok as u64
        });
        __bindgen_bitfield_unit.set(8usize, 56u8, {
            let reserved: u64 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_integrity__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_item_integrity__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_item_integrity__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_item_integrity__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_flow_item_integrity__bindgen_ty_1::value"]
        [::core::mem::offset_of!(rte_flow_item_integrity__bindgen_ty_1, value) - 0usize];
};
impl Default for rte_flow_item_integrity__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_integrity"]
        [::core::mem::size_of::<rte_flow_item_integrity>() - 16usize];
    ["Alignment of rte_flow_item_integrity"]
        [::core::mem::align_of::<rte_flow_item_integrity>() - 8usize];
    ["Offset of field: rte_flow_item_integrity::level"]
        [::core::mem::offset_of!(rte_flow_item_integrity, level) - 0usize];
};
impl Default for rte_flow_item_integrity {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_integrity_mask: rte_flow_item_integrity;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_CONNTRACK\nMatches the state of a packet after it passed the connection tracking\nexamination. The state is a bitmap of one RTE_FLOW_CONNTRACK_PKT_STATE*\nor a reasonable combination of these bits."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_conntrack {
    pub flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_conntrack"][::core::mem::size_of::<rte_flow_item_conntrack>() - 4usize];
    ["Alignment of rte_flow_item_conntrack"]
        [::core::mem::align_of::<rte_flow_item_conntrack>() - 4usize];
    ["Offset of field: rte_flow_item_conntrack::flags"]
        [::core::mem::offset_of!(rte_flow_item_conntrack, flags) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_conntrack_mask: rte_flow_item_conntrack;
}
#[doc = "Provides an ethdev port ID for use with the following items:\nRTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR,\nRTE_FLOW_ITEM_TYPE_REPRESENTED_PORT."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ethdev {
    #[doc = "< ethdev port ID"]
    pub port_id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ethdev"][::core::mem::size_of::<rte_flow_item_ethdev>() - 2usize];
    ["Alignment of rte_flow_item_ethdev"][::core::mem::align_of::<rte_flow_item_ethdev>() - 2usize];
    ["Offset of field: rte_flow_item_ethdev::port_id"]
        [::core::mem::offset_of!(rte_flow_item_ethdev, port_id) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_ethdev_mask: rte_flow_item_ethdev;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_L2TPV2\nMatches L2TPv2 Header"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_l2tpv2 {
    pub hdr: rte_l2tpv2_combined_msg_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_l2tpv2"][::core::mem::size_of::<rte_flow_item_l2tpv2>() - 26usize];
    ["Alignment of rte_flow_item_l2tpv2"][::core::mem::align_of::<rte_flow_item_l2tpv2>() - 1usize];
    ["Offset of field: rte_flow_item_l2tpv2::hdr"]
        [::core::mem::offset_of!(rte_flow_item_l2tpv2, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_l2tpv2_mask: rte_flow_item_l2tpv2;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_PPP\nMatches PPP Header"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ppp {
    pub hdr: rte_ppp_hdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ppp"][::core::mem::size_of::<rte_flow_item_ppp>() - 4usize];
    ["Alignment of rte_flow_item_ppp"][::core::mem::align_of::<rte_flow_item_ppp>() - 1usize];
    ["Offset of field: rte_flow_item_ppp::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ppp, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_ppp_mask: rte_flow_item_ppp;
}
#[doc = "RTE_FLOW_ITEM_TYPE_IB_BTH.\nMatches an InfiniBand base transport header in RoCE packet."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ib_bth {
    #[doc = "< InfiniBand base transport header definition."]
    pub hdr: rte_ib_bth,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ib_bth"][::core::mem::size_of::<rte_flow_item_ib_bth>() - 12usize];
    ["Alignment of rte_flow_item_ib_bth"][::core::mem::align_of::<rte_flow_item_ib_bth>() - 1usize];
    ["Offset of field: rte_flow_item_ib_bth::hdr"]
        [::core::mem::offset_of!(rte_flow_item_ib_bth, hdr) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_ib_bth_mask: rte_flow_item_ib_bth;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ITEM_TYPE_RANDOM\nMatches a random value."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_random {
    pub value: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_random"][::core::mem::size_of::<rte_flow_item_random>() - 4usize];
    ["Alignment of rte_flow_item_random"][::core::mem::align_of::<rte_flow_item_random>() - 4usize];
    ["Offset of field: rte_flow_item_random::value"]
        [::core::mem::offset_of!(rte_flow_item_random, value) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_random_mask: rte_flow_item_random;
}
#[doc = "Matching pattern item definition.\nA pattern is formed by stacking items starting from the lowest protocol\nlayer to match. This stacking restriction does not apply to meta items\nwhich can be placed anywhere in the stack without affecting the meaning\nof the resulting pattern.\nPatterns are terminated by END items.\nThe spec field should be a valid pointer to a structure of the related\nitem type. It may remain unspecified (NULL) in many cases to request\nbroad (nonspecific) matching. In such cases, last and mask must also be\nset to NULL.\nOptionally, last can point to a structure of the same type to define an\ninclusive range. This is mostly supported by integer and address fields,\nmay cause errors otherwise. Fields that do not support ranges must be set\nto 0 or to the same value as the corresponding fields in spec.\nOnly the fields defined to nonzero values in the default masks (see\nrte_flow_item_{name}_mask constants) are considered relevant by\ndefault. This can be overridden by providing a mask structure of the\nsame type with applicable bits set to one. It can also be used to\npartially filter out specific fields (e.g. as an alternate mean to match\nranges of IP addresses).\nMask is a simple bit-mask applied before interpreting the contents of\nspec and last, which may yield unexpected results if not used\ncarefully. For example, if for an IPv4 address field, spec provides\n10.1.2.3, last provides 10.3.4.5 and mask provides 255.255.0.0, the\neffective range becomes 10.1.0.0 to 10.3.255.255."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item {
    #[doc = "< Item type."]
    pub type_: rte_flow_item_type::Type,
    #[doc = "< Pointer to item specification structure."]
    pub spec: *const ::core::ffi::c_void,
    #[doc = "< Defines an inclusive range (spec to last)."]
    pub last: *const ::core::ffi::c_void,
    #[doc = "< Bit-mask applied to spec and last."]
    pub mask: *const ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item"][::core::mem::size_of::<rte_flow_item>() - 32usize];
    ["Alignment of rte_flow_item"][::core::mem::align_of::<rte_flow_item>() - 8usize];
    ["Offset of field: rte_flow_item::type_"]
        [::core::mem::offset_of!(rte_flow_item, type_) - 0usize];
    ["Offset of field: rte_flow_item::spec"][::core::mem::offset_of!(rte_flow_item, spec) - 8usize];
    ["Offset of field: rte_flow_item::last"]
        [::core::mem::offset_of!(rte_flow_item, last) - 16usize];
    ["Offset of field: rte_flow_item::mask"]
        [::core::mem::offset_of!(rte_flow_item, mask) - 24usize];
};
impl Default for rte_flow_item {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_FLEX\nMatches a specified set of fields within the network protocol\nheader. Each field is presented as set of bits with specified width, and\nbit offset from the header beginning.\nThe pattern is concatenation of bit fields configured at item creation\nby rte_flow_flex_item_create(). At configuration the fields are presented\nby sample_data array.\nThis type does not support ranges (struct rte_flow_item.last)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex {
    #[doc = "< Opaque item handle."]
    pub handle: *mut rte_flow_item_flex_handle,
    #[doc = "< Pattern length in bytes."]
    pub length: u32,
    #[doc = "< Combined bitfields pattern to match."]
    pub pattern: *const u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex"][::core::mem::size_of::<rte_flow_item_flex>() - 24usize];
    ["Alignment of rte_flow_item_flex"][::core::mem::align_of::<rte_flow_item_flex>() - 8usize];
    ["Offset of field: rte_flow_item_flex::handle"]
        [::core::mem::offset_of!(rte_flow_item_flex, handle) - 0usize];
    ["Offset of field: rte_flow_item_flex::length"]
        [::core::mem::offset_of!(rte_flow_item_flex, length) - 8usize];
    ["Offset of field: rte_flow_item_flex::pattern"]
        [::core::mem::offset_of!(rte_flow_item_flex, pattern) - 16usize];
};
impl Default for rte_flow_item_flex {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_item_flex_field_mode {
    #[doc = "Field bit offset calculation mode."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Dummy field, used for byte boundary alignment in pattern.\nPattern mask and data are ignored in the match. All configuration\nparameters besides field size are ignored."]
    pub const FIELD_MODE_DUMMY: Type = 0;
    #[doc = "Fixed offset field. The bit offset from header beginning\nis permanent and defined by field_base parameter."]
    pub const FIELD_MODE_FIXED: Type = 1;
    #[doc = "The field bit offset is extracted from other header field (indirect\noffset field). The resulting field offset to match is calculated as:\nfield_base + (*offset_base & offset_mask) << offset_shift"]
    pub const FIELD_MODE_OFFSET: Type = 2;
    #[doc = "The field bit offset is extracted from other header field (indirect\noffset field), the latter is considered as bitmask containing some\nnumber of one bits, the resulting field offset to match is\ncalculated as:\nfield_base + bitcount(*offset_base & offset_mask) << offset_shift"]
    pub const FIELD_MODE_BITMASK: Type = 3;
}
pub mod rte_flow_item_flex_tunnel_mode {
    #[doc = "Flex item field tunnel mode"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "The protocol header can be present in the packet only once.\nNo multiple flex item flow inclusions (for inner/outer) are allowed.\nNo any relations with tunnel protocols are imposed. The drivers\ncan optimize hardware resource usage to handle match on single flex\nitem of specific type."]
    pub const FLEX_TUNNEL_MODE_SINGLE: Type = 0;
    #[doc = "Flex item presents outer header only."]
    pub const FLEX_TUNNEL_MODE_OUTER: Type = 1;
    #[doc = "Flex item presents inner header only."]
    pub const FLEX_TUNNEL_MODE_INNER: Type = 2;
    #[doc = "Flex item presents either inner or outer header. The driver\nhandles as many multiple inners as hardware supports."]
    pub const FLEX_TUNNEL_MODE_MULTI: Type = 3;
    #[doc = "Flex item presents tunnel protocol header."]
    pub const FLEX_TUNNEL_MODE_TUNNEL: Type = 4;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_field {
    #[doc = "Defines how match field offset is calculated over the packet."]
    pub field_mode: rte_flow_item_flex_field_mode::Type,
    #[doc = "< Field size in bits."]
    pub field_size: u32,
    #[doc = "< Field offset in bits."]
    pub field_base: i32,
    #[doc = "< Indirect offset field offset in bits."]
    pub offset_base: u32,
    #[doc = "< Indirect offset field bit mask."]
    pub offset_mask: u32,
    #[doc = "< Indirect offset multiply factor."]
    pub offset_shift: i32,
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_field"]
        [::core::mem::size_of::<rte_flow_item_flex_field>() - 28usize];
    ["Alignment of rte_flow_item_flex_field"]
        [::core::mem::align_of::<rte_flow_item_flex_field>() - 4usize];
    ["Offset of field: rte_flow_item_flex_field::field_mode"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, field_mode) - 0usize];
    ["Offset of field: rte_flow_item_flex_field::field_size"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, field_size) - 4usize];
    ["Offset of field: rte_flow_item_flex_field::field_base"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, field_base) - 8usize];
    ["Offset of field: rte_flow_item_flex_field::offset_base"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, offset_base) - 12usize];
    ["Offset of field: rte_flow_item_flex_field::offset_mask"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, offset_mask) - 16usize];
    ["Offset of field: rte_flow_item_flex_field::offset_shift"]
        [::core::mem::offset_of!(rte_flow_item_flex_field, offset_shift) - 20usize];
};
impl Default for rte_flow_item_flex_field {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_item_flex_field {
    #[inline]
    pub fn field_id(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_field_id(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn field_id_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_field_id_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(16usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(16usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(field_id: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let field_id: u32 = unsafe { ::core::mem::transmute(field_id) };
            field_id as u64
        });
        __bindgen_bitfield_unit.set(16usize, 16u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_link {
    #[doc = "Preceding/following header. The item type must be always provided.\nFor preceding one item must specify the header value/mask to match\nfor the link be taken and start the flex item header parsing."]
    pub item: rte_flow_item,
    #[doc = "Next field value to match to continue with one of the configured\nnext protocols."]
    pub next: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_link"]
        [::core::mem::size_of::<rte_flow_item_flex_link>() - 40usize];
    ["Alignment of rte_flow_item_flex_link"]
        [::core::mem::align_of::<rte_flow_item_flex_link>() - 8usize];
    ["Offset of field: rte_flow_item_flex_link::item"]
        [::core::mem::offset_of!(rte_flow_item_flex_link, item) - 0usize];
    ["Offset of field: rte_flow_item_flex_link::next"]
        [::core::mem::offset_of!(rte_flow_item_flex_link, next) - 32usize];
};
impl Default for rte_flow_item_flex_link {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_conf {
    #[doc = "Specifies the flex item and tunnel relations and tells the PMD\nwhether flex item can be used for inner, outer or both headers,\nor whether flex item presents the tunnel protocol itself."]
    pub tunnel: rte_flow_item_flex_tunnel_mode::Type,
    #[doc = "The next header offset, it presents the network header size covered\nby the flex item and can be obtained with all supported offset\ncalculating methods (fixed, dedicated field, bitmask, etc)."]
    pub next_header: rte_flow_item_flex_field,
    #[doc = "Specifies the next protocol field to match with link next protocol\nvalues and continue packet parsing with matching link."]
    pub next_protocol: rte_flow_item_flex_field,
    #[doc = "The fields will be sampled and presented for explicit match\nwith pattern in the rte_flow_flex_item. There can be multiple\nfields descriptors, the number should be specified by nb_samples."]
    pub sample_data: *mut rte_flow_item_flex_field,
    #[doc = "Number of field descriptors in the sample_data array."]
    pub nb_samples: u32,
    #[doc = "Input link defines the flex item relation with preceding\nheader. It specified the preceding item type and provides pattern\nto match. The flex item will continue parsing and will provide the\ndata to flow match in case if there is the match with one of input\nlinks."]
    pub input_link: *mut rte_flow_item_flex_link,
    #[doc = "Number of link descriptors in the input link array."]
    pub nb_inputs: u32,
    #[doc = "Output link defines the next protocol field value to match and\nthe following protocol header to continue packet parsing. Also\ndefines the tunnel-related behaviour."]
    pub output_link: *mut rte_flow_item_flex_link,
    #[doc = "Number of link descriptors in the output link array."]
    pub nb_outputs: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_conf"]
        [::core::mem::size_of::<rte_flow_item_flex_conf>() - 112usize];
    ["Alignment of rte_flow_item_flex_conf"]
        [::core::mem::align_of::<rte_flow_item_flex_conf>() - 8usize];
    ["Offset of field: rte_flow_item_flex_conf::tunnel"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, tunnel) - 0usize];
    ["Offset of field: rte_flow_item_flex_conf::next_header"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, next_header) - 4usize];
    ["Offset of field: rte_flow_item_flex_conf::next_protocol"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, next_protocol) - 32usize];
    ["Offset of field: rte_flow_item_flex_conf::sample_data"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, sample_data) - 64usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_samples"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, nb_samples) - 72usize];
    ["Offset of field: rte_flow_item_flex_conf::input_link"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, input_link) - 80usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_inputs"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, nb_inputs) - 88usize];
    ["Offset of field: rte_flow_item_flex_conf::output_link"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, output_link) - 96usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_outputs"]
        [::core::mem::offset_of!(rte_flow_item_flex_conf, nb_outputs) - 104usize];
};
impl Default for rte_flow_item_flex_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ITEM_TYPE_METER_COLOR.\nMatches Color Marker set by a Meter."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_meter_color {
    #[doc = "< Meter color marker."]
    pub color: rte_color::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_meter_color"]
        [::core::mem::size_of::<rte_flow_item_meter_color>() - 4usize];
    ["Alignment of rte_flow_item_meter_color"]
        [::core::mem::align_of::<rte_flow_item_meter_color>() - 4usize];
    ["Offset of field: rte_flow_item_meter_color::color"]
        [::core::mem::offset_of!(rte_flow_item_meter_color, color) - 0usize];
};
impl Default for rte_flow_item_meter_color {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    pub static rte_flow_item_meter_color_mask: rte_flow_item_meter_color;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ITEM_TYPE_AGGR_AFFINITY\nFor multiple ports aggregated to a single DPDK port,\nmatch the aggregated port receiving the packets."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_aggr_affinity {
    #[doc = "An aggregated port receiving the packets.\nNumbering starts from 1.\nNumber of aggregated ports is reported by rte_eth_dev_count_aggr_ports()."]
    pub affinity: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_aggr_affinity"]
        [::core::mem::size_of::<rte_flow_item_aggr_affinity>() - 1usize];
    ["Alignment of rte_flow_item_aggr_affinity"]
        [::core::mem::align_of::<rte_flow_item_aggr_affinity>() - 1usize];
    ["Offset of field: rte_flow_item_aggr_affinity::affinity"]
        [::core::mem::offset_of!(rte_flow_item_aggr_affinity, affinity) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_aggr_affinity_mask: rte_flow_item_aggr_affinity;
}
#[doc = "RTE_FLOW_ITEM_TYPE_TX_QUEUE\nTx queue number.\n\n# See also\n\n> [`struct`] rte_flow_item_tx_queue"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_tx_queue {
    #[doc = "Tx queue number of packet being transmitted."]
    pub tx_queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_tx_queue"][::core::mem::size_of::<rte_flow_item_tx_queue>() - 2usize];
    ["Alignment of rte_flow_item_tx_queue"]
        [::core::mem::align_of::<rte_flow_item_tx_queue>() - 2usize];
    ["Offset of field: rte_flow_item_tx_queue::tx_queue"]
        [::core::mem::offset_of!(rte_flow_item_tx_queue, tx_queue) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_tx_queue_mask: rte_flow_item_tx_queue;
}
#[doc = "RTE_FLOW_ITEM_TYPE_PTYPE\nMatches the packet type as defined in rte_mbuf_ptype."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_ptype {
    #[doc = "< L2/L3/L4 and tunnel information."]
    pub packet_type: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_ptype"][::core::mem::size_of::<rte_flow_item_ptype>() - 4usize];
    ["Alignment of rte_flow_item_ptype"][::core::mem::align_of::<rte_flow_item_ptype>() - 4usize];
    ["Offset of field: rte_flow_item_ptype::packet_type"]
        [::core::mem::offset_of!(rte_flow_item_ptype, packet_type) - 0usize];
};
unsafe extern "C" {
    pub static rte_flow_item_ptype_mask: rte_flow_item_ptype;
}
pub mod rte_flow_field_id {
    #[doc = "Packet header field IDs, used by RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\nand RTE_FLOW_ITEM_TYPE_COMPARE."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Start of a packet."]
    pub const RTE_FLOW_FIELD_START: Type = 0;
    #[doc = "< Destination MAC Address."]
    pub const RTE_FLOW_FIELD_MAC_DST: Type = 1;
    #[doc = "< Source MAC Address."]
    pub const RTE_FLOW_FIELD_MAC_SRC: Type = 2;
    #[doc = "< VLAN Tag Identifier."]
    pub const RTE_FLOW_FIELD_VLAN_TYPE: Type = 3;
    #[doc = "< VLAN Identifier."]
    pub const RTE_FLOW_FIELD_VLAN_ID: Type = 4;
    #[doc = "< EtherType."]
    pub const RTE_FLOW_FIELD_MAC_TYPE: Type = 5;
    #[doc = "< IPv4 DSCP."]
    pub const RTE_FLOW_FIELD_IPV4_DSCP: Type = 6;
    #[doc = "< IPv4 Time To Live."]
    pub const RTE_FLOW_FIELD_IPV4_TTL: Type = 7;
    #[doc = "< IPv4 Source Address."]
    pub const RTE_FLOW_FIELD_IPV4_SRC: Type = 8;
    #[doc = "< IPv4 Destination Address."]
    pub const RTE_FLOW_FIELD_IPV4_DST: Type = 9;
    #[doc = "< IPv6 DSCP."]
    pub const RTE_FLOW_FIELD_IPV6_DSCP: Type = 10;
    #[doc = "< IPv6 Hop Limit."]
    pub const RTE_FLOW_FIELD_IPV6_HOPLIMIT: Type = 11;
    #[doc = "< IPv6 Source Address."]
    pub const RTE_FLOW_FIELD_IPV6_SRC: Type = 12;
    #[doc = "< IPv6 Destination Address."]
    pub const RTE_FLOW_FIELD_IPV6_DST: Type = 13;
    #[doc = "< TCP Source Port Number."]
    pub const RTE_FLOW_FIELD_TCP_PORT_SRC: Type = 14;
    #[doc = "< TCP Destination Port Number."]
    pub const RTE_FLOW_FIELD_TCP_PORT_DST: Type = 15;
    #[doc = "< TCP Sequence Number."]
    pub const RTE_FLOW_FIELD_TCP_SEQ_NUM: Type = 16;
    #[doc = "< TCP Acknowledgment Number."]
    pub const RTE_FLOW_FIELD_TCP_ACK_NUM: Type = 17;
    #[doc = "< TCP Flags."]
    pub const RTE_FLOW_FIELD_TCP_FLAGS: Type = 18;
    #[doc = "< UDP Source Port Number."]
    pub const RTE_FLOW_FIELD_UDP_PORT_SRC: Type = 19;
    #[doc = "< UDP Destination Port Number."]
    pub const RTE_FLOW_FIELD_UDP_PORT_DST: Type = 20;
    #[doc = "< VXLAN Network Identifier."]
    pub const RTE_FLOW_FIELD_VXLAN_VNI: Type = 21;
    #[doc = "< GENEVE Network Identifier."]
    pub const RTE_FLOW_FIELD_GENEVE_VNI: Type = 22;
    #[doc = "< GTP Tunnel Endpoint Identifier."]
    pub const RTE_FLOW_FIELD_GTP_TEID: Type = 23;
    #[doc = "< Tag value."]
    pub const RTE_FLOW_FIELD_TAG: Type = 24;
    #[doc = "< Mark value."]
    pub const RTE_FLOW_FIELD_MARK: Type = 25;
    #[doc = "< Metadata value."]
    pub const RTE_FLOW_FIELD_META: Type = 26;
    #[doc = "< Memory pointer."]
    pub const RTE_FLOW_FIELD_POINTER: Type = 27;
    #[doc = "< Immediate value."]
    pub const RTE_FLOW_FIELD_VALUE: Type = 28;
    #[doc = "< IPv4 ECN."]
    pub const RTE_FLOW_FIELD_IPV4_ECN: Type = 29;
    #[doc = "< IPv6 ECN."]
    pub const RTE_FLOW_FIELD_IPV6_ECN: Type = 30;
    #[doc = "< GTP QFI."]
    pub const RTE_FLOW_FIELD_GTP_PSC_QFI: Type = 31;
    #[doc = "< Meter color marker."]
    pub const RTE_FLOW_FIELD_METER_COLOR: Type = 32;
    #[doc = "< IPv6 next header."]
    pub const RTE_FLOW_FIELD_IPV6_PROTO: Type = 33;
    #[doc = "< Flex item."]
    pub const RTE_FLOW_FIELD_FLEX_ITEM: Type = 34;
    #[doc = "< Hash result."]
    pub const RTE_FLOW_FIELD_HASH_RESULT: Type = 35;
    #[doc = "< GENEVE option type."]
    pub const RTE_FLOW_FIELD_GENEVE_OPT_TYPE: Type = 36;
    #[doc = "< GENEVE option class."]
    pub const RTE_FLOW_FIELD_GENEVE_OPT_CLASS: Type = 37;
    #[doc = "< GENEVE option data."]
    pub const RTE_FLOW_FIELD_GENEVE_OPT_DATA: Type = 38;
    #[doc = "< MPLS header."]
    pub const RTE_FLOW_FIELD_MPLS: Type = 39;
    #[doc = "< TCP data offset."]
    pub const RTE_FLOW_FIELD_TCP_DATA_OFFSET: Type = 40;
    #[doc = "< IPv4 IHL."]
    pub const RTE_FLOW_FIELD_IPV4_IHL: Type = 41;
    #[doc = "< IPv4 total length."]
    pub const RTE_FLOW_FIELD_IPV4_TOTAL_LEN: Type = 42;
    #[doc = "< IPv6 payload length."]
    pub const RTE_FLOW_FIELD_IPV6_PAYLOAD_LEN: Type = 43;
    #[doc = "< IPv4 next protocol."]
    pub const RTE_FLOW_FIELD_IPV4_PROTO: Type = 44;
    #[doc = "< IPv6 flow label."]
    pub const RTE_FLOW_FIELD_IPV6_FLOW_LABEL: Type = 45;
    #[doc = "< IPv6 traffic class."]
    pub const RTE_FLOW_FIELD_IPV6_TRAFFIC_CLASS: Type = 46;
    #[doc = "< ESP SPI."]
    pub const RTE_FLOW_FIELD_ESP_SPI: Type = 47;
    #[doc = "< ESP Sequence Number."]
    pub const RTE_FLOW_FIELD_ESP_SEQ_NUM: Type = 48;
    #[doc = "< ESP next protocol value."]
    pub const RTE_FLOW_FIELD_ESP_PROTO: Type = 49;
    #[doc = "< Random value."]
    pub const RTE_FLOW_FIELD_RANDOM: Type = 50;
    #[doc = "< VXLAN last reserved byte."]
    pub const RTE_FLOW_FIELD_VXLAN_LAST_RSVD: Type = 51;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nPacket header field descriptions, used by RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\nand RTE_FLOW_ITEM_TYPE_COMPARE."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_field_data {
    #[doc = "< Field or memory type ID."]
    pub field: rte_flow_field_id::Type,
    pub anon1: rte_flow_field_data__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_field_data__bindgen_ty_1 {
    pub anon1: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1,
    #[doc = "Immediate value for RTE_FLOW_FIELD_VALUE, presented in the\nsame byte order and length as in relevant rte_flow_item_xxx.\nThe immediate source bitfield offset is inherited from\nthe destination's one."]
    pub value: [u8; 16usize],
    #[doc = "Memory address for RTE_FLOW_FIELD_POINTER, memory layout\nshould be the same as for relevant field in the\nrte_flow_item_xxx structure."]
    pub pvalue: *mut ::core::ffi::c_void,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_field_data__bindgen_ty_1__bindgen_ty_1 {
    pub anon1: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    #[doc = "Number of bits to skip from a field."]
    pub offset: u32,
}
#[doc = "Encapsulation level and tag index or flex item handle."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    pub anon1: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    pub flex_handle: *mut rte_flow_item_flex_handle,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "Packet encapsulation level containing\nthe field to modify.\n- `0` requests the default behavior.\nDepending on the packet type, it\ncan mean outermost, innermost or\nanything in between.\nIt basically stands for the\ninnermost encapsulation level.\nModification can be performed\naccording to PMD and device\ncapabilities.\n- `1` requests modification to be\nperformed on the outermost packet\nencapsulation level.\n- `2` and subsequent values request\nmodification to be performed on\nthe specified inner packet\nencapsulation level, from\noutermost to innermost (lower to\nhigher values).\nValues other than `0` are not\nnecessarily supported.\n> **Note** that for MPLS field,\nencapsulation level also include\ntunnel since MPLS may appear in\nouter, inner or tunnel."]
    pub level: u8,
    pub anon1:
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { # [doc = "Tag index array inside\nencapsulation level.\nUsed for VLAN, MPLS or TAG types."] pub tag_index : u8 , pub anon1 : rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , }
#[doc = "Geneve option identifier.\nRelevant only for\nRTE_FLOW_FIELD_GENEVE_OPT_XXXX\nmodification type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    #[doc = "Geneve option type."]
    pub type_: u8,
    #[doc = "Geneve option class."]
    pub class_id: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: size_of :: < rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Alignment of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: core :: mem :: align_of :: < rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 2usize] ;
    ["Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::type_"] [:: core :: mem :: offset_of ! (rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , type_) - 0usize] ;
    ["Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::class_id"] [:: core :: mem :: offset_of ! (rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , class_id) - 2usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    [
        "Size of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1",
    ][::core::mem::size_of::<
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 4usize];
    [
        "Alignment of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1",
    ][::core::mem::align_of::<
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 2usize];
    [
        "Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::tag_index",
    ][::core::mem::offset_of!(
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        tag_index
    ) - 0usize];
};
impl Default
    for rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<
            rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 6usize];
    ["Alignment of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<
            rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 2usize];
    [
        "Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::level",
    ][::core::mem::offset_of!(
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        level
    ) - 0usize];
};
impl Default for rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"][::core::mem::size_of::<
        rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 8usize];
    ["Alignment of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1>()
            - 8usize];
    ["Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::flex_handle"]
        [::core::mem::offset_of!(
            rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
            flex_handle
        ) - 0usize];
};
impl Default for rte_flow_field_data__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_field_data__bindgen_ty_1__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_flow_field_data__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_field_data__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_flow_field_data__bindgen_ty_1__bindgen_ty_1::offset"]
        [::core::mem::offset_of!(rte_flow_field_data__bindgen_ty_1__bindgen_ty_1, offset) - 8usize];
};
impl Default for rte_flow_field_data__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_field_data__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_flow_field_data__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_field_data__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_flow_field_data__bindgen_ty_1::value"]
        [::core::mem::offset_of!(rte_flow_field_data__bindgen_ty_1, value) - 0usize];
    ["Offset of field: rte_flow_field_data__bindgen_ty_1::pvalue"]
        [::core::mem::offset_of!(rte_flow_field_data__bindgen_ty_1, pvalue) - 0usize];
};
impl Default for rte_flow_field_data__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_field_data"][::core::mem::size_of::<rte_flow_field_data>() - 24usize];
    ["Alignment of rte_flow_field_data"][::core::mem::align_of::<rte_flow_field_data>() - 8usize];
    ["Offset of field: rte_flow_field_data::field"]
        [::core::mem::offset_of!(rte_flow_field_data, field) - 0usize];
};
impl Default for rte_flow_field_data {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_item_compare_op {
    #[doc = "Expected operation types for compare item."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Compare result equal."]
    pub const RTE_FLOW_ITEM_COMPARE_EQ: Type = 0;
    #[doc = "Compare result not equal."]
    pub const RTE_FLOW_ITEM_COMPARE_NE: Type = 1;
    #[doc = "Compare result less than."]
    pub const RTE_FLOW_ITEM_COMPARE_LT: Type = 2;
    #[doc = "Compare result less than or equal."]
    pub const RTE_FLOW_ITEM_COMPARE_LE: Type = 3;
    #[doc = "Compare result great than."]
    pub const RTE_FLOW_ITEM_COMPARE_GT: Type = 4;
    #[doc = "Compare result great than or equal."]
    pub const RTE_FLOW_ITEM_COMPARE_GE: Type = 5;
}
#[doc = "RTE_FLOW_ITEM_TYPE_COMPARE\nMatches the packet with compare result.\nThe operation means a compare with b result."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_item_compare {
    #[doc = "The compare operation."]
    pub operation: rte_flow_item_compare_op::Type,
    #[doc = "Field be compared."]
    pub a: rte_flow_field_data,
    #[doc = "Field as comparator."]
    pub b: rte_flow_field_data,
    #[doc = "Compare width."]
    pub width: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_compare"][::core::mem::size_of::<rte_flow_item_compare>() - 64usize];
    ["Alignment of rte_flow_item_compare"]
        [::core::mem::align_of::<rte_flow_item_compare>() - 8usize];
    ["Offset of field: rte_flow_item_compare::operation"]
        [::core::mem::offset_of!(rte_flow_item_compare, operation) - 0usize];
    ["Offset of field: rte_flow_item_compare::a"]
        [::core::mem::offset_of!(rte_flow_item_compare, a) - 8usize];
    ["Offset of field: rte_flow_item_compare::b"]
        [::core::mem::offset_of!(rte_flow_item_compare, b) - 32usize];
    ["Offset of field: rte_flow_item_compare::width"]
        [::core::mem::offset_of!(rte_flow_item_compare, width) - 56usize];
};
impl Default for rte_flow_item_compare {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_action_type {
    #[doc = "Action types.\nEach possible action is represented by a type.\nAn action can have an associated configuration object.\nSeveral actions combined in a list can be assigned\nto a flow rule and are performed in order.\nThey fall in three categories:\n- Actions that modify the fate of matching traffic, for instance by\ndropping or assigning it a specific destination.\n- Actions that modify matching traffic contents or its properties. This\nincludes adding/removing encapsulation, encryption, compression and\nmarks.\n- Actions related to the flow rule itself, such as updating counters or\nmaking it non-terminating.\nFlow rules being terminating by default, not specifying any action of the\nfate kind results in undefined behavior. This applies to both ingress and\negress.\nPASSTHRU, when supported, makes a flow rule non-terminating."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "End marker for action lists. Prevents further processing of\nactions, thereby ending the list.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_END: Type = 0;
    #[doc = "Used as a placeholder for convenience. It is ignored and simply\ndiscarded by PMDs.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_VOID: Type = 1;
    #[doc = "Leaves traffic up for additional processing by subsequent flow\nrules; makes a flow rule non-terminating.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_PASSTHRU: Type = 2;
    #[doc = "RTE_FLOW_ACTION_TYPE_JUMP\nRedirects packets to a group on the current device.\nSee struct rte_flow_action_jump."]
    pub const RTE_FLOW_ACTION_TYPE_JUMP: Type = 3;
    #[doc = "Attaches an integer value to packets and sets RTE_MBUF_F_RX_FDIR and\nRTE_MBUF_F_RX_FDIR_ID mbuf flags.\nSee struct rte_flow_action_mark.\nOne should negotiate mark delivery from the NIC to the PMD.\n\n# See also\n\n> [`rte_eth_rx_metadata_negotiate()`]\n> [`RTE_ETH_RX_METADATA_USER_MARK`]"]
    pub const RTE_FLOW_ACTION_TYPE_MARK: Type = 4;
    #[doc = "Flags packets. Similar to MARK without a specific value; only\nsets the RTE_MBUF_F_RX_FDIR mbuf flag.\nNo associated configuration structure.\nOne should negotiate flag delivery from the NIC to the PMD.\n\n# See also\n\n> [`rte_eth_rx_metadata_negotiate()`]\n> [`RTE_ETH_RX_METADATA_USER_FLAG`]"]
    pub const RTE_FLOW_ACTION_TYPE_FLAG: Type = 5;
    #[doc = "Assigns packets to a given queue index.\nSee struct rte_flow_action_queue."]
    pub const RTE_FLOW_ACTION_TYPE_QUEUE: Type = 6;
    #[doc = "Drops packets.\nPASSTHRU overrides this action if both are specified.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_DROP: Type = 7;
    #[doc = "Enables counters for this flow rule.\nThese counters can be retrieved and reset through rte_flow_query() or\nrte_flow_action_handle_query() if the action provided via handle,\nsee struct rte_flow_query_count.\nSee struct rte_flow_action_count."]
    pub const RTE_FLOW_ACTION_TYPE_COUNT: Type = 8;
    #[doc = "Similar to QUEUE, except RSS is additionally performed on packets\nto spread them among several queues according to the provided\nparameters.\nSee struct rte_flow_action_rss."]
    pub const RTE_FLOW_ACTION_TYPE_RSS: Type = 9;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT`]\nDirects matching traffic to the physical function (PF) of the\ncurrent device.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_PF: Type = 10;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT`]\nDirects matching traffic to a given virtual function of the\ncurrent device.\nSee struct rte_flow_action_vf."]
    pub const RTE_FLOW_ACTION_TYPE_VF: Type = 11;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT`]\nDirects matching traffic to a given DPDK port ID.\nSee struct rte_flow_action_port_id."]
    pub const RTE_FLOW_ACTION_TYPE_PORT_ID: Type = 12;
    #[doc = "Traffic metering and policing (MTR).\nSee struct rte_flow_action_meter.\nSee file rte_mtr.h for MTR object configuration."]
    pub const RTE_FLOW_ACTION_TYPE_METER: Type = 13;
    #[doc = "Redirects packets to security engine of current device for security\nprocessing as specified by security session.\nSee struct rte_flow_action_security."]
    pub const RTE_FLOW_ACTION_TYPE_SECURITY: Type = 14;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nImplements OFPAT_DEC_NW_TTL (\"decrement IP TTL\") as defined by\nthe OpenFlow Switch Specification.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_OF_DEC_NW_TTL: Type = 15;
    #[doc = "Implements OFPAT_POP_VLAN (\"pop the outer VLAN tag\") as defined\nby the OpenFlow Switch Specification.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_OF_POP_VLAN: Type = 16;
    #[doc = "Implements OFPAT_PUSH_VLAN (\"push a new VLAN tag\") as defined by\nthe OpenFlow Switch Specification.\nSee struct rte_flow_action_of_push_vlan."]
    pub const RTE_FLOW_ACTION_TYPE_OF_PUSH_VLAN: Type = 17;
    #[doc = "Implements OFPAT_SET_VLAN_VID (\"set the 802.1q VLAN ID\") as\ndefined by the OpenFlow Switch Specification.\nSee struct rte_flow_action_of_set_vlan_vid."]
    pub const RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_VID: Type = 18;
    #[doc = "Implements OFPAT_SET_LAN_PCP (\"set the 802.1q priority\") as\ndefined by the OpenFlow Switch Specification.\nSee struct rte_flow_action_of_set_vlan_pcp."]
    pub const RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_PCP: Type = 19;
    #[doc = "Implements OFPAT_POP_MPLS (\"pop the outer MPLS tag\") as defined\nby the OpenFlow Switch Specification.\nSee struct rte_flow_action_of_pop_mpls."]
    pub const RTE_FLOW_ACTION_TYPE_OF_POP_MPLS: Type = 20;
    #[doc = "Implements OFPAT_PUSH_MPLS (\"push a new MPLS tag\") as defined by\nthe OpenFlow Switch Specification.\nSee struct rte_flow_action_of_push_mpls."]
    pub const RTE_FLOW_ACTION_TYPE_OF_PUSH_MPLS: Type = 21;
    #[doc = "Encapsulate flow in VXLAN tunnel as defined in\nrte_flow_action_vxlan_encap action structure.\nSee struct rte_flow_action_vxlan_encap."]
    pub const RTE_FLOW_ACTION_TYPE_VXLAN_ENCAP: Type = 22;
    #[doc = "Decapsulate outer most VXLAN tunnel from matched flow.\nIf flow pattern does not define a valid VXLAN tunnel (as specified by\nRFC7348) then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION\nerror."]
    pub const RTE_FLOW_ACTION_TYPE_VXLAN_DECAP: Type = 23;
    #[doc = "Encapsulate flow in NVGRE tunnel defined in the\nrte_flow_action_nvgre_encap action structure.\nSee struct rte_flow_action_nvgre_encap."]
    pub const RTE_FLOW_ACTION_TYPE_NVGRE_ENCAP: Type = 24;
    #[doc = "Decapsulate outer most NVGRE tunnel from matched flow.\nIf flow pattern does not define a valid NVGRE tunnel (as specified by\nRFC7637) then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION\nerror."]
    pub const RTE_FLOW_ACTION_TYPE_NVGRE_DECAP: Type = 25;
    #[doc = "Add outer header whose template is provided in its data buffer\nSee struct rte_flow_action_raw_encap."]
    pub const RTE_FLOW_ACTION_TYPE_RAW_ENCAP: Type = 26;
    #[doc = "Remove outer header whose template is provided in its data buffer.\nSee struct rte_flow_action_raw_decap"]
    pub const RTE_FLOW_ACTION_TYPE_RAW_DECAP: Type = 27;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv4 source address in the outermost IPv4 header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_ipv4."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV4_SRC: Type = 28;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv4 destination address in the outermost IPv4 header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_ipv4."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV4_DST: Type = 29;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv6 source address in the outermost IPv6 header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_ipv6."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV6_SRC: Type = 30;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv6 destination address in the outermost IPv6 header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_ipv6."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV6_DST: Type = 31;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify source port number in the outermost TCP/UDP header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_TCP\nor RTE_FLOW_ITEM_TYPE_UDP, then the PMD should return a\nRTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_tp."]
    pub const RTE_FLOW_ACTION_TYPE_SET_TP_SRC: Type = 32;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify destination port number in the outermost TCP/UDP header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_TCP\nor RTE_FLOW_ITEM_TYPE_UDP, then the PMD should return a\nRTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_tp."]
    pub const RTE_FLOW_ACTION_TYPE_SET_TP_DST: Type = 33;
    #[doc = "Swap the source and destination MAC addresses in the outermost\nEthernet header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_MAC_SWAP: Type = 34;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nDecrease TTL value directly\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_DEC_TTL: Type = 35;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nSet TTL value\nSee struct rte_flow_action_set_ttl"]
    pub const RTE_FLOW_ACTION_TYPE_SET_TTL: Type = 36;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nSet source MAC address from matched flow.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\nthe PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_mac."]
    pub const RTE_FLOW_ACTION_TYPE_SET_MAC_SRC: Type = 37;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nSet destination MAC address from matched flow.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\nthe PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_mac."]
    pub const RTE_FLOW_ACTION_TYPE_SET_MAC_DST: Type = 38;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nIncrease sequence number in the outermost TCP header.\nAction configuration specifies the value to increase\nTCP sequence number as a big-endian 32 bit integer.\n`conf` type:\n@code rte_be32_t * @endcode Using this action on non-matching traffic will result in\nundefined behavior."]
    pub const RTE_FLOW_ACTION_TYPE_INC_TCP_SEQ: Type = 39;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nDecrease sequence number in the outermost TCP header.\nAction configuration specifies the value to decrease\nTCP sequence number as a big-endian 32 bit integer.\n`conf` type:\n@code rte_be32_t * @endcode Using this action on non-matching traffic will result in\nundefined behavior."]
    pub const RTE_FLOW_ACTION_TYPE_DEC_TCP_SEQ: Type = 40;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nIncrease acknowledgment number in the outermost TCP header.\nAction configuration specifies the value to increase\nTCP acknowledgment number as a big-endian 32 bit integer.\n`conf` type:\n@code rte_be32_t * @endcode Using this action on non-matching traffic will result in\nundefined behavior."]
    pub const RTE_FLOW_ACTION_TYPE_INC_TCP_ACK: Type = 41;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nDecrease acknowledgment number in the outermost TCP header.\nAction configuration specifies the value to decrease\nTCP acknowledgment number as a big-endian 32 bit integer.\n`conf` type:\n@code rte_be32_t * @endcode Using this action on non-matching traffic will result in\nundefined behavior."]
    pub const RTE_FLOW_ACTION_TYPE_DEC_TCP_ACK: Type = 42;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nSet Tag.\nTag is for internal flow usage only and\nis not delivered to the application.\nSee struct rte_flow_action_set_tag."]
    pub const RTE_FLOW_ACTION_TYPE_SET_TAG: Type = 43;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nSet metadata on ingress or egress path.\nSee struct rte_flow_action_set_meta."]
    pub const RTE_FLOW_ACTION_TYPE_SET_META: Type = 44;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv4 DSCP in the outermost IP header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_dscp."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV4_DSCP: Type = 45;
    #[doc = "@warning This is a legacy action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_MODIFY_FIELD`]\nModify IPv6 DSCP in the outermost IP header.\nIf flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\nthen the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\nSee struct rte_flow_action_set_dscp."]
    pub const RTE_FLOW_ACTION_TYPE_SET_IPV6_DSCP: Type = 46;
    #[doc = "Report as aged flow if timeout passed without any matching on the\nflow.\nSee struct rte_flow_action_age.\nSee function rte_flow_get_q_aged_flows\nSee function rte_flow_get_aged_flows\nsee enum RTE_ETH_EVENT_FLOW_AGED\nSee struct rte_flow_query_age\nSee struct rte_flow_update_age"]
    pub const RTE_FLOW_ACTION_TYPE_AGE: Type = 47;
    #[doc = "The matching packets will be duplicated with specified ratio and\napplied with own set of actions with a fate action.\nSee struct rte_flow_action_sample."]
    pub const RTE_FLOW_ACTION_TYPE_SAMPLE: Type = 48;
    #[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_INDIRECT`]\nDescribe action shared across multiple flow rules.\nAllow multiple rules reference the same action by handle (see\nstruct rte_flow_shared_action)."]
    pub const RTE_FLOW_ACTION_TYPE_SHARED: Type = 49;
    #[doc = "Modify a packet header field, tag, mark or metadata.\nAllow the modification of an arbitrary header field via\nset, add and sub operations or copying its content into\ntag, meta or mark for future processing.\nSee struct rte_flow_action_modify_field."]
    pub const RTE_FLOW_ACTION_TYPE_MODIFY_FIELD: Type = 50;
    #[doc = "An action handle is referenced in a rule through an indirect action.\nThe same action handle may be used in multiple rules for the same\nor different ethdev ports."]
    pub const RTE_FLOW_ACTION_TYPE_INDIRECT: Type = 51;
    #[doc = "[META]\nEnable tracking a TCP connection state.\n\n# See also\n\n> [`struct`] rte_flow_action_conntrack."]
    pub const RTE_FLOW_ACTION_TYPE_CONNTRACK: Type = 52;
    #[doc = "Color the packet to reflect the meter color result.\nSet the meter color in the mbuf to the selected color.\nSee struct rte_flow_action_meter_color."]
    pub const RTE_FLOW_ACTION_TYPE_METER_COLOR: Type = 53;
    #[doc = "At embedded switch level, sends matching traffic to the given ethdev.\n\n# See also\n\n> [`struct`] rte_flow_action_ethdev"]
    pub const RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR: Type = 54;
    #[doc = "At embedded switch level, send matching traffic to\nthe entity represented by the given ethdev.\n\n# See also\n\n> [`struct`] rte_flow_action_ethdev"]
    pub const RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT: Type = 55;
    #[doc = "Traffic metering and marking (MTR).\n\n# See also\n\n> [`struct`] rte_flow_action_meter_mark\nSee file rte_mtr.h for MTR profile object configuration."]
    pub const RTE_FLOW_ACTION_TYPE_METER_MARK: Type = 56;
    #[doc = "Send packets to the kernel, without going to userspace at all.\nThe packets will be received by the kernel driver sharing\nthe same device as the DPDK port on which this action is configured.\nThis action mostly suits bifurcated driver model.\nNo associated configuration structure."]
    pub const RTE_FLOW_ACTION_TYPE_SEND_TO_KERNEL: Type = 57;
    #[doc = "Apply the quota verdict (PASS or BLOCK) to a flow.\n\n# See also\n\n> [`struct`] rte_flow_action_quota\n> [`struct`] rte_flow_query_quota\n> [`struct`] rte_flow_update_quota"]
    pub const RTE_FLOW_ACTION_TYPE_QUOTA: Type = 58;
    #[doc = "Skip congestion management configuration.\nUsing rte_eth_cman_config_set(), the application\ncan configure ethdev Rx queue's congestion mechanism.\nThis flow action allows to skip the congestion configuration\napplied to the given ethdev Rx queue."]
    pub const RTE_FLOW_ACTION_TYPE_SKIP_CMAN: Type = 59;
    #[doc = "RTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH\nPush IPv6 extension into IPv6 packet.\n\n# See also\n\n> [`struct`] rte_flow_action_ipv6_ext_push."]
    pub const RTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH: Type = 60;
    #[doc = "RTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE\nRemove IPv6 extension from IPv6 packet whose type\nis provided in its configuration buffer.\n\n# See also\n\n> [`struct`] rte_flow_action_ipv6_ext_remove."]
    pub const RTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE: Type = 61;
    #[doc = "Action handle to reference flow actions list.\n\n# See also\n\n> [`struct`] rte_flow_action_indirect_list"]
    pub const RTE_FLOW_ACTION_TYPE_INDIRECT_LIST: Type = 62;
    #[doc = "Program action. These actions are defined by the program currently\nloaded on the device. For example, these actions are applicable to\ndevices that can be programmed through the P4 language.\n\n# See also\n\n> [`struct`] rte_flow_action_prog."]
    pub const RTE_FLOW_ACTION_TYPE_PROG: Type = 63;
    #[doc = "NAT64 translation of IPv4/IPv6 headers.\n\n# See also\n\n> [`struct`] rte_flow_action_nat64"]
    pub const RTE_FLOW_ACTION_TYPE_NAT64: Type = 64;
    #[doc = "RTE_FLOW_ACTION_TYPE_JUMP_TO_TABLE_INDEX,\nRedirects packets to a particular index in a flow table.\n\n# See also\n\n> [`struct`] rte_flow_action_jump_to_table_index."]
    pub const RTE_FLOW_ACTION_TYPE_JUMP_TO_TABLE_INDEX: Type = 65;
}
pub mod rte_flow_quota_mode {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQUOTA operational mode.\n\n# See also\n\n> [`struct`] rte_flow_action_quota"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Count packets."]
    pub const RTE_FLOW_QUOTA_MODE_PACKET: Type = 1;
    #[doc = "< Count packet bytes starting from L2."]
    pub const RTE_FLOW_QUOTA_MODE_L2: Type = 2;
    #[doc = "< Count packet bytes starting from L3."]
    pub const RTE_FLOW_QUOTA_MODE_L3: Type = 3;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate QUOTA action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_QUOTA`]"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_quota {
    #[doc = "< Quota operational mode."]
    pub mode: rte_flow_quota_mode::Type,
    #[doc = "< Quota value."]
    pub quota: i64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_quota"][::core::mem::size_of::<rte_flow_action_quota>() - 16usize];
    ["Alignment of rte_flow_action_quota"]
        [::core::mem::align_of::<rte_flow_action_quota>() - 8usize];
    ["Offset of field: rte_flow_action_quota::mode"]
        [::core::mem::offset_of!(rte_flow_action_quota, mode) - 0usize];
    ["Offset of field: rte_flow_action_quota::quota"]
        [::core::mem::offset_of!(rte_flow_action_quota, quota) - 8usize];
};
impl Default for rte_flow_action_quota {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery indirect QUOTA action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_QUOTA`]"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_query_quota {
    #[doc = "< Quota value."]
    pub quota: i64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_query_quota"][::core::mem::size_of::<rte_flow_query_quota>() - 8usize];
    ["Alignment of rte_flow_query_quota"][::core::mem::align_of::<rte_flow_query_quota>() - 8usize];
    ["Offset of field: rte_flow_query_quota::quota"]
        [::core::mem::offset_of!(rte_flow_query_quota, quota) - 0usize];
};
pub mod rte_flow_update_quota_op {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nIndirect QUOTA update operations.\n\n# See also\n\n> [`struct`] rte_flow_update_quota"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Set new quota value."]
    pub const RTE_FLOW_UPDATE_QUOTA_SET: Type = 0;
    #[doc = "< Increase quota value."]
    pub const RTE_FLOW_UPDATE_QUOTA_ADD: Type = 1;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_QUOTA`]\nUpdate indirect QUOTA action."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_update_quota {
    #[doc = "< Update operation."]
    pub op: rte_flow_update_quota_op::Type,
    #[doc = "< Quota value."]
    pub quota: i64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_update_quota"][::core::mem::size_of::<rte_flow_update_quota>() - 16usize];
    ["Alignment of rte_flow_update_quota"]
        [::core::mem::align_of::<rte_flow_update_quota>() - 8usize];
    ["Offset of field: rte_flow_update_quota::op"]
        [::core::mem::offset_of!(rte_flow_update_quota, op) - 0usize];
    ["Offset of field: rte_flow_update_quota::quota"]
        [::core::mem::offset_of!(rte_flow_update_quota, quota) - 8usize];
};
impl Default for rte_flow_update_quota {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_MARK\nAttaches an integer value to packets and sets RTE_MBUF_F_RX_FDIR and\nRTE_MBUF_F_RX_FDIR_ID mbuf flags.\nThis value is arbitrary and application-defined. Maximum allowed value\ndepends on the underlying implementation. It is returned in the\nhash.fdir.hi mbuf field."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_mark {
    #[doc = "< Integer value to return with packets."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_mark"][::core::mem::size_of::<rte_flow_action_mark>() - 4usize];
    ["Alignment of rte_flow_action_mark"][::core::mem::align_of::<rte_flow_action_mark>() - 4usize];
    ["Offset of field: rte_flow_action_mark::id"]
        [::core::mem::offset_of!(rte_flow_action_mark, id) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_JUMP\nRedirects packets to a group on the current device.\nIn a hierarchy of groups, which can be used to represent physical or logical\nflow tables on the device, this action allows the action to be a redirect to\na group on that device."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_jump {
    pub group: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_jump"][::core::mem::size_of::<rte_flow_action_jump>() - 4usize];
    ["Alignment of rte_flow_action_jump"][::core::mem::align_of::<rte_flow_action_jump>() - 4usize];
    ["Offset of field: rte_flow_action_jump::group"]
        [::core::mem::offset_of!(rte_flow_action_jump, group) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_QUEUE\nAssign packets to a given queue index."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_queue {
    #[doc = "< Queue index to use."]
    pub index: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_queue"][::core::mem::size_of::<rte_flow_action_queue>() - 2usize];
    ["Alignment of rte_flow_action_queue"]
        [::core::mem::align_of::<rte_flow_action_queue>() - 2usize];
    ["Offset of field: rte_flow_action_queue::index"]
        [::core::mem::offset_of!(rte_flow_action_queue, index) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_AGE\nReport flow as aged-out if timeout passed without any matching\non the flow. RTE_ETH_EVENT_FLOW_AGED event is triggered when a\nport detects new aged-out flows.\nThe flow context and the flow handle will be reported by the either\nrte_flow_get_aged_flows or rte_flow_get_q_aged_flows APIs."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_age {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "The user flow context, NULL means the rte_flow pointer."]
    pub context: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_age"][::core::mem::size_of::<rte_flow_action_age>() - 16usize];
    ["Alignment of rte_flow_action_age"][::core::mem::align_of::<rte_flow_action_age>() - 8usize];
    ["Offset of field: rte_flow_action_age::context"]
        [::core::mem::offset_of!(rte_flow_action_age, context) - 8usize];
};
impl Default for rte_flow_action_age {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_action_age {
    #[inline]
    pub fn timeout(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 24u8) as u32) }
    }
    #[inline]
    pub fn set_timeout(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 24u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn timeout_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                24u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_timeout_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                24u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(24usize, 8u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(24usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                8u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(timeout: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 24u8, {
            let timeout: u32 = unsafe { ::core::mem::transmute(timeout) };
            timeout as u64
        });
        __bindgen_bitfield_unit.set(24usize, 8u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_AGE (query)\nQuery structure to retrieve the aging status information of a\nshared AGE action, or a flow rule using the AGE action."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_query_age {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_query_age"][::core::mem::size_of::<rte_flow_query_age>() - 4usize];
    ["Alignment of rte_flow_query_age"][::core::mem::align_of::<rte_flow_query_age>() - 4usize];
};
impl rte_flow_query_age {
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 6u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                6u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn aged(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_aged(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn aged_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_aged_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn sec_since_last_hit_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_sec_since_last_hit_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sec_since_last_hit_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_sec_since_last_hit_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn sec_since_last_hit(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 24u8) as u32) }
    }
    #[inline]
    pub fn set_sec_since_last_hit(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 24u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sec_since_last_hit_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                24u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_sec_since_last_hit_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                24u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        reserved: u32,
        aged: u32,
        sec_since_last_hit_valid: u32,
        sec_since_last_hit: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 6u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let aged: u32 = unsafe { ::core::mem::transmute(aged) };
            aged as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let sec_since_last_hit_valid: u32 =
                unsafe { ::core::mem::transmute(sec_since_last_hit_valid) };
            sec_since_last_hit_valid as u64
        });
        __bindgen_bitfield_unit.set(8usize, 24u8, {
            let sec_since_last_hit: u32 = unsafe { ::core::mem::transmute(sec_since_last_hit) };
            sec_since_last_hit as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_AGE\nUpdate indirect AGE action attributes:\n- Timeout can be updated including stop/start action:\n+-------------+-------------+------------------------------+\n| Old Timeout | New Timeout | Updating                     |\n+=============+=============+==============================+\n| 0           | positive    | Start aging with new value   |\n+-------------+-------------+------------------------------+\n| positive    | 0           | Stop aging\t\t\t  |\n+-------------+-------------+------------------------------+\n| positive    | positive    | Change timeout to new value  |\n+-------------+-------------+------------------------------+\n- sec_since_last_hit can be reset."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_update_age {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_update_age"][::core::mem::size_of::<rte_flow_update_age>() - 4usize];
    ["Alignment of rte_flow_update_age"][::core::mem::align_of::<rte_flow_update_age>() - 4usize];
};
impl rte_flow_update_age {
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 6u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                6u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn timeout_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_timeout_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn timeout_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_timeout_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn timeout(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 24u8) as u32) }
    }
    #[inline]
    pub fn set_timeout(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 24u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn timeout_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                24u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_timeout_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                24u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn touch(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(31usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_touch(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(31usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn touch_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                31usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_touch_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                31usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        reserved: u32,
        timeout_valid: u32,
        timeout: u32,
        touch: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 6u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let timeout_valid: u32 = unsafe { ::core::mem::transmute(timeout_valid) };
            timeout_valid as u64
        });
        __bindgen_bitfield_unit.set(7usize, 24u8, {
            let timeout: u32 = unsafe { ::core::mem::transmute(timeout) };
            timeout as u64
        });
        __bindgen_bitfield_unit.set(31usize, 1u8, {
            let touch: u32 = unsafe { ::core::mem::transmute(touch) };
            touch as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_COUNT\nAdds a counter action to a matched flow.\nIf more than one count action is specified in a single flow rule, then each\naction must specify a unique ID.\nCounters can be retrieved and reset through ``rte_flow_query()``, see\n``struct rte_flow_query_count``.\nFor ports within the same switch domain then the counter ID namespace extends\nto all ports within that switch domain."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_count {
    #[doc = "< Counter ID."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_count"][::core::mem::size_of::<rte_flow_action_count>() - 4usize];
    ["Alignment of rte_flow_action_count"]
        [::core::mem::align_of::<rte_flow_action_count>() - 4usize];
    ["Offset of field: rte_flow_action_count::id"]
        [::core::mem::offset_of!(rte_flow_action_count, id) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_COUNT (query)\nQuery structure to retrieve and reset flow rule counters."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_query_count {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "< Number of hits for this rule [out]."]
    pub hits: u64,
    #[doc = "< Number of bytes through this rule [out]."]
    pub bytes: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_query_count"][::core::mem::size_of::<rte_flow_query_count>() - 24usize];
    ["Alignment of rte_flow_query_count"][::core::mem::align_of::<rte_flow_query_count>() - 8usize];
    ["Offset of field: rte_flow_query_count::hits"]
        [::core::mem::offset_of!(rte_flow_query_count, hits) - 8usize];
    ["Offset of field: rte_flow_query_count::bytes"]
        [::core::mem::offset_of!(rte_flow_query_count, bytes) - 16usize];
};
impl rte_flow_query_count {
    #[inline]
    pub fn reset(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_reset(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reset_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reset_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hits_set(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_hits_set(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hits_set_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_hits_set_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn bytes_set(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_bytes_set(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn bytes_set_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_bytes_set_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 29u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 29u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                29u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                29u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        reset: u32,
        hits_set: u32,
        bytes_set: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let reset: u32 = unsafe { ::core::mem::transmute(reset) };
            reset as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let hits_set: u32 = unsafe { ::core::mem::transmute(hits_set) };
            hits_set as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let bytes_set: u32 = unsafe { ::core::mem::transmute(bytes_set) };
            bytes_set as u64
        });
        __bindgen_bitfield_unit.set(3usize, 29u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_RSS\nSimilar to QUEUE, except RSS is additionally performed on packets to\nspread them among several queues according to the provided parameters.\nUnlike global RSS settings used by other DPDK APIs, unsetting the\n`types` field does not disable RSS in a flow rule. Doing so instead\nrequests safe unspecified \"best-effort\" settings from the underlying PMD,\nwhich depending on the flow rule, may result in anything ranging from\nempty (single queue) to all-inclusive RSS.\nNote: RSS hash result is stored in the hash.rss mbuf field which overlaps\nhash.fdir.lo. Since the MARK action sets the hash.fdir.hi field only,\nboth can be requested simultaneously."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_rss {
    #[doc = "< RSS hash function to apply."]
    pub func: rte_eth_hash_function::Type,
    #[doc = "Packet encapsulation level RSS hash `types` apply to.\n- `0` requests the default behavior. Depending on the packet\ntype, it can mean outermost, innermost, anything in between or\neven no RSS.\nIt basically stands for the innermost encapsulation level RSS\ncan be performed on according to PMD and device capabilities.\n- `1` requests RSS to be performed on the outermost packet\nencapsulation level.\n- `2` and subsequent values request RSS to be performed on the\nspecified inner packet encapsulation level, from outermost to\ninnermost (lower to higher values).\nValues other than `0` are not necessarily supported.\nRequesting a specific RSS level on unrecognized traffic results\nin undefined behavior. For predictable results, it is recommended\nto make the flow rule pattern match packet headers up to the\nrequested encapsulation level so that only matching traffic goes\nthrough."]
    pub level: u32,
    #[doc = "< Specific RSS hash types (see RTE_ETH_RSS_*)."]
    pub types: u64,
    #[doc = "< Hash key length in bytes."]
    pub key_len: u32,
    #[doc = "< Number of entries in `queue.`"]
    pub queue_num: u32,
    #[doc = "< Hash key."]
    pub key: *const u8,
    #[doc = "< Queue indices to use."]
    pub queue: *const u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_rss"][::core::mem::size_of::<rte_flow_action_rss>() - 40usize];
    ["Alignment of rte_flow_action_rss"][::core::mem::align_of::<rte_flow_action_rss>() - 8usize];
    ["Offset of field: rte_flow_action_rss::func"]
        [::core::mem::offset_of!(rte_flow_action_rss, func) - 0usize];
    ["Offset of field: rte_flow_action_rss::level"]
        [::core::mem::offset_of!(rte_flow_action_rss, level) - 4usize];
    ["Offset of field: rte_flow_action_rss::types"]
        [::core::mem::offset_of!(rte_flow_action_rss, types) - 8usize];
    ["Offset of field: rte_flow_action_rss::key_len"]
        [::core::mem::offset_of!(rte_flow_action_rss, key_len) - 16usize];
    ["Offset of field: rte_flow_action_rss::queue_num"]
        [::core::mem::offset_of!(rte_flow_action_rss, queue_num) - 20usize];
    ["Offset of field: rte_flow_action_rss::key"]
        [::core::mem::offset_of!(rte_flow_action_rss, key) - 24usize];
    ["Offset of field: rte_flow_action_rss::queue"]
        [::core::mem::offset_of!(rte_flow_action_rss, queue) - 32usize];
};
impl Default for rte_flow_action_rss {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT`]\nRTE_FLOW_ACTION_TYPE_VF\nDirects matching traffic to a given virtual function of the current\ndevice.\nPackets matched by a VF pattern item can be redirected to their original\nVF ID instead of the specified one. This parameter may not be available\nand is not guaranteed to work properly if the VF part is matched by a\nprior flow rule or if packets are not addressed to a VF in the first\nplace."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_vf {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "< VF ID."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_vf"][::core::mem::size_of::<rte_flow_action_vf>() - 8usize];
    ["Alignment of rte_flow_action_vf"][::core::mem::align_of::<rte_flow_action_vf>() - 4usize];
    ["Offset of field: rte_flow_action_vf::id"]
        [::core::mem::offset_of!(rte_flow_action_vf, id) - 4usize];
};
impl rte_flow_action_vf {
    #[inline]
    pub fn original(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_original(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn original_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_original_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 31u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 31u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                31u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                31u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(original: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let original: u32 = unsafe { ::core::mem::transmute(original) };
            original as u64
        });
        __bindgen_bitfield_unit.set(1usize, 31u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "> **Deprecated** # See also\n\n> [`RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR`]\n> [`RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT`]\nRTE_FLOW_ACTION_TYPE_PORT_ID\nDirects matching traffic to a given DPDK port ID.\n> [`RTE_FLOW_ITEM_TYPE_PORT_ID`]"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_port_id {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    #[doc = "< DPDK port ID."]
    pub id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_port_id"][::core::mem::size_of::<rte_flow_action_port_id>() - 8usize];
    ["Alignment of rte_flow_action_port_id"]
        [::core::mem::align_of::<rte_flow_action_port_id>() - 4usize];
    ["Offset of field: rte_flow_action_port_id::id"]
        [::core::mem::offset_of!(rte_flow_action_port_id, id) - 4usize];
};
impl rte_flow_action_port_id {
    #[inline]
    pub fn original(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_original(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn original_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_original_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 31u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 31u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                31u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                31u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(original: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let original: u32 = unsafe { ::core::mem::transmute(original) };
            original as u64
        });
        __bindgen_bitfield_unit.set(1usize, 31u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_METER\nTraffic metering and policing (MTR).\nPackets matched by items of this type can be either dropped or passed to the\nnext item with their color set by the MTR object."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_meter {
    #[doc = "< MTR object ID created with rte_mtr_create()."]
    pub mtr_id: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_meter"][::core::mem::size_of::<rte_flow_action_meter>() - 4usize];
    ["Alignment of rte_flow_action_meter"]
        [::core::mem::align_of::<rte_flow_action_meter>() - 4usize];
    ["Offset of field: rte_flow_action_meter::mtr_id"]
        [::core::mem::offset_of!(rte_flow_action_meter, mtr_id) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_SECURITY\nPerform the security action on flows matched by the pattern items\naccording to the configuration of the security session.\nThis action modifies the payload of matched flows. For INLINE_CRYPTO, the\nsecurity protocol headers and IV are fully provided by the application as\nspecified in the flow pattern. The payload of matching packets is\nencrypted on egress, and decrypted and authenticated on ingress.\nFor INLINE_PROTOCOL, the security protocol is fully offloaded to HW,\nproviding full encapsulation and decapsulation of packets in security\nprotocols. The flow pattern specifies both the outer security header fields\nand the inner packet fields. The security session specified in the action\nmust match the pattern parameters.\nThe security session specified in the action must be created on the same\nport as the flow action that is being specified.\nThe ingress/egress flow attribute should match that specified in the\nsecurity session if the security session supports the definition of the\ndirection.\nMultiple flows can be configured to use the same security session.\nThe NULL value is allowed for security session. If security session is NULL,\nthen SPI field in ESP flow item and IP addresses in flow items 'IPv4' and\n'IPv6' will be allowed to be a range. The rule thus created can enable\nsecurity processing on multiple flows."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_security {
    #[doc = "< Pointer to security session structure."]
    pub security_session: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_security"]
        [::core::mem::size_of::<rte_flow_action_security>() - 8usize];
    ["Alignment of rte_flow_action_security"]
        [::core::mem::align_of::<rte_flow_action_security>() - 8usize];
    ["Offset of field: rte_flow_action_security::security_session"]
        [::core::mem::offset_of!(rte_flow_action_security, security_session) - 0usize];
};
impl Default for rte_flow_action_security {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_nat64_type {
    #[doc = "NAT64 translation type for IP headers."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< IPv6 to IPv4 headers translation."]
    pub const RTE_FLOW_NAT64_6TO4: Type = 0;
    #[doc = "< IPv4 to IPv6 headers translation."]
    pub const RTE_FLOW_NAT64_4TO6: Type = 1;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ACTION_TYPE_NAT64\nSpecify the NAT64 translation type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_nat64 {
    pub type_: rte_flow_nat64_type::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_nat64"][::core::mem::size_of::<rte_flow_action_nat64>() - 4usize];
    ["Alignment of rte_flow_action_nat64"]
        [::core::mem::align_of::<rte_flow_action_nat64>() - 4usize];
    ["Offset of field: rte_flow_action_nat64::type_"]
        [::core::mem::offset_of!(rte_flow_action_nat64, type_) - 0usize];
};
impl Default for rte_flow_action_nat64 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_OF_PUSH_VLAN\nImplements OFPAT_PUSH_VLAN (\"push a new VLAN tag\") as defined by the\nOpenFlow Switch Specification."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_of_push_vlan {
    #[doc = "< EtherType."]
    pub ethertype: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_of_push_vlan"]
        [::core::mem::size_of::<rte_flow_action_of_push_vlan>() - 2usize];
    ["Alignment of rte_flow_action_of_push_vlan"]
        [::core::mem::align_of::<rte_flow_action_of_push_vlan>() - 2usize];
    ["Offset of field: rte_flow_action_of_push_vlan::ethertype"]
        [::core::mem::offset_of!(rte_flow_action_of_push_vlan, ethertype) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_VID\nImplements OFPAT_SET_VLAN_VID (\"set the 802.1q VLAN ID\") as defined by\nthe OpenFlow Switch Specification."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_of_set_vlan_vid {
    #[doc = "< VLAN ID."]
    pub vlan_vid: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_of_set_vlan_vid"]
        [::core::mem::size_of::<rte_flow_action_of_set_vlan_vid>() - 2usize];
    ["Alignment of rte_flow_action_of_set_vlan_vid"]
        [::core::mem::align_of::<rte_flow_action_of_set_vlan_vid>() - 2usize];
    ["Offset of field: rte_flow_action_of_set_vlan_vid::vlan_vid"]
        [::core::mem::offset_of!(rte_flow_action_of_set_vlan_vid, vlan_vid) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_PCP\nImplements OFPAT_SET_LAN_PCP (\"set the 802.1q priority\") as defined by\nthe OpenFlow Switch Specification."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_of_set_vlan_pcp {
    #[doc = "< VLAN priority."]
    pub vlan_pcp: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_of_set_vlan_pcp"]
        [::core::mem::size_of::<rte_flow_action_of_set_vlan_pcp>() - 1usize];
    ["Alignment of rte_flow_action_of_set_vlan_pcp"]
        [::core::mem::align_of::<rte_flow_action_of_set_vlan_pcp>() - 1usize];
    ["Offset of field: rte_flow_action_of_set_vlan_pcp::vlan_pcp"]
        [::core::mem::offset_of!(rte_flow_action_of_set_vlan_pcp, vlan_pcp) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_OF_POP_MPLS\nImplements OFPAT_POP_MPLS (\"pop the outer MPLS tag\") as defined by the\nOpenFlow Switch Specification."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_of_pop_mpls {
    #[doc = "< EtherType."]
    pub ethertype: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_of_pop_mpls"]
        [::core::mem::size_of::<rte_flow_action_of_pop_mpls>() - 2usize];
    ["Alignment of rte_flow_action_of_pop_mpls"]
        [::core::mem::align_of::<rte_flow_action_of_pop_mpls>() - 2usize];
    ["Offset of field: rte_flow_action_of_pop_mpls::ethertype"]
        [::core::mem::offset_of!(rte_flow_action_of_pop_mpls, ethertype) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_OF_PUSH_MPLS\nImplements OFPAT_PUSH_MPLS (\"push a new MPLS tag\") as defined by the\nOpenFlow Switch Specification."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_of_push_mpls {
    #[doc = "< EtherType."]
    pub ethertype: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_of_push_mpls"]
        [::core::mem::size_of::<rte_flow_action_of_push_mpls>() - 2usize];
    ["Alignment of rte_flow_action_of_push_mpls"]
        [::core::mem::align_of::<rte_flow_action_of_push_mpls>() - 2usize];
    ["Offset of field: rte_flow_action_of_push_mpls::ethertype"]
        [::core::mem::offset_of!(rte_flow_action_of_push_mpls, ethertype) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_VXLAN_ENCAP\nVXLAN tunnel end-point encapsulation data definition\nThe tunnel definition is provided through the flow item pattern, the\nprovided pattern must conform to RFC7348 for the tunnel specified. The flow\ndefinition must be provided in order from the RTE_FLOW_ITEM_TYPE_ETH\ndefinition up the end item which is specified by RTE_FLOW_ITEM_TYPE_END.\nThe mask field allows user to specify which fields in the flow item\ndefinitions can be ignored and which have valid data and can be used\nverbatim.\nNote: the last field is not used in the definition of a tunnel and can be\nignored.\nValid flow definition for RTE_FLOW_ACTION_TYPE_VXLAN_ENCAP include:\n- ETH / IPV4 / UDP / VXLAN / END\n- ETH / IPV6 / UDP / VXLAN / END\n- ETH / VLAN / IPV4 / UDP / VXLAN / END"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_vxlan_encap {
    #[doc = "Encapsulating vxlan tunnel definition\n(terminated by the END pattern item)."]
    pub definition: *mut rte_flow_item,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_vxlan_encap"]
        [::core::mem::size_of::<rte_flow_action_vxlan_encap>() - 8usize];
    ["Alignment of rte_flow_action_vxlan_encap"]
        [::core::mem::align_of::<rte_flow_action_vxlan_encap>() - 8usize];
    ["Offset of field: rte_flow_action_vxlan_encap::definition"]
        [::core::mem::offset_of!(rte_flow_action_vxlan_encap, definition) - 0usize];
};
impl Default for rte_flow_action_vxlan_encap {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_NVGRE_ENCAP\nNVGRE tunnel end-point encapsulation data definition\nThe tunnel definition is provided through the flow item pattern  the\nprovided pattern must conform with RFC7637. The flow definition must be\nprovided in order from the RTE_FLOW_ITEM_TYPE_ETH definition up the end item\nwhich is specified by RTE_FLOW_ITEM_TYPE_END.\nThe mask field allows user to specify which fields in the flow item\ndefinitions can be ignored and which have valid data and can be used\nverbatim.\nNote: the last field is not used in the definition of a tunnel and can be\nignored.\nValid flow definition for RTE_FLOW_ACTION_TYPE_NVGRE_ENCAP include:\n- ETH / IPV4 / NVGRE / END\n- ETH / VLAN / IPV6 / NVGRE / END"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_nvgre_encap {
    #[doc = "Encapsulating nvgre tunnel definition\n(terminated by the END pattern item)."]
    pub definition: *mut rte_flow_item,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_nvgre_encap"]
        [::core::mem::size_of::<rte_flow_action_nvgre_encap>() - 8usize];
    ["Alignment of rte_flow_action_nvgre_encap"]
        [::core::mem::align_of::<rte_flow_action_nvgre_encap>() - 8usize];
    ["Offset of field: rte_flow_action_nvgre_encap::definition"]
        [::core::mem::offset_of!(rte_flow_action_nvgre_encap, definition) - 0usize];
};
impl Default for rte_flow_action_nvgre_encap {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_RAW_ENCAP\nRaw tunnel end-point encapsulation data definition.\nThe data holds the headers definitions to be applied on the packet.\nThe data must start with ETH header up to the tunnel item header itself.\nWhen used right after RAW_DECAP (for decapsulating L3 tunnel type for\nexample MPLSoGRE) the data will just hold layer 2 header.\nThe preserve parameter holds which bits in the packet the PMD is not allowed\nto change, this parameter can also be NULL and then the PMD is allowed\nto update any field.\nsize holds the number of bytes in `data` and `preserve.`"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_raw_encap {
    #[doc = "< Encapsulation data."]
    pub data: *mut u8,
    #[doc = "< Bit-mask of `data` to preserve on output."]
    pub preserve: *mut u8,
    #[doc = "< Size of `data` and `preserve.`"]
    pub size: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_raw_encap"]
        [::core::mem::size_of::<rte_flow_action_raw_encap>() - 24usize];
    ["Alignment of rte_flow_action_raw_encap"]
        [::core::mem::align_of::<rte_flow_action_raw_encap>() - 8usize];
    ["Offset of field: rte_flow_action_raw_encap::data"]
        [::core::mem::offset_of!(rte_flow_action_raw_encap, data) - 0usize];
    ["Offset of field: rte_flow_action_raw_encap::preserve"]
        [::core::mem::offset_of!(rte_flow_action_raw_encap, preserve) - 8usize];
    ["Offset of field: rte_flow_action_raw_encap::size"]
        [::core::mem::offset_of!(rte_flow_action_raw_encap, size) - 16usize];
};
impl Default for rte_flow_action_raw_encap {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_RAW_DECAP\nRaw tunnel end-point decapsulation data definition.\nThe data holds the headers definitions to be removed from the packet.\nThe data must start with ETH header up to the tunnel item header itself.\nWhen used right before RAW_DECAP (for encapsulating L3 tunnel type for\nexample MPLSoGRE) the data will just hold layer 2 header.\nsize holds the number of bytes in `data.`"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_raw_decap {
    #[doc = "< Encapsulation data."]
    pub data: *mut u8,
    #[doc = "< Size of `data` and `preserve.`"]
    pub size: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_raw_decap"]
        [::core::mem::size_of::<rte_flow_action_raw_decap>() - 16usize];
    ["Alignment of rte_flow_action_raw_decap"]
        [::core::mem::align_of::<rte_flow_action_raw_decap>() - 8usize];
    ["Offset of field: rte_flow_action_raw_decap::data"]
        [::core::mem::offset_of!(rte_flow_action_raw_decap, data) - 0usize];
    ["Offset of field: rte_flow_action_raw_decap::size"]
        [::core::mem::offset_of!(rte_flow_action_raw_decap, size) - 8usize];
};
impl Default for rte_flow_action_raw_decap {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SET_IPV4_SRC\nRTE_FLOW_ACTION_TYPE_SET_IPV4_DST\nAllows modification of IPv4 source (RTE_FLOW_ACTION_TYPE_SET_IPV4_SRC)\nand destination address (RTE_FLOW_ACTION_TYPE_SET_IPV4_DST) in the\nspecified outermost IPv4 header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_ipv4 {
    pub ipv4_addr: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_ipv4"]
        [::core::mem::size_of::<rte_flow_action_set_ipv4>() - 4usize];
    ["Alignment of rte_flow_action_set_ipv4"]
        [::core::mem::align_of::<rte_flow_action_set_ipv4>() - 4usize];
    ["Offset of field: rte_flow_action_set_ipv4::ipv4_addr"]
        [::core::mem::offset_of!(rte_flow_action_set_ipv4, ipv4_addr) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SET_IPV6_SRC\nRTE_FLOW_ACTION_TYPE_SET_IPV6_DST\nAllows modification of IPv6 source (RTE_FLOW_ACTION_TYPE_SET_IPV6_SRC)\nand destination address (RTE_FLOW_ACTION_TYPE_SET_IPV6_DST) in the\nspecified outermost IPv6 header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_ipv6 {
    pub ipv6_addr: rte_ipv6_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_ipv6"]
        [::core::mem::size_of::<rte_flow_action_set_ipv6>() - 16usize];
    ["Alignment of rte_flow_action_set_ipv6"]
        [::core::mem::align_of::<rte_flow_action_set_ipv6>() - 1usize];
    ["Offset of field: rte_flow_action_set_ipv6::ipv6_addr"]
        [::core::mem::offset_of!(rte_flow_action_set_ipv6, ipv6_addr) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH\nValid flow definition for RTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH include:\n- IPV6_EXT TYPE / IPV6_EXT_HEADER_IN_TYPE / END\nThe data must be added as the last IPv6 extension."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_ipv6_ext_push {
    #[doc = "< IPv6 extension header data."]
    pub data: *mut u8,
    #[doc = "< Size (in bytes) of `data.`"]
    pub size: usize,
    #[doc = "< Type of IPv6 extension."]
    pub type_: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_ipv6_ext_push"]
        [::core::mem::size_of::<rte_flow_action_ipv6_ext_push>() - 24usize];
    ["Alignment of rte_flow_action_ipv6_ext_push"]
        [::core::mem::align_of::<rte_flow_action_ipv6_ext_push>() - 8usize];
    ["Offset of field: rte_flow_action_ipv6_ext_push::data"]
        [::core::mem::offset_of!(rte_flow_action_ipv6_ext_push, data) - 0usize];
    ["Offset of field: rte_flow_action_ipv6_ext_push::size"]
        [::core::mem::offset_of!(rte_flow_action_ipv6_ext_push, size) - 8usize];
    ["Offset of field: rte_flow_action_ipv6_ext_push::type_"]
        [::core::mem::offset_of!(rte_flow_action_ipv6_ext_push, type_) - 16usize];
};
impl Default for rte_flow_action_ipv6_ext_push {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE\nValid flow definition for RTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE include:\n- IPV6_EXT TYPE / END"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_ipv6_ext_remove {
    #[doc = "< Type of IPv6 extension."]
    pub type_: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_ipv6_ext_remove"]
        [::core::mem::size_of::<rte_flow_action_ipv6_ext_remove>() - 1usize];
    ["Alignment of rte_flow_action_ipv6_ext_remove"]
        [::core::mem::align_of::<rte_flow_action_ipv6_ext_remove>() - 1usize];
    ["Offset of field: rte_flow_action_ipv6_ext_remove::type_"]
        [::core::mem::offset_of!(rte_flow_action_ipv6_ext_remove, type_) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SET_TP_SRC\nRTE_FLOW_ACTION_TYPE_SET_TP_DST\nAllows modification of source (RTE_FLOW_ACTION_TYPE_SET_TP_SRC)\nand destination (RTE_FLOW_ACTION_TYPE_SET_TP_DST) port numbers\nin the specified outermost TCP/UDP header."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_tp {
    pub port: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_tp"][::core::mem::size_of::<rte_flow_action_set_tp>() - 2usize];
    ["Alignment of rte_flow_action_set_tp"]
        [::core::mem::align_of::<rte_flow_action_set_tp>() - 2usize];
    ["Offset of field: rte_flow_action_set_tp::port"]
        [::core::mem::offset_of!(rte_flow_action_set_tp, port) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_SET_TTL\nSet the TTL value directly for IPv4 or IPv6"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_ttl {
    pub ttl_value: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_ttl"][::core::mem::size_of::<rte_flow_action_set_ttl>() - 1usize];
    ["Alignment of rte_flow_action_set_ttl"]
        [::core::mem::align_of::<rte_flow_action_set_ttl>() - 1usize];
    ["Offset of field: rte_flow_action_set_ttl::ttl_value"]
        [::core::mem::offset_of!(rte_flow_action_set_ttl, ttl_value) - 0usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_SET_MAC\nSet MAC address from the matched flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_mac {
    pub mac_addr: [u8; 6usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_mac"][::core::mem::size_of::<rte_flow_action_set_mac>() - 6usize];
    ["Alignment of rte_flow_action_set_mac"]
        [::core::mem::align_of::<rte_flow_action_set_mac>() - 1usize];
    ["Offset of field: rte_flow_action_set_mac::mac_addr"]
        [::core::mem::offset_of!(rte_flow_action_set_mac, mac_addr) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SET_TAG\nSet a tag which is a transient data used during flow matching. This is not\ndelivered to application. Multiple tags are supported by specifying index."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_tag {
    pub data: u32,
    pub mask: u32,
    pub index: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_tag"]
        [::core::mem::size_of::<rte_flow_action_set_tag>() - 12usize];
    ["Alignment of rte_flow_action_set_tag"]
        [::core::mem::align_of::<rte_flow_action_set_tag>() - 4usize];
    ["Offset of field: rte_flow_action_set_tag::data"]
        [::core::mem::offset_of!(rte_flow_action_set_tag, data) - 0usize];
    ["Offset of field: rte_flow_action_set_tag::mask"]
        [::core::mem::offset_of!(rte_flow_action_set_tag, mask) - 4usize];
    ["Offset of field: rte_flow_action_set_tag::index"]
        [::core::mem::offset_of!(rte_flow_action_set_tag, index) - 8usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SET_META\nSet metadata. Metadata set by mbuf metadata dynamic field with\nRTE_MBUF_DYNFLAG_TX_METADATA flag on egress will be overridden by this\naction. On ingress, the metadata will be carried by mbuf metadata dynamic\nfield with RTE_MBUF_DYNFLAG_RX_METADATA flag if set.  The dynamic mbuf field\nmust be registered in advance by rte_flow_dynf_metadata_register().\nAltering partial bits is supported with mask. For bits which have never\nbeen set, unpredictable value will be seen depending on driver\nimplementation. For loopback/hairpin packet, metadata set on Rx/Tx may\nor may not be propagated to the other path depending on HW capability.\nRTE_FLOW_ITEM_TYPE_META matches metadata."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_meta {
    pub data: u32,
    pub mask: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_meta"]
        [::core::mem::size_of::<rte_flow_action_set_meta>() - 8usize];
    ["Alignment of rte_flow_action_set_meta"]
        [::core::mem::align_of::<rte_flow_action_set_meta>() - 4usize];
    ["Offset of field: rte_flow_action_set_meta::data"]
        [::core::mem::offset_of!(rte_flow_action_set_meta, data) - 0usize];
    ["Offset of field: rte_flow_action_set_meta::mask"]
        [::core::mem::offset_of!(rte_flow_action_set_meta, mask) - 4usize];
};
#[doc = "RTE_FLOW_ACTION_TYPE_SET_IPV4_DSCP\nRTE_FLOW_ACTION_TYPE_SET_IPV6_DSCP\nSet the DSCP value for IPv4/IPv6 header.\nDSCP in low 6 bits, rest ignored."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_set_dscp {
    pub dscp: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_set_dscp"]
        [::core::mem::size_of::<rte_flow_action_set_dscp>() - 1usize];
    ["Alignment of rte_flow_action_set_dscp"]
        [::core::mem::align_of::<rte_flow_action_set_dscp>() - 1usize];
    ["Offset of field: rte_flow_action_set_dscp::dscp"]
        [::core::mem::offset_of!(rte_flow_action_set_dscp, dscp) - 0usize];
};
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_INDIRECT\nOpaque type returned after successfully creating an indirect action object.\nThe definition of the object handle is different per driver or\nper direct action type.\nThis handle can be used to manage and query the related direct action:\n- referenced in single flow rule or across multiple flow rules\nover multiple ports\n- update action object configuration\n- query action object data\n- destroy action object"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_handle {
    _unused: [u8; 0],
}
pub mod rte_flow_conntrack_state {
    #[doc = "The state of a TCP connection."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "SYN-ACK packet was seen."]
    pub const RTE_FLOW_CONNTRACK_STATE_SYN_RECV: Type = 0;
    #[doc = "3-way handshake was done."]
    pub const RTE_FLOW_CONNTRACK_STATE_ESTABLISHED: Type = 1;
    #[doc = "First FIN packet was received to close the connection."]
    pub const RTE_FLOW_CONNTRACK_STATE_FIN_WAIT: Type = 2;
    #[doc = "First FIN was ACKed."]
    pub const RTE_FLOW_CONNTRACK_STATE_CLOSE_WAIT: Type = 3;
    #[doc = "Second FIN was received, waiting for the last ACK."]
    pub const RTE_FLOW_CONNTRACK_STATE_LAST_ACK: Type = 4;
    #[doc = "Second FIN was ACKed, connection was closed."]
    pub const RTE_FLOW_CONNTRACK_STATE_TIME_WAIT: Type = 5;
}
pub mod rte_flow_conntrack_tcp_last_index {
    #[doc = "The last passed TCP packet flags of a connection."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< No Flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_NONE: Type = 0;
    #[doc = "< With SYN flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_SYN: Type = 1;
    #[doc = "< With SYNACK flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_SYNACK: Type = 2;
    #[doc = "< With FIN flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_FIN: Type = 4;
    #[doc = "< With ACK flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_ACK: Type = 8;
    #[doc = "< With RST flag."]
    pub const RTE_FLOW_CONNTRACK_FLAG_RST: Type = 16;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nConfiguration parameters for each direction of a TCP connection.\nAll fields should be in host byte order.\nIf needed, driver should convert all fields to network byte order\nif HW needs them in that way."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_tcp_dir_param {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "Maximal value of sequence + payload length in sent\npackets (next ACK from the opposite direction)."]
    pub sent_end: u32,
    #[doc = "Maximal value of (ACK + window size) in received packet + length\nover sent packet (maximal sequence could be sent)."]
    pub reply_end: u32,
    #[doc = "Maximal value of actual window size in sent packets."]
    pub max_win: u32,
    #[doc = "Maximal value of ACK in sent packets."]
    pub max_ack: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tcp_dir_param"][::core::mem::size_of::<rte_flow_tcp_dir_param>() - 20usize];
    ["Alignment of rte_flow_tcp_dir_param"]
        [::core::mem::align_of::<rte_flow_tcp_dir_param>() - 4usize];
    ["Offset of field: rte_flow_tcp_dir_param::sent_end"]
        [::core::mem::offset_of!(rte_flow_tcp_dir_param, sent_end) - 4usize];
    ["Offset of field: rte_flow_tcp_dir_param::reply_end"]
        [::core::mem::offset_of!(rte_flow_tcp_dir_param, reply_end) - 8usize];
    ["Offset of field: rte_flow_tcp_dir_param::max_win"]
        [::core::mem::offset_of!(rte_flow_tcp_dir_param, max_win) - 12usize];
    ["Offset of field: rte_flow_tcp_dir_param::max_ack"]
        [::core::mem::offset_of!(rte_flow_tcp_dir_param, max_ack) - 16usize];
};
impl rte_flow_tcp_dir_param {
    #[inline]
    pub fn scale(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_scale(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn scale_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_scale_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn close_initiated(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_close_initiated(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn close_initiated_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_close_initiated_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn last_ack_seen(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_last_ack_seen(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn last_ack_seen_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_last_ack_seen_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn data_unacked(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_data_unacked(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn data_unacked_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_data_unacked_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        scale: u32,
        close_initiated: u32,
        last_ack_seen: u32,
        data_unacked: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let scale: u32 = unsafe { ::core::mem::transmute(scale) };
            scale as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let close_initiated: u32 = unsafe { ::core::mem::transmute(close_initiated) };
            close_initiated as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let last_ack_seen: u32 = unsafe { ::core::mem::transmute(last_ack_seen) };
            last_ack_seen as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let data_unacked: u32 = unsafe { ::core::mem::transmute(data_unacked) };
            data_unacked as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_CONNTRACK\nConfiguration and initial state for the connection tracking module.\nThis structure could be used for both setting and query.\nAll fields should be in host byte order."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_conntrack {
    #[doc = "The peer port number, can be the same port."]
    pub peer_port: u16,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "The current state of this connection."]
    pub state: rte_flow_conntrack_state::Type,
    #[doc = "Scaling factor for maximal allowed ACK window."]
    pub max_ack_window: u8,
    #[doc = "Maximal allowed number of retransmission times."]
    pub retransmission_limit: u8,
    #[doc = "TCP parameters of the original direction."]
    pub original_dir: rte_flow_tcp_dir_param,
    #[doc = "TCP parameters of the reply direction."]
    pub reply_dir: rte_flow_tcp_dir_param,
    #[doc = "The window value of the last packet passed this conntrack."]
    pub last_window: u16,
    pub last_index: rte_flow_conntrack_tcp_last_index::Type,
    #[doc = "The sequence of the last packet passed this conntrack."]
    pub last_seq: u32,
    #[doc = "The acknowledgment of the last packet passed this conntrack."]
    pub last_ack: u32,
    #[doc = "The total value ACK + payload length of the last packet\npassed this conntrack."]
    pub last_end: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_conntrack"]
        [::core::mem::size_of::<rte_flow_action_conntrack>() - 72usize];
    ["Alignment of rte_flow_action_conntrack"]
        [::core::mem::align_of::<rte_flow_action_conntrack>() - 4usize];
    ["Offset of field: rte_flow_action_conntrack::peer_port"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, peer_port) - 0usize];
    ["Offset of field: rte_flow_action_conntrack::state"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, state) - 4usize];
    ["Offset of field: rte_flow_action_conntrack::max_ack_window"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, max_ack_window) - 8usize];
    ["Offset of field: rte_flow_action_conntrack::retransmission_limit"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, retransmission_limit) - 9usize];
    ["Offset of field: rte_flow_action_conntrack::original_dir"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, original_dir) - 12usize];
    ["Offset of field: rte_flow_action_conntrack::reply_dir"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, reply_dir) - 32usize];
    ["Offset of field: rte_flow_action_conntrack::last_window"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, last_window) - 52usize];
    ["Offset of field: rte_flow_action_conntrack::last_index"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, last_index) - 56usize];
    ["Offset of field: rte_flow_action_conntrack::last_seq"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, last_seq) - 60usize];
    ["Offset of field: rte_flow_action_conntrack::last_ack"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, last_ack) - 64usize];
    ["Offset of field: rte_flow_action_conntrack::last_end"]
        [::core::mem::offset_of!(rte_flow_action_conntrack, last_end) - 68usize];
};
impl Default for rte_flow_action_conntrack {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_action_conntrack {
    #[inline]
    pub fn is_original_dir(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_is_original_dir(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn is_original_dir_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_is_original_dir_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn enable(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_enable(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn enable_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_enable_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn live_connection(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_live_connection(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn live_connection_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_live_connection_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn selective_ack(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_selective_ack(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn selective_ack_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_selective_ack_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn challenge_ack_passed(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_challenge_ack_passed(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn challenge_ack_passed_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_challenge_ack_passed_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn last_direction(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(5usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_last_direction(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(5usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn last_direction_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                5usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_last_direction_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                5usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn liberal_mode(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_liberal_mode(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn liberal_mode_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_liberal_mode_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        is_original_dir: u32,
        enable: u32,
        live_connection: u32,
        selective_ack: u32,
        challenge_ack_passed: u32,
        last_direction: u32,
        liberal_mode: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let is_original_dir: u32 = unsafe { ::core::mem::transmute(is_original_dir) };
            is_original_dir as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let enable: u32 = unsafe { ::core::mem::transmute(enable) };
            enable as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let live_connection: u32 = unsafe { ::core::mem::transmute(live_connection) };
            live_connection as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let selective_ack: u32 = unsafe { ::core::mem::transmute(selective_ack) };
            selective_ack as u64
        });
        __bindgen_bitfield_unit.set(4usize, 1u8, {
            let challenge_ack_passed: u32 = unsafe { ::core::mem::transmute(challenge_ack_passed) };
            challenge_ack_passed as u64
        });
        __bindgen_bitfield_unit.set(5usize, 1u8, {
            let last_direction: u32 = unsafe { ::core::mem::transmute(last_direction) };
            last_direction as u64
        });
        __bindgen_bitfield_unit.set(6usize, 1u8, {
            let liberal_mode: u32 = unsafe { ::core::mem::transmute(liberal_mode) };
            liberal_mode as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_CONNTRACK\nWrapper structure for the context update interface.\nPorts cannot support updating, and the only valid solution is to\ndestroy the old context and create a new one instead."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_modify_conntrack {
    #[doc = "New connection tracking parameters to be updated."]
    pub new_ct: rte_flow_action_conntrack,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_modify_conntrack"]
        [::core::mem::size_of::<rte_flow_modify_conntrack>() - 76usize];
    ["Alignment of rte_flow_modify_conntrack"]
        [::core::mem::align_of::<rte_flow_modify_conntrack>() - 4usize];
    ["Offset of field: rte_flow_modify_conntrack::new_ct"]
        [::core::mem::offset_of!(rte_flow_modify_conntrack, new_ct) - 0usize];
};
impl Default for rte_flow_modify_conntrack {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_modify_conntrack {
    #[inline]
    pub fn direction(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_direction(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn direction_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_direction_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn state(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_state(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn state_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_state_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 30u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 30u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                30u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                30u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        direction: u32,
        state: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let direction: u32 = unsafe { ::core::mem::transmute(direction) };
            direction as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let state: u32 = unsafe { ::core::mem::transmute(state) };
            state as u64
        });
        __bindgen_bitfield_unit.set(2usize, 30u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_METER_COLOR\nThe meter color should be set in the packet meta-data\n(i.e. struct rte_mbuf::sched::color)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_meter_color {
    #[doc = "< Packet color."]
    pub color: rte_color::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_meter_color"]
        [::core::mem::size_of::<rte_flow_action_meter_color>() - 4usize];
    ["Alignment of rte_flow_action_meter_color"]
        [::core::mem::align_of::<rte_flow_action_meter_color>() - 4usize];
    ["Offset of field: rte_flow_action_meter_color::color"]
        [::core::mem::offset_of!(rte_flow_action_meter_color, color) - 0usize];
};
impl Default for rte_flow_action_meter_color {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Provides an ethdev port ID for use with the following actions:\nRTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR,\nRTE_FLOW_ACTION_TYPE_REPRESENTED_PORT."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_action_ethdev {
    #[doc = "< ethdev port ID"]
    pub port_id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_ethdev"][::core::mem::size_of::<rte_flow_action_ethdev>() - 2usize];
    ["Alignment of rte_flow_action_ethdev"]
        [::core::mem::align_of::<rte_flow_action_ethdev>() - 2usize];
    ["Offset of field: rte_flow_action_ethdev::port_id"]
        [::core::mem::offset_of!(rte_flow_action_ethdev, port_id) - 0usize];
};
pub mod rte_flow_modify_op {
    #[doc = "Operation types for MODIFY_FIELD action."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Set a new value."]
    pub const RTE_FLOW_MODIFY_SET: Type = 0;
    #[doc = "< Add a value to a field."]
    pub const RTE_FLOW_MODIFY_ADD: Type = 1;
    #[doc = "< Subtract a value from a field."]
    pub const RTE_FLOW_MODIFY_SUB: Type = 2;
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_MODIFY_FIELD\nModify a destination header field according to the specified\noperation. Another field of the packet can be used as a source as well\nas tag, mark, metadata, immediate value or a pointer to it."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_action_modify_field {
    #[doc = "< Operation to perform."]
    pub operation: rte_flow_modify_op::Type,
    #[doc = "< Destination field."]
    pub dst: rte_flow_field_data,
    #[doc = "< Source field."]
    pub src: rte_flow_field_data,
    #[doc = "< Number of bits to use from a source field."]
    pub width: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_modify_field"]
        [::core::mem::size_of::<rte_flow_action_modify_field>() - 64usize];
    ["Alignment of rte_flow_action_modify_field"]
        [::core::mem::align_of::<rte_flow_action_modify_field>() - 8usize];
    ["Offset of field: rte_flow_action_modify_field::operation"]
        [::core::mem::offset_of!(rte_flow_action_modify_field, operation) - 0usize];
    ["Offset of field: rte_flow_action_modify_field::dst"]
        [::core::mem::offset_of!(rte_flow_action_modify_field, dst) - 8usize];
    ["Offset of field: rte_flow_action_modify_field::src"]
        [::core::mem::offset_of!(rte_flow_action_modify_field, src) - 32usize];
    ["Offset of field: rte_flow_action_modify_field::width"]
        [::core::mem::offset_of!(rte_flow_action_modify_field, width) - 56usize];
};
impl Default for rte_flow_action_modify_field {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_METER_MARK\nTraffic metering and marking (MTR).\nMeters a packet stream and marks its packets either\ngreen, yellow, or red according to the specified profile.\nThe policy is optional and may be specified for defining\nsubsequent actions based on a color assigned by MTR.\nAlternatively, the METER_COLOR item may be used for this."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_meter_mark {
    pub profile: *mut rte_flow_meter_profile,
    pub policy: *mut rte_flow_meter_policy,
    #[doc = "Metering mode: 0 - Color-Blind, 1 - Color-Aware."]
    pub color_mode: ::core::ffi::c_int,
    #[doc = "Metering state: 0 - Disabled, 1 - Enabled."]
    pub state: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_meter_mark"]
        [::core::mem::size_of::<rte_flow_action_meter_mark>() - 24usize];
    ["Alignment of rte_flow_action_meter_mark"]
        [::core::mem::align_of::<rte_flow_action_meter_mark>() - 8usize];
    ["Offset of field: rte_flow_action_meter_mark::profile"]
        [::core::mem::offset_of!(rte_flow_action_meter_mark, profile) - 0usize];
    ["Offset of field: rte_flow_action_meter_mark::policy"]
        [::core::mem::offset_of!(rte_flow_action_meter_mark, policy) - 8usize];
    ["Offset of field: rte_flow_action_meter_mark::color_mode"]
        [::core::mem::offset_of!(rte_flow_action_meter_mark, color_mode) - 16usize];
    ["Offset of field: rte_flow_action_meter_mark::state"]
        [::core::mem::offset_of!(rte_flow_action_meter_mark, state) - 20usize];
};
impl Default for rte_flow_action_meter_mark {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE_FLOW_ACTION_TYPE_METER_MARK\nWrapper structure for the context update interface."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_update_meter_mark {
    #[doc = "New meter_mark parameters to be updated."]
    pub meter_mark: rte_flow_action_meter_mark,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    pub __bindgen_padding_0: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_update_meter_mark"]
        [::core::mem::size_of::<rte_flow_update_meter_mark>() - 32usize];
    ["Alignment of rte_flow_update_meter_mark"]
        [::core::mem::align_of::<rte_flow_update_meter_mark>() - 8usize];
    ["Offset of field: rte_flow_update_meter_mark::meter_mark"]
        [::core::mem::offset_of!(rte_flow_update_meter_mark, meter_mark) - 0usize];
};
impl Default for rte_flow_update_meter_mark {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_flow_update_meter_mark {
    #[inline]
    pub fn profile_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_profile_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn profile_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_profile_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn policy_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_policy_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn policy_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_policy_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn color_mode_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_color_mode_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn color_mode_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_color_mode_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn state_valid(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_state_valid(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn state_valid_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_state_valid_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 28u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 28u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                28u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                28u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        profile_valid: u32,
        policy_valid: u32,
        color_mode_valid: u32,
        state_valid: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let profile_valid: u32 = unsafe { ::core::mem::transmute(profile_valid) };
            profile_valid as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let policy_valid: u32 = unsafe { ::core::mem::transmute(policy_valid) };
            policy_valid as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let color_mode_valid: u32 = unsafe { ::core::mem::transmute(color_mode_valid) };
            color_mode_valid as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let state_valid: u32 = unsafe { ::core::mem::transmute(state_valid) };
            state_valid as u64
        });
        __bindgen_bitfield_unit.set(4usize, 28u8, {
            let reserved: u32 = unsafe { ::core::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "# See also\n\n> [`RTE_FLOW_ACTION_TYPE_METER_MARK`]\n> [`RTE_FLOW_ACTION_TYPE_INDIRECT_LIST`]\nUpdate flow mutable context."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_indirect_update_flow_meter_mark {
    #[doc = "Updated init color applied to packet"]
    pub init_color: rte_color::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_indirect_update_flow_meter_mark"]
        [::core::mem::size_of::<rte_flow_indirect_update_flow_meter_mark>() - 4usize];
    ["Alignment of rte_flow_indirect_update_flow_meter_mark"]
        [::core::mem::align_of::<rte_flow_indirect_update_flow_meter_mark>() - 4usize];
    ["Offset of field: rte_flow_indirect_update_flow_meter_mark::init_color"]
        [::core::mem::offset_of!(rte_flow_indirect_update_flow_meter_mark, init_color) - 0usize];
};
impl Default for rte_flow_indirect_update_flow_meter_mark {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nProgram action argument configuration parameters.\nFor each action argument, its *size* must be non-zero and its *value* must\npoint to a valid array of *size* bytes specified in network byte order.\n\n# See also\n\n> [`struct`] rte_flow_action_prog"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_prog_argument {
    #[doc = "Argument name."]
    pub name: *const ::core::ffi::c_char,
    #[doc = "Argument size in bytes."]
    pub size: u32,
    #[doc = "Argument value."]
    pub value: *const u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_prog_argument"]
        [::core::mem::size_of::<rte_flow_action_prog_argument>() - 24usize];
    ["Alignment of rte_flow_action_prog_argument"]
        [::core::mem::align_of::<rte_flow_action_prog_argument>() - 8usize];
    ["Offset of field: rte_flow_action_prog_argument::name"]
        [::core::mem::offset_of!(rte_flow_action_prog_argument, name) - 0usize];
    ["Offset of field: rte_flow_action_prog_argument::size"]
        [::core::mem::offset_of!(rte_flow_action_prog_argument, size) - 8usize];
    ["Offset of field: rte_flow_action_prog_argument::value"]
        [::core::mem::offset_of!(rte_flow_action_prog_argument, value) - 16usize];
};
impl Default for rte_flow_action_prog_argument {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice.\nRTE_FLOW_ACTION_TYPE_PROG\nProgram action configuration parameters.\nEach action can have zero or more arguments. When *args_num* is non-zero, the\n*args* parameter must point to a valid array of *args_num* elements.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_PROG`]"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_prog {
    #[doc = "Action name."]
    pub name: *const ::core::ffi::c_char,
    #[doc = "Number of action arguments."]
    pub args_num: u32,
    #[doc = "Action arguments array."]
    pub args: *const rte_flow_action_prog_argument,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_prog"][::core::mem::size_of::<rte_flow_action_prog>() - 24usize];
    ["Alignment of rte_flow_action_prog"][::core::mem::align_of::<rte_flow_action_prog>() - 8usize];
    ["Offset of field: rte_flow_action_prog::name"]
        [::core::mem::offset_of!(rte_flow_action_prog, name) - 0usize];
    ["Offset of field: rte_flow_action_prog::args_num"]
        [::core::mem::offset_of!(rte_flow_action_prog, args_num) - 8usize];
    ["Offset of field: rte_flow_action_prog::args"]
        [::core::mem::offset_of!(rte_flow_action_prog, args) - 16usize];
};
impl Default for rte_flow_action_prog {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Mbuf dynamic field offset for metadata."]
    pub static mut rte_flow_dynf_metadata_offs: i32;
}
unsafe extern "C" {
    #[doc = "Mbuf dynamic field flag mask for metadata."]
    pub static mut rte_flow_dynf_metadata_mask: u64;
}
unsafe extern "C" {
    #[link_name = "rte_flow_dynf_metadata_get_w"]
    pub fn rte_flow_dynf_metadata_get(m: *mut rte_mbuf) -> u32;
}
unsafe extern "C" {
    #[link_name = "rte_flow_dynf_metadata_set_w"]
    pub fn rte_flow_dynf_metadata_set(m: *mut rte_mbuf, v: u32);
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_JUMP_TO_TABLE_INDEX\nRedirects packets to a particular index in a flow table.\n"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_jump_to_table_index {
    pub table: *mut rte_flow_template_table,
    pub index: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_jump_to_table_index"]
        [::core::mem::size_of::<rte_flow_action_jump_to_table_index>() - 16usize];
    ["Alignment of rte_flow_action_jump_to_table_index"]
        [::core::mem::align_of::<rte_flow_action_jump_to_table_index>() - 8usize];
    ["Offset of field: rte_flow_action_jump_to_table_index::table"]
        [::core::mem::offset_of!(rte_flow_action_jump_to_table_index, table) - 0usize];
    ["Offset of field: rte_flow_action_jump_to_table_index::index"]
        [::core::mem::offset_of!(rte_flow_action_jump_to_table_index, index) - 8usize];
};
impl Default for rte_flow_action_jump_to_table_index {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Definition of a single action.\nA list of actions is terminated by a END action.\nFor simple actions without a configuration object, conf remains NULL."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action {
    #[doc = "< Action type."]
    pub type_: rte_flow_action_type::Type,
    #[doc = "< Pointer to action configuration object."]
    pub conf: *const ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action"][::core::mem::size_of::<rte_flow_action>() - 16usize];
    ["Alignment of rte_flow_action"][::core::mem::align_of::<rte_flow_action>() - 8usize];
    ["Offset of field: rte_flow_action::type_"]
        [::core::mem::offset_of!(rte_flow_action, type_) - 0usize];
    ["Offset of field: rte_flow_action::conf"]
        [::core::mem::offset_of!(rte_flow_action, conf) - 8usize];
};
impl Default for rte_flow_action {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Opaque type returned after successfully creating a flow.\nThis handle can be used to manage and query the related flow (e.g. to\ndestroy it or retrieve counters)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow {
    _unused: [u8; 0],
}
#[doc = "Opaque type for Meter profile object returned by MTR API.\nThis handle can be used to create Meter actions instead of profile ID."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_meter_profile {
    _unused: [u8; 0],
}
#[doc = "Opaque type for Meter policy object returned by MTR API.\nThis handle can be used to create Meter actions instead of policy ID."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_meter_policy {
    _unused: [u8; 0],
}
#[doc = "@warning **EXPERIMENTAL:** this structure may change without prior notice\nRTE_FLOW_ACTION_TYPE_SAMPLE\nAdds a sample action to a matched flow.\nThe matching packets will be duplicated with specified ratio and applied\nwith own set of actions with a fate action, the sampled packet could be\nredirected to queue or port. All the packets continue processing on the\ndefault flow path.\nWhen the sample ratio is set to 1 then the packets will be 100% mirrored.\nAdditional action list be supported to add for sampled or mirrored packets."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_sample {
    #[doc = "< packets sampled equals to '1/ratio'."]
    pub ratio: u32,
    #[doc = "sub-action list specific for the sampling hit cases."]
    pub actions: *const rte_flow_action,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_sample"][::core::mem::size_of::<rte_flow_action_sample>() - 16usize];
    ["Alignment of rte_flow_action_sample"]
        [::core::mem::align_of::<rte_flow_action_sample>() - 8usize];
    ["Offset of field: rte_flow_action_sample::ratio"]
        [::core::mem::offset_of!(rte_flow_action_sample, ratio) - 0usize];
    ["Offset of field: rte_flow_action_sample::actions"]
        [::core::mem::offset_of!(rte_flow_action_sample, actions) - 8usize];
};
impl Default for rte_flow_action_sample {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_error_type {
    #[doc = "Verbose error types.\nMost of them provide the type of the object referenced by struct\nrte_flow_error.cause."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< No error."]
    pub const RTE_FLOW_ERROR_TYPE_NONE: Type = 0;
    #[doc = "< Cause unspecified."]
    pub const RTE_FLOW_ERROR_TYPE_UNSPECIFIED: Type = 1;
    #[doc = "< Flow rule (handle)."]
    pub const RTE_FLOW_ERROR_TYPE_HANDLE: Type = 2;
    #[doc = "< Group field."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR_GROUP: Type = 3;
    #[doc = "< Priority field."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR_PRIORITY: Type = 4;
    #[doc = "< Ingress field."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR_INGRESS: Type = 5;
    #[doc = "< Egress field."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR_EGRESS: Type = 6;
    #[doc = "< Transfer field."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR_TRANSFER: Type = 7;
    #[doc = "< Attributes structure."]
    pub const RTE_FLOW_ERROR_TYPE_ATTR: Type = 8;
    #[doc = "< Pattern length."]
    pub const RTE_FLOW_ERROR_TYPE_ITEM_NUM: Type = 9;
    #[doc = "< Item specification."]
    pub const RTE_FLOW_ERROR_TYPE_ITEM_SPEC: Type = 10;
    #[doc = "< Item specification range."]
    pub const RTE_FLOW_ERROR_TYPE_ITEM_LAST: Type = 11;
    #[doc = "< Item specification mask."]
    pub const RTE_FLOW_ERROR_TYPE_ITEM_MASK: Type = 12;
    #[doc = "< Specific pattern item."]
    pub const RTE_FLOW_ERROR_TYPE_ITEM: Type = 13;
    #[doc = "< Number of actions."]
    pub const RTE_FLOW_ERROR_TYPE_ACTION_NUM: Type = 14;
    #[doc = "< Action configuration."]
    pub const RTE_FLOW_ERROR_TYPE_ACTION_CONF: Type = 15;
    #[doc = "< Specific action."]
    pub const RTE_FLOW_ERROR_TYPE_ACTION: Type = 16;
    #[doc = "< Current device state."]
    pub const RTE_FLOW_ERROR_TYPE_STATE: Type = 17;
}
#[doc = "Verbose error structure definition.\nThis object is normally allocated by applications and set by PMDs, the\nmessage points to a constant string which does not need to be freed by\nthe application, however its pointer can be considered valid only as long\nas its associated DPDK port remains configured. Closing the underlying\ndevice or unloading the PMD invalidates it.\nBoth cause and message may be NULL regardless of the error type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_error {
    #[doc = "< Cause field and error types."]
    pub type_: rte_flow_error_type::Type,
    #[doc = "< Object responsible for the error."]
    pub cause: *const ::core::ffi::c_void,
    #[doc = "< Human-readable error message."]
    pub message: *const ::core::ffi::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_error"][::core::mem::size_of::<rte_flow_error>() - 24usize];
    ["Alignment of rte_flow_error"][::core::mem::align_of::<rte_flow_error>() - 8usize];
    ["Offset of field: rte_flow_error::type_"]
        [::core::mem::offset_of!(rte_flow_error, type_) - 0usize];
    ["Offset of field: rte_flow_error::cause"]
        [::core::mem::offset_of!(rte_flow_error, cause) - 8usize];
    ["Offset of field: rte_flow_error::message"]
        [::core::mem::offset_of!(rte_flow_error, message) - 16usize];
};
impl Default for rte_flow_error {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Complete flow rule description.\nThis object type is used when converting a flow rule description.\n\n# See also\n\n> [`RTE_FLOW_CONV_OP_RULE`]\n> [`rte_flow_conv()`]"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_conv_rule {
    pub anon1: rte_flow_conv_rule__bindgen_ty_1,
    pub anon2: rte_flow_conv_rule__bindgen_ty_2,
    pub anon3: rte_flow_conv_rule__bindgen_ty_3,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_conv_rule__bindgen_ty_1 {
    #[doc = "< RO attributes."]
    pub attr_ro: *const rte_flow_attr,
    #[doc = "< Attributes."]
    pub attr: *mut rte_flow_attr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_conv_rule__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_conv_rule__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_conv_rule__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_conv_rule__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_1::attr_ro"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_1, attr_ro) - 0usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_1::attr"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_1, attr) - 0usize];
};
impl Default for rte_flow_conv_rule__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_conv_rule__bindgen_ty_2 {
    #[doc = "< RO pattern."]
    pub pattern_ro: *const rte_flow_item,
    #[doc = "< Pattern items."]
    pub pattern: *mut rte_flow_item,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_conv_rule__bindgen_ty_2"]
        [::core::mem::size_of::<rte_flow_conv_rule__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_flow_conv_rule__bindgen_ty_2"]
        [::core::mem::align_of::<rte_flow_conv_rule__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_2::pattern_ro"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_2, pattern_ro) - 0usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_2::pattern"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_2, pattern) - 0usize];
};
impl Default for rte_flow_conv_rule__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_conv_rule__bindgen_ty_3 {
    #[doc = "< RO actions."]
    pub actions_ro: *const rte_flow_action,
    #[doc = "< List of actions."]
    pub actions: *mut rte_flow_action,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_conv_rule__bindgen_ty_3"]
        [::core::mem::size_of::<rte_flow_conv_rule__bindgen_ty_3>() - 8usize];
    ["Alignment of rte_flow_conv_rule__bindgen_ty_3"]
        [::core::mem::align_of::<rte_flow_conv_rule__bindgen_ty_3>() - 8usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_3::actions_ro"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_3, actions_ro) - 0usize];
    ["Offset of field: rte_flow_conv_rule__bindgen_ty_3::actions"]
        [::core::mem::offset_of!(rte_flow_conv_rule__bindgen_ty_3, actions) - 0usize];
};
impl Default for rte_flow_conv_rule__bindgen_ty_3 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_conv_rule"][::core::mem::size_of::<rte_flow_conv_rule>() - 24usize];
    ["Alignment of rte_flow_conv_rule"][::core::mem::align_of::<rte_flow_conv_rule>() - 8usize];
};
impl Default for rte_flow_conv_rule {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_flow_conv_op {
    #[doc = "Conversion operations for flow API objects.\n\n# See also\n\n> [`rte_flow_conv()`]"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "No operation to perform.\nrte_flow_conv() simply returns 0."]
    pub const RTE_FLOW_CONV_OP_NONE: Type = 0;
    #[doc = "Convert attributes structure.\nThis is a basic copy of an attributes structure.\n- `src` type:\n@code const struct rte_flow_attr * @endcode - `dst` type:\n@code struct rte_flow_attr * @endcode "]
    pub const RTE_FLOW_CONV_OP_ATTR: Type = 1;
    #[doc = "Convert a single item.\nDuplicates `spec,` `last` and `mask` but not outside objects.\n- `src` type:\n@code const struct rte_flow_item * @endcode - `dst` type:\n@code struct rte_flow_item * @endcode "]
    pub const RTE_FLOW_CONV_OP_ITEM: Type = 2;
    #[doc = "Convert a single item mask.\nDuplicates only `mask.`\n- `src` type:\n@code const struct rte_flow_item * @endcode - `dst` type:\n@code struct rte_flow_item * @endcode "]
    pub const RTE_FLOW_CONV_OP_ITEM_MASK: Type = 3;
    #[doc = "Convert a single action.\nDuplicates `conf` but not outside objects.\n- `src` type:\n@code const struct rte_flow_action * @endcode - `dst` type:\n@code struct rte_flow_action * @endcode "]
    pub const RTE_FLOW_CONV_OP_ACTION: Type = 4;
    #[doc = "Convert an entire pattern.\nDuplicates all pattern items at once with the same constraints as\nRTE_FLOW_CONV_OP_ITEM.\n- `src` type:\n@code const struct rte_flow_item * @endcode - `dst` type:\n@code struct rte_flow_item * @endcode "]
    pub const RTE_FLOW_CONV_OP_PATTERN: Type = 5;
    #[doc = "Convert a list of actions.\nDuplicates the entire list of actions at once with the same\nconstraints as RTE_FLOW_CONV_OP_ACTION.\n- `src` type:\n@code const struct rte_flow_action * @endcode - `dst` type:\n@code struct rte_flow_action * @endcode "]
    pub const RTE_FLOW_CONV_OP_ACTIONS: Type = 6;
    #[doc = "Convert a complete flow rule description.\nComprises attributes, pattern and actions together at once with\nthe usual constraints.\n- `src` type:\n@code const struct rte_flow_conv_rule * @endcode - `dst` type:\n@code struct rte_flow_conv_rule * @endcode "]
    pub const RTE_FLOW_CONV_OP_RULE: Type = 7;
    #[doc = "Convert item type to its name string.\nWrites a NUL-terminated string to `dst.` Like snprintf(), the\nreturned value excludes the terminator which is always written\nnonetheless.\n- `src` type:\n@code (const void *)enum rte_flow_item_type @endcode - `dst` type:\n@code char * @endcode "]
    pub const RTE_FLOW_CONV_OP_ITEM_NAME: Type = 8;
    #[doc = "Convert action type to its name string.\nWrites a NUL-terminated string to `dst.` Like snprintf(), the\nreturned value excludes the terminator which is always written\nnonetheless.\n- `src` type:\n@code (const void *)enum rte_flow_action_type @endcode - `dst` type:\n@code char * @endcode "]
    pub const RTE_FLOW_CONV_OP_ACTION_NAME: Type = 9;
    #[doc = "Convert item type to pointer to item name.\nRetrieves item name pointer from its type. The string itself is\nnot copied; instead, a unique pointer to an internal static\nconstant storage is written to `dst.`\n- `src` type:\n@code (const void *)enum rte_flow_item_type @endcode - `dst` type:\n@code const char ** @endcode "]
    pub const RTE_FLOW_CONV_OP_ITEM_NAME_PTR: Type = 10;
    #[doc = "Convert action type to pointer to action name.\nRetrieves action name pointer from its type. The string itself is\nnot copied; instead, a unique pointer to an internal static\nconstant storage is written to `dst.`\n- `src` type:\n@code (const void *)enum rte_flow_action_type @endcode - `dst` type:\n@code const char ** @endcode "]
    pub const RTE_FLOW_CONV_OP_ACTION_NAME_PTR: Type = 11;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDump hardware internal representation information of\nrte flow to file.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `flow` [in]  -\nThe pointer of flow rule to dump. Dump all rules if NULL.\n* `file` [in]  -\nA pointer to a file for output.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative value otherwise."]
    pub fn rte_flow_dev_dump(
        port_id: u16,
        flow: *mut rte_flow,
        file: *mut FILE,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if mbuf dynamic field for metadata is registered.\n\n# Returns\n\nTrue if registered, false otherwise."]
    #[link_name = "rte_flow_dynf_metadata_avail_w"]
    pub fn rte_flow_dynf_metadata_avail() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register mbuf dynamic field and flag for metadata.\nThis function must be called prior to use SET_META action in order to\nregister the dynamic mbuf field. Otherwise, the data cannot be delivered to\napplication.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_dynf_metadata_register() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check whether a flow rule can be created on a given port.\nThe flow rule is validated for correctness and whether it could be accepted\nby the device given sufficient resources. The rule is checked against the\ncurrent device mode and queue configuration. The flow rule may also\noptionally be validated against existing flow rules and device resources.\nThis function has no effect on the target device.\nThe returned value is guaranteed to remain valid only as long as no\nsuccessful calls to rte_flow_create() or rte_flow_destroy() are made in\nthe meantime and no device parameter affecting flow rules in any way are\nmodified, due to possible collisions or resource limitations (although in\nsuch cases EINVAL should not be returned).\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `attr` [in]  -\nFlow rule attributes.\n* `pattern` [in]  -\nPattern specification (list terminated by the END pattern item).\n* `actions` [in]  -\nAssociated actions (list terminated by the END action).\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 if flow rule is valid and can be created. A negative errno value\notherwise (rte_errno is also set), the following errors are defined:\n-ENOSYS: underlying device does not support this functionality.\n-EIO: underlying device is removed.\n-EINVAL: unknown or invalid rule specification.\n-ENOTSUP: valid but unsupported rule specification (e.g. partial\nbit-masks are unsupported).\n-EEXIST: collision with an existing rule. Only returned if device\nsupports flow rule collision checking and there was a flow rule\ncollision. Not receiving this return code is no guarantee that creating\nthe rule will not fail due to a collision.\n-ENOMEM: not enough memory to execute the function, or if the device\nsupports resource validation, resource limitation on the device.\n-EBUSY: action cannot be performed due to busy device resources, may\nsucceed if the affected queues or even the entire port are in a stopped\nstate (see rte_eth_dev_rx_queue_stop() and rte_eth_dev_stop())."]
    pub fn rte_flow_validate(
        port_id: u16,
        attr: *const rte_flow_attr,
        pattern: *const rte_flow_item,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a flow rule on a given port.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `attr` [in]  -\nFlow rule attributes.\n* `pattern` [in]  -\nPattern specification (list terminated by the END pattern item).\n* `actions` [in]  -\nAssociated actions (list terminated by the END action).\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise and rte_errno is set\nto the positive version of one of the error codes defined for\nrte_flow_validate()."]
    pub fn rte_flow_create(
        port_id: u16,
        attr: *const rte_flow_attr,
        pattern: *const rte_flow_item,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = "Destroy a flow rule on a given port.\nFailure to destroy a flow rule handle may occur when other flow rules\ndepend on it, and destroying it would result in an inconsistent state.\nThis function is only guaranteed to succeed if handles are destroyed in\nreverse order of their creation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `flow` -\nFlow rule handle to destroy.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_destroy(
        port_id: u16,
        flow: *mut rte_flow,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Update a flow rule with new actions on a given port.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `flow` -\nFlow rule handle to update.\n* `actions` [in]  -\nAssociated actions (list terminated by the END action).\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_actions_update(
        port_id: u16,
        flow: *mut rte_flow,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Destroy all flow rules associated with a port.\nIn the unlikely event of failure, handles are still considered destroyed\nand no longer valid but the port must be assumed to be in an inconsistent\nstate.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_flush(port_id: u16, error: *mut rte_flow_error) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Query an existing flow rule.\nThis function allows retrieving flow-specific data such as counters.\nData is gathered by special actions which must be present in the flow\nrule definition.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_COUNT`]\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `flow` -\nFlow rule handle to query.\n* `action` -\nAction definition as defined in original flow rule.\n* `data` [in, out]  -\nPointer to storage for the associated query data type.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_query(
        port_id: u16,
        flow: *mut rte_flow,
        action: *const rte_flow_action,
        data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Restrict ingress traffic to the defined flow rules.\nIsolated mode guarantees that all ingress traffic comes from defined flow\nrules only (current and future).\nWhen enabled with a bifurcated driver,\nnon-matched packets are routed to the kernel driver interface.\nWhen disabled (the default),\nthere may be some default rules routing traffic to the DPDK port.\nBesides making ingress more deterministic, it allows PMDs to safely reuse\nresources otherwise assigned to handle the remaining traffic, such as\nglobal RSS configuration settings, VLAN filters, MAC address entries,\nlegacy filter API rules and so on in order to expand the set of possible\nflow rule types.\nCalling this function as soon as possible after device initialization,\nideally before the first call to rte_eth_dev_configure(), is recommended\nto avoid possible failures due to conflicting settings.\nOnce effective, leaving isolated mode may not be possible depending on\nPMD implementation.\nAdditionally, the following functionality has no effect on the underlying\nport and may return errors such as ENOTSUP (\"not supported\"):\n- Toggling promiscuous mode.\n- Toggling allmulticast mode.\n- Configuring MAC addresses.\n- Configuring multicast addresses.\n- Configuring VLAN filters.\n- Configuring Rx filters through the legacy API (e.g. FDIR).\n- Configuring global RSS settings.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `set` -\nNonzero to enter isolated mode, attempt to leave it otherwise.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_isolate(
        port_id: u16,
        set: ::core::ffi::c_int,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize flow error structure.\n\n# Arguments\n\n* `error` [out]  -\nPointer to flow error structure (may be NULL).\n* `code` -\nRelated error code (rte_errno).\n* `type` -\nCause field and error types.\n* `cause` -\nObject responsible for the error.\n* `message` -\nHuman-readable error message.\n\n# Returns\n\nNegative error code (errno value) and rte_errno is set."]
    pub fn rte_flow_error_set(
        error: *mut rte_flow_error,
        code: ::core::ffi::c_int,
        type_: rte_flow_error_type::Type,
        cause: *const ::core::ffi::c_void,
        message: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
#[doc = "> **Deprecated** # See also\n\n> [`rte_flow_copy()`]"]
#[repr(C)]
#[derive(Debug)]
pub struct rte_flow_desc {
    #[doc = "< Allocated space including data[]."]
    pub size: usize,
    #[doc = "< Attributes."]
    pub attr: rte_flow_attr,
    #[doc = "< Items."]
    pub items: *mut rte_flow_item,
    #[doc = "< Actions."]
    pub actions: *mut rte_flow_action,
    #[doc = "< Storage for items/actions."]
    pub data: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_desc"][::core::mem::size_of::<rte_flow_desc>() - 40usize];
    ["Alignment of rte_flow_desc"][::core::mem::align_of::<rte_flow_desc>() - 8usize];
    ["Offset of field: rte_flow_desc::size"][::core::mem::offset_of!(rte_flow_desc, size) - 0usize];
    ["Offset of field: rte_flow_desc::attr"][::core::mem::offset_of!(rte_flow_desc, attr) - 8usize];
    ["Offset of field: rte_flow_desc::items"]
        [::core::mem::offset_of!(rte_flow_desc, items) - 24usize];
    ["Offset of field: rte_flow_desc::actions"]
        [::core::mem::offset_of!(rte_flow_desc, actions) - 32usize];
    ["Offset of field: rte_flow_desc::data"]
        [::core::mem::offset_of!(rte_flow_desc, data) - 40usize];
};
impl Default for rte_flow_desc {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "> **Deprecated** Copy an rte_flow rule description.\nThis interface is kept for compatibility with older applications but is\nimplemented as a wrapper to rte_flow_conv(). It is deprecated due to its\nlack of flexibility and reliance on a type unusable with C++ programs\n(struct rte_flow_desc).\n\n# Arguments\n\n* `fd` [in]  -\nFlow rule description.\n* `len` [in]  -\nTotal size of allocated data for the flow description.\n* `attr` [in]  -\nFlow rule attributes.\n* `items` [in]  -\nPattern specification (list terminated by the END pattern item).\n* `actions` [in]  -\nAssociated actions (list terminated by the END action).\n\n# Returns\n\nIf len is greater or equal to the size of the flow, the total size of the\nflow description and its data.\nIf len is lower than the size of the flow, the number of bytes that would\nhave been written to desc had it been sufficient. Nothing is written."]
    pub fn rte_flow_copy(
        fd: *mut rte_flow_desc,
        len: usize,
        attr: *const rte_flow_attr,
        items: *const rte_flow_item,
        actions: *const rte_flow_action,
    ) -> usize;
}
unsafe extern "C" {
    #[doc = "Flow object conversion helper.\nThis function performs conversion of various flow API objects to a\npre-allocated destination buffer. See enum rte_flow_conv_op for possible\noperations and details about each of them.\nSince destination buffer must be large enough, it works in a manner\nreminiscent of snprintf():\n- If `size` is 0, `dst` may be a NULL pointer, otherwise `dst` must be\nnon-NULL.\n- If positive, the returned value represents the number of bytes needed\nto store the conversion of `src` to `dst` according to `op`\nregardless of the `size` parameter.\n- Since no more than `size` bytes can be written to `dst,` output is\ntruncated and may be inconsistent when the returned value is larger\nthan that.\n- In case of conversion error, a negative error code is returned and\n`dst` contents are unspecified.\n\n# Arguments\n\n* `op` -\nOperation to perform, related to the object type of `dst.`\n* `dst` [out]  -\nDestination buffer address. Must be suitably aligned by the caller.\n* `size` -\nDestination buffer size in bytes.\n* `src` [in]  -\nSource object to copy. Depending on `op,` its type may differ from\nthat of `dst.`\n* `error` [out]  -\nPerform verbose error reporting if not NULL. Initialized in case of\nerror only.\n\n# Returns\n\nThe number of bytes required to convert `src` to `dst` on success, a\nnegative errno value otherwise and rte_errno is set.\n\n# See also\n\n> [`rte_flow_conv_op`]"]
    pub fn rte_flow_conv(
        op: rte_flow_conv_op::Type,
        dst: *mut ::core::ffi::c_void,
        size: usize,
        src: *const ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get aged-out flows of a given port.\nRTE_ETH_EVENT_FLOW_AGED event will be triggered when at least one new aged\nout flow was detected after the last call to rte_flow_get_aged_flows.\nThis function can be called to get the aged flows asynchronously from the\nevent callback or synchronously regardless the event.\nThis is not safe to call rte_flow_get_aged_flows function with other flow\nfunctions from multiple threads simultaneously.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `contexts` [in, out]  -\nThe address of an array of pointers to the aged-out flows contexts.\n* `nb_contexts` [in]  -\nThe length of context array pointers.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. Initialized in case of\nerror only.\n\n# Returns\n\nif nb_contexts is 0, return the amount of all aged contexts.\nif nb_contexts is not 0 , return the amount of aged flows reported\nin the context array, otherwise negative errno value.\n\n# See also\n\n> [`rte_flow_action_age`]\n> [`RTE_ETH_EVENT_FLOW_AGED`]"]
    pub fn rte_flow_get_aged_flows(
        port_id: u16,
        contexts: *mut *mut ::core::ffi::c_void,
        nb_contexts: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nGet aged-out flows of a given port on the given flow queue.\nIf application configure port attribute with RTE_FLOW_PORT_FLAG_STRICT_QUEUE,\nthere is no RTE_ETH_EVENT_FLOW_AGED event and this function must be called to\nget the aged flows synchronously.\nIf application configure port attribute without\nRTE_FLOW_PORT_FLAG_STRICT_QUEUE, RTE_ETH_EVENT_FLOW_AGED event will be\ntriggered at least one new aged out flow was detected on any flow queue after\nthe last call to rte_flow_get_q_aged_flows.\nIn addition, the `queue_id` will be ignored.\nThis function can be called to get the aged flows asynchronously from the\nevent callback or synchronously regardless the event.\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue to query. Ignored when RTE_FLOW_PORT_FLAG_STRICT_QUEUE not set.\n* `contexts` [in, out]  -\nThe address of an array of pointers to the aged-out flows contexts.\n* `nb_contexts` [in]  -\nThe length of context array pointers.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. Initialized in case of\nerror only.\n\n# Returns\n\nif nb_contexts is 0, return the amount of all aged contexts.\nif nb_contexts is not 0 , return the amount of aged flows reported\nin the context array, otherwise negative errno value.\n\n# See also\n\n> [`rte_flow_action_age`]\n> [`RTE_ETH_EVENT_FLOW_AGED`]\n> [`rte_flow_port_flag`]"]
    pub fn rte_flow_get_q_aged_flows(
        port_id: u16,
        queue_id: u32,
        contexts: *mut *mut ::core::ffi::c_void,
        nb_contexts: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Specify indirect action object configuration"]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_indir_action_conf {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_indir_action_conf"]
        [::core::mem::size_of::<rte_flow_indir_action_conf>() - 4usize];
    ["Alignment of rte_flow_indir_action_conf"]
        [::core::mem::align_of::<rte_flow_indir_action_conf>() - 4usize];
};
impl rte_flow_indir_action_conf {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::core::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::core::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::core::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate an indirect action object that can be used in flow rules\nvia its handle.\nThe created object handle has single state and configuration\nacross all the flow rules using it.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `conf` [in]  -\nAction configuration for the indirect action object creation.\n* `action` [in]  -\nSpecific configuration of the indirect action object.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise and rte_errno is set\nto one of the error codes defined:\n- (ENODEV) if *port_id* invalid.\n- (ENOSYS) if underlying device does not support this functionality.\n- (EIO) if underlying device is removed.\n- (EINVAL) if *action* invalid.\n- (ENOTSUP) if *action* valid but unsupported."]
    pub fn rte_flow_action_handle_create(
        port_id: u16,
        conf: *const rte_flow_indir_action_conf,
        action: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_handle;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestroy indirect action by handle.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `handle` [in]  -\nHandle for the indirect action object to be destroyed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-ENOENT) if action pointed by *action* handle was not found.\n- (-EBUSY) if action pointed by *action* handle still used by some rules\nrte_errno is also set."]
    pub fn rte_flow_action_handle_destroy(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nUpdate in-place the action configuration and / or state pointed\nby action *handle* with the configuration provided as *update* argument.\nThe update of the action configuration effects all flow rules reusing\nthe action via *handle*.\nThe update general pointer provides the ability of partial updating.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `handle` [in]  -\nHandle for the indirect action object to be updated.\n* `update` [in]  -\nUpdate profile specification used to modify the action pointed by handle.\n*update* could be with the same type of the immediate action corresponding\nto the *handle* argument when creating, or a wrapper structure includes\naction configuration to be updated and bit fields to indicate the member\nof fields inside the action to update.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-EINVAL) if *update* invalid.\n- (-ENOTSUP) if *update* valid but unsupported.\n- (-ENOENT) if indirect action object pointed by *handle* was not found.\nrte_errno is also set."]
    pub fn rte_flow_action_handle_update(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        update: *const ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery the direct action by corresponding indirect action object handle.\nRetrieve action-specific data such as counters.\nData is gathered by special action which may be present/referenced in\nmore than one flow rule definition.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_COUNT`]\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `handle` [in]  -\nHandle for the action object to query.\n* `data` [in, out]  -\nPointer to storage for the associated query data type.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_action_handle_query(
        port_id: u16,
        handle: *const rte_flow_action_handle,
        data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Tunnel has a type and the key information."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_tunnel {
    #[doc = "Tunnel type, for example RTE_FLOW_ITEM_TYPE_VXLAN,\nRTE_FLOW_ITEM_TYPE_NVGRE etc."]
    pub type_: rte_flow_item_type::Type,
    #[doc = "< Tunnel identification."]
    pub tun_id: u64,
    pub anon1: rte_flow_tunnel__bindgen_ty_1,
    #[doc = "< Tunnel port source."]
    pub tp_src: rte_be16_t,
    #[doc = "< Tunnel port destination."]
    pub tp_dst: rte_be16_t,
    #[doc = "< Tunnel flags."]
    pub tun_flags: u16,
    #[doc = "< True for valid IPv6 fields. Otherwise IPv4."]
    pub is_ipv6: bool,
    #[doc = "< TOS for IPv4, TC for IPv6."]
    pub tos: u8,
    #[doc = "< TTL for IPv4, HL for IPv6."]
    pub ttl: u8,
    #[doc = "< Flow Label for IPv6."]
    pub label: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_tunnel__bindgen_ty_1 {
    pub ipv4: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1,
    pub ipv6: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< IPv4 source address."]
    pub src_addr: rte_be32_t,
    #[doc = "< IPv4 destination address."]
    pub dst_addr: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1::src_addr"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1, src_addr) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1::dst_addr"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1, dst_addr) - 4usize];
};
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< IPv6 source address."]
    pub src_addr: rte_ipv6_addr,
    #[doc = "< IPv6 destination address."]
    pub dst_addr: rte_ipv6_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2>() - 32usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2>() - 1usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2::src_addr"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2, src_addr) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2::dst_addr"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2, dst_addr) - 16usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1"]
        [::core::mem::size_of::<rte_flow_tunnel__bindgen_ty_1>() - 32usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1"]
        [::core::mem::align_of::<rte_flow_tunnel__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1::ipv4"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1, ipv4) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1::ipv6"]
        [::core::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1, ipv6) - 0usize];
};
impl Default for rte_flow_tunnel__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel"][::core::mem::size_of::<rte_flow_tunnel>() - 64usize];
    ["Alignment of rte_flow_tunnel"][::core::mem::align_of::<rte_flow_tunnel>() - 8usize];
    ["Offset of field: rte_flow_tunnel::type_"]
        [::core::mem::offset_of!(rte_flow_tunnel, type_) - 0usize];
    ["Offset of field: rte_flow_tunnel::tun_id"]
        [::core::mem::offset_of!(rte_flow_tunnel, tun_id) - 8usize];
    ["Offset of field: rte_flow_tunnel::tp_src"]
        [::core::mem::offset_of!(rte_flow_tunnel, tp_src) - 48usize];
    ["Offset of field: rte_flow_tunnel::tp_dst"]
        [::core::mem::offset_of!(rte_flow_tunnel, tp_dst) - 50usize];
    ["Offset of field: rte_flow_tunnel::tun_flags"]
        [::core::mem::offset_of!(rte_flow_tunnel, tun_flags) - 52usize];
    ["Offset of field: rte_flow_tunnel::is_ipv6"]
        [::core::mem::offset_of!(rte_flow_tunnel, is_ipv6) - 54usize];
    ["Offset of field: rte_flow_tunnel::tos"]
        [::core::mem::offset_of!(rte_flow_tunnel, tos) - 55usize];
    ["Offset of field: rte_flow_tunnel::ttl"]
        [::core::mem::offset_of!(rte_flow_tunnel, ttl) - 56usize];
    ["Offset of field: rte_flow_tunnel::label"]
        [::core::mem::offset_of!(rte_flow_tunnel, label) - 60usize];
};
impl Default for rte_flow_tunnel {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Restore information structure to communicate the current packet processing\nstate when some of the processing pipeline is done in hardware and should\ncontinue in software."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_restore_info {
    #[doc = "Bitwise flags (RTE_FLOW_RESTORE_INFO_*) to indicate validation of\nother fields in struct rte_flow_restore_info."]
    pub flags: u64,
    #[doc = "< Group ID where packed missed"]
    pub group_id: u32,
    #[doc = "< Tunnel information."]
    pub tunnel: rte_flow_tunnel,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_restore_info"][::core::mem::size_of::<rte_flow_restore_info>() - 80usize];
    ["Alignment of rte_flow_restore_info"]
        [::core::mem::align_of::<rte_flow_restore_info>() - 8usize];
    ["Offset of field: rte_flow_restore_info::flags"]
        [::core::mem::offset_of!(rte_flow_restore_info, flags) - 0usize];
    ["Offset of field: rte_flow_restore_info::group_id"]
        [::core::mem::offset_of!(rte_flow_restore_info, group_id) - 8usize];
    ["Offset of field: rte_flow_restore_info::tunnel"]
        [::core::mem::offset_of!(rte_flow_restore_info, tunnel) - 16usize];
};
impl Default for rte_flow_restore_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Allocate an array of actions to be used in rte_flow_create, to implement\ntunnel-decap-set for the given tunnel.\nSample usage:\nactions vxlan_decap / tunnel-decap-set(tunnel properties) /\njump group 0 / end\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `tunnel` [in]  -\nTunnel properties.\n* `actions` [out]  -\nArray of actions to be allocated by the PMD. This array should be\nconcatenated with the actions array provided to rte_flow_create.\n* `num_of_actions` [out]  -\nNumber of actions allocated.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_decap_set(
        port_id: u16,
        tunnel: *mut rte_flow_tunnel,
        actions: *mut *mut rte_flow_action,
        num_of_actions: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Allocate an array of items to be used in rte_flow_create, to implement\ntunnel-match for the given tunnel.\nSample usage:\npattern tunnel-match(tunnel properties) / outer-header-matches /\ninner-header-matches / end\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `tunnel` [in]  -\nTunnel properties.\n* `items` [out]  -\nArray of items to be allocated by the PMD. This array should be\nconcatenated with the items array provided to rte_flow_create.\n* `num_of_items` [out]  -\nNumber of items allocated.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_match(
        port_id: u16,
        tunnel: *mut rte_flow_tunnel,
        items: *mut *mut rte_flow_item,
        num_of_items: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "On reception of a mbuf from HW, a call to rte_flow_get_restore_info() may be\nrequired to retrieve some metadata.\nThis function returns the associated mbuf ol_flags.\nNote: the dynamic flag is registered during a call to\nrte_eth_rx_metadata_negotiate() with RTE_ETH_RX_METADATA_TUNNEL_ID.\n\n# Returns\n\nThe offload flag indicating rte_flow_get_restore_info() must be called."]
    pub fn rte_flow_restore_info_dynflag() -> u64;
}
unsafe extern "C" {
    #[doc = "If a mbuf contains the rte_flow_restore_info_dynflag() flag in ol_flags,\npopulate the current packet processing state.\nOne should negotiate tunnel metadata delivery from the NIC to the HW.\n\n# See also\n\n> [`rte_eth_rx_metadata_negotiate()`]\n> [`RTE_ETH_RX_METADATA_TUNNEL_ID`]\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `m` [in]  -\nMbuf struct.\n* `info` [out]  -\nRestore information. Upon success contains the HW state.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_get_restore_info(
        port_id: u16,
        m: *mut rte_mbuf,
        info: *mut rte_flow_restore_info,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Release the action array as allocated by rte_flow_tunnel_decap_set.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `actions` [in]  -\nArray of actions to be released.\n* `num_of_actions` [in]  -\nNumber of elements in actions array.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_action_decap_release(
        port_id: u16,
        actions: *mut rte_flow_action,
        num_of_actions: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Release the item array as allocated by rte_flow_tunnel_match.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `items` [in]  -\nArray of items to be released.\n* `num_of_items` [in]  -\nNumber of elements in item array.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_item_release(
        port_id: u16,
        items: *mut rte_flow_item,
        num_of_items: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get a proxy port to manage \"transfer\" flows.\nManaging \"transfer\" flows requires that the user communicate them\nvia a port which has the privilege to control the embedded switch.\nFor some vendors, all ports in a given switching domain have\nthis privilege. For other vendors, it's only one port.\nThis API indicates such a privileged port (a \"proxy\")\nfor a given port in the same switching domain.\n> **Note** If the PMD serving `port_id` doesn't have the corresponding method\nimplemented, the API will return `port_id` via `proxy_port_id.`\n\n# Arguments\n\n* `port_id` -\nIndicates the port to get a \"proxy\" for\n* `proxy_port_id` [out]  -\nIndicates the \"proxy\" port\n* `error` [out]  -\nIf not NULL, allows the PMD to provide verbose report in case of error\n\n# Returns\n\n0 on success, a negative error code otherwise"]
    pub fn rte_flow_pick_transfer_proxy(
        port_id: u16,
        proxy_port_id: *mut u16,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate the flex item with specified configuration over\nthe Ethernet device.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `conf` [in]  -\nItem configuration.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\nNon-NULL opaque pointer on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_flex_item_create(
        port_id: u16,
        conf: *const rte_flow_item_flex_conf,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_item_flex_handle;
}
unsafe extern "C" {
    #[doc = "Release the flex item on the specified Ethernet device.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `handle` [in]  -\nHandle of the item existing on the specified device.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_flex_item_release(
        port_id: u16,
        handle: *const rte_flow_item_flex_handle,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nInformation about flow engine resources.\nThe zero value means a resource is not supported."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_port_info {
    #[doc = "Maximum number of queues for asynchronous operations."]
    pub max_nb_queues: u32,
    #[doc = "Maximum number of counters.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_COUNT`]"]
    pub max_nb_counters: u32,
    #[doc = "Maximum number of aging objects.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_AGE`]"]
    pub max_nb_aging_objects: u32,
    #[doc = "Maximum number traffic meters.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_METER`]"]
    pub max_nb_meters: u32,
    #[doc = "Maximum number connection trackings.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_CONNTRACK`]"]
    pub max_nb_conn_tracks: u32,
    #[doc = "Maximum number of quota actions.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_QUOTA`]"]
    pub max_nb_quotas: u32,
    #[doc = "Port supported flags (RTE_FLOW_PORT_FLAG_*)."]
    pub supported_flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_port_info"][::core::mem::size_of::<rte_flow_port_info>() - 28usize];
    ["Alignment of rte_flow_port_info"][::core::mem::align_of::<rte_flow_port_info>() - 4usize];
    ["Offset of field: rte_flow_port_info::max_nb_queues"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_queues) - 0usize];
    ["Offset of field: rte_flow_port_info::max_nb_counters"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_counters) - 4usize];
    ["Offset of field: rte_flow_port_info::max_nb_aging_objects"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_aging_objects) - 8usize];
    ["Offset of field: rte_flow_port_info::max_nb_meters"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_meters) - 12usize];
    ["Offset of field: rte_flow_port_info::max_nb_conn_tracks"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_conn_tracks) - 16usize];
    ["Offset of field: rte_flow_port_info::max_nb_quotas"]
        [::core::mem::offset_of!(rte_flow_port_info, max_nb_quotas) - 20usize];
    ["Offset of field: rte_flow_port_info::supported_flags"]
        [::core::mem::offset_of!(rte_flow_port_info, supported_flags) - 24usize];
};
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nInformation about flow engine asynchronous queues.\nThe value only valid if `port_attr.max_nb_queues` is not zero."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_queue_info {
    #[doc = "Maximum number of operations a queue can hold."]
    pub max_size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_queue_info"][::core::mem::size_of::<rte_flow_queue_info>() - 4usize];
    ["Alignment of rte_flow_queue_info"][::core::mem::align_of::<rte_flow_queue_info>() - 4usize];
    ["Offset of field: rte_flow_queue_info::max_size"]
        [::core::mem::offset_of!(rte_flow_queue_info, max_size) - 0usize];
};
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nGet information about flow engine resources.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `port_info` [out]  -\nA pointer to a structure of type *rte_flow_port_info*\nto be filled with the resources information of the port.\n* `queue_info` [out]  -\nA pointer to a structure of type *rte_flow_queue_info*\nto be filled with the asynchronous queues information.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_info_get(
        port_id: u16,
        port_info: *mut rte_flow_port_info,
        queue_info: *mut rte_flow_queue_info,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nFlow engine resources settings.\nThe zero value means on demand resource allocations only."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_port_attr {
    #[doc = "Number of counters to configure.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_COUNT`]"]
    pub nb_counters: u32,
    #[doc = "Number of aging objects to configure.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_AGE`]"]
    pub nb_aging_objects: u32,
    #[doc = "Number of traffic meters to configure.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_METER`]"]
    pub nb_meters: u32,
    #[doc = "Number of connection trackings to configure.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_CONNTRACK`]"]
    pub nb_conn_tracks: u32,
    #[doc = "Port to base shared objects on."]
    pub host_port_id: u16,
    #[doc = "Maximum number of quota actions.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_QUOTA`]"]
    pub nb_quotas: u32,
    #[doc = "Port flags (RTE_FLOW_PORT_FLAG_*)."]
    pub flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_port_attr"][::core::mem::size_of::<rte_flow_port_attr>() - 28usize];
    ["Alignment of rte_flow_port_attr"][::core::mem::align_of::<rte_flow_port_attr>() - 4usize];
    ["Offset of field: rte_flow_port_attr::nb_counters"]
        [::core::mem::offset_of!(rte_flow_port_attr, nb_counters) - 0usize];
    ["Offset of field: rte_flow_port_attr::nb_aging_objects"]
        [::core::mem::offset_of!(rte_flow_port_attr, nb_aging_objects) - 4usize];
    ["Offset of field: rte_flow_port_attr::nb_meters"]
        [::core::mem::offset_of!(rte_flow_port_attr, nb_meters) - 8usize];
    ["Offset of field: rte_flow_port_attr::nb_conn_tracks"]
        [::core::mem::offset_of!(rte_flow_port_attr, nb_conn_tracks) - 12usize];
    ["Offset of field: rte_flow_port_attr::host_port_id"]
        [::core::mem::offset_of!(rte_flow_port_attr, host_port_id) - 16usize];
    ["Offset of field: rte_flow_port_attr::nb_quotas"]
        [::core::mem::offset_of!(rte_flow_port_attr, nb_quotas) - 20usize];
    ["Offset of field: rte_flow_port_attr::flags"]
        [::core::mem::offset_of!(rte_flow_port_attr, flags) - 24usize];
};
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nFlow engine asynchronous queues settings.\nThe value means default value picked by PMD."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_queue_attr {
    #[doc = "Number of flow rule operations a queue can hold."]
    pub size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_queue_attr"][::core::mem::size_of::<rte_flow_queue_attr>() - 4usize];
    ["Alignment of rte_flow_queue_attr"][::core::mem::align_of::<rte_flow_queue_attr>() - 4usize];
    ["Offset of field: rte_flow_queue_attr::size"]
        [::core::mem::offset_of!(rte_flow_queue_attr, size) - 0usize];
};
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nConfigure the port's flow API engine.\nThis API can only be invoked before the application\nstarts using the rest of the flow library functions.\nThe API can be invoked multiple times to change the settings.\nThe port, however, may reject changes and keep the old config.\nParameters in configuration attributes must not exceed\nnumbers of resources returned by the rte_flow_info_get API.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `port_attr` [in]  -\nPort configuration attributes.\n* `nb_queue` [in]  -\nNumber of flow queues to be configured.\n* `queue_attr` [in]  -\nArray that holds attributes for each flow queue.\nNumber of elements is set in `port_attr.nb_queues.`\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_configure(
        port_id: u16,
        port_attr: *const rte_flow_port_attr,
        nb_queue: u16,
        queue_attr: *mut *const rte_flow_queue_attr,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Opaque type returned after successful creation of pattern template.\nThis handle can be used to manage the created pattern template."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_pattern_template {
    _unused: [u8; 0],
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nFlow pattern template attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_pattern_template_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_pattern_template_attr"]
        [::core::mem::size_of::<rte_flow_pattern_template_attr>() - 4usize];
    ["Alignment of rte_flow_pattern_template_attr"]
        [::core::mem::align_of::<rte_flow_pattern_template_attr>() - 4usize];
};
impl rte_flow_pattern_template_attr {
    #[inline]
    pub fn relaxed_matching(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_relaxed_matching(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn relaxed_matching_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_relaxed_matching_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        relaxed_matching: u32,
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let relaxed_matching: u32 = unsafe { ::core::mem::transmute(relaxed_matching) };
            relaxed_matching as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let ingress: u32 = unsafe { ::core::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let egress: u32 = unsafe { ::core::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let transfer: u32 = unsafe { ::core::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate flow pattern template.\nThe pattern template defines common matching fields without values.\nFor example, matching on 5 tuple TCP flow, the template will be\neth(null) + IPv4(source + dest) + TCP(s_port + d_port),\nwhile values for each rule will be set during the flow rule creation.\nThe number and order of items in the template must be the same\nat the rule creation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `template_attr` [in]  -\nPattern template attributes.\n* `pattern` [in]  -\nPattern specification (list terminated by the END pattern item).\nThe spec member of an item is not used unless the end member is used.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_pattern_template_create(
        port_id: u16,
        template_attr: *const rte_flow_pattern_template_attr,
        pattern: *const rte_flow_item,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_pattern_template;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestroy flow pattern template.\nThis function may be called only when\nthere are no more tables referencing this template.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `pattern_template` [in]  -\nHandle of the template to be destroyed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_pattern_template_destroy(
        port_id: u16,
        pattern_template: *mut rte_flow_pattern_template,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Opaque type returned after successful creation of actions template.\nThis handle can be used to manage the created actions template."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_actions_template {
    _unused: [u8; 0],
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nFlow actions template attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_actions_template_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_actions_template_attr"]
        [::core::mem::size_of::<rte_flow_actions_template_attr>() - 4usize];
    ["Alignment of rte_flow_actions_template_attr"]
        [::core::mem::align_of::<rte_flow_actions_template_attr>() - 4usize];
};
impl rte_flow_actions_template_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::core::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::core::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::core::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate flow actions template.\nThe actions template holds a list of action types without values.\nFor example, the template to change TCP ports is TCP(s_port + d_port),\nwhile values for each rule will be set during the flow rule creation.\nThe number and order of actions in the template must be the same\nat the rule creation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `template_attr` [in]  -\nTemplate attributes.\n* `actions` [in]  -\nAssociated actions (list terminated by the END action).\nThe spec member is only used if `masks` spec is non-zero.\n* `masks` [in]  -\nList of actions that marks which of the action's member is constant.\nA mask has the same format as the corresponding action.\nIf the action field in `masks` is not 0,\nthe corresponding value in an action from `actions` will be the part\nof the template and used in all flow rules.\nThe order of actions in `masks` is the same as in `actions.`\nIn case of indirect actions present in `actions,`\nthe actual action type should be present in `mask.`\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_actions_template_create(
        port_id: u16,
        template_attr: *const rte_flow_actions_template_attr,
        actions: *const rte_flow_action,
        masks: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_actions_template;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestroy flow actions template.\nThis function may be called only when\nthere are no more tables referencing this template.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `actions_template` [in]  -\nHandle to the template to be destroyed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_actions_template_destroy(
        port_id: u16,
        actions_template: *mut rte_flow_actions_template,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Opaque type returned after successful creation of a template table.\nThis handle can be used to manage the created template table."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_template_table {
    _unused: [u8; 0],
}
pub mod rte_flow_table_insertion_type {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nTemplate table flow rules insertion type."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Pattern-based insertion."]
    pub const RTE_FLOW_TABLE_INSERTION_TYPE_PATTERN: Type = 0;
    #[doc = "Index-based insertion."]
    pub const RTE_FLOW_TABLE_INSERTION_TYPE_INDEX: Type = 1;
    #[doc = "Index-based insertion with pattern."]
    pub const RTE_FLOW_TABLE_INSERTION_TYPE_INDEX_WITH_PATTERN: Type = 2;
}
pub mod rte_flow_table_hash_func {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nTemplate table hash index calculation function."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Default hash calculation."]
    pub const RTE_FLOW_TABLE_HASH_FUNC_DEFAULT: Type = 0;
    #[doc = "Linear hash calculation."]
    pub const RTE_FLOW_TABLE_HASH_FUNC_LINEAR: Type = 1;
    #[doc = "32-bit checksum hash calculation."]
    pub const RTE_FLOW_TABLE_HASH_FUNC_CRC32: Type = 2;
    #[doc = "16-bit checksum hash calculation."]
    pub const RTE_FLOW_TABLE_HASH_FUNC_CRC16: Type = 3;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nTable attributes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_template_table_attr {
    #[doc = "Flow attributes to be used in each rule generated from this table."]
    pub flow_attr: rte_flow_attr,
    #[doc = "Maximum number of flow rules that this table holds."]
    pub nb_flows: u32,
    #[doc = "Optional hint flags for driver optimization.\nThe effect may vary in the different drivers.\nThe functionality must not rely on the hints.\nValue is composed with RTE_FLOW_TABLE_SPECIALIZE_* based on application\ndesign choices.\nMisused hints may mislead the driver, it may result in an undefined behavior."]
    pub specialize: u32,
    #[doc = "Insertion type for flow rules."]
    pub insertion_type: rte_flow_table_insertion_type::Type,
    #[doc = "Hash calculation function for the packet matching."]
    pub hash_func: rte_flow_table_hash_func::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_template_table_attr"]
        [::core::mem::size_of::<rte_flow_template_table_attr>() - 28usize];
    ["Alignment of rte_flow_template_table_attr"]
        [::core::mem::align_of::<rte_flow_template_table_attr>() - 4usize];
    ["Offset of field: rte_flow_template_table_attr::flow_attr"]
        [::core::mem::offset_of!(rte_flow_template_table_attr, flow_attr) - 0usize];
    ["Offset of field: rte_flow_template_table_attr::nb_flows"]
        [::core::mem::offset_of!(rte_flow_template_table_attr, nb_flows) - 12usize];
    ["Offset of field: rte_flow_template_table_attr::specialize"]
        [::core::mem::offset_of!(rte_flow_template_table_attr, specialize) - 16usize];
    ["Offset of field: rte_flow_template_table_attr::insertion_type"]
        [::core::mem::offset_of!(rte_flow_template_table_attr, insertion_type) - 20usize];
    ["Offset of field: rte_flow_template_table_attr::hash_func"]
        [::core::mem::offset_of!(rte_flow_template_table_attr, hash_func) - 24usize];
};
impl Default for rte_flow_template_table_attr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery whether a table can be resized.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `tbl_attr` -\nTemplate table.\n\n# Returns\n\nTrue if the table can be resized."]
    pub fn rte_flow_template_table_resizable(
        port_id: u16,
        tbl_attr: *const rte_flow_template_table_attr,
    ) -> bool;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate flow template table.\nA template table consists of multiple pattern templates and actions\ntemplates associated with a single set of rule attributes (group ID,\npriority and traffic direction).\nEach rule is free to use any combination of pattern and actions templates\nand specify particular values for items and actions it would like to change.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `table_attr` [in]  -\nTemplate table attributes.\n* `pattern_templates` [in]  -\nArray of pattern templates to be used in this table.\n* `nb_pattern_templates` [in]  -\nThe number of pattern templates in the pattern_templates array.\n* `actions_templates` [in]  -\nArray of actions templates to be used in this table.\n* `nb_actions_templates` [in]  -\nThe number of actions templates in the actions_templates array.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_template_table_create(
        port_id: u16,
        table_attr: *const rte_flow_template_table_attr,
        pattern_templates: *mut *mut rte_flow_pattern_template,
        nb_pattern_templates: u8,
        actions_templates: *mut *mut rte_flow_actions_template,
        nb_actions_templates: u8,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_template_table;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestroy flow template table.\nThis function may be called only when\nthere are no more flow rules referencing this table.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `template_table` [in]  -\nHandle to the table to be destroyed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_template_table_destroy(
        port_id: u16,
        template_table: *mut rte_flow_template_table,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSet group miss actions.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `group_id` -\nIdentifier of a group to set miss actions for.\n* `attr` -\nGroup attributes.\n* `actions` -\nList of group miss actions.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_group_set_miss_actions(
        port_id: u16,
        group_id: u32,
        attr: *const rte_flow_group_attr,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nAsynchronous operation attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_op_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_op_attr"][::core::mem::size_of::<rte_flow_op_attr>() - 4usize];
    ["Alignment of rte_flow_op_attr"][::core::mem::align_of::<rte_flow_op_attr>() - 4usize];
};
impl rte_flow_op_attr {
    #[inline]
    pub fn postpone(&self) -> u32 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_postpone(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn postpone_raw(this: *const Self) -> u32 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_postpone_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(postpone: u32) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let postpone: u32 = unsafe { ::core::mem::transmute(postpone) };
            postpone as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue rule creation operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue used to insert the rule.\n* `op_attr` [in]  -\nRule creation operation attributes.\n* `template_table` [in]  -\nTemplate table to select templates from.\n* `pattern` [in]  -\nList of pattern items to be used.\nThe list order should match the order in the pattern template.\nThe spec is the only relevant member of the item that is being used.\n* `pattern_template_index` [in]  -\nPattern template index in the table.\n* `actions` [in]  -\nList of actions to be used.\nThe list order should match the order in the actions template.\n* `actions_template_index` [in]  -\nActions template index in the table.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set.\nThe rule handle doesn't mean that the rule has been populated.\nOnly completion result indicates that if there was success or failure."]
    pub fn rte_flow_async_create(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        template_table: *mut rte_flow_template_table,
        pattern: *const rte_flow_item,
        pattern_template_index: u8,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue rule creation operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue used to insert the rule.\n* `op_attr` [in]  -\nRule creation operation attributes.\n* `template_table` [in]  -\nTemplate table to select templates from.\n* `rule_index` [in]  -\nRule index in the table.\n* `actions` [in]  -\nList of actions to be used.\nThe list order should match the order in the actions template.\n* `actions_template_index` [in]  -\nActions template index in the table.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set.\nThe rule handle doesn't mean that the rule has been populated.\nOnly completion result indicates that if there was success or failure."]
    pub fn rte_flow_async_create_by_index(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        template_table: *mut rte_flow_template_table,
        rule_index: u32,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue rule creation by index with pattern operation.\nPackets are only matched if there is a rule inserted at the index.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue used to insert the rule.\n* `op_attr` [in]  -\nRule creation operation attributes.\n* `template_table` [in]  -\nTemplate table to select templates from.\n* `rule_index` [in]  -\nRule index in the table.\nInserting a rule to already occupied index results in undefined behavior.\n* `pattern` [in]  -\nList of pattern items to be used.\nThe list order should match the order in the pattern template.\nThe spec is the only relevant member of the item that is being used.\n* `pattern_template_index` [in]  -\nPattern template index in the table.\n* `actions` [in]  -\nList of actions to be used.\nThe list order should match the order in the actions template.\n* `actions_template_index` [in]  -\nActions template index in the table.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nHandle on success, NULL otherwise and rte_errno is set.\nThe rule handle doesn't mean that the rule has been populated.\nOnly completion result indicates that if there was success or failure."]
    pub fn rte_flow_async_create_by_index_with_pattern(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        template_table: *mut rte_flow_template_table,
        rule_index: u32,
        pattern: *const rte_flow_item,
        pattern_template_index: u8,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue rule destruction operation.\nThis function enqueues a destruction operation on the queue.\nApplication should assume that after calling this function\nthe rule handle is not valid anymore.\nCompletion indicates the full removal of the rule from the HW.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue which is used to destroy the rule.\nThis must match the queue on which the rule was created.\n* `op_attr` [in]  -\nRule destruction operation attributes.\n* `flow` [in]  -\nFlow handle to be destroyed.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        flow: *mut rte_flow,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue rule update operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue used to insert the rule.\n* `op_attr` [in]  -\nRule creation operation attributes.\n* `flow` [in]  -\nFlow rule to be updated.\n* `actions` [in]  -\nList of actions to be used.\nThe list order should match the order in the actions template.\n* `actions_template_index` [in]  -\nActions template index in the table.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_actions_update(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        flow: *mut rte_flow,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nPush all internally stored rules to the HW.\nPostponed rules are rules that were inserted with the postpone flag set.\nCan be used to notify the HW about batch of rules prepared by the SW to\nreduce the number of communications between the HW and SW.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue to be pushed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_push(
        port_id: u16,
        queue_id: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
pub mod rte_flow_op_status {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nAsynchronous operation status."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "The operation was completed successfully."]
    pub const RTE_FLOW_OP_SUCCESS: Type = 0;
    #[doc = "The operation was not completed successfully."]
    pub const RTE_FLOW_OP_ERROR: Type = 1;
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nAsynchronous operation result."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_op_result {
    #[doc = "Returns the status of the operation that this completion signals."]
    pub status: rte_flow_op_status::Type,
    #[doc = "The user data that will be returned on the completion events."]
    pub user_data: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_op_result"][::core::mem::size_of::<rte_flow_op_result>() - 16usize];
    ["Alignment of rte_flow_op_result"][::core::mem::align_of::<rte_flow_op_result>() - 8usize];
    ["Offset of field: rte_flow_op_result::status"]
        [::core::mem::offset_of!(rte_flow_op_result, status) - 0usize];
    ["Offset of field: rte_flow_op_result::user_data"]
        [::core::mem::offset_of!(rte_flow_op_result, user_data) - 8usize];
};
impl Default for rte_flow_op_result {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nPull a rte flow operation.\nThe application must invoke this function in order to complete\nthe flow rule offloading and to retrieve the flow rule operation status.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue which is used to pull the operation.\n* `res` [out]  -\nArray of results that will be set.\n* `n_res` [in]  -\nMaximum number of results that can be returned.\nThis value is equal to the size of the res array.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nNumber of results that were pulled,\na negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_pull(
        port_id: u16,
        queue_id: u32,
        res: *mut rte_flow_op_result,
        n_res: u16,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue indirect action creation operation.\n\n# See also\n\n> [`rte_flow_action_handle_create`]\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to create the rule.\n* `op_attr` [in]  -\nIndirect action creation operation attributes.\n* `indir_action_conf` [in]  -\nAction configuration for the indirect action object creation.\n* `action` [in]  -\nSpecific configuration of the indirect action object.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_create(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        indir_action_conf: *const rte_flow_indir_action_conf,
        action: *const rte_flow_action,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_handle;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue indirect action destruction operation.\nThe destroy queue must be the same\nas the queue on which the action was created.\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to destroy the rule.\n* `op_attr` [in]  -\nIndirect action destruction operation attributes.\n* `action_handle` [in]  -\nHandle for the indirect action object to be destroyed.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *mut rte_flow_action_handle,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue indirect action update operation.\n\n# See also\n\n> [`rte_flow_action_handle_create`]\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to update the rule.\n* `op_attr` [in]  -\nIndirect action update operation attributes.\n* `action_handle` [in]  -\nHandle for the indirect action object to be updated.\n* `update` [in]  -\nUpdate profile specification used to modify the action pointed by handle.\n*update* could be with the same type of the immediate action corresponding\nto the *handle* argument when creating, or a wrapper structure includes\naction configuration to be updated and bit fields to indicate the member\nof fields inside the action to update.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_update(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *mut rte_flow_action_handle,
        update: *const ::core::ffi::c_void,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue indirect action query operation.\nRetrieve action-specific data such as counters.\nData is gathered by special action which may be present/referenced in\nmore than one flow rule definition.\nData will be available only when completion event returns.\n\n# See also\n\n> [`rte_flow_async_action_handle_query`]\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to query the action.\n* `op_attr` [in]  -\nIndirect action update operation attributes.\n* `action_handle` [in]  -\nHandle for the action object to query.\n* `data` [in, out]  -\nPointer to storage for the associated query data type.\nThe out data will be available only when completion event returns\nfrom rte_flow_pull.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_query(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *const rte_flow_action_handle,
        data: *mut ::core::ffi::c_void,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
pub mod rte_flow_query_update_mode {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery and update operational mode.\n\n# See also\n\n> [`rte_flow_action_handle_query_update()`]\n> [`rte_flow_async_action_handle_query_update()`]"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Query before update."]
    pub const RTE_FLOW_QU_QUERY_FIRST: Type = 1;
    #[doc = "< Query after  update."]
    pub const RTE_FLOW_QU_UPDATE_FIRST: Type = 2;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery and/or update indirect flow action.\nIf both query and update not NULL, the function atomically\nqueries and updates indirect action. Query and update are carried in order\nspecified in the mode parameter.\nIf ether query or update is NULL, the function executes\ncomplementing operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `handle` -\nHandle for the indirect action object to be updated.\n* `update` -\nIf not NULL, update profile specification used to modify the action\npointed by handle.\n* `query` -\nIf not NULL pointer to storage for the associated query data type.\n* `mode` -\nOperational mode.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *handle* or *mode* invalid or\nboth *query* and *update* are NULL."]
    pub fn rte_flow_action_handle_query_update(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        update: *const ::core::ffi::c_void,
        query: *mut ::core::ffi::c_void,
        mode: rte_flow_query_update_mode::Type,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue async indirect flow action query and/or update\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue which is used to update the rule.\n* `attr` -\nIndirect action update operation attributes.\n* `handle` -\nHandle for the indirect action object to be updated.\n* `update` -\nIf not NULL, update profile specification used to modify the action\npointed by handle.\n* `query` -\nIf not NULL, pointer to storage for the associated query data type.\nQuery result returned on async completion event.\n* `mode` -\nOperational mode.\n* `user_data` -\nThe user data that will be returned on async completion event.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *handle* or *mode* invalid or\nboth *update* and *query* are NULL."]
    pub fn rte_flow_async_action_handle_query_update(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        handle: *mut rte_flow_action_handle,
        update: *const ::core::ffi::c_void,
        query: *mut ::core::ffi::c_void,
        mode: rte_flow_query_update_mode::Type,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_list_handle {
    _unused: [u8; 0],
}
#[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nConfigure INDIRECT_LIST flow action.\n\n# See also\n\n> [`RTE_FLOW_ACTION_TYPE_INDIRECT_LIST`]"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_indirect_list {
    #[doc = "Indirect action list handle"]
    pub handle: *mut rte_flow_action_list_handle,
    #[doc = "Flow mutable configuration array.\nNULL if the handle has no flow mutable configuration update.\nOtherwise, if the handle was created with list A1 / A2 .. An / END\nsize of conf is n.\nconf[i] points to flow mutable update of Ai in the handle\nactions list or NULL if Ai has no update."]
    pub conf: *mut *const ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action_indirect_list"]
        [::core::mem::size_of::<rte_flow_action_indirect_list>() - 16usize];
    ["Alignment of rte_flow_action_indirect_list"]
        [::core::mem::align_of::<rte_flow_action_indirect_list>() - 8usize];
    ["Offset of field: rte_flow_action_indirect_list::handle"]
        [::core::mem::offset_of!(rte_flow_action_indirect_list, handle) - 0usize];
    ["Offset of field: rte_flow_action_indirect_list::conf"]
        [::core::mem::offset_of!(rte_flow_action_indirect_list, conf) - 8usize];
};
impl Default for rte_flow_action_indirect_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCreate an indirect flow action object from flow actions list.\nThe object is identified by a unique handle.\nThe handle has single state and configuration\nacross all the flow rules using it.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `conf` [in]  -\nAction configuration for the indirect action list creation.\n* `actions` [in]  -\nSpecific configuration of the indirect action lists.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise and rte_errno is set\nto one of the error codes defined:\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-EINVAL) if *actions* list invalid.\n- (-ENOTSUP) if *action* list element valid but unsupported."]
    pub fn rte_flow_action_list_handle_create(
        port_id: u16,
        conf: *const rte_flow_indir_action_conf,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_list_handle;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nAsync function call to create an indirect flow action object\nfrom flow actions list.\nThe object is identified by a unique handle.\nThe handle has single state and configuration\nacross all the flow rules using it.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to update the rule.\n* `attr` [in]  -\nIndirect action update operation attributes.\n* `conf` [in]  -\nAction configuration for the indirect action list creation.\n* `actions` [in]  -\nSpecific configuration of the indirect action list.\n* `user_data` [in]  -\nThe user data that will be returned on async completion event.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise and rte_errno is set\nto one of the error codes defined:\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-EINVAL) if *actions* list invalid.\n- (-ENOTSUP) if *action* list element valid but unsupported."]
    pub fn rte_flow_async_action_list_handle_create(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        conf: *const rte_flow_indir_action_conf,
        actions: *const rte_flow_action,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_list_handle;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestroy indirect actions list by handle.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `handle` [in]  -\nHandle for the indirect actions list to be destroyed.\n* `error` [out]  -\nPerform verbose error reporting if not NULL. PMDs initialize this\nstructure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-ENOENT) if actions list pointed by *action* handle was not found.\n- (-EBUSY) if actions list pointed by *action* handle still used"]
    pub fn rte_flow_action_list_handle_destroy(
        port_id: u16,
        handle: *mut rte_flow_action_list_handle,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue indirect action list destruction operation.\nThe destroy queue must be the same\nas the queue on which the action was created.\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `queue_id` [in]  -\nFlow queue which is used to destroy the rule.\n* `op_attr` [in]  -\nIndirect action destruction operation attributes.\n* `handle` [in]  -\nHandle for the indirect action object to be destroyed.\n* `user_data` [in]  -\nThe user data that will be returned on the completion events.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOSYS) if underlying device does not support this functionality.\n- (-EIO) if underlying device is removed.\n- (-ENOENT) if actions list pointed by *action* handle was not found.\n- (-EBUSY) if actions list pointed by *action* handle still used"]
    pub fn rte_flow_async_action_list_handle_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        handle: *mut rte_flow_action_list_handle,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nQuery and/or update indirect flow actions list.\nIf both query and update not NULL, the function atomically\nqueries and updates indirect action. Query and update are carried in order\nspecified in the mode parameter.\nIf ether query or update is NULL, the function executes\ncomplementing operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `handle` -\nHandle for the indirect actions list object to be updated.\n* `update` -\nIf the action list handle was created from n actions A1 / A2 ... An / END\nnon-NULL update parameter is an array [U1, U2, ... Un] where Ui points to\nAi update context or NULL if Ai should not be updated.\n* `query` -\nIf the action list handle was created from n actions A1 / A2 ... An / END\nnon-NULL query parameter is an array [Q1, Q2, ... Qn] where Qi points to\nAi query context or NULL if Ai should not be queried.\n* `mode` -\nOperational mode.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *handle* or *mode* invalid or\nboth *query* and *update* are NULL."]
    pub fn rte_flow_action_list_handle_query_update(
        port_id: u16,
        handle: *const rte_flow_action_list_handle,
        update: *mut *const ::core::ffi::c_void,
        query: *mut *mut ::core::ffi::c_void,
        mode: rte_flow_query_update_mode::Type,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nEnqueue async indirect flow actions list query and/or update\nIf both query and update not NULL, the function atomically\nqueries and updates indirect action. Query and update are carried in order\nspecified in the mode parameter.\nIf ether query or update is NULL, the function executes\ncomplementing operation.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue_id` -\nFlow queue which is used to update the rule.\n* `attr` -\nIndirect action update operation attributes.\n* `handle` -\nHandle for the indirect actions list object to be updated.\n* `update` -\nIf the action list handle was created from n actions A1 / A2 ... An / END\nnon-NULL update parameter is an array [U1, U2, ... Un] where Ui points to\nAi update context or NULL if Ai should not be updated.\n* `query` -\nIf the action list handle was created from n actions A1 / A2 ... An / END\nnon-NULL query parameter is an array [Q1, Q2, ... Qn] where Qi points to\nAi query context or NULL if Ai should not be queried.\nQuery result returned on async completion event.\n* `mode` -\nOperational mode.\n* `user_data` -\nThe user data that will be returned on async completion event.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *handle* or *mode* invalid or\nboth *update* and *query* are NULL."]
    pub fn rte_flow_async_action_list_handle_query_update(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        handle: *const rte_flow_action_list_handle,
        update: *mut *const ::core::ffi::c_void,
        query: *mut *mut ::core::ffi::c_void,
        mode: rte_flow_query_update_mode::Type,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nCalculate the hash for a given pattern in a given table as\ncalculated by the HW.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `table` -\nThe table the SW wishes to simulate.\n* `pattern` -\nThe values to be used in the hash calculation.\n* `pattern_template_index` -\nThe pattern index in the table to be used for the calculation.\n* `hash` -\nUsed to return the calculated hash.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality."]
    pub fn rte_flow_calc_table_hash(
        port_id: u16,
        table: *const rte_flow_template_table,
        pattern: *const rte_flow_item,
        pattern_template_index: u8,
        hash: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
pub mod rte_flow_encap_hash_field {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nDestination field type for the hash calculation, when encap action is used.\nThe encap field implies the size, meaning XXX_SRC_PORT hash len is 2 bytes,\nwhile XXX_NVGRE_FLOW_ID hash len is 1 byte.\n\n# See also\n\n> [`function`] rte_flow_calc_encap_hash"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Calculate hash placed in UDP source port field."]
    pub const RTE_FLOW_ENCAP_HASH_FIELD_SRC_PORT: Type = 0;
    #[doc = "Calculate hash placed in NVGRE flow ID field."]
    pub const RTE_FLOW_ENCAP_HASH_FIELD_NVGRE_FLOW_ID: Type = 1;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nSimulate HW hash calculation that is done when an encap action is being used.\nThis hash can be stored in tunnel outer header to improve packet distribution.\n\n# Arguments\n\n* `port_id` [in]  -\nPort identifier of Ethernet device.\n* `pattern` [in]  -\nThe values to be used in the hash calculation.\n* `dest_field` [in]  -\nType of destination field for hash calculation.\n* `hash_len` [in]  -\nThe length of the hash pointer in bytes. Should be according to dest_field.\n* `hash` [out]  -\nUsed to return the calculated hash. It will be written in network order,\nso hash[0] is the MSB.\nThe number of bytes is based on the destination field type.\n* `error` [out]  -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *pattern* doesn't hold enough information to calculate the hash\nor the dest is not supported."]
    pub fn rte_flow_calc_encap_hash(
        port_id: u16,
        pattern: *const rte_flow_item,
        dest_field: rte_flow_encap_hash_field::Type,
        hash_len: u8,
        hash: *mut u8,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nUpdate template table for new flow rules capacity.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `table` -\nTemplate table to modify.\n* `nb_rules` -\nNew flow rules capacity.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *table* is not resizable or\n*table* resize to *nb_rules* is not supported or\nunrecoverable *table* error."]
    pub fn rte_flow_template_table_resize(
        port_id: u16,
        table: *mut rte_flow_template_table,
        nb_rules: u32,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nUpdate *rule* for the new *table* configuration after table resize.\nMust be called for each *rule* created before *table* resize.\nIf called for *rule* created after *table* resize returns success.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `queue` -\nFlow queue for async operation.\n* `attr` -\nAsync operation attributes.\n* `rule` -\nFlow rule to update.\n* `user_data` -\nThe user data that will be returned on async completion event.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EINVAL) if *table* was not resized.\nIf *rule* cannot be updated after *table* resize,\nunrecoverable *table* error."]
    pub fn rte_flow_async_update_resized(
        port_id: u16,
        queue: u32,
        attr: *const rte_flow_op_attr,
        rule: *mut rte_flow,
        user_data: *mut ::core::ffi::c_void,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nResume normal operational mode after table was resized and\ntable rules were updated for the new table configuration.\n\n# Arguments\n\n* `port_id` -\nPort identifier of Ethernet device.\n* `table` -\nTemplate table that undergoing resize operation.\n* `error` -\nPerform verbose error reporting if not NULL.\nPMDs initialize this structure in case of error only.\n\n# Returns\n\n- (0) if success.\n- (-ENODEV) if *port_id* invalid.\n- (-ENOTSUP) if underlying device does not support this functionality.\n- (-EBUSY) if not all *table* rules were updated.\n- (-EINVAL) if *table* cannot complete table resize,\nunrecoverable error."]
    pub fn rte_flow_template_table_resize_complete(
        port_id: u16,
        table: *mut rte_flow_template_table,
        error: *mut rte_flow_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "A structure used to define the ntuple filter entry\nto support RTE_ETH_FILTER_NTUPLE data representation."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_ntuple_filter {
    #[doc = "< Flags from RTE_NTUPLE_FLAGS_*"]
    pub flags: u16,
    #[doc = "< Destination IP address in big endian."]
    pub dst_ip: u32,
    #[doc = "< Mask of destination IP address."]
    pub dst_ip_mask: u32,
    #[doc = "< Source IP address in big endian."]
    pub src_ip: u32,
    #[doc = "< Mask of destination IP address."]
    pub src_ip_mask: u32,
    #[doc = "< Destination port in big endian."]
    pub dst_port: u16,
    #[doc = "< Mask of destination port."]
    pub dst_port_mask: u16,
    #[doc = "< Source Port in big endian."]
    pub src_port: u16,
    #[doc = "< Mask of source port."]
    pub src_port_mask: u16,
    #[doc = "< L4 protocol."]
    pub proto: u8,
    #[doc = "< Mask of L4 protocol."]
    pub proto_mask: u8,
    #[doc = "tcp_flags only meaningful when the proto is TCP.\nThe packet matched above ntuple fields and contain\nany set bit in tcp_flags will hit this filter."]
    pub tcp_flags: u8,
    #[doc = "< seven levels (001b-111b), 111b is highest,\nused when more than one filter matches."]
    pub priority: u16,
    #[doc = "< Queue assigned to when match"]
    pub queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ntuple_filter"][::core::mem::size_of::<rte_eth_ntuple_filter>() - 36usize];
    ["Alignment of rte_eth_ntuple_filter"]
        [::core::mem::align_of::<rte_eth_ntuple_filter>() - 4usize];
    ["Offset of field: rte_eth_ntuple_filter::flags"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, flags) - 0usize];
    ["Offset of field: rte_eth_ntuple_filter::dst_ip"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, dst_ip) - 4usize];
    ["Offset of field: rte_eth_ntuple_filter::dst_ip_mask"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, dst_ip_mask) - 8usize];
    ["Offset of field: rte_eth_ntuple_filter::src_ip"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, src_ip) - 12usize];
    ["Offset of field: rte_eth_ntuple_filter::src_ip_mask"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, src_ip_mask) - 16usize];
    ["Offset of field: rte_eth_ntuple_filter::dst_port"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, dst_port) - 20usize];
    ["Offset of field: rte_eth_ntuple_filter::dst_port_mask"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, dst_port_mask) - 22usize];
    ["Offset of field: rte_eth_ntuple_filter::src_port"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, src_port) - 24usize];
    ["Offset of field: rte_eth_ntuple_filter::src_port_mask"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, src_port_mask) - 26usize];
    ["Offset of field: rte_eth_ntuple_filter::proto"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, proto) - 28usize];
    ["Offset of field: rte_eth_ntuple_filter::proto_mask"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, proto_mask) - 29usize];
    ["Offset of field: rte_eth_ntuple_filter::tcp_flags"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, tcp_flags) - 30usize];
    ["Offset of field: rte_eth_ntuple_filter::priority"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, priority) - 32usize];
    ["Offset of field: rte_eth_ntuple_filter::queue"]
        [::core::mem::offset_of!(rte_eth_ntuple_filter, queue) - 34usize];
};
pub mod rte_eth_input_set_field {
    #[doc = "Input set fields for Flow Director and Hash filters"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_INPUT_SET_UNKNOWN: Type = 0;
    #[doc = "L2"]
    pub const RTE_ETH_INPUT_SET_L2_SRC_MAC: Type = 1;
    #[doc = "L2"]
    pub const RTE_ETH_INPUT_SET_L2_DST_MAC: Type = 2;
    #[doc = "L2"]
    pub const RTE_ETH_INPUT_SET_L2_OUTER_VLAN: Type = 3;
    #[doc = "L2"]
    pub const RTE_ETH_INPUT_SET_L2_INNER_VLAN: Type = 4;
    #[doc = "L2"]
    pub const RTE_ETH_INPUT_SET_L2_ETHERTYPE: Type = 5;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_SRC_IP4: Type = 129;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_DST_IP4: Type = 130;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_SRC_IP6: Type = 131;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_DST_IP6: Type = 132;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP4_TOS: Type = 133;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP4_PROTO: Type = 134;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP6_TC: Type = 135;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP6_NEXT_HEADER: Type = 136;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP4_TTL: Type = 137;
    #[doc = "L3"]
    pub const RTE_ETH_INPUT_SET_L3_IP6_HOP_LIMITS: Type = 138;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_UDP_SRC_PORT: Type = 257;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_UDP_DST_PORT: Type = 258;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_TCP_SRC_PORT: Type = 259;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_TCP_DST_PORT: Type = 260;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_SCTP_SRC_PORT: Type = 261;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_SCTP_DST_PORT: Type = 262;
    #[doc = "L4"]
    pub const RTE_ETH_INPUT_SET_L4_SCTP_VERIFICATION_TAG: Type = 263;
    #[doc = "Tunnel"]
    pub const RTE_ETH_INPUT_SET_TUNNEL_L2_INNER_DST_MAC: Type = 385;
    #[doc = "Tunnel"]
    pub const RTE_ETH_INPUT_SET_TUNNEL_L2_INNER_SRC_MAC: Type = 386;
    #[doc = "Tunnel"]
    pub const RTE_ETH_INPUT_SET_TUNNEL_L2_INNER_VLAN: Type = 387;
    #[doc = "Tunnel"]
    pub const RTE_ETH_INPUT_SET_TUNNEL_L4_UDP_KEY: Type = 388;
    #[doc = "Tunnel"]
    pub const RTE_ETH_INPUT_SET_TUNNEL_GRE_KEY: Type = 389;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_1ST_WORD: Type = 641;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_2ND_WORD: Type = 642;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_3RD_WORD: Type = 643;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_4TH_WORD: Type = 644;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_5TH_WORD: Type = 645;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_6TH_WORD: Type = 646;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_7TH_WORD: Type = 647;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_FLEX_PAYLOAD_8TH_WORD: Type = 648;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_DEFAULT: Type = 65533;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_NONE: Type = 65534;
    #[doc = "Flexible Payload"]
    pub const RTE_ETH_INPUT_SET_MAX: Type = 65535;
}
pub mod rte_filter_input_set_op {
    #[doc = "Filters input set operations"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_INPUT_SET_OP_UNKNOWN: Type = 0;
    #[doc = "< select input set"]
    pub const RTE_ETH_INPUT_SET_SELECT: Type = 1;
    #[doc = "< add input set entry"]
    pub const RTE_ETH_INPUT_SET_ADD: Type = 2;
    pub const RTE_ETH_INPUT_SET_OP_MAX: Type = 3;
}
#[doc = "A structure used to define the input set configuration for\nflow director and hash filters"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_input_set_conf {
    pub flow_type: u16,
    pub inset_size: u16,
    pub field: [rte_eth_input_set_field::Type; 128usize],
    pub op: rte_filter_input_set_op::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_input_set_conf"][::core::mem::size_of::<rte_eth_input_set_conf>() - 520usize];
    ["Alignment of rte_eth_input_set_conf"]
        [::core::mem::align_of::<rte_eth_input_set_conf>() - 4usize];
    ["Offset of field: rte_eth_input_set_conf::flow_type"]
        [::core::mem::offset_of!(rte_eth_input_set_conf, flow_type) - 0usize];
    ["Offset of field: rte_eth_input_set_conf::inset_size"]
        [::core::mem::offset_of!(rte_eth_input_set_conf, inset_size) - 2usize];
    ["Offset of field: rte_eth_input_set_conf::field"]
        [::core::mem::offset_of!(rte_eth_input_set_conf, field) - 4usize];
    ["Offset of field: rte_eth_input_set_conf::op"]
        [::core::mem::offset_of!(rte_eth_input_set_conf, op) - 516usize];
};
impl Default for rte_eth_input_set_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to define the input for L2 flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_l2_flow {
    #[doc = "< Ether type in big endian"]
    pub ether_type: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_l2_flow"][::core::mem::size_of::<rte_eth_l2_flow>() - 2usize];
    ["Alignment of rte_eth_l2_flow"][::core::mem::align_of::<rte_eth_l2_flow>() - 2usize];
    ["Offset of field: rte_eth_l2_flow::ether_type"]
        [::core::mem::offset_of!(rte_eth_l2_flow, ether_type) - 0usize];
};
#[doc = "A structure used to define the input for IPV4 flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_ipv4_flow {
    #[doc = "< IPv4 source address in big endian."]
    pub src_ip: u32,
    #[doc = "< IPv4 destination address in big endian."]
    pub dst_ip: u32,
    #[doc = "< Type of service to match."]
    pub tos: u8,
    #[doc = "< Time to live to match."]
    pub ttl: u8,
    #[doc = "< Protocol, next header in big endian."]
    pub proto: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ipv4_flow"][::core::mem::size_of::<rte_eth_ipv4_flow>() - 12usize];
    ["Alignment of rte_eth_ipv4_flow"][::core::mem::align_of::<rte_eth_ipv4_flow>() - 4usize];
    ["Offset of field: rte_eth_ipv4_flow::src_ip"]
        [::core::mem::offset_of!(rte_eth_ipv4_flow, src_ip) - 0usize];
    ["Offset of field: rte_eth_ipv4_flow::dst_ip"]
        [::core::mem::offset_of!(rte_eth_ipv4_flow, dst_ip) - 4usize];
    ["Offset of field: rte_eth_ipv4_flow::tos"]
        [::core::mem::offset_of!(rte_eth_ipv4_flow, tos) - 8usize];
    ["Offset of field: rte_eth_ipv4_flow::ttl"]
        [::core::mem::offset_of!(rte_eth_ipv4_flow, ttl) - 9usize];
    ["Offset of field: rte_eth_ipv4_flow::proto"]
        [::core::mem::offset_of!(rte_eth_ipv4_flow, proto) - 10usize];
};
#[doc = "A structure used to define the input for IPV4 UDP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_udpv4_flow {
    #[doc = "< IPv4 fields to match."]
    pub ip: rte_eth_ipv4_flow,
    #[doc = "< UDP source port in big endian."]
    pub src_port: u16,
    #[doc = "< UDP destination port in big endian."]
    pub dst_port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_udpv4_flow"][::core::mem::size_of::<rte_eth_udpv4_flow>() - 16usize];
    ["Alignment of rte_eth_udpv4_flow"][::core::mem::align_of::<rte_eth_udpv4_flow>() - 4usize];
    ["Offset of field: rte_eth_udpv4_flow::ip"]
        [::core::mem::offset_of!(rte_eth_udpv4_flow, ip) - 0usize];
    ["Offset of field: rte_eth_udpv4_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_udpv4_flow, src_port) - 12usize];
    ["Offset of field: rte_eth_udpv4_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_udpv4_flow, dst_port) - 14usize];
};
#[doc = "A structure used to define the input for IPV4 TCP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_tcpv4_flow {
    #[doc = "< IPv4 fields to match."]
    pub ip: rte_eth_ipv4_flow,
    #[doc = "< TCP source port in big endian."]
    pub src_port: u16,
    #[doc = "< TCP destination port in big endian."]
    pub dst_port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_tcpv4_flow"][::core::mem::size_of::<rte_eth_tcpv4_flow>() - 16usize];
    ["Alignment of rte_eth_tcpv4_flow"][::core::mem::align_of::<rte_eth_tcpv4_flow>() - 4usize];
    ["Offset of field: rte_eth_tcpv4_flow::ip"]
        [::core::mem::offset_of!(rte_eth_tcpv4_flow, ip) - 0usize];
    ["Offset of field: rte_eth_tcpv4_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_tcpv4_flow, src_port) - 12usize];
    ["Offset of field: rte_eth_tcpv4_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_tcpv4_flow, dst_port) - 14usize];
};
#[doc = "A structure used to define the input for IPV4 SCTP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_sctpv4_flow {
    #[doc = "< IPv4 fields to match."]
    pub ip: rte_eth_ipv4_flow,
    #[doc = "< SCTP source port in big endian."]
    pub src_port: u16,
    #[doc = "< SCTP destination port in big endian."]
    pub dst_port: u16,
    #[doc = "< Verify tag in big endian"]
    pub verify_tag: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_sctpv4_flow"][::core::mem::size_of::<rte_eth_sctpv4_flow>() - 20usize];
    ["Alignment of rte_eth_sctpv4_flow"][::core::mem::align_of::<rte_eth_sctpv4_flow>() - 4usize];
    ["Offset of field: rte_eth_sctpv4_flow::ip"]
        [::core::mem::offset_of!(rte_eth_sctpv4_flow, ip) - 0usize];
    ["Offset of field: rte_eth_sctpv4_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_sctpv4_flow, src_port) - 12usize];
    ["Offset of field: rte_eth_sctpv4_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_sctpv4_flow, dst_port) - 14usize];
    ["Offset of field: rte_eth_sctpv4_flow::verify_tag"]
        [::core::mem::offset_of!(rte_eth_sctpv4_flow, verify_tag) - 16usize];
};
#[doc = "A structure used to define the input for IPV6 flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_ipv6_flow {
    #[doc = "< IPv6 source address in big endian."]
    pub src_ip: [u32; 4usize],
    #[doc = "< IPv6 destination address in big endian."]
    pub dst_ip: [u32; 4usize],
    #[doc = "< Traffic class to match."]
    pub tc: u8,
    #[doc = "< Protocol, next header to match."]
    pub proto: u8,
    #[doc = "< Hop limits to match."]
    pub hop_limits: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ipv6_flow"][::core::mem::size_of::<rte_eth_ipv6_flow>() - 36usize];
    ["Alignment of rte_eth_ipv6_flow"][::core::mem::align_of::<rte_eth_ipv6_flow>() - 4usize];
    ["Offset of field: rte_eth_ipv6_flow::src_ip"]
        [::core::mem::offset_of!(rte_eth_ipv6_flow, src_ip) - 0usize];
    ["Offset of field: rte_eth_ipv6_flow::dst_ip"]
        [::core::mem::offset_of!(rte_eth_ipv6_flow, dst_ip) - 16usize];
    ["Offset of field: rte_eth_ipv6_flow::tc"]
        [::core::mem::offset_of!(rte_eth_ipv6_flow, tc) - 32usize];
    ["Offset of field: rte_eth_ipv6_flow::proto"]
        [::core::mem::offset_of!(rte_eth_ipv6_flow, proto) - 33usize];
    ["Offset of field: rte_eth_ipv6_flow::hop_limits"]
        [::core::mem::offset_of!(rte_eth_ipv6_flow, hop_limits) - 34usize];
};
#[doc = "A structure used to define the input for IPV6 UDP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_udpv6_flow {
    #[doc = "< IPv6 fields to match."]
    pub ip: rte_eth_ipv6_flow,
    #[doc = "< UDP source port in big endian."]
    pub src_port: u16,
    #[doc = "< UDP destination port in big endian."]
    pub dst_port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_udpv6_flow"][::core::mem::size_of::<rte_eth_udpv6_flow>() - 40usize];
    ["Alignment of rte_eth_udpv6_flow"][::core::mem::align_of::<rte_eth_udpv6_flow>() - 4usize];
    ["Offset of field: rte_eth_udpv6_flow::ip"]
        [::core::mem::offset_of!(rte_eth_udpv6_flow, ip) - 0usize];
    ["Offset of field: rte_eth_udpv6_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_udpv6_flow, src_port) - 36usize];
    ["Offset of field: rte_eth_udpv6_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_udpv6_flow, dst_port) - 38usize];
};
#[doc = "A structure used to define the input for IPV6 TCP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_tcpv6_flow {
    #[doc = "< IPv6 fields to match."]
    pub ip: rte_eth_ipv6_flow,
    #[doc = "< TCP source port to in big endian."]
    pub src_port: u16,
    #[doc = "< TCP destination port in big endian."]
    pub dst_port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_tcpv6_flow"][::core::mem::size_of::<rte_eth_tcpv6_flow>() - 40usize];
    ["Alignment of rte_eth_tcpv6_flow"][::core::mem::align_of::<rte_eth_tcpv6_flow>() - 4usize];
    ["Offset of field: rte_eth_tcpv6_flow::ip"]
        [::core::mem::offset_of!(rte_eth_tcpv6_flow, ip) - 0usize];
    ["Offset of field: rte_eth_tcpv6_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_tcpv6_flow, src_port) - 36usize];
    ["Offset of field: rte_eth_tcpv6_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_tcpv6_flow, dst_port) - 38usize];
};
#[doc = "A structure used to define the input for IPV6 SCTP flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_sctpv6_flow {
    #[doc = "< IPv6 fields to match."]
    pub ip: rte_eth_ipv6_flow,
    #[doc = "< SCTP source port in big endian."]
    pub src_port: u16,
    #[doc = "< SCTP destination port in big endian."]
    pub dst_port: u16,
    #[doc = "< Verify tag in big endian."]
    pub verify_tag: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_sctpv6_flow"][::core::mem::size_of::<rte_eth_sctpv6_flow>() - 44usize];
    ["Alignment of rte_eth_sctpv6_flow"][::core::mem::align_of::<rte_eth_sctpv6_flow>() - 4usize];
    ["Offset of field: rte_eth_sctpv6_flow::ip"]
        [::core::mem::offset_of!(rte_eth_sctpv6_flow, ip) - 0usize];
    ["Offset of field: rte_eth_sctpv6_flow::src_port"]
        [::core::mem::offset_of!(rte_eth_sctpv6_flow, src_port) - 36usize];
    ["Offset of field: rte_eth_sctpv6_flow::dst_port"]
        [::core::mem::offset_of!(rte_eth_sctpv6_flow, dst_port) - 38usize];
    ["Offset of field: rte_eth_sctpv6_flow::verify_tag"]
        [::core::mem::offset_of!(rte_eth_sctpv6_flow, verify_tag) - 40usize];
};
#[doc = "A structure used to define the input for MAC VLAN flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_mac_vlan_flow {
    #[doc = "< Mac address to match."]
    pub mac_addr: rte_ether_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_mac_vlan_flow"][::core::mem::size_of::<rte_eth_mac_vlan_flow>() - 6usize];
    ["Alignment of rte_eth_mac_vlan_flow"]
        [::core::mem::align_of::<rte_eth_mac_vlan_flow>() - 2usize];
    ["Offset of field: rte_eth_mac_vlan_flow::mac_addr"]
        [::core::mem::offset_of!(rte_eth_mac_vlan_flow, mac_addr) - 0usize];
};
pub mod rte_eth_fdir_tunnel_type {
    #[doc = "Tunnel type for flow director."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_FDIR_TUNNEL_TYPE_UNKNOWN: Type = 0;
    pub const RTE_FDIR_TUNNEL_TYPE_NVGRE: Type = 1;
    pub const RTE_FDIR_TUNNEL_TYPE_VXLAN: Type = 2;
}
#[doc = "A structure used to define the input for tunnel flow, now it's VxLAN or\nNVGRE"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_tunnel_flow {
    #[doc = "< Tunnel type to match."]
    pub tunnel_type: rte_eth_fdir_tunnel_type::Type,
    #[doc = "Tunnel ID to match. TNI, VNI... in big endian."]
    pub tunnel_id: u32,
    #[doc = "< Mac address to match."]
    pub mac_addr: rte_ether_addr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_tunnel_flow"][::core::mem::size_of::<rte_eth_tunnel_flow>() - 16usize];
    ["Alignment of rte_eth_tunnel_flow"][::core::mem::align_of::<rte_eth_tunnel_flow>() - 4usize];
    ["Offset of field: rte_eth_tunnel_flow::tunnel_type"]
        [::core::mem::offset_of!(rte_eth_tunnel_flow, tunnel_type) - 0usize];
    ["Offset of field: rte_eth_tunnel_flow::tunnel_id"]
        [::core::mem::offset_of!(rte_eth_tunnel_flow, tunnel_id) - 4usize];
    ["Offset of field: rte_eth_tunnel_flow::mac_addr"]
        [::core::mem::offset_of!(rte_eth_tunnel_flow, mac_addr) - 8usize];
};
impl Default for rte_eth_tunnel_flow {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "An union contains the inputs for all types of flow\nItems in flows need to be in big endian"]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_fdir_flow {
    pub l2_flow: rte_eth_l2_flow,
    pub udp4_flow: rte_eth_udpv4_flow,
    pub tcp4_flow: rte_eth_tcpv4_flow,
    pub sctp4_flow: rte_eth_sctpv4_flow,
    pub ip4_flow: rte_eth_ipv4_flow,
    pub udp6_flow: rte_eth_udpv6_flow,
    pub tcp6_flow: rte_eth_tcpv6_flow,
    pub sctp6_flow: rte_eth_sctpv6_flow,
    pub ipv6_flow: rte_eth_ipv6_flow,
    pub mac_vlan_flow: rte_eth_mac_vlan_flow,
    pub tunnel_flow: rte_eth_tunnel_flow,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_flow"][::core::mem::size_of::<rte_eth_fdir_flow>() - 44usize];
    ["Alignment of rte_eth_fdir_flow"][::core::mem::align_of::<rte_eth_fdir_flow>() - 4usize];
    ["Offset of field: rte_eth_fdir_flow::l2_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, l2_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::udp4_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, udp4_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::tcp4_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, tcp4_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::sctp4_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, sctp4_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::ip4_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, ip4_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::udp6_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, udp6_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::tcp6_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, tcp6_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::sctp6_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, sctp6_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::ipv6_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, ipv6_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::mac_vlan_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, mac_vlan_flow) - 0usize];
    ["Offset of field: rte_eth_fdir_flow::tunnel_flow"]
        [::core::mem::offset_of!(rte_eth_fdir_flow, tunnel_flow) - 0usize];
};
impl Default for rte_eth_fdir_flow {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to contain extend input of flow"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_fdir_flow_ext {
    pub vlan_tci: u16,
    pub flexbytes: [u8; 16usize],
    #[doc = "< 1 for VF, 0 for port dev"]
    pub is_vf: u8,
    #[doc = "< VF ID, available when is_vf is 1"]
    pub dst_id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_flow_ext"][::core::mem::size_of::<rte_eth_fdir_flow_ext>() - 22usize];
    ["Alignment of rte_eth_fdir_flow_ext"]
        [::core::mem::align_of::<rte_eth_fdir_flow_ext>() - 2usize];
    ["Offset of field: rte_eth_fdir_flow_ext::vlan_tci"]
        [::core::mem::offset_of!(rte_eth_fdir_flow_ext, vlan_tci) - 0usize];
    ["Offset of field: rte_eth_fdir_flow_ext::flexbytes"]
        [::core::mem::offset_of!(rte_eth_fdir_flow_ext, flexbytes) - 2usize];
    ["Offset of field: rte_eth_fdir_flow_ext::is_vf"]
        [::core::mem::offset_of!(rte_eth_fdir_flow_ext, is_vf) - 18usize];
    ["Offset of field: rte_eth_fdir_flow_ext::dst_id"]
        [::core::mem::offset_of!(rte_eth_fdir_flow_ext, dst_id) - 20usize];
};
#[doc = "A structure used to define the input for a flow director filter entry"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_fdir_input {
    pub flow_type: u16,
    pub flow: rte_eth_fdir_flow,
    pub flow_ext: rte_eth_fdir_flow_ext,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_input"][::core::mem::size_of::<rte_eth_fdir_input>() - 72usize];
    ["Alignment of rte_eth_fdir_input"][::core::mem::align_of::<rte_eth_fdir_input>() - 4usize];
    ["Offset of field: rte_eth_fdir_input::flow_type"]
        [::core::mem::offset_of!(rte_eth_fdir_input, flow_type) - 0usize];
    ["Offset of field: rte_eth_fdir_input::flow"]
        [::core::mem::offset_of!(rte_eth_fdir_input, flow) - 4usize];
    ["Offset of field: rte_eth_fdir_input::flow_ext"]
        [::core::mem::offset_of!(rte_eth_fdir_input, flow_ext) - 48usize];
};
impl Default for rte_eth_fdir_input {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_eth_fdir_behavior {
    #[doc = "Behavior will be taken if FDIR match"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_FDIR_ACCEPT: Type = 0;
    pub const RTE_ETH_FDIR_REJECT: Type = 1;
    pub const RTE_ETH_FDIR_PASSTHRU: Type = 2;
}
pub mod rte_eth_fdir_status {
    #[doc = "Flow director report status\nIt defines what will be reported if FDIR entry is matched."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Report nothing."]
    pub const RTE_ETH_FDIR_NO_REPORT_STATUS: Type = 0;
    #[doc = "< Only report FD ID."]
    pub const RTE_ETH_FDIR_REPORT_ID: Type = 1;
    #[doc = "< Report FD ID and 4 flex bytes."]
    pub const RTE_ETH_FDIR_REPORT_ID_FLEX_4: Type = 2;
    #[doc = "< Report 8 flex bytes."]
    pub const RTE_ETH_FDIR_REPORT_FLEX_8: Type = 3;
}
#[doc = "A structure used to define an action when match FDIR packet filter."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fdir_action {
    #[doc = "< Queue assigned to if FDIR match."]
    pub rx_queue: u16,
    #[doc = "< Behavior will be taken"]
    pub behavior: rte_eth_fdir_behavior::Type,
    #[doc = "< Status report option"]
    pub report_status: rte_eth_fdir_status::Type,
    pub flex_off: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_action"][::core::mem::size_of::<rte_eth_fdir_action>() - 16usize];
    ["Alignment of rte_eth_fdir_action"][::core::mem::align_of::<rte_eth_fdir_action>() - 4usize];
    ["Offset of field: rte_eth_fdir_action::rx_queue"]
        [::core::mem::offset_of!(rte_eth_fdir_action, rx_queue) - 0usize];
    ["Offset of field: rte_eth_fdir_action::behavior"]
        [::core::mem::offset_of!(rte_eth_fdir_action, behavior) - 4usize];
    ["Offset of field: rte_eth_fdir_action::report_status"]
        [::core::mem::offset_of!(rte_eth_fdir_action, report_status) - 8usize];
    ["Offset of field: rte_eth_fdir_action::flex_off"]
        [::core::mem::offset_of!(rte_eth_fdir_action, flex_off) - 12usize];
};
impl Default for rte_eth_fdir_action {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to define the flow director filter entry."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_fdir_filter {
    pub soft_id: u32,
    #[doc = "< Input set"]
    pub input: rte_eth_fdir_input,
    #[doc = "< Action taken when match"]
    pub action: rte_eth_fdir_action,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_filter"][::core::mem::size_of::<rte_eth_fdir_filter>() - 92usize];
    ["Alignment of rte_eth_fdir_filter"][::core::mem::align_of::<rte_eth_fdir_filter>() - 4usize];
    ["Offset of field: rte_eth_fdir_filter::soft_id"]
        [::core::mem::offset_of!(rte_eth_fdir_filter, soft_id) - 0usize];
    ["Offset of field: rte_eth_fdir_filter::input"]
        [::core::mem::offset_of!(rte_eth_fdir_filter, input) - 4usize];
    ["Offset of field: rte_eth_fdir_filter::action"]
        [::core::mem::offset_of!(rte_eth_fdir_filter, action) - 76usize];
};
impl Default for rte_eth_fdir_filter {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to configure FDIR masks that are used by the device\nto match the various fields of Rx packet headers."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_fdir_masks {
    #[doc = "< Bit mask for vlan_tci in big endian"]
    pub vlan_tci_mask: u16,
    #[doc = "Bit mask for ipv4 flow in big endian."]
    pub ipv4_mask: rte_eth_ipv4_flow,
    #[doc = "Bit mask for ipv6 flow in big endian."]
    pub ipv6_mask: rte_eth_ipv6_flow,
    #[doc = "Bit mask for L4 source port in big endian."]
    pub src_port_mask: u16,
    #[doc = "Bit mask for L4 destination port in big endian."]
    pub dst_port_mask: u16,
    #[doc = "6 bit mask for proper 6 bytes of Mac address, bit 0 matches the\nfirst byte on the wire"]
    pub mac_addr_byte_mask: u8,
    #[doc = "Bit mask for tunnel ID in big endian."]
    pub tunnel_id_mask: u32,
    #[doc = "< 1 - Match tunnel type,\n0 - Ignore tunnel type."]
    pub tunnel_type_mask: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_masks"][::core::mem::size_of::<rte_eth_fdir_masks>() - 68usize];
    ["Alignment of rte_eth_fdir_masks"][::core::mem::align_of::<rte_eth_fdir_masks>() - 4usize];
    ["Offset of field: rte_eth_fdir_masks::vlan_tci_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, vlan_tci_mask) - 0usize];
    ["Offset of field: rte_eth_fdir_masks::ipv4_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, ipv4_mask) - 4usize];
    ["Offset of field: rte_eth_fdir_masks::ipv6_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, ipv6_mask) - 16usize];
    ["Offset of field: rte_eth_fdir_masks::src_port_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, src_port_mask) - 52usize];
    ["Offset of field: rte_eth_fdir_masks::dst_port_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, dst_port_mask) - 54usize];
    ["Offset of field: rte_eth_fdir_masks::mac_addr_byte_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, mac_addr_byte_mask) - 56usize];
    ["Offset of field: rte_eth_fdir_masks::tunnel_id_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, tunnel_id_mask) - 60usize];
    ["Offset of field: rte_eth_fdir_masks::tunnel_type_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_masks, tunnel_type_mask) - 64usize];
};
pub mod rte_eth_payload_type {
    #[doc = "Payload type"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_ETH_PAYLOAD_UNKNOWN: Type = 0;
    pub const RTE_ETH_RAW_PAYLOAD: Type = 1;
    pub const RTE_ETH_L2_PAYLOAD: Type = 2;
    pub const RTE_ETH_L3_PAYLOAD: Type = 3;
    pub const RTE_ETH_L4_PAYLOAD: Type = 4;
    pub const RTE_ETH_PAYLOAD_MAX: Type = 8;
}
#[doc = "A structure used to select bytes extracted from the protocol layers to\nflexible payload for filter"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_flex_payload_cfg {
    #[doc = "< Payload type"]
    pub type_: rte_eth_payload_type::Type,
    pub src_offset: [u16; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_flex_payload_cfg"]
        [::core::mem::size_of::<rte_eth_flex_payload_cfg>() - 36usize];
    ["Alignment of rte_eth_flex_payload_cfg"]
        [::core::mem::align_of::<rte_eth_flex_payload_cfg>() - 4usize];
    ["Offset of field: rte_eth_flex_payload_cfg::type_"]
        [::core::mem::offset_of!(rte_eth_flex_payload_cfg, type_) - 0usize];
    ["Offset of field: rte_eth_flex_payload_cfg::src_offset"]
        [::core::mem::offset_of!(rte_eth_flex_payload_cfg, src_offset) - 4usize];
};
impl Default for rte_eth_flex_payload_cfg {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to define FDIR masks for flexible payload\nfor each flow type"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_fdir_flex_mask {
    pub flow_type: u16,
    pub mask: [u8; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_flex_mask"][::core::mem::size_of::<rte_eth_fdir_flex_mask>() - 18usize];
    ["Alignment of rte_eth_fdir_flex_mask"]
        [::core::mem::align_of::<rte_eth_fdir_flex_mask>() - 2usize];
    ["Offset of field: rte_eth_fdir_flex_mask::flow_type"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_mask, flow_type) - 0usize];
    ["Offset of field: rte_eth_fdir_flex_mask::mask"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_mask, mask) - 2usize];
};
#[doc = "A structure used to define all flexible payload related setting\ninclude flex payload and flex mask"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fdir_flex_conf {
    #[doc = "< The number of following payload cfg"]
    pub nb_payloads: u16,
    #[doc = "< The number of following mask"]
    pub nb_flexmasks: u16,
    pub flex_set: [rte_eth_flex_payload_cfg; 8usize],
    pub flex_mask: [rte_eth_fdir_flex_mask; 24usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_flex_conf"][::core::mem::size_of::<rte_eth_fdir_flex_conf>() - 724usize];
    ["Alignment of rte_eth_fdir_flex_conf"]
        [::core::mem::align_of::<rte_eth_fdir_flex_conf>() - 4usize];
    ["Offset of field: rte_eth_fdir_flex_conf::nb_payloads"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_conf, nb_payloads) - 0usize];
    ["Offset of field: rte_eth_fdir_flex_conf::nb_flexmasks"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_conf, nb_flexmasks) - 2usize];
    ["Offset of field: rte_eth_fdir_flex_conf::flex_set"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_conf, flex_set) - 4usize];
    ["Offset of field: rte_eth_fdir_flex_conf::flex_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_flex_conf, flex_mask) - 292usize];
};
impl Default for rte_eth_fdir_flex_conf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_fdir_mode {
    #[doc = "Flow Director setting modes: none, signature or perfect."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Disable FDIR support."]
    pub const RTE_FDIR_MODE_NONE: Type = 0;
    #[doc = "< Enable FDIR signature filter mode."]
    pub const RTE_FDIR_MODE_SIGNATURE: Type = 1;
    #[doc = "< Enable FDIR perfect filter mode."]
    pub const RTE_FDIR_MODE_PERFECT: Type = 2;
    #[doc = "< Enable FDIR filter mode - MAC VLAN."]
    pub const RTE_FDIR_MODE_PERFECT_MAC_VLAN: Type = 3;
    #[doc = "< Enable FDIR filter mode - tunnel."]
    pub const RTE_FDIR_MODE_PERFECT_TUNNEL: Type = 4;
}
#[doc = "A structure used to get the information of flow director filter.\nIt supports RTE_ETH_FILTER_FDIR with RTE_ETH_FILTER_INFO operation.\nIt includes the mode, flexible payload configuration information,\ncapabilities and supported flow types, flexible payload characters.\nIt can be gotten to help taking specific configurations per device."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fdir_info {
    #[doc = "< Flow director mode"]
    pub mode: rte_fdir_mode::Type,
    pub mask: rte_eth_fdir_masks,
    #[doc = "Flex payload configuration information"]
    pub flex_conf: rte_eth_fdir_flex_conf,
    #[doc = "< Guaranteed spaces."]
    pub guarant_spc: u32,
    #[doc = "< Best effort spaces."]
    pub best_spc: u32,
    #[doc = "Bit mask for every supported flow type."]
    pub flow_types_mask: [u64; 1usize],
    #[doc = "< Total flex payload in bytes."]
    pub max_flexpayload: u32,
    #[doc = "Flexible payload unit in bytes. Size and alignments of all flex\npayload segments should be multiplies of this value."]
    pub flex_payload_unit: u32,
    #[doc = "Max number of flexible payload continuous segments.\nEach segment should be a multiple of flex_payload_unit."]
    pub max_flex_payload_segment_num: u32,
    #[doc = "Maximum src_offset in bytes allowed. It indicates that\nsrc_offset[i] in struct rte_eth_flex_payload_cfg should be less\nthan this value."]
    pub flex_payload_limit: u16,
    #[doc = "Flex bitmask unit in bytes. Size of flex bitmasks should be a\nmultiply of this value."]
    pub flex_bitmask_unit: u32,
    #[doc = "Max supported size of flex bitmasks in flex_bitmask_unit"]
    pub max_flex_bitmask_num: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_info"][::core::mem::size_of::<rte_eth_fdir_info>() - 840usize];
    ["Alignment of rte_eth_fdir_info"][::core::mem::align_of::<rte_eth_fdir_info>() - 8usize];
    ["Offset of field: rte_eth_fdir_info::mode"]
        [::core::mem::offset_of!(rte_eth_fdir_info, mode) - 0usize];
    ["Offset of field: rte_eth_fdir_info::mask"]
        [::core::mem::offset_of!(rte_eth_fdir_info, mask) - 4usize];
    ["Offset of field: rte_eth_fdir_info::flex_conf"]
        [::core::mem::offset_of!(rte_eth_fdir_info, flex_conf) - 72usize];
    ["Offset of field: rte_eth_fdir_info::guarant_spc"]
        [::core::mem::offset_of!(rte_eth_fdir_info, guarant_spc) - 796usize];
    ["Offset of field: rte_eth_fdir_info::best_spc"]
        [::core::mem::offset_of!(rte_eth_fdir_info, best_spc) - 800usize];
    ["Offset of field: rte_eth_fdir_info::flow_types_mask"]
        [::core::mem::offset_of!(rte_eth_fdir_info, flow_types_mask) - 808usize];
    ["Offset of field: rte_eth_fdir_info::max_flexpayload"]
        [::core::mem::offset_of!(rte_eth_fdir_info, max_flexpayload) - 816usize];
    ["Offset of field: rte_eth_fdir_info::flex_payload_unit"]
        [::core::mem::offset_of!(rte_eth_fdir_info, flex_payload_unit) - 820usize];
    ["Offset of field: rte_eth_fdir_info::max_flex_payload_segment_num"]
        [::core::mem::offset_of!(rte_eth_fdir_info, max_flex_payload_segment_num) - 824usize];
    ["Offset of field: rte_eth_fdir_info::flex_payload_limit"]
        [::core::mem::offset_of!(rte_eth_fdir_info, flex_payload_limit) - 828usize];
    ["Offset of field: rte_eth_fdir_info::flex_bitmask_unit"]
        [::core::mem::offset_of!(rte_eth_fdir_info, flex_bitmask_unit) - 832usize];
    ["Offset of field: rte_eth_fdir_info::max_flex_bitmask_num"]
        [::core::mem::offset_of!(rte_eth_fdir_info, max_flex_bitmask_num) - 836usize];
};
impl Default for rte_eth_fdir_info {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "A structure used to define the statistics of flow director.\nIt supports RTE_ETH_FILTER_FDIR with RTE_ETH_FILTER_STATS operation."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_eth_fdir_stats {
    #[doc = "< Number of filters with collision."]
    pub collision: u32,
    #[doc = "< Number of free filters."]
    pub free: u32,
    pub maxhash: u32,
    #[doc = "< Longest linked list of filters."]
    pub maxlen: u32,
    #[doc = "< Number of added filters."]
    pub add: u64,
    #[doc = "< Number of removed filters."]
    pub remove: u64,
    #[doc = "< Number of failed added filters."]
    pub f_add: u64,
    #[doc = "< Number of failed removed filters."]
    pub f_remove: u64,
    #[doc = "< Number of filters in guaranteed spaces."]
    pub guarant_cnt: u32,
    #[doc = "< Number of filters in best effort spaces."]
    pub best_cnt: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fdir_stats"][::core::mem::size_of::<rte_eth_fdir_stats>() - 56usize];
    ["Alignment of rte_eth_fdir_stats"][::core::mem::align_of::<rte_eth_fdir_stats>() - 8usize];
    ["Offset of field: rte_eth_fdir_stats::collision"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, collision) - 0usize];
    ["Offset of field: rte_eth_fdir_stats::free"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, free) - 4usize];
    ["Offset of field: rte_eth_fdir_stats::maxhash"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, maxhash) - 8usize];
    ["Offset of field: rte_eth_fdir_stats::maxlen"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, maxlen) - 12usize];
    ["Offset of field: rte_eth_fdir_stats::add"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, add) - 16usize];
    ["Offset of field: rte_eth_fdir_stats::remove"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, remove) - 24usize];
    ["Offset of field: rte_eth_fdir_stats::f_add"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, f_add) - 32usize];
    ["Offset of field: rte_eth_fdir_stats::f_remove"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, f_remove) - 40usize];
    ["Offset of field: rte_eth_fdir_stats::guarant_cnt"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, guarant_cnt) - 48usize];
    ["Offset of field: rte_eth_fdir_stats::best_cnt"]
        [::core::mem::offset_of!(rte_eth_fdir_stats, best_cnt) - 52usize];
};
unsafe extern "C" {
    #[doc = "Create a new ethdev port from a set of rings\n\n# Arguments\n\n* `name` -\nname to be given to the new ethdev port\n* `rx_queues` -\npointer to array of rte_rings to be used as RX queues\n* `nb_rx_queues` -\nnumber of elements in the rx_queues array\n* `tx_queues` -\npointer to array of rte_rings to be used as TX queues\n* `nb_tx_queues` -\nnumber of elements in the tx_queues array\n* `numa_node` -\nthe numa node on which the memory for this port is to be allocated\n\n# Returns\n\nthe port number of the newly created the ethdev or -1 on error."]
    pub fn rte_eth_from_rings(
        name: *const ::core::ffi::c_char,
        rx_queues: *const *mut rte_ring,
        nb_rx_queues: ::core::ffi::c_uint,
        tx_queues: *const *mut rte_ring,
        nb_tx_queues: ::core::ffi::c_uint,
        numa_node: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a new ethdev port from a ring\nThis function is a shortcut call for rte_eth_from_rings for the\ncase where one wants to take a single rte_ring and use it as though\nit were an ethdev\n\n# Arguments\n\n* `ring` -\nthe ring to be used as an ethdev\n\n# Returns\n\nthe port number of the newly created ethdev, or -1 on error"]
    pub fn rte_eth_from_ring(r: *mut rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub static mut rte_hash_crc32_alg: u8;
}
unsafe extern "C" {
    #[doc = "Use single crc32 instruction to perform a hash on a byte value.\nFall back to software crc32 implementation in case SSE4.2 is\nnot supported."]
    #[link_name = "rte_hash_crc_1byte_w"]
    pub fn rte_hash_crc_1byte(data: u8, init_val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Use single crc32 instruction to perform a hash on a 2 bytes value.\nFall back to software crc32 implementation in case SSE4.2 is\nnot supported."]
    #[link_name = "rte_hash_crc_2byte_w"]
    pub fn rte_hash_crc_2byte(data: u16, init_val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Use single crc32 instruction to perform a hash on a 4 byte value.\nFall back to software crc32 implementation in case SSE4.2 is\nnot supported."]
    #[link_name = "rte_hash_crc_4byte_w"]
    pub fn rte_hash_crc_4byte(data: u32, init_val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Use single crc32 instruction to perform a hash on a 8 byte value.\nFall back to software crc32 implementation in case SSE4.2 is\nnot supported."]
    #[link_name = "rte_hash_crc_8byte_w"]
    pub fn rte_hash_crc_8byte(data: u64, init_val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Allow or disallow use of SSE4.2/ARMv8 intrinsics for CRC32 hash\ncalculation.\n\n# Arguments\n\n* `alg` -\nAn OR of following flags:\n- (CRC32_SW) Don't use SSE4.2/ARMv8 intrinsics (default non-[x86/ARMv8])\n- (CRC32_SSE42) Use SSE4.2 intrinsics if available\n- (CRC32_SSE42_x64) Use 64-bit SSE4.2 intrinsic if available (default x86)\n- (CRC32_ARM64) Use ARMv8 CRC intrinsic if available (default ARMv8)"]
    pub fn rte_hash_crc_set_alg(alg: u8);
}
unsafe extern "C" {
    #[doc = "Calculate CRC32 hash on user-supplied byte array.\n\n# Arguments\n\n* `data` -\nData to perform hash on.\n* `data_len` -\nHow many bytes to use to calculate hash value.\n* `init_val` -\nValue to initialise hash generator.\n\n# Returns\n\n32bit calculated hash value."]
    #[link_name = "rte_hash_crc_w"]
    pub fn rte_hash_crc(data: *const ::core::ffi::c_void, data_len: u32, init_val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Same as rte_jhash, but takes two seeds and return two uint32_ts.\npc and pb must be non-null, and *pc and *pb must both be initialized\nwith seeds. If you pass in (*pb)=0, the output (*pc) will be\nthe same as the return value from rte_jhash.\n\n# Arguments\n\n* `key` -\nKey to calculate hash of.\n* `length` -\nLength of key in bytes.\n* `pc` -\nIN: seed OUT: primary hash value.\n* `pb` -\nIN: second seed OUT: secondary hash value."]
    #[link_name = "rte_jhash_2hashes_w"]
    pub fn rte_jhash_2hashes(
        key: *const ::core::ffi::c_void,
        length: u32,
        pc: *mut u32,
        pb: *mut u32,
    );
}
unsafe extern "C" {
    #[doc = "Same as rte_jhash_32b, but takes two seeds and return two uint32_ts.\npc and pb must be non-null, and *pc and *pb must both be initialized\nwith seeds. If you pass in (*pb)=0, the output (*pc) will be\nthe same as the return value from rte_jhash_32b.\n\n# Arguments\n\n* `k` -\nKey to calculate hash of.\n* `length` -\nLength of key in units of 4 bytes.\n* `pc` -\nIN: seed OUT: primary hash value.\n* `pb` -\nIN: second seed OUT: secondary hash value."]
    #[link_name = "rte_jhash_32b_2hashes_w"]
    pub fn rte_jhash_32b_2hashes(k: *const u32, length: u32, pc: *mut u32, pb: *mut u32);
}
unsafe extern "C" {
    #[doc = "The most generic version, hashes an arbitrary sequence\nof bytes.  No alignment or length assumptions are made about\nthe input key.  For keys not aligned to four byte boundaries\nor a multiple of four bytes in length, the memory region\njust after may be read (but not used in the computation).\nThis may cross a page boundary.\n\n# Arguments\n\n* `key` -\nKey to calculate hash of.\n* `length` -\nLength of key in bytes.\n* `initval` -\nInitialising value of hash.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_jhash_w"]
    pub fn rte_jhash(key: *const ::core::ffi::c_void, length: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "A special optimized version that handles 1 or more of uint32_ts.\nThe length parameter here is the number of uint32_ts in the key.\n\n# Arguments\n\n* `k` -\nKey to calculate hash of.\n* `length` -\nLength of key in units of 4 bytes.\n* `initval` -\nInitialising value of hash.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_jhash_32b_w"]
    pub fn rte_jhash_32b(k: *const u32, length: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "A special ultra-optimized versions that knows it is hashing exactly\n3 words.\n\n# Arguments\n\n* `a` -\nFirst word to calculate hash of.\n* `b` -\nSecond word to calculate hash of.\n* `c` -\nThird word to calculate hash of.\n* `initval` -\nInitialising value of hash.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_jhash_3words_w"]
    pub fn rte_jhash_3words(a: u32, b: u32, c: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "A special ultra-optimized versions that knows it is hashing exactly\n2 words.\n\n# Arguments\n\n* `a` -\nFirst word to calculate hash of.\n* `b` -\nSecond word to calculate hash of.\n* `initval` -\nInitialising value of hash.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_jhash_2words_w"]
    pub fn rte_jhash_2words(a: u32, b: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "A special ultra-optimized versions that knows it is hashing exactly\n1 word.\n\n# Arguments\n\n* `a` -\nWord to calculate hash of.\n* `initval` -\nInitialising value of hash.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_jhash_1word_w"]
    pub fn rte_jhash_1word(a: u32, initval: u32) -> u32;
}
#[doc = "Type of function that can be used for calculating the hash value."]
pub type rte_fbk_hash_fn =
    ::core::option::Option<unsafe extern "C" fn(key: u32, init_val: u32) -> u32>;
#[doc = "Parameters used when creating four-byte key hash table."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_fbk_hash_params {
    #[doc = "< Name of the hash table."]
    pub name: *const ::core::ffi::c_char,
    #[doc = "< Total number of entries."]
    pub entries: u32,
    #[doc = "< Number of entries in a bucket."]
    pub entries_per_bucket: u32,
    #[doc = "< Socket to allocate memory on."]
    pub socket_id: ::core::ffi::c_int,
    #[doc = "< The hash function."]
    pub hash_func: rte_fbk_hash_fn,
    #[doc = "< For initialising hash function."]
    pub init_val: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbk_hash_params"][::core::mem::size_of::<rte_fbk_hash_params>() - 40usize];
    ["Alignment of rte_fbk_hash_params"][::core::mem::align_of::<rte_fbk_hash_params>() - 8usize];
    ["Offset of field: rte_fbk_hash_params::name"]
        [::core::mem::offset_of!(rte_fbk_hash_params, name) - 0usize];
    ["Offset of field: rte_fbk_hash_params::entries"]
        [::core::mem::offset_of!(rte_fbk_hash_params, entries) - 8usize];
    ["Offset of field: rte_fbk_hash_params::entries_per_bucket"]
        [::core::mem::offset_of!(rte_fbk_hash_params, entries_per_bucket) - 12usize];
    ["Offset of field: rte_fbk_hash_params::socket_id"]
        [::core::mem::offset_of!(rte_fbk_hash_params, socket_id) - 16usize];
    ["Offset of field: rte_fbk_hash_params::hash_func"]
        [::core::mem::offset_of!(rte_fbk_hash_params, hash_func) - 24usize];
    ["Offset of field: rte_fbk_hash_params::init_val"]
        [::core::mem::offset_of!(rte_fbk_hash_params, init_val) - 32usize];
};
impl Default for rte_fbk_hash_params {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Individual entry in the four-byte key hash table."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_fbk_hash_entry {
    #[doc = "< For accessing entire entry."]
    pub whole_entry: u64,
    #[doc = "< For accessing each entry part."]
    pub entry: rte_fbk_hash_entry__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_fbk_hash_entry__bindgen_ty_1 {
    #[doc = "< Non-zero if entry is active."]
    pub is_entry: u16,
    #[doc = "< Value returned by lookup."]
    pub value: u16,
    #[doc = "< Key used to find value."]
    pub key: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbk_hash_entry__bindgen_ty_1"]
        [::core::mem::size_of::<rte_fbk_hash_entry__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_fbk_hash_entry__bindgen_ty_1"]
        [::core::mem::align_of::<rte_fbk_hash_entry__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_fbk_hash_entry__bindgen_ty_1::is_entry"]
        [::core::mem::offset_of!(rte_fbk_hash_entry__bindgen_ty_1, is_entry) - 0usize];
    ["Offset of field: rte_fbk_hash_entry__bindgen_ty_1::value"]
        [::core::mem::offset_of!(rte_fbk_hash_entry__bindgen_ty_1, value) - 2usize];
    ["Offset of field: rte_fbk_hash_entry__bindgen_ty_1::key"]
        [::core::mem::offset_of!(rte_fbk_hash_entry__bindgen_ty_1, key) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbk_hash_entry"][::core::mem::size_of::<rte_fbk_hash_entry>() - 8usize];
    ["Alignment of rte_fbk_hash_entry"][::core::mem::align_of::<rte_fbk_hash_entry>() - 8usize];
    ["Offset of field: rte_fbk_hash_entry::whole_entry"]
        [::core::mem::offset_of!(rte_fbk_hash_entry, whole_entry) - 0usize];
    ["Offset of field: rte_fbk_hash_entry::entry"]
        [::core::mem::offset_of!(rte_fbk_hash_entry, entry) - 0usize];
};
impl Default for rte_fbk_hash_entry {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "The four-byte key hash table structure."]
#[repr(C)]
pub struct rte_fbk_hash_table {
    #[doc = "< Name of the hash."]
    pub name: [::core::ffi::c_char; 32usize],
    #[doc = "< Total number of entries."]
    pub entries: u32,
    #[doc = "< Number of entries in a bucket."]
    pub entries_per_bucket: u32,
    #[doc = "< How many entries are used."]
    pub used_entries: u32,
    #[doc = "< To find which bucket the key is in."]
    pub bucket_mask: u32,
    #[doc = "< Convert bucket to table offset."]
    pub bucket_shift: u32,
    #[doc = "< The hash function."]
    pub hash_func: rte_fbk_hash_fn,
    #[doc = "< For initialising hash function."]
    pub init_val: u32,
    #[doc = "A flat table of all buckets."]
    pub t: __IncompleteArrayField<rte_fbk_hash_entry>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbk_hash_table"][::core::mem::size_of::<rte_fbk_hash_table>() - 72usize];
    ["Alignment of rte_fbk_hash_table"][::core::mem::align_of::<rte_fbk_hash_table>() - 8usize];
    ["Offset of field: rte_fbk_hash_table::name"]
        [::core::mem::offset_of!(rte_fbk_hash_table, name) - 0usize];
    ["Offset of field: rte_fbk_hash_table::entries"]
        [::core::mem::offset_of!(rte_fbk_hash_table, entries) - 32usize];
    ["Offset of field: rte_fbk_hash_table::entries_per_bucket"]
        [::core::mem::offset_of!(rte_fbk_hash_table, entries_per_bucket) - 36usize];
    ["Offset of field: rte_fbk_hash_table::used_entries"]
        [::core::mem::offset_of!(rte_fbk_hash_table, used_entries) - 40usize];
    ["Offset of field: rte_fbk_hash_table::bucket_mask"]
        [::core::mem::offset_of!(rte_fbk_hash_table, bucket_mask) - 44usize];
    ["Offset of field: rte_fbk_hash_table::bucket_shift"]
        [::core::mem::offset_of!(rte_fbk_hash_table, bucket_shift) - 48usize];
    ["Offset of field: rte_fbk_hash_table::hash_func"]
        [::core::mem::offset_of!(rte_fbk_hash_table, hash_func) - 56usize];
    ["Offset of field: rte_fbk_hash_table::init_val"]
        [::core::mem::offset_of!(rte_fbk_hash_table, init_val) - 64usize];
    ["Offset of field: rte_fbk_hash_table::t"]
        [::core::mem::offset_of!(rte_fbk_hash_table, t) - 72usize];
};
impl Default for rte_fbk_hash_table {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Find the offset into hash table of the bucket containing a particular key.\n\n# Arguments\n\n* `ht` -\nPointer to hash table.\n* `key` -\nKey to calculate bucket for.\n\n# Returns\n\nOffset into hash table."]
    #[link_name = "rte_fbk_hash_get_bucket_w"]
    pub fn rte_fbk_hash_get_bucket(ht: *const rte_fbk_hash_table, key: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Add a key to an existing hash table with bucket id.\nThis operation is not multi-thread safe\nand should only be called from one thread.\n\n# Arguments\n\n* `ht` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n* `value` -\nValue to associate with key.\n* `bucket` -\nBucket to associate with key.\n\n# Returns\n\n0 if ok, or negative value on error."]
    #[link_name = "rte_fbk_hash_add_key_with_bucket_w"]
    pub fn rte_fbk_hash_add_key_with_bucket(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        value: u16,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a key to an existing hash table. This operation is not multi-thread safe\nand should only be called from one thread.\n\n# Arguments\n\n* `ht` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n* `value` -\nValue to associate with key.\n\n# Returns\n\n0 if ok, or negative value on error."]
    #[link_name = "rte_fbk_hash_add_key_w"]
    pub fn rte_fbk_hash_add_key(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        value: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a key with a given bucket id from an existing hash table.\nThis operation is not multi-thread\nsafe and should only be called from one thread.\n\n# Arguments\n\n* `ht` -\nHash table to remove the key from.\n* `key` -\nKey to remove from the hash table.\n* `bucket` -\nBucket id associate with key.\n\n# Returns\n\n0 if ok, or negative value on error."]
    #[link_name = "rte_fbk_hash_delete_key_with_bucket_w"]
    pub fn rte_fbk_hash_delete_key_with_bucket(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a key from an existing hash table. This operation is not multi-thread\nsafe and should only be called from one thread.\n\n# Arguments\n\n* `ht` -\nHash table to remove the key from.\n* `key` -\nKey to remove from the hash table.\n\n# Returns\n\n0 if ok, or negative value on error."]
    #[link_name = "rte_fbk_hash_delete_key_w"]
    pub fn rte_fbk_hash_delete_key(ht: *mut rte_fbk_hash_table, key: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a key in the hash table with a given bucketid.\nThis operation is multi-thread safe.\n\n# Arguments\n\n* `ht` -\nHash table to look in.\n* `key` -\nKey to find.\n* `bucket` -\nBucket associate to the key.\n\n# Returns\n\nThe value that was associated with the key, or negative value on error."]
    #[link_name = "rte_fbk_hash_lookup_with_bucket_w"]
    pub fn rte_fbk_hash_lookup_with_bucket(
        ht: *const rte_fbk_hash_table,
        key: u32,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a key in the hash table. This operation is multi-thread safe.\n\n# Arguments\n\n* `ht` -\nHash table to look in.\n* `key` -\nKey to find.\n\n# Returns\n\nThe value that was associated with the key, or negative value on error."]
    #[link_name = "rte_fbk_hash_lookup_w"]
    pub fn rte_fbk_hash_lookup(ht: *const rte_fbk_hash_table, key: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Delete all entries in a hash table. This operation is not multi-thread\nsafe and should only be called from one thread.\n\n# Arguments\n\n* `ht` -\nHash table to delete entries in."]
    #[link_name = "rte_fbk_hash_clear_all_w"]
    pub fn rte_fbk_hash_clear_all(ht: *mut rte_fbk_hash_table);
}
unsafe extern "C" {
    #[doc = "Find what fraction of entries are being used.\n\n# Arguments\n\n* `ht` -\nHash table to find how many entries are being used in.\n\n# Returns\n\nLoad factor of the hash table, or negative value on error."]
    #[link_name = "rte_fbk_hash_get_load_factor_w"]
    pub fn rte_fbk_hash_get_load_factor(ht: *mut rte_fbk_hash_table) -> f64;
}
unsafe extern "C" {
    #[doc = "Performs a lookup for an existing hash table, and returns a pointer to\nthe table if found.\n\n# Arguments\n\n* `name` -\nName of the hash table to find\n\n# Returns\n\npointer to hash table structure or NULL on error with rte_errno\nset appropriately. Possible rte_errno values include:\n- ENOENT - required entry not available to return."]
    pub fn rte_fbk_hash_find_existing(name: *const ::core::ffi::c_char) -> *mut rte_fbk_hash_table;
}
unsafe extern "C" {
    #[doc = "Free all memory used by a hash table.\nHas no effect on hash tables allocated in memory zones\n\n# Arguments\n\n* `ht` -\nHash table to deallocate."]
    pub fn rte_fbk_hash_free(ht: *mut rte_fbk_hash_table);
}
unsafe extern "C" {
    #[doc = "Create a new hash table for use with four byte keys.\n\n# Arguments\n\n* `params` -\nParameters used in creation of hash table.\n\n# Returns\n\nPointer to hash table structure that is used in future hash table\noperations, or NULL on error with rte_errno set appropriately.\nPossible rte_errno error values include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- E_RTE_SECONDARY - function was called from a secondary process instance\n- EINVAL - invalid parameter value passed to function\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_fbk_hash_create(params: *const rte_fbk_hash_params) -> *mut rte_fbk_hash_table;
}
#[doc = "GENEVE protocol header. (draft-ietf-nvo3-geneve-09)\nContains:\n2-bits version (must be 0).\n6-bits option length in four byte multiples, not including the eight\nbytes of the fixed tunnel header.\n1-bit control packet.\n1-bit critical options in packet.\n6-bits reserved\n16-bits Protocol Type. The protocol data unit after the Geneve header\nfollowing the EtherType convention. Ethernet itself is represented by\nthe value 0x6558.\n24-bits Virtual Network Identifier (VNI). Virtual network unique identified.\n8-bits reserved bits (must be 0 on transmission and ignored on receipt).\nMore-bits (optional) variable length options."]
#[repr(C, packed)]
pub struct rte_geneve_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    #[doc = "< Protocol type."]
    pub proto: rte_be16_t,
    #[doc = "< Virtual network identifier."]
    pub vni: [u8; 3usize],
    #[doc = "< Reserved."]
    pub reserved2: u8,
    #[doc = "< Variable length options."]
    pub opts: __IncompleteArrayField<u32>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_geneve_hdr"][::core::mem::size_of::<rte_geneve_hdr>() - 8usize];
    ["Alignment of rte_geneve_hdr"][::core::mem::align_of::<rte_geneve_hdr>() - 1usize];
    ["Offset of field: rte_geneve_hdr::proto"]
        [::core::mem::offset_of!(rte_geneve_hdr, proto) - 2usize];
    ["Offset of field: rte_geneve_hdr::vni"][::core::mem::offset_of!(rte_geneve_hdr, vni) - 4usize];
    ["Offset of field: rte_geneve_hdr::reserved2"]
        [::core::mem::offset_of!(rte_geneve_hdr, reserved2) - 7usize];
    ["Offset of field: rte_geneve_hdr::opts"]
        [::core::mem::offset_of!(rte_geneve_hdr, opts) - 8usize];
};
impl Default for rte_geneve_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_geneve_hdr {
    #[inline]
    pub fn opt_len(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_opt_len(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn opt_len_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_opt_len_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ver(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(6usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_ver(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(6usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ver_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                6usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ver_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                6usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved1(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(8usize, 6u8) as u8) }
    }
    #[inline]
    pub fn set_reserved1(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(8usize, 6u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved1_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                6u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_reserved1_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                6u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn critical(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(14usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_critical(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(14usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn critical_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                14usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_critical_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                14usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn oam(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(15usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_oam(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(15usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn oam_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                15usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_oam_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                15usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        opt_len: u8,
        ver: u8,
        reserved1: u8,
        critical: u8,
        oam: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 6u8, {
            let opt_len: u8 = unsafe { ::core::mem::transmute(opt_len) };
            opt_len as u64
        });
        __bindgen_bitfield_unit.set(6usize, 2u8, {
            let ver: u8 = unsafe { ::core::mem::transmute(ver) };
            ver as u64
        });
        __bindgen_bitfield_unit.set(8usize, 6u8, {
            let reserved1: u8 = unsafe { ::core::mem::transmute(reserved1) };
            reserved1 as u64
        });
        __bindgen_bitfield_unit.set(14usize, 1u8, {
            let critical: u8 = unsafe { ::core::mem::transmute(critical) };
            critical as u64
        });
        __bindgen_bitfield_unit.set(15usize, 1u8, {
            let oam: u8 = unsafe { ::core::mem::transmute(oam) };
            oam as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    pub static mut rte_rcu_log_type: ::core::ffi::c_int;
}
#[doc = "Worker thread counter"]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_rcu_qsbr_cnt {
    pub cnt: u64,
    pub lock_cnt: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_rcu_qsbr_cnt"][::core::mem::size_of::<rte_rcu_qsbr_cnt>() - 64usize];
    ["Alignment of rte_rcu_qsbr_cnt"][::core::mem::align_of::<rte_rcu_qsbr_cnt>() - 64usize];
    ["Offset of field: rte_rcu_qsbr_cnt::cnt"]
        [::core::mem::offset_of!(rte_rcu_qsbr_cnt, cnt) - 0usize];
    ["Offset of field: rte_rcu_qsbr_cnt::lock_cnt"]
        [::core::mem::offset_of!(rte_rcu_qsbr_cnt, lock_cnt) - 8usize];
};
impl Default for rte_rcu_qsbr_cnt {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE Quiescent State variable structure.\nThis structure has two elements that vary in size based on the\n'max_threads' parameter.\n1) Quiescent state counter array\n2) Register thread ID array"]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug)]
pub struct rte_rcu_qsbr {
    pub token: u64,
    pub acked_token: u64,
    pub __bindgen_padding_0: [u32; 12usize],
    pub num_elems: u32,
    pub num_threads: u32,
    pub max_threads: u32,
    pub __bindgen_padding_1: [u64; 6usize],
    pub qsbr_cnt: __IncompleteArrayField<rte_rcu_qsbr_cnt>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_rcu_qsbr"][::core::mem::size_of::<rte_rcu_qsbr>() - 128usize];
    ["Alignment of rte_rcu_qsbr"][::core::mem::align_of::<rte_rcu_qsbr>() - 64usize];
    ["Offset of field: rte_rcu_qsbr::token"][::core::mem::offset_of!(rte_rcu_qsbr, token) - 0usize];
    ["Offset of field: rte_rcu_qsbr::acked_token"]
        [::core::mem::offset_of!(rte_rcu_qsbr, acked_token) - 8usize];
    ["Offset of field: rte_rcu_qsbr::num_elems"]
        [::core::mem::offset_of!(rte_rcu_qsbr, num_elems) - 64usize];
    ["Offset of field: rte_rcu_qsbr::num_threads"]
        [::core::mem::offset_of!(rte_rcu_qsbr, num_threads) - 68usize];
    ["Offset of field: rte_rcu_qsbr::max_threads"]
        [::core::mem::offset_of!(rte_rcu_qsbr, max_threads) - 72usize];
    ["Offset of field: rte_rcu_qsbr::qsbr_cnt"]
        [::core::mem::offset_of!(rte_rcu_qsbr, qsbr_cnt) - 128usize];
};
impl Default for rte_rcu_qsbr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Call back function called to free the resources.\n\n# Arguments\n\n* `p` -\nPointer provided while creating the defer queue\n* `e` -\nPointer to the resource data stored on the defer queue\n* `n` -\nNumber of resources to free. Currently, this is set to 1.\n\n# Returns\n\nNone"]
pub type rte_rcu_qsbr_free_resource_t = ::core::option::Option<
    unsafe extern "C" fn(
        p: *mut ::core::ffi::c_void,
        e: *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ),
>;
#[doc = "Parameters used when creating the defer queue."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_rcu_qsbr_dq_parameters {
    pub name: *const ::core::ffi::c_char,
    pub flags: u32,
    pub size: u32,
    pub esize: u32,
    pub trigger_reclaim_limit: u32,
    pub max_reclaim_size: u32,
    pub free_fn: rte_rcu_qsbr_free_resource_t,
    pub p: *mut ::core::ffi::c_void,
    pub v: *mut rte_rcu_qsbr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_rcu_qsbr_dq_parameters"]
        [::core::mem::size_of::<rte_rcu_qsbr_dq_parameters>() - 56usize];
    ["Alignment of rte_rcu_qsbr_dq_parameters"]
        [::core::mem::align_of::<rte_rcu_qsbr_dq_parameters>() - 8usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::name"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, name) - 0usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::flags"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, flags) - 8usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::size"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, size) - 12usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::esize"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, esize) - 16usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::trigger_reclaim_limit"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, trigger_reclaim_limit) - 20usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::max_reclaim_size"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, max_reclaim_size) - 24usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::free_fn"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, free_fn) - 32usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::p"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, p) - 40usize];
    ["Offset of field: rte_rcu_qsbr_dq_parameters::v"]
        [::core::mem::offset_of!(rte_rcu_qsbr_dq_parameters, v) - 48usize];
};
impl Default for rte_rcu_qsbr_dq_parameters {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "RTE defer queue structure.\nThis structure holds the defer queue. The defer queue is used to\nhold the deleted entries from the data structure that are not\nyet freed."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_rcu_qsbr_dq {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Return the size of the memory occupied by a Quiescent State variable.\n\n# Arguments\n\n* `max_threads` -\nMaximum number of threads reporting quiescent state on this variable.\n\n# Returns\n\nOn success - size of memory in bytes required for this QS variable.\nOn error - 1 with error code set in rte_errno.\nPossible rte_errno codes are:\n- EINVAL - max_threads is 0"]
    pub fn rte_rcu_qsbr_get_memsize(max_threads: u32) -> usize;
}
unsafe extern "C" {
    #[doc = "Initialize a Quiescent State (QS) variable.\n\n# Arguments\n\n* `v` -\nQS variable\n* `max_threads` -\nMaximum number of threads reporting quiescent state on this variable.\nThis should be the same value as passed to rte_rcu_qsbr_get_memsize.\n\n# Returns\n\nOn success - 0\nOn error - 1 with error code set in rte_errno.\nPossible rte_errno codes are:\n- EINVAL - max_threads is 0 or 'v' is NULL."]
    pub fn rte_rcu_qsbr_init(v: *mut rte_rcu_qsbr, max_threads: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Register a reader thread to report its quiescent state\non a QS variable.\nThis is implemented as a lock-free function. It is multi-thread\nsafe.\nAny reader thread that wants to report its quiescent state must\ncall this API. This can be called during initialization or as part\nof the packet processing loop.\nNote that rte_rcu_qsbr_thread_online must be called before the\nthread updates its quiescent state using rte_rcu_qsbr_quiescent.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nReader thread with this thread ID will report its quiescent state on\nthe QS variable. thread_id is a value between 0 and (max_threads - 1).\n'max_threads' is the parameter passed in 'rte_rcu_qsbr_init' API."]
    pub fn rte_rcu_qsbr_thread_register(
        v: *mut rte_rcu_qsbr,
        thread_id: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove a reader thread, from the list of threads reporting their\nquiescent state on a QS variable.\nThis is implemented as a lock-free function. It is multi-thread safe.\nThis API can be called from the reader threads during shutdown.\nOngoing quiescent state queries will stop waiting for the status from this\nunregistered reader thread.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nReader thread with this thread ID will stop reporting its quiescent\nstate on the QS variable."]
    pub fn rte_rcu_qsbr_thread_unregister(
        v: *mut rte_rcu_qsbr,
        thread_id: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a registered reader thread, to the list of threads reporting their\nquiescent state on a QS variable.\nThis is implemented as a lock-free function. It is multi-thread\nsafe.\nAny registered reader thread that wants to report its quiescent state must\ncall this API before calling rte_rcu_qsbr_quiescent. This can be called\nduring initialization or as part of the packet processing loop.\nThe reader thread must call rte_rcu_qsbr_thread_offline API, before\ncalling any functions that block, to ensure that rte_rcu_qsbr_check\nAPI does not wait indefinitely for the reader thread to update its QS.\nThe reader thread must call rte_rcu_thread_online API, after the blocking\nfunction call returns, to ensure that rte_rcu_qsbr_check API\nwaits for the reader thread to update its quiescent state.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nReader thread with this thread ID will report its quiescent state on\nthe QS variable."]
    #[link_name = "rte_rcu_qsbr_thread_online_w"]
    pub fn rte_rcu_qsbr_thread_online(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Remove a registered reader thread from the list of threads reporting their\nquiescent state on a QS variable.\nThis is implemented as a lock-free function. It is multi-thread\nsafe.\nThis can be called during initialization or as part of the packet\nprocessing loop.\nThe reader thread must call rte_rcu_qsbr_thread_offline API, before\ncalling any functions that block, to ensure that rte_rcu_qsbr_check\nAPI does not wait indefinitely for the reader thread to update its QS.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nrte_rcu_qsbr_check API will not wait for the reader thread with\nthis thread ID to report its quiescent state on the QS variable."]
    #[link_name = "rte_rcu_qsbr_thread_offline_w"]
    pub fn rte_rcu_qsbr_thread_offline(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Acquire a lock for accessing a shared data structure.\nThis is implemented as a lock-free function. It is multi-thread\nsafe.\nThis API is provided to aid debugging. This should be called before\naccessing a shared data structure.\nWhen RTE_LIBRTE_RCU_DEBUG is enabled a lock counter is incremented.\nSimilarly rte_rcu_qsbr_unlock will decrement the counter. When the\nrte_rcu_qsbr_check API will verify that this counter is 0.\nWhen RTE_LIBRTE_RCU_DEBUG is disabled, this API will do nothing.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nReader thread id"]
    #[link_name = "rte_rcu_qsbr_lock_w"]
    pub fn rte_rcu_qsbr_lock(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Release a lock after accessing a shared data structure.\nThis is implemented as a lock-free function. It is multi-thread\nsafe.\nThis API is provided to aid debugging. This should be called after\naccessing a shared data structure.\nWhen RTE_LIBRTE_RCU_DEBUG is enabled, rte_rcu_qsbr_unlock will\ndecrement a lock counter. rte_rcu_qsbr_check API will verify that this\ncounter is 0.\nWhen RTE_LIBRTE_RCU_DEBUG is disabled, this API will do nothing.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nReader thread id"]
    #[link_name = "rte_rcu_qsbr_unlock_w"]
    pub fn rte_rcu_qsbr_unlock(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Ask the reader threads to report the quiescent state\nstatus.\nThis is implemented as a lock-free function. It is multi-thread\nsafe and can be called from worker threads.\n\n# Arguments\n\n* `v` -\nQS variable\n\n# Returns\n\n- This is the token for this call of the API. This should be\npassed to rte_rcu_qsbr_check API."]
    #[link_name = "rte_rcu_qsbr_start_w"]
    pub fn rte_rcu_qsbr_start(v: *mut rte_rcu_qsbr) -> u64;
}
unsafe extern "C" {
    #[doc = "Update quiescent state for a reader thread.\nThis is implemented as a lock-free function. It is multi-thread safe.\nAll the reader threads registered to report their quiescent state\non the QS variable must call this API.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nUpdate the quiescent state for the reader with this thread ID."]
    #[link_name = "rte_rcu_qsbr_quiescent_w"]
    pub fn rte_rcu_qsbr_quiescent(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Checks if all the reader threads have entered the quiescent state\nreferenced by token.\nThis is implemented as a lock-free function. It is multi-thread\nsafe and can be called from the worker threads as well.\nIf this API is called with 'wait' set to true, the following\nfactors must be considered:\n1) If the calling thread is also reporting the status on the\nsame QS variable, it must update the quiescent state status, before\ncalling this API.\n2) In addition, while calling from multiple threads, only\none of those threads can be reporting the quiescent state status\non a given QS variable.\n\n# Arguments\n\n* `v` -\nQS variable\n* `t` -\nToken returned by rte_rcu_qsbr_start API\n* `wait` -\nIf true, block till all the reader threads have completed entering\nthe quiescent state referenced by token 't'.\n\n# Returns\n\n- 0 if all reader threads have NOT passed through specified number\nof quiescent states.\n- 1 if all reader threads have passed through specified number\nof quiescent states."]
    #[link_name = "rte_rcu_qsbr_check_w"]
    pub fn rte_rcu_qsbr_check(v: *mut rte_rcu_qsbr, t: u64, wait: bool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Wait till the reader threads have entered quiescent state.\nThis is implemented as a lock-free function. It is multi-thread safe.\nThis API can be thought of as a wrapper around rte_rcu_qsbr_start and\nrte_rcu_qsbr_check APIs.\nIf this API is called from multiple threads, only one of\nthose threads can be reporting the quiescent state status on a\ngiven QS variable.\n\n# Arguments\n\n* `v` -\nQS variable\n* `thread_id` -\nThread ID of the caller if it is registered to report quiescent state\non this QS variable (i.e. the calling thread is also part of the\nreadside critical section). If not, pass RTE_QSBR_THRID_INVALID."]
    pub fn rte_rcu_qsbr_synchronize(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "Dump the details of a single QS variables to a file.\nIt is NOT multi-thread safe.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `v` -\nQS variable\n\n# Returns\n\nOn success - 0\nOn error - 1 with error code set in rte_errno.\nPossible rte_errno codes are:\n- EINVAL - NULL parameters are passed"]
    pub fn rte_rcu_qsbr_dump(f: *mut FILE, v: *mut rte_rcu_qsbr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a queue used to store the data structure elements that can\nbe freed later. This queue is referred to as 'defer queue'.\n\n# Arguments\n\n* `params` -\nParameters to create a defer queue.\n\n# Returns\n\nOn success - Valid pointer to defer queue\nOn error - NULL\nPossible rte_errno codes are:\n- EINVAL - NULL parameters are passed\n- ENOMEM - Not enough memory"]
    pub fn rte_rcu_qsbr_dq_create(
        params: *const rte_rcu_qsbr_dq_parameters,
    ) -> *mut rte_rcu_qsbr_dq;
}
unsafe extern "C" {
    #[doc = "Enqueue one resource to the defer queue and start the grace period.\nThe resource will be freed later after at least one grace period\nis over.\nIf the defer queue is full, it will attempt to reclaim resources.\nIt will also reclaim resources at regular intervals to avoid\nthe defer queue from growing too big.\nMulti-thread safety is provided as the defer queue configuration.\nWhen multi-thread safety is requested, it is possible that the\nresources are not stored in their order of deletion. This results\nin resources being held in the defer queue longer than they should.\n\n# Arguments\n\n* `dq` -\nDefer queue to allocate an entry from.\n* `e` -\nPointer to resource data to copy to the defer queue. The size of\nthe data to copy is equal to the element size provided when the\ndefer queue was created.\n\n# Returns\n\nOn success - 0\nOn error - 1 with rte_errno set to\n- EINVAL - NULL parameters are passed\n- ENOSPC - Defer queue is full. This condition can not happen\nif the defer queue size is equal (or larger) than the\nnumber of elements in the data structure."]
    pub fn rte_rcu_qsbr_dq_enqueue(
        dq: *mut rte_rcu_qsbr_dq,
        e: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Free resources from the defer queue.\nThis API is multi-thread safe.\n\n# Arguments\n\n* `dq` -\nDefer queue to free an entry from.\n* `n` -\nMaximum number of resources to free.\n* `freed` -\nNumber of resources that were freed.\n* `pending` -\nNumber of resources pending on the defer queue. This number might not\nbe accurate if multi-thread safety is configured.\n* `available` -\nNumber of resources that can be added to the defer queue.\nThis number might not be accurate if multi-thread safety is configured.\n\n# Returns\n\nOn successful reclamation of at least 1 resource - 0\nOn error - 1 with rte_errno set to\n- EINVAL - NULL parameters are passed"]
    pub fn rte_rcu_qsbr_dq_reclaim(
        dq: *mut rte_rcu_qsbr_dq,
        n: ::core::ffi::c_uint,
        freed: *mut ::core::ffi::c_uint,
        pending: *mut ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Delete a defer queue.\nIt tries to reclaim all the resources on the defer queue.\nIf any of the resources have not completed the grace period\nthe reclamation stops and returns immediately. The rest of\nthe resources are not reclaimed and the defer queue is not\nfreed.\n\n# Arguments\n\n* `dq` -\nDefer queue to delete.\n\n# Returns\n\nOn success - 0\nOn error - 1\nPossible rte_errno codes are:\n- EAGAIN - Some of the resources have not completed at least 1 grace\nperiod, try again."]
    pub fn rte_rcu_qsbr_dq_delete(dq: *mut rte_rcu_qsbr_dq) -> ::core::ffi::c_int;
}
#[doc = "The type of hash value of a key.\nIt should be a value of at least 32bit with fully random pattern."]
pub type hash_sig_t = u32;
#[doc = "Type of function that can be used for calculating the hash value."]
pub type rte_hash_function = ::core::option::Option<
    unsafe extern "C" fn(key: *const ::core::ffi::c_void, key_len: u32, init_val: u32) -> u32,
>;
#[doc = "Type of function used to compare the hash key."]
pub type rte_hash_cmp_eq_t = ::core::option::Option<
    unsafe extern "C" fn(
        key1: *const ::core::ffi::c_void,
        key2: *const ::core::ffi::c_void,
        key_len: usize,
    ) -> ::core::ffi::c_int,
>;
#[doc = "Type of function used to free data stored in the key.\nRequired when using internal RCU to allow application to free key-data once\nthe key is returned to the ring of free key-slots."]
pub type rte_hash_free_key_data = ::core::option::Option<
    unsafe extern "C" fn(p: *mut ::core::ffi::c_void, key_data: *mut ::core::ffi::c_void),
>;
#[doc = "Parameters used when creating the hash table."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_hash_parameters {
    #[doc = "< Name of the hash."]
    pub name: *const ::core::ffi::c_char,
    #[doc = "< Total hash table entries."]
    pub entries: u32,
    #[doc = "< Unused field. Should be set to 0"]
    pub reserved: u32,
    #[doc = "< Length of hash key."]
    pub key_len: u32,
    #[doc = "< Primary Hash function used to calculate hash."]
    pub hash_func: rte_hash_function,
    #[doc = "< Init value used by hash_func."]
    pub hash_func_init_val: u32,
    #[doc = "< NUMA Socket ID for memory."]
    pub socket_id: ::core::ffi::c_int,
    #[doc = "< Indicate if additional parameters are present."]
    pub extra_flag: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_hash_parameters"][::core::mem::size_of::<rte_hash_parameters>() - 48usize];
    ["Alignment of rte_hash_parameters"][::core::mem::align_of::<rte_hash_parameters>() - 8usize];
    ["Offset of field: rte_hash_parameters::name"]
        [::core::mem::offset_of!(rte_hash_parameters, name) - 0usize];
    ["Offset of field: rte_hash_parameters::entries"]
        [::core::mem::offset_of!(rte_hash_parameters, entries) - 8usize];
    ["Offset of field: rte_hash_parameters::reserved"]
        [::core::mem::offset_of!(rte_hash_parameters, reserved) - 12usize];
    ["Offset of field: rte_hash_parameters::key_len"]
        [::core::mem::offset_of!(rte_hash_parameters, key_len) - 16usize];
    ["Offset of field: rte_hash_parameters::hash_func"]
        [::core::mem::offset_of!(rte_hash_parameters, hash_func) - 24usize];
    ["Offset of field: rte_hash_parameters::hash_func_init_val"]
        [::core::mem::offset_of!(rte_hash_parameters, hash_func_init_val) - 32usize];
    ["Offset of field: rte_hash_parameters::socket_id"]
        [::core::mem::offset_of!(rte_hash_parameters, socket_id) - 36usize];
    ["Offset of field: rte_hash_parameters::extra_flag"]
        [::core::mem::offset_of!(rte_hash_parameters, extra_flag) - 40usize];
};
impl Default for rte_hash_parameters {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_hash_qsbr_mode {
    #[doc = "RCU reclamation modes"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Create defer queue for reclaim."]
    pub const RTE_HASH_QSBR_MODE_DQ: Type = 0;
    #[doc = "Use blocking mode reclaim. No defer queue created."]
    pub const RTE_HASH_QSBR_MODE_SYNC: Type = 1;
}
#[doc = "HASH RCU QSBR configuration structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_hash_rcu_config {
    #[doc = "< RCU QSBR variable."]
    pub v: *mut rte_rcu_qsbr,
    pub mode: rte_hash_qsbr_mode::Type,
    pub dq_size: u32,
    #[doc = "< Threshold to trigger auto reclaim."]
    pub trigger_reclaim_limit: u32,
    pub max_reclaim_size: u32,
    pub key_data_ptr: *mut ::core::ffi::c_void,
    pub free_key_data_func: rte_hash_free_key_data,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_hash_rcu_config"][::core::mem::size_of::<rte_hash_rcu_config>() - 40usize];
    ["Alignment of rte_hash_rcu_config"][::core::mem::align_of::<rte_hash_rcu_config>() - 8usize];
    ["Offset of field: rte_hash_rcu_config::v"]
        [::core::mem::offset_of!(rte_hash_rcu_config, v) - 0usize];
    ["Offset of field: rte_hash_rcu_config::mode"]
        [::core::mem::offset_of!(rte_hash_rcu_config, mode) - 8usize];
    ["Offset of field: rte_hash_rcu_config::dq_size"]
        [::core::mem::offset_of!(rte_hash_rcu_config, dq_size) - 12usize];
    ["Offset of field: rte_hash_rcu_config::trigger_reclaim_limit"]
        [::core::mem::offset_of!(rte_hash_rcu_config, trigger_reclaim_limit) - 16usize];
    ["Offset of field: rte_hash_rcu_config::max_reclaim_size"]
        [::core::mem::offset_of!(rte_hash_rcu_config, max_reclaim_size) - 20usize];
    ["Offset of field: rte_hash_rcu_config::key_data_ptr"]
        [::core::mem::offset_of!(rte_hash_rcu_config, key_data_ptr) - 24usize];
    ["Offset of field: rte_hash_rcu_config::free_key_data_func"]
        [::core::mem::offset_of!(rte_hash_rcu_config, free_key_data_func) - 32usize];
};
impl Default for rte_hash_rcu_config {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "@internal A hash table structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_hash {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "De-allocate all memory used by hash table.\n\n# Arguments\n\n* `h` -\nHash table to free, if NULL, the function does nothing."]
    pub fn rte_hash_free(h: *mut rte_hash);
}
unsafe extern "C" {
    #[doc = "Create a new hash table.\n\n# Arguments\n\n* `params` -\nParameters used to create and initialise the hash table.\n\n# Returns\n\nPointer to hash table structure that is used in future hash table\noperations, or NULL on error, with error code set in rte_errno.\nPossible rte_errno errors include:\n- E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n- E_RTE_SECONDARY - function was called from a secondary process instance\n- ENOENT - missing entry\n- EINVAL - invalid parameter passed to function\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a memzone with the same name already exists\n- ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_hash_create(params: *const rte_hash_parameters) -> *mut rte_hash;
}
unsafe extern "C" {
    #[doc = "Set a new hash compare function other than the default one.\n> **Note** Function pointer does not work with multi-process, so do not use it\nin multi-process mode.\n\n# Arguments\n\n* `h` -\nHash table for which the function is to be changed\n* `func` -\nNew compare function"]
    pub fn rte_hash_set_cmp_func(h: *mut rte_hash, func: rte_hash_cmp_eq_t);
}
unsafe extern "C" {
    #[doc = "Find an existing hash table object and return a pointer to it.\n\n# Arguments\n\n* `name` -\nName of the hash table as passed to rte_hash_create()\n\n# Returns\n\nPointer to hash table or NULL if object not found\nwith rte_errno set appropriately. Possible rte_errno values include:\n- ENOENT - value not available for return"]
    pub fn rte_hash_find_existing(name: *const ::core::ffi::c_char) -> *mut rte_hash;
}
unsafe extern "C" {
    #[doc = "Reset all hash structure, by zeroing all entries.\nWhen RTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY_LF is enabled,\nit is application's responsibility to make sure that\nnone of the readers are referencing the hash table\nwhile calling this API.\n\n# Arguments\n\n* `h` -\nHash table to reset"]
    pub fn rte_hash_reset(h: *mut rte_hash);
}
unsafe extern "C" {
    #[doc = "Return the number of keys in the hash table\n\n# Arguments\n\n* `h` -\nHash table to query from\n\n# Returns\n\n- -EINVAL if parameters are invalid\n- A value indicating how many keys were inserted in the table."]
    pub fn rte_hash_count(h: *const rte_hash) -> i32;
}
unsafe extern "C" {
    #[doc = "Return the maximum key value ID that could possibly be returned by\nrte_hash_add_key function.\n\n# Arguments\n\n* `h` -\nHash table to query from\n\n# Returns\n\n- -EINVAL if parameters are invalid\n- A value indicating the max key ID of key slots present in the table."]
    pub fn rte_hash_max_key_id(h: *const rte_hash) -> i32;
}
unsafe extern "C" {
    #[doc = "Add a key-value pair to an existing hash table.\nThis operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\nIf the key exists already in the table, this API updates its value\nwith 'data' passed in this API. It is the responsibility of\nthe application to manage any memory associated with the old value.\nThe readers might still be using the old value even after this API\nhas returned.\n\n# Arguments\n\n* `h` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n* `data` -\nData to add to the hash table.\n\n# Returns\n\n- 0 if added successfully\n- -EINVAL if the parameters are invalid.\n- -ENOSPC if there is no space in the hash for this key."]
    pub fn rte_hash_add_key_data(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        data: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a key-value pair with a pre-computed hash value\nto an existing hash table.\nThis operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\nIf the key exists already in the table, this API updates its value\nwith 'data' passed in this API. It is the responsibility of\nthe application to manage any memory associated with the old value.\nThe readers might still be using the old value even after this API\nhas returned.\n\n# Arguments\n\n* `h` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n* `sig` -\nPrecomputed hash value for 'key'\n* `data` -\nData to add to the hash table.\n\n# Returns\n\n- 0 if added successfully\n- -EINVAL if the parameters are invalid.\n- -ENOSPC if there is no space in the hash for this key."]
    pub fn rte_hash_add_key_with_hash_data(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        sig: hash_sig_t,
        data: *mut ::core::ffi::c_void,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Add a key to an existing hash table. This operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOSPC if there is no space in the hash for this key.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key. This\nunique key id may be larger than the user specified entry count\nwhen RTE_HASH_EXTRA_FLAGS_MULTI_WRITER_ADD flag is set."]
    pub fn rte_hash_add_key(h: *const rte_hash, key: *const ::core::ffi::c_void) -> i32;
}
unsafe extern "C" {
    #[doc = "Add a key to an existing hash table.\nThis operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to add the key to.\n* `key` -\nKey to add to the hash table.\n* `sig` -\nPrecomputed hash value for 'key'.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOSPC if there is no space in the hash for this key.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key. This\nunique key ID may be larger than the user specified entry count\nwhen RTE_HASH_EXTRA_FLAGS_MULTI_WRITER_ADD flag is set."]
    pub fn rte_hash_add_key_with_hash(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        sig: hash_sig_t,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Remove a key from an existing hash table.\nThis operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\nIf RTE_HASH_EXTRA_FLAGS_NO_FREE_ON_DEL or\nRTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY_LF is enabled and\ninternal RCU is NOT enabled,\nthe key index returned by rte_hash_add_key_xxx APIs will not be\nfreed by this API. rte_hash_free_key_with_position API must be called\nadditionally to free the index associated with the key.\nrte_hash_free_key_with_position API should be called after all\nthe readers have stopped referencing the entry corresponding to\nthis key. RCU mechanisms could be used to determine such a state.\n\n# Arguments\n\n* `h` -\nHash table to remove the key from.\n* `key` -\nKey to remove from the hash table.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added."]
    pub fn rte_hash_del_key(h: *const rte_hash, key: *const ::core::ffi::c_void) -> i32;
}
unsafe extern "C" {
    #[doc = "Remove a key from an existing hash table.\nThis operation is not multi-thread safe\nand should only be called from one thread by default.\nThread safety can be enabled by setting flag during\ntable creation.\nIf RTE_HASH_EXTRA_FLAGS_NO_FREE_ON_DEL or\nRTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY_LF is enabled and\ninternal RCU is NOT enabled,\nthe key index returned by rte_hash_add_key_xxx APIs will not be\nfreed by this API. rte_hash_free_key_with_position API must be called\nadditionally to free the index associated with the key.\nrte_hash_free_key_with_position API should be called after all\nthe readers have stopped referencing the entry corresponding to\nthis key. RCU mechanisms could be used to determine such a state.\n\n# Arguments\n\n* `h` -\nHash table to remove the key from.\n* `key` -\nKey to remove from the hash table.\n* `sig` -\nPrecomputed hash value for 'key'.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added."]
    pub fn rte_hash_del_key_with_hash(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        sig: hash_sig_t,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Find a key in the hash table given the position.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to get the key from.\n* `position` -\nPosition returned when the key was inserted.\n* `key` -\nOutput containing a pointer to the key\n\n# Returns\n\n- 0 if retrieved successfully\n- -EINVAL if the parameters are invalid.\n- -ENOENT if no valid key is found in the given position."]
    pub fn rte_hash_get_key_with_position(
        h: *const rte_hash,
        position: i32,
        key: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Free a hash key in the hash table given the position\nof the key. This operation is not multi-thread safe and should\nonly be called from one thread by default. Thread safety\ncan be enabled by setting flag during table creation.\nIf RTE_HASH_EXTRA_FLAGS_NO_FREE_ON_DEL or\nRTE_HASH_EXTRA_FLAGS_RW_CONCURRENCY_LF is enabled and\ninternal RCU is NOT enabled,\nthe key index returned by rte_hash_del_key_xxx APIs must be freed\nusing this API. This API should be called after all the readers\nhave stopped referencing the entry corresponding to this key.\nRCU mechanisms could be used to determine such a state.\nThis API does not validate if the key is already freed.\n\n# Arguments\n\n* `h` -\nHash table to free the key from.\n* `position` -\nPosition returned when the key was deleted.\n\n# Returns\n\n- 0 if freed successfully\n- -EINVAL if the parameters are invalid."]
    pub fn rte_hash_free_key_with_position(h: *const rte_hash, position: i32)
    -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a key-value pair in the hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `key` -\nKey to find.\n* `data` -\nOutput with pointer to data returned from the hash table.\n\n# Returns\n\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added.\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found."]
    pub fn rte_hash_lookup_data(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        data: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a key-value pair with a pre-computed hash value\nto an existing hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `key` -\nKey to find.\n* `sig` -\nPrecomputed hash value for 'key'\n* `data` -\nOutput with pointer to data returned from the hash table.\n\n# Returns\n\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added.\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found."]
    pub fn rte_hash_lookup_with_hash_data(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        sig: hash_sig_t,
        data: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a key in the hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `key` -\nKey to find.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added."]
    pub fn rte_hash_lookup(h: *const rte_hash, key: *const ::core::ffi::c_void) -> i32;
}
unsafe extern "C" {
    #[doc = "Find a key in the hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `key` -\nKey to find.\n* `sig` -\nPrecomputed hash value for 'key'.\n\n# Returns\n\n- -EINVAL if the parameters are invalid.\n- -ENOENT if the key is not found.\n- A non-negative value that can be used by the caller as an offset into an\narray of user data. This value is unique for this key, and is the same\nvalue that was returned when the key was added."]
    pub fn rte_hash_lookup_with_hash(
        h: *const rte_hash,
        key: *const ::core::ffi::c_void,
        sig: hash_sig_t,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Calc a hash value by key.\nThis operation is not multi-process safe.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `key` -\nKey to find.\n\n# Returns\n\n- hash value"]
    pub fn rte_hash_hash(h: *const rte_hash, key: *const ::core::ffi::c_void) -> hash_sig_t;
}
unsafe extern "C" {
    #[doc = "Find multiple keys in the hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `keys` -\nA pointer to a list of keys to look for.\n* `num_keys` -\nHow many keys are in the keys list (less than RTE_HASH_LOOKUP_BULK_MAX).\n* `hit_mask` -\nOutput containing a bitmask with all successful lookups.\n* `data` -\nOutput containing array of data returned from all the successful lookups.\n\n# Returns\n\n-EINVAL if there's an error, otherwise number of successful lookups."]
    pub fn rte_hash_lookup_bulk_data(
        h: *const rte_hash,
        keys: *mut *const ::core::ffi::c_void,
        num_keys: u32,
        hit_mask: *mut u64,
        data: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find multiple keys in the hash table with precomputed hash value array.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `keys` -\nA pointer to a list of keys to look for.\n* `sig` -\nA pointer to a list of precomputed hash values for keys.\n* `num_keys` -\nHow many keys are in the keys list (less than RTE_HASH_LOOKUP_BULK_MAX).\n* `positions` -\nOutput containing a list of values, corresponding to the list of keys that\ncan be used by the caller as an offset into an array of user data. These\nvalues are unique for each key, and are the same values that were returned\nwhen each key was added. If a key in the list was not found, then -ENOENT\nwill be the value.\n\n# Returns\n\n-EINVAL if there's an error, otherwise 0."]
    pub fn rte_hash_lookup_with_hash_bulk(
        h: *const rte_hash,
        keys: *mut *const ::core::ffi::c_void,
        sig: *mut hash_sig_t,
        num_keys: u32,
        positions: *mut i32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find multiple keys in the hash table with precomputed hash value array.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `keys` -\nA pointer to a list of keys to look for.\n* `sig` -\nA pointer to a list of precomputed hash values for keys.\n* `num_keys` -\nHow many keys are in the keys list (less than RTE_HASH_LOOKUP_BULK_MAX).\n* `hit_mask` -\nOutput containing a bitmask with all successful lookups.\n* `data` -\nOutput containing array of data returned from all the successful lookups.\n\n# Returns\n\n-EINVAL if there's an error, otherwise number of successful lookups."]
    pub fn rte_hash_lookup_with_hash_bulk_data(
        h: *const rte_hash,
        keys: *mut *const ::core::ffi::c_void,
        sig: *mut hash_sig_t,
        num_keys: u32,
        hit_mask: *mut u64,
        data: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find multiple keys in the hash table.\nThis operation is multi-thread safe with regarding to other lookup threads.\nRead-write concurrency can be enabled by setting flag during\ntable creation.\n\n# Arguments\n\n* `h` -\nHash table to look in.\n* `keys` -\nA pointer to a list of keys to look for.\n* `num_keys` -\nHow many keys are in the keys list (less than RTE_HASH_LOOKUP_BULK_MAX).\n* `positions` -\nOutput containing a list of values, corresponding to the list of keys that\ncan be used by the caller as an offset into an array of user data. These\nvalues are unique for each key, and are the same values that were returned\nwhen each key was added. If a key in the list was not found, then -ENOENT\nwill be the value.\n\n# Returns\n\n-EINVAL if there's an error, otherwise 0."]
    pub fn rte_hash_lookup_bulk(
        h: *const rte_hash,
        keys: *mut *const ::core::ffi::c_void,
        num_keys: u32,
        positions: *mut i32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Iterate through the hash table, returning key-value pairs.\n\n# Arguments\n\n* `h` -\nHash table to iterate\n* `key` -\nOutput containing the key where current iterator\nwas pointing at\n* `data` -\nOutput containing the data associated with key.\nReturns NULL if data was not stored.\n* `next` -\nPointer to iterator. Should be 0 to start iterating the hash table.\nIterator is incremented after each call of this function.\n\n# Returns\n\nPosition where key was stored, if successful.\n- -EINVAL if the parameters are invalid.\n- -ENOENT if end of the hash table."]
    pub fn rte_hash_iterate(
        h: *const rte_hash,
        key: *mut *const ::core::ffi::c_void,
        data: *mut *mut ::core::ffi::c_void,
        next: *mut u32,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Associate RCU QSBR variable with a Hash object.\nThis API should be called to enable the integrated RCU QSBR support and\nshould be called immediately after creating the Hash object.\n\n# Arguments\n\n* `h` -\nthe hash object to add RCU QSBR\n* `cfg` -\nRCU QSBR configuration\n\n# Returns\n\nOn success - 0\nOn error - 1 with error code set in rte_errno.\nPossible rte_errno codes are:\n- EINVAL - invalid pointer\n- EEXIST - already added QSBR\n- ENOMEM - memory allocation failure"]
    pub fn rte_hash_rcu_qsbr_add(
        h: *mut rte_hash,
        cfg: *mut rte_hash_rcu_config,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Reclaim resources from the defer queue.\nThis API reclaim the resources from the defer queue if rcu is enabled.\n\n# Arguments\n\n* `h` -\nThe hash object to reclaim resources.\n* `freed` -\nNumber of resources that were freed.\n* `pending` -\nNumber of resources pending on the defer queue.\nThis number might not be accurate if multi-thread safety is configured.\n* `available` -\nNumber of resources that can be added to the defer queue.\nThis number might not be accurate if multi-thread safety is configured.\n\n# Returns\n\nOn success - 0\nOn error - 1 with error code set in rte_errno.\nPossible rte_errno codes are:\n- EINVAL - invalid pointer"]
    pub fn rte_hash_rcu_qsbr_dq_reclaim(
        h: *mut rte_hash,
        freed: *mut ::core::ffi::c_uint,
        pending: *mut ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump out memory in a special hex dump format.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output.\n* `title` -\nIf not NULL this string is printed as a header to the output.\n* `buf` -\nThis is the buffer address to print out.\n* `len` -\nThe number of bytes to dump out."]
    pub fn rte_hexdump(
        f: *mut FILE,
        title: *const ::core::ffi::c_char,
        buf: *const ::core::ffi::c_void,
        len: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Dump out memory in a hex format with colons between bytes.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output.\n* `title` -\nIf not NULL this string is printed as a header to the output.\n* `buf` -\nThis is the buffer address to print out.\n* `len` -\nThe number of bytes to dump out."]
    pub fn rte_memdump(
        f: *mut FILE,
        title: *const ::core::ffi::c_char,
        buf: *const ::core::ffi::c_void,
        len: ::core::ffi::c_uint,
    );
}
pub mod rte_hypervisor {
    #[doc = "@file Hypervisor awareness."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_HYPERVISOR_NONE: Type = 0;
    pub const RTE_HYPERVISOR_KVM: Type = 1;
    pub const RTE_HYPERVISOR_HYPERV: Type = 2;
    pub const RTE_HYPERVISOR_VMWARE: Type = 3;
    pub const RTE_HYPERVISOR_UNKNOWN: Type = 4;
}
unsafe extern "C" {
    #[doc = "Get the id of hypervisor it is running on."]
    pub fn rte_hypervisor_get() -> rte_hypervisor::Type;
}
unsafe extern "C" {
    #[doc = "Get the name of a given hypervisor id."]
    pub fn rte_hypervisor_get_name(id: rte_hypervisor::Type) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[link_name = "rte_read8_relaxed_w"]
    pub fn rte_read8_relaxed(addr: *const ::core::ffi::c_void) -> u8;
}
unsafe extern "C" {
    #[link_name = "rte_read16_relaxed_w"]
    pub fn rte_read16_relaxed(addr: *const ::core::ffi::c_void) -> u16;
}
unsafe extern "C" {
    #[link_name = "rte_read32_relaxed_w"]
    pub fn rte_read32_relaxed(addr: *const ::core::ffi::c_void) -> u32;
}
unsafe extern "C" {
    #[link_name = "rte_read64_relaxed_w"]
    pub fn rte_read64_relaxed(addr: *const ::core::ffi::c_void) -> u64;
}
unsafe extern "C" {
    #[link_name = "rte_write8_relaxed_w"]
    pub fn rte_write8_relaxed(value: u8, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write16_relaxed_w"]
    pub fn rte_write16_relaxed(value: u16, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write32_relaxed_w"]
    pub fn rte_write32_relaxed(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write64_relaxed_w"]
    pub fn rte_write64_relaxed(value: u64, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_read8_w"]
    pub fn rte_read8(addr: *const ::core::ffi::c_void) -> u8;
}
unsafe extern "C" {
    #[link_name = "rte_read16_w"]
    pub fn rte_read16(addr: *const ::core::ffi::c_void) -> u16;
}
unsafe extern "C" {
    #[link_name = "rte_read32_w"]
    pub fn rte_read32(addr: *const ::core::ffi::c_void) -> u32;
}
unsafe extern "C" {
    #[link_name = "rte_read64_w"]
    pub fn rte_read64(addr: *const ::core::ffi::c_void) -> u64;
}
unsafe extern "C" {
    #[link_name = "rte_write8_w"]
    pub fn rte_write8(value: u8, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write16_w"]
    pub fn rte_write16(value: u16, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write32_w"]
    pub fn rte_write32(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write64_w"]
    pub fn rte_write64(value: u64, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write32_wc_relaxed_w"]
    pub fn rte_write32_wc_relaxed(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[link_name = "rte_write32_wc_w"]
    pub fn rte_write32_wc(value: u32, addr: *mut ::core::ffi::c_void);
}
pub mod rte_keepalive_state {
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_KA_STATE_UNUSED: Type = 0;
    pub const RTE_KA_STATE_ALIVE: Type = 1;
    pub const RTE_KA_STATE_MISSING: Type = 4;
    pub const RTE_KA_STATE_DEAD: Type = 2;
    pub const RTE_KA_STATE_GONE: Type = 3;
    pub const RTE_KA_STATE_DOZING: Type = 5;
    pub const RTE_KA_STATE_SLEEP: Type = 6;
}
#[doc = "Keepalive failure callback.\nReceives a data pointer passed to rte_keepalive_create() and the id of the\nfailed core.\n\n# Arguments\n\n* `data` - Data pointer passed to rte_keepalive_create()\n* `id_core` - ID of the core that has failed"]
pub type rte_keepalive_failure_callback_t = ::core::option::Option<
    unsafe extern "C" fn(data: *mut ::core::ffi::c_void, id_core: ::core::ffi::c_int),
>;
#[doc = "Keepalive relay callback.\nReceives a data pointer passed to rte_keepalive_register_relay_callback(),\nthe id of the core for which state is to be forwarded, and details of the\ncurrent core state.\n\n# Arguments\n\n* `data` - Data pointer passed to rte_keepalive_register_relay_callback()\n* `id_core` - ID of the core for which state is being reported\n* `core_state` - The current state of the core\n* `last_seen` - Timestamp of when core was last seen alive"]
pub type rte_keepalive_relay_callback_t = ::core::option::Option<
    unsafe extern "C" fn(
        data: *mut ::core::ffi::c_void,
        id_core: ::core::ffi::c_int,
        core_state: rte_keepalive_state::Type,
        last_seen: u64,
    ),
>;
#[doc = "Keepalive state structure.\n@internal "]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_keepalive {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Initialise keepalive sub-system.\n\n# Arguments\n\n* `callback` -\nFunction called upon detection of a dead core.\n* `data` -\nData pointer to be passed to function callback.\n\n# Returns\n\nKeepalive structure success, NULL on failure."]
    pub fn rte_keepalive_create(
        callback: rte_keepalive_failure_callback_t,
        data: *mut ::core::ffi::c_void,
    ) -> *mut rte_keepalive;
}
unsafe extern "C" {
    #[doc = "Checks & handles keepalive state of monitored cores.\n\n# Arguments\n\n* `*ptr_timer` - Triggering timer (unused)\n* `*ptr_data` -  Data pointer (keepalive structure)"]
    pub fn rte_keepalive_dispatch_pings(
        ptr_timer: *mut ::core::ffi::c_void,
        ptr_data: *mut ::core::ffi::c_void,
    );
}
unsafe extern "C" {
    #[doc = "Registers a core for keepalive checks.\n\n# Arguments\n\n* `*keepcfg` -\nKeepalive structure pointer\n* `id_core` -\nID number of core to register."]
    pub fn rte_keepalive_register_core(keepcfg: *mut rte_keepalive, id_core: ::core::ffi::c_int);
}
unsafe extern "C" {
    #[doc = "Per-core keepalive check.\n\n# Arguments\n\n* `*keepcfg` -\nKeepalive structure pointer\nThis function needs to be called from within the main process loop of\nthe LCore to be checked."]
    pub fn rte_keepalive_mark_alive(keepcfg: *mut rte_keepalive);
}
unsafe extern "C" {
    #[doc = "Per-core sleep-time indication.\n\n# Arguments\n\n* `*keepcfg` -\nKeepalive structure pointer\nIf CPU idling is enabled, this function needs to be called from within\nthe main process loop of the LCore going to sleep, in order to avoid\nthe LCore being mis-detected as dead."]
    pub fn rte_keepalive_mark_sleep(keepcfg: *mut rte_keepalive);
}
unsafe extern "C" {
    #[doc = "Registers a 'live core' callback.\nThe complement of the 'dead core' callback. This is called when a\ncore is known to be alive, and is intended for cases when an app\nneeds to know 'liveness' beyond just knowing when a core has died.\n\n# Arguments\n\n* `*keepcfg` -\nKeepalive structure pointer\n* `callback` -\nFunction called upon detection of a dead core.\n* `data` -\nData pointer to be passed to function callback."]
    pub fn rte_keepalive_register_relay_callback(
        keepcfg: *mut rte_keepalive,
        callback: rte_keepalive_relay_callback_t,
        data: *mut ::core::ffi::c_void,
    );
}
#[doc = "Callback prototype used by rte_kvargs_process().\n\n# Arguments\n\n* `key` -\nThe key to consider, it will not be NULL.\n* `value` -\nThe value corresponding to the key, it may be NULL (e.g. only with key)\n* `opaque` -\nAn opaque pointer coming from the caller.\n\n# Returns\n\n- >=0 handle key success.\n- <0 on error."]
pub type arg_handler_t = ::core::option::Option<
    unsafe extern "C" fn(
        key: *const ::core::ffi::c_char,
        value: *const ::core::ffi::c_char,
        opaque: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int,
>;
#[doc = "A key/value association"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_kvargs_pair {
    #[doc = "< the name (key) of the association"]
    pub key: *mut ::core::ffi::c_char,
    #[doc = "< the value associated to that key"]
    pub value: *mut ::core::ffi::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_kvargs_pair"][::core::mem::size_of::<rte_kvargs_pair>() - 16usize];
    ["Alignment of rte_kvargs_pair"][::core::mem::align_of::<rte_kvargs_pair>() - 8usize];
    ["Offset of field: rte_kvargs_pair::key"]
        [::core::mem::offset_of!(rte_kvargs_pair, key) - 0usize];
    ["Offset of field: rte_kvargs_pair::value"]
        [::core::mem::offset_of!(rte_kvargs_pair, value) - 8usize];
};
impl Default for rte_kvargs_pair {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Store a list of key/value associations"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_kvargs {
    #[doc = "< copy of the argument string"]
    pub str_: *mut ::core::ffi::c_char,
    #[doc = "< number of entries in the list"]
    pub count: ::core::ffi::c_uint,
    #[doc = "< list of key/values"]
    pub pairs: [rte_kvargs_pair; 32usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_kvargs"][::core::mem::size_of::<rte_kvargs>() - 528usize];
    ["Alignment of rte_kvargs"][::core::mem::align_of::<rte_kvargs>() - 8usize];
    ["Offset of field: rte_kvargs::str_"][::core::mem::offset_of!(rte_kvargs, str_) - 0usize];
    ["Offset of field: rte_kvargs::count"][::core::mem::offset_of!(rte_kvargs, count) - 8usize];
    ["Offset of field: rte_kvargs::pairs"][::core::mem::offset_of!(rte_kvargs, pairs) - 16usize];
};
impl Default for rte_kvargs {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Allocate a rte_kvargs and store key/value associations from a string\nThe function allocates and fills a rte_kvargs structure from a given\nstring whose format is key1=value1,key2=value2,...\nThe structure can be freed with rte_kvargs_free().\n\n# Arguments\n\n* `args` -\nThe input string containing the key/value associations\n* `valid_keys` -\nA list of valid keys (table of const char *, the last must be NULL).\nThis argument is ignored if NULL\n\n# Returns\n\n- A pointer to an allocated rte_kvargs structure on success\n- NULL on error"]
    pub fn rte_kvargs_parse(
        args: *const ::core::ffi::c_char,
        valid_keys: *const *const ::core::ffi::c_char,
    ) -> *mut rte_kvargs;
}
unsafe extern "C" {
    #[doc = "Allocate a rte_kvargs and store key/value associations from a string.\nThis version will consider any byte from valid_ends as a possible\nterminating character, and will not parse beyond any of their occurrence.\nThe function allocates and fills an rte_kvargs structure from a given\nstring whose format is key1=value1,key2=value2,...\nThe structure can be freed with rte_kvargs_free().\n\n# Arguments\n\n* `args` -\nThe input string containing the key/value associations\n* `valid_keys` -\nA list of valid keys (table of const char *, the last must be NULL).\nThis argument is ignored if NULL\n* `valid_ends` -\nAcceptable terminating characters.\nIf NULL, the behavior is the same as ``rte_kvargs_parse``.\n\n# Returns\n\n- A pointer to an allocated rte_kvargs structure on success\n- NULL on error"]
    pub fn rte_kvargs_parse_delim(
        args: *const ::core::ffi::c_char,
        valid_keys: *const *const ::core::ffi::c_char,
        valid_ends: *const ::core::ffi::c_char,
    ) -> *mut rte_kvargs;
}
unsafe extern "C" {
    #[doc = "Free a rte_kvargs structure\nFree a rte_kvargs structure previously allocated with\nrte_kvargs_parse().\n\n# Arguments\n\n* `kvlist` -\nThe rte_kvargs structure. No error if NULL."]
    pub fn rte_kvargs_free(kvlist: *mut rte_kvargs);
}
unsafe extern "C" {
    #[doc = "Get the value associated with a given key.\nIf multiple keys match, the value of the first one is returned.\nThe memory returned is allocated as part of the rte_kvargs structure,\nit must never be modified.\n\n# Arguments\n\n* `kvlist` -\nA list of rte_kvargs pair of 'key=value'.\n* `key` -\nThe matching key.\n\n# Returns\n\nNULL if no key matches the input,\na value associated with a matching key otherwise."]
    pub fn rte_kvargs_get(
        kvlist: *const rte_kvargs,
        key: *const ::core::ffi::c_char,
    ) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the value associated with a given key and value.\nFind the first entry in the kvlist whose key and value match the\nones passed as argument.\nThe memory returned is allocated as part of the rte_kvargs structure,\nit must never be modified.\n\n# Arguments\n\n* `kvlist` -\nA list of rte_kvargs pair of 'key=value'.\n* `key` -\nThe matching key. If NULL, any key will match.\n* `value` -\nThe matching value. If NULL, any value will match.\n\n# Returns\n\nNULL if no key matches the input,\na value associated with a matching key otherwise."]
    pub fn rte_kvargs_get_with_value(
        kvlist: *const rte_kvargs,
        key: *const ::core::ffi::c_char,
        value: *const ::core::ffi::c_char,
    ) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Call a handler function for each key=value matching the key\nFor each key=value association that matches the given key, calls the\nhandler function with the for a given arg_name passing the value on the\ndictionary for that key and a given extra argument.\n> **Note** Compared to # See also\n\n> [`rte_kvargs_process_opt,`] this API will return -1\nwhen handle only-key case (that is the matched key's value is NULL).\n\n# Arguments\n\n* `kvlist` -\nThe rte_kvargs structure.\n* `key_match` -\nThe key on which the handler should be called, or NULL to process handler\non all associations\n* `handler` -\nThe function to call for each matching key\n* `opaque_arg` -\nA pointer passed unchanged to the handler\n\n# Returns\n\n- 0 on success\n- Negative on error"]
    pub fn rte_kvargs_process(
        kvlist: *const rte_kvargs,
        key_match: *const ::core::ffi::c_char,
        handler: arg_handler_t,
        opaque_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Call a handler function for each key=value or only-key matching the key\nFor each key=value or only-key association that matches the given key, calls\nthe handler function with the for a given arg_name passing the value on the\ndictionary for that key and a given extra argument.\n\n# Arguments\n\n* `kvlist` -\nThe rte_kvargs structure.\n* `key_match` -\nThe key on which the handler should be called, or NULL to process handler\non all associations\n* `handler` -\nThe function to call for each matching key\n* `opaque_arg` -\nA pointer passed unchanged to the handler\n\n# Returns\n\n- 0 on success\n- Negative on error"]
    pub fn rte_kvargs_process_opt(
        kvlist: *const rte_kvargs,
        key_match: *const ::core::ffi::c_char,
        handler: arg_handler_t,
        opaque_arg: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Count the number of associations matching the given key\n\n# Arguments\n\n* `kvlist` -\nThe rte_kvargs structure\n* `key_match` -\nThe key that should match, or NULL to count all associations\n\n# Returns\n\nThe number of entries"]
    pub fn rte_kvargs_count(
        kvlist: *const rte_kvargs,
        key_match: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_uint;
}
#[doc = "Structure to hold heap statistics obtained from rte_malloc_get_socket_stats function."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_malloc_socket_stats {
    #[doc = "< Total bytes on heap"]
    pub heap_totalsz_bytes: usize,
    #[doc = "< Total free bytes on heap"]
    pub heap_freesz_bytes: usize,
    #[doc = "< Size in bytes of largest free block"]
    pub greatest_free_size: usize,
    #[doc = "< Number of free elements on heap"]
    pub free_count: ::core::ffi::c_uint,
    #[doc = "< Number of allocated elements on heap"]
    pub alloc_count: ::core::ffi::c_uint,
    #[doc = "< Total allocated bytes on heap"]
    pub heap_allocsz_bytes: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_malloc_socket_stats"]
        [::core::mem::size_of::<rte_malloc_socket_stats>() - 40usize];
    ["Alignment of rte_malloc_socket_stats"]
        [::core::mem::align_of::<rte_malloc_socket_stats>() - 8usize];
    ["Offset of field: rte_malloc_socket_stats::heap_totalsz_bytes"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, heap_totalsz_bytes) - 0usize];
    ["Offset of field: rte_malloc_socket_stats::heap_freesz_bytes"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, heap_freesz_bytes) - 8usize];
    ["Offset of field: rte_malloc_socket_stats::greatest_free_size"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, greatest_free_size) - 16usize];
    ["Offset of field: rte_malloc_socket_stats::free_count"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, free_count) - 24usize];
    ["Offset of field: rte_malloc_socket_stats::alloc_count"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, alloc_count) - 28usize];
    ["Offset of field: rte_malloc_socket_stats::heap_allocsz_bytes"]
        [::core::mem::offset_of!(rte_malloc_socket_stats, heap_allocsz_bytes) - 32usize];
};
unsafe extern "C" {
    #[doc = "Frees the memory space pointed to by the provided pointer.\nThis pointer must have been returned by a previous call to\nrte_malloc(), rte_zmalloc(), rte_calloc() or rte_realloc(). The behaviour of\nrte_free() is undefined if the pointer does not match this requirement.\nIf the pointer is NULL, the function does nothing.\n\n# Arguments\n\n* `ptr` -\nThe pointer to memory to be freed."]
    pub fn rte_free(ptr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    #[doc = "This function allocates memory from the huge-page area of memory. The memory\nis not cleared. In NUMA systems, the memory allocated resides on the same\nNUMA socket as the core that calls this function.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `size` -\nSize (in bytes) to be allocated.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_malloc(
        type_: *const ::core::ffi::c_char,
        size: usize,
        align: ::core::ffi::c_uint,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Allocate zeroed memory from the heap.\nEquivalent to rte_malloc() except that the memory zone is\ninitialised with zeros. In NUMA systems, the memory allocated resides on the\nsame NUMA socket as the core that calls this function.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `size` -\nSize (in bytes) to be allocated.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_zmalloc(
        type_: *const ::core::ffi::c_char,
        size: usize,
        align: ::core::ffi::c_uint,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Replacement function for calloc(), using huge-page memory. Memory area is\ninitialised with zeros. In NUMA systems, the memory allocated resides on the\nsame NUMA socket as the core that calls this function.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `num` -\nNumber of elements to be allocated.\n* `size` -\nSize (in bytes) of a single element.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_calloc(
        type_: *const ::core::ffi::c_char,
        num: usize,
        size: usize,
        align: ::core::ffi::c_uint,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Replacement function for realloc(), using huge-page memory. Reserved area\nmemory is resized, preserving contents. In NUMA systems, the new area\nmay not reside on the same NUMA node as the old one.\n\n# Arguments\n\n* `ptr` -\nPointer to already allocated memory\n* `size` -\nSize (in bytes) of new area. If this is 0, memory is freed.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the reallocated memory."]
    pub fn rte_realloc(
        ptr: *mut ::core::ffi::c_void,
        size: usize,
        align: ::core::ffi::c_uint,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Replacement function for realloc(), using huge-page memory. Reserved area\nmemory is resized, preserving contents. In NUMA systems, the new area\nresides on requested NUMA socket.\n\n# Arguments\n\n* `ptr` -\nPointer to already allocated memory\n* `size` -\nSize (in bytes) of new area. If this is 0, memory is freed.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n* `socket` -\nNUMA socket to allocate memory on.\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the reallocated memory."]
    pub fn rte_realloc_socket(
        ptr: *mut ::core::ffi::c_void,
        size: usize,
        align: ::core::ffi::c_uint,
        socket: ::core::ffi::c_int,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "This function allocates memory from the huge-page area of memory. The memory\nis not cleared.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `size` -\nSize (in bytes) to be allocated.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n* `socket` -\nNUMA socket to allocate memory on. If SOCKET_ID_ANY is used, this function\nwill behave the same as rte_malloc().\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_malloc_socket(
        type_: *const ::core::ffi::c_char,
        size: usize,
        align: ::core::ffi::c_uint,
        socket: ::core::ffi::c_int,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Allocate zeroed memory from the heap.\nEquivalent to rte_malloc() except that the memory zone is\ninitialised with zeros.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `size` -\nSize (in bytes) to be allocated.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n* `socket` -\nNUMA socket to allocate memory on. If SOCKET_ID_ANY is used, this function\nwill behave the same as rte_zmalloc().\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_zmalloc_socket(
        type_: *const ::core::ffi::c_char,
        size: usize,
        align: ::core::ffi::c_uint,
        socket: ::core::ffi::c_int,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Replacement function for calloc(), using huge-page memory. Memory area is\ninitialised with zeros.\n\n# Arguments\n\n* `type` -\nA string identifying the type of allocated objects (useful for tracing).\nCan be NULL.\n* `num` -\nNumber of elements to be allocated.\n* `size` -\nSize (in bytes) of a single element.\n* `align` -\nIf 0, the return is a pointer that is suitably aligned for any kind of\nvariable (in the same manner as malloc()).\nOtherwise, the return is a pointer that is a multiple of *align*. In\nthis case, it must obviously be a power of two. (Minimum alignment is the\ncacheline size, i.e. 64-bytes)\n* `socket` -\nNUMA socket to allocate memory on. If SOCKET_ID_ANY is used, this function\nwill behave the same as rte_calloc().\n\n# Returns\n\n- NULL on error. Not enough memory, or invalid arguments (size is 0,\nalign is not a power of two).\n- Otherwise, the pointer to the allocated object."]
    pub fn rte_calloc_socket(
        type_: *const ::core::ffi::c_char,
        num: usize,
        size: usize,
        align: ::core::ffi::c_uint,
        socket: ::core::ffi::c_int,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "If malloc debug is enabled, check a memory block for header\nand trailer markers to indicate that all is well with the block.\nIf size is non-null, also return the size of the block.\n\n# Arguments\n\n* `ptr` -\npointer to the start of a data block, must have been returned\nby a previous call to rte_malloc(), rte_zmalloc(), rte_calloc()\nor rte_realloc()\n* `size` -\nif non-null, and memory block pointer is valid, returns the size\nof the memory block\n\n# Returns\n\n-1 on error, invalid pointer passed or header and trailer markers\nare missing or corrupted\n0 on success"]
    pub fn rte_malloc_validate(
        ptr: *const ::core::ffi::c_void,
        size: *mut usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get heap statistics for the specified heap.\n> **Note** This function is not thread-safe with respect to\n``rte_malloc_heap_create()``/``rte_malloc_heap_destroy()`` functions.\n\n# Arguments\n\n* `socket` -\nAn unsigned integer specifying the socket to get heap statistics for\n* `socket_stats` -\nA structure which provides memory to store statistics\n\n# Returns\n\nNull on error\nPointer to structure storing statistics on success"]
    pub fn rte_malloc_get_socket_stats(
        socket: ::core::ffi::c_int,
        socket_stats: *mut rte_malloc_socket_stats,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add memory chunk to a heap with specified name.\n> **Note** Multiple memory chunks can be added to the same heap\n> **Note** Before accessing this memory in other processes, it needs to be\nattached in each of those processes by calling\n``rte_malloc_heap_memory_attach`` in each other process.\n> **Note** Memory must be previously allocated for DPDK to be able to use it as a\nmalloc heap. Failing to do so will result in undefined behavior, up to and\nincluding segmentation faults.\n> **Note** Calling this function will erase any contents already present at the\nsupplied memory address.\n\n# Arguments\n\n* `heap_name` -\nName of the heap to add memory chunk to\n* `va_addr` -\nStart of virtual area to add to the heap. Must be aligned by ``page_sz``.\n* `len` -\nLength of virtual area to add to the heap. Must be aligned by ``page_sz``.\n* `iova_addrs` -\nArray of page IOVA addresses corresponding to each page in this memory\narea. Can be NULL, in which case page IOVA addresses will be set to\nRTE_BAD_IOVA.\n* `n_pages` -\nNumber of elements in the iova_addrs array. Ignored if  ``iova_addrs``\nis NULL.\n* `page_sz` -\nPage size of the underlying memory\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nEPERM  - attempted to add memory to a reserved heap\nENOSPC - no more space in internal config to store a new memory chunk"]
    pub fn rte_malloc_heap_memory_add(
        heap_name: *const ::core::ffi::c_char,
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
        iova_addrs: *mut rte_iova_t,
        n_pages: ::core::ffi::c_uint,
        page_sz: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove memory chunk from heap with specified name.\n> **Note** Memory chunk being removed must be the same as one that was added;\npartially removing memory chunks is not supported\n> **Note** Memory area must not contain any allocated elements to allow its\nremoval from the heap\n> **Note** All other processes must detach from the memory chunk prior to it being\nremoved from the heap.\n\n# Arguments\n\n* `heap_name` -\nName of the heap to remove memory from\n* `va_addr` -\nVirtual address to remove from the heap\n* `len` -\nLength of virtual area to remove from the heap\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - one of the parameters was invalid\nEPERM  - attempted to remove memory from a reserved heap\nENOENT - heap or memory chunk was not found\nEBUSY  - memory chunk still contains data"]
    pub fn rte_malloc_heap_memory_remove(
        heap_name: *const ::core::ffi::c_char,
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Attach to an already existing chunk of external memory in another process.\n> **Note** This function must be called before any attempt is made to use an\nalready existing external memory chunk. This function does *not* need to\nbe called if a call to ``rte_malloc_heap_memory_add`` was made in the\ncurrent process.\n\n# Arguments\n\n* `heap_name` -\nHeap name to which this chunk of memory belongs\n* `va_addr` -\nStart address of memory chunk to attach to\n* `len` -\nLength of memory chunk to attach to\n\n# Returns\n\n0 on successful attach\n-1 on unsuccessful attach, with rte_errno set to indicate cause for error:\nEINVAL - one of the parameters was invalid\nEPERM  - attempted to attach memory to a reserved heap\nENOENT - heap or memory chunk was not found"]
    pub fn rte_malloc_heap_memory_attach(
        heap_name: *const ::core::ffi::c_char,
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Detach from a chunk of external memory in secondary process.\n> **Note** This function must be called in before any attempt is made to remove\nexternal memory from the heap in another process. This function does *not*\nneed to be called if a call to ``rte_malloc_heap_memory_remove`` will be\ncalled in current process.\n\n# Arguments\n\n* `heap_name` -\nHeap name to which this chunk of memory belongs\n* `va_addr` -\nStart address of memory chunk to attach to\n* `len` -\nLength of memory chunk to attach to\n\n# Returns\n\n0 on successful detach\n-1 on unsuccessful detach, with rte_errno set to indicate cause for error:\nEINVAL - one of the parameters was invalid\nEPERM  - attempted to detach memory from a reserved heap\nENOENT - heap or memory chunk was not found"]
    pub fn rte_malloc_heap_memory_detach(
        heap_name: *const ::core::ffi::c_char,
        va_addr: *mut ::core::ffi::c_void,
        len: usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Creates a new empty malloc heap with a specified name.\n> **Note** Heaps created via this call will automatically get assigned a unique\nsocket ID, which can be found using ``rte_malloc_heap_get_socket()``\n\n# Arguments\n\n* `heap_name` -\nName of the heap to create.\n\n# Returns\n\n- 0 on successful creation\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - ``heap_name`` was NULL, empty or too long\nEEXIST - heap by name of ``heap_name`` already exists\nENOSPC - no more space in internal config to store a new heap"]
    pub fn rte_malloc_heap_create(heap_name: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Destroys a previously created malloc heap with specified name.\n> **Note** This function will return a failure result if not all memory allocated\nfrom the heap has been freed back to the heap\n> **Note** This function will return a failure result if not all memory segments\nwere removed from the heap prior to its destruction\n\n# Arguments\n\n* `heap_name` -\nName of the heap to create.\n\n# Returns\n\n- 0 on success\n- -1 in case of error, with rte_errno set to one of the following:\nEINVAL - ``heap_name`` was NULL, empty or too long\nENOENT - heap by the name of ``heap_name`` was not found\nEPERM  - attempting to destroy reserved heap\nEBUSY  - heap still contains data"]
    pub fn rte_malloc_heap_destroy(heap_name: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find socket ID corresponding to a named heap.\n\n# Arguments\n\n* `name` -\nHeap name to find socket ID for\n\n# Returns\n\nSocket ID in case of success (a non-negative number)\n-1 in case of error, with rte_errno set to one of the following:\nEINVAL - ``name`` was NULL\nENOENT - heap identified by the name ``name`` was not found"]
    pub fn rte_malloc_heap_get_socket(name: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check if a given socket ID refers to externally allocated memory.\n> **Note** Passing SOCKET_ID_ANY will return 0.\n\n# Arguments\n\n* `socket_id` -\nSocket ID to check\n\n# Returns\n\n1 if socket ID refers to externally allocated memory\n0 if socket ID refers to internal DPDK memory\n-1 if socket ID is invalid"]
    pub fn rte_malloc_heap_socket_is_external(socket_id: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump statistics.\nDump for the specified type to a file. If the type argument is\nNULL, all memory types will be dumped.\n> **Note** This function is not thread-safe with respect to\n``rte_malloc_heap_create()``/``rte_malloc_heap_destroy()`` functions.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output\n* `type` -\nDeprecated parameter unused."]
    pub fn rte_malloc_dump_stats(f: *mut FILE, type_: *const ::core::ffi::c_char);
}
unsafe extern "C" {
    #[doc = "Dump contents of all malloc heaps to a file.\n> **Note** This function is not thread-safe with respect to\n``rte_malloc_heap_create()``/``rte_malloc_heap_destroy()`` functions.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_malloc_dump_heaps(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Return the IO address of a virtual address obtained through\nrte_malloc\n\n# Arguments\n\n* `addr` -\nAddress obtained from a previous rte_malloc call\n\n# Returns\n\nRTE_BAD_IOVA on error\notherwise return an address suitable for IO"]
    pub fn rte_malloc_virt2iova(addr: *const ::core::ffi::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Set the platform supported pktmbuf HW mempool ops name\nThis function allow the HW to register the actively supported HW mempool\nops_name. Only one HW mempool ops can be registered at any point of time.\n\n# Arguments\n\n* `ops_name` -\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_mbuf_set_platform_mempool_ops(
        ops_name: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get configured platform supported pktmbuf HW mempool ops name\nThis function returns the platform supported mempool ops name.\n\n# Returns\n\n- On success, platform pool ops name.\n- On failure, NULL."]
    pub fn rte_mbuf_platform_mempool_ops() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Set the user preferred pktmbuf mempool ops name\nThis function can be used by the user to configure user preferred\nmempool ops name.\n\n# Arguments\n\n* `ops_name` -\n\n# Returns\n\n- On success, zero.\n- On failure, a negative value."]
    pub fn rte_mbuf_set_user_mempool_ops(
        ops_name: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get user preferred pool ops name for mbuf\nThis function returns the user configured mempool ops name.\n\n# Returns\n\n- On success, user pool ops name..\n- On failure, NULL."]
    pub fn rte_mbuf_user_mempool_ops() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Get the best mempool ops name for pktmbuf.\nThis function is used to determine the best options for mempool ops for\npktmbuf allocations. Following are the priority order:\n1. User defined, 2. Platform HW supported, 3. Compile time configured.\nThis function is also used by the rte_pktmbuf_pool_create to get the best\nmempool ops name.\n\n# Returns\n\nreturns preferred mbuf pool ops name"]
    pub fn rte_mbuf_best_mempool_ops() -> *const ::core::ffi::c_char;
}
#[doc = "The rte_mcslock_t type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mcslock {
    pub next: *mut rte_mcslock,
    #[doc = "1 if the queue locked, 0 otherwise"]
    pub locked: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mcslock"][::core::mem::size_of::<rte_mcslock>() - 16usize];
    ["Alignment of rte_mcslock"][::core::mem::align_of::<rte_mcslock>() - 8usize];
    ["Offset of field: rte_mcslock::next"][::core::mem::offset_of!(rte_mcslock, next) - 0usize];
    ["Offset of field: rte_mcslock::locked"][::core::mem::offset_of!(rte_mcslock, locked) - 8usize];
};
impl Default for rte_mcslock {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "The rte_mcslock_t type."]
pub type rte_mcslock_t = rte_mcslock;
unsafe extern "C" {
    #[doc = "Take the MCS lock.\n\n# Arguments\n\n* `msl` -\nA pointer to the pointer of a MCS lock.\nWhen the lock is initialized or declared, the msl pointer should be\nset to NULL.\n* `me` -\nA pointer to a new node of MCS lock. Each CPU/thread acquiring the\nlock should use its 'own node'."]
    #[link_name = "rte_mcslock_lock_w"]
    pub fn rte_mcslock_lock(msl: *mut *mut rte_mcslock_t, me: *mut rte_mcslock_t);
}
unsafe extern "C" {
    #[doc = "Release the MCS lock.\n\n# Arguments\n\n* `msl` -\nA pointer to the pointer of a MCS lock.\n* `me` -\nA pointer to the node of MCS lock passed in rte_mcslock_lock."]
    #[link_name = "rte_mcslock_unlock_w"]
    pub fn rte_mcslock_unlock(msl: *mut *mut rte_mcslock_t, me: *mut rte_mcslock_t);
}
unsafe extern "C" {
    #[doc = "Try to take the lock.\n\n# Arguments\n\n* `msl` -\nA pointer to the pointer of a MCS lock.\n* `me` -\nA pointer to a new node of MCS lock.\n\n# Returns\n\n1 if the lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_mcslock_trylock_w"]
    pub fn rte_mcslock_trylock(
        msl: *mut *mut rte_mcslock_t,
        me: *mut rte_mcslock_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the lock is taken.\n\n# Arguments\n\n* `msl` -\nA pointer to a MCS lock node.\n\n# Returns\n\n1 if the lock is currently taken; 0 otherwise."]
    #[link_name = "rte_mcslock_is_locked_w"]
    pub fn rte_mcslock_is_locked(msl: *mut rte_mcslock_t) -> ::core::ffi::c_int;
}
#[doc = "MPLS header."]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mpls_hdr {
    #[doc = "< Label(msb)."]
    pub tag_msb: rte_be16_t,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Time to live."]
    pub ttl: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mpls_hdr"][::core::mem::size_of::<rte_mpls_hdr>() - 4usize];
    ["Alignment of rte_mpls_hdr"][::core::mem::align_of::<rte_mpls_hdr>() - 1usize];
    ["Offset of field: rte_mpls_hdr::tag_msb"]
        [::core::mem::offset_of!(rte_mpls_hdr, tag_msb) - 0usize];
    ["Offset of field: rte_mpls_hdr::ttl"][::core::mem::offset_of!(rte_mpls_hdr, ttl) - 3usize];
};
impl rte_mpls_hdr {
    #[inline]
    pub fn bs(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_bs(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn bs_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_bs_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tc(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(1usize, 3u8) as u8) }
    }
    #[inline]
    pub fn set_tc(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(1usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tc_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                3u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_tc_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tag_lsb(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_tag_lsb(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tag_lsb_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_tag_lsb_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(bs: u8, tc: u8, tag_lsb: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let bs: u8 = unsafe { ::core::mem::transmute(bs) };
            bs as u64
        });
        __bindgen_bitfield_unit.set(1usize, 3u8, {
            let tc: u8 = unsafe { ::core::mem::transmute(tc) };
            tc as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let tag_lsb: u8 = unsafe { ::core::mem::transmute(tag_lsb) };
            tag_lsb as u64
        });
        __bindgen_bitfield_unit
    }
}
pub mod rte_mtr_stats_type {
    #[doc = "Statistics counter type"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Number of packets passed as green by the policer."]
    pub const RTE_MTR_STATS_N_PKTS_GREEN: Type = 1;
    #[doc = "Number of packets passed as yellow by the policer."]
    pub const RTE_MTR_STATS_N_PKTS_YELLOW: Type = 2;
    #[doc = "Number of packets passed as red by the policer."]
    pub const RTE_MTR_STATS_N_PKTS_RED: Type = 4;
    #[doc = "Number of packets dropped by the policer."]
    pub const RTE_MTR_STATS_N_PKTS_DROPPED: Type = 8;
    #[doc = "Number of bytes passed as green by the policer."]
    pub const RTE_MTR_STATS_N_BYTES_GREEN: Type = 16;
    #[doc = "Number of bytes passed as yellow by the policer."]
    pub const RTE_MTR_STATS_N_BYTES_YELLOW: Type = 32;
    #[doc = "Number of bytes passed as red by the policer."]
    pub const RTE_MTR_STATS_N_BYTES_RED: Type = 64;
    #[doc = "Number of bytes dropped by the policer."]
    pub const RTE_MTR_STATS_N_BYTES_DROPPED: Type = 128;
}
#[doc = "Statistics counters"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mtr_stats {
    #[doc = "Number of packets passed by the policer (per color)."]
    pub n_pkts: [u64; 3usize],
    #[doc = "Number of bytes passed by the policer (per color)."]
    pub n_bytes: [u64; 3usize],
    #[doc = "Number of packets dropped by the policer."]
    pub n_pkts_dropped: u64,
    #[doc = "Number of bytes passed by the policer."]
    pub n_bytes_dropped: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_stats"][::core::mem::size_of::<rte_mtr_stats>() - 64usize];
    ["Alignment of rte_mtr_stats"][::core::mem::align_of::<rte_mtr_stats>() - 8usize];
    ["Offset of field: rte_mtr_stats::n_pkts"]
        [::core::mem::offset_of!(rte_mtr_stats, n_pkts) - 0usize];
    ["Offset of field: rte_mtr_stats::n_bytes"]
        [::core::mem::offset_of!(rte_mtr_stats, n_bytes) - 24usize];
    ["Offset of field: rte_mtr_stats::n_pkts_dropped"]
        [::core::mem::offset_of!(rte_mtr_stats, n_pkts_dropped) - 48usize];
    ["Offset of field: rte_mtr_stats::n_bytes_dropped"]
        [::core::mem::offset_of!(rte_mtr_stats, n_bytes_dropped) - 56usize];
};
pub mod rte_mtr_algorithm {
    #[doc = "Traffic metering algorithms"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "No traffic metering performed, the output color is the same as the\ninput color for every input packet. The meter of the MTR object is\nworking in pass-through mode, having same effect as meter disable.\n\n# See also\n\n> [`rte_mtr_meter_disable()`]"]
    pub const RTE_MTR_NONE: Type = 0;
    #[doc = "Single Rate Three Color Marker (srTCM) - IETF RFC 2697."]
    pub const RTE_MTR_SRTCM_RFC2697: Type = 1;
    #[doc = "Two Rate Three Color Marker (trTCM) - IETF RFC 2698."]
    pub const RTE_MTR_TRTCM_RFC2698: Type = 2;
    #[doc = "Two Rate Three Color Marker (trTCM) - IETF RFC 4115."]
    pub const RTE_MTR_TRTCM_RFC4115: Type = 3;
}
#[doc = "Meter profile"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mtr_meter_profile {
    #[doc = "Traffic metering algorithm."]
    pub alg: rte_mtr_algorithm::Type,
    pub anon1: rte_mtr_meter_profile__bindgen_ty_1,
    #[doc = "When zero, the byte mode is enabled for the current profile, so the\n*rate* and *size* fields are specified in bytes per second\nand bytes, respectively.\nWhen non-zero, the packet mode is enabled for the current profile,\nso the *rate* and *size* fields are specified in packets per second\nand packets, respectively."]
    pub packet_mode: ::core::ffi::c_int,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mtr_meter_profile__bindgen_ty_1 {
    pub srtcm_rfc2697: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1,
    pub trtcm_rfc2698: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2,
    pub trtcm_rfc4115: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3,
}
#[doc = "Items only valid when *alg* is set to srTCM - RFC 2697."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "Committed Information Rate (CIR)\n(bytes per second or packets per second)."]
    pub cir: u64,
    #[doc = "Committed Burst Size (CBS) (bytes or packets)."]
    pub cbs: u64,
    #[doc = "Excess Burst Size (EBS) (bytes or packets)."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1>() - 24usize];
    ["Alignment of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1::cir"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1, cir) - 0usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1::cbs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1, cbs) - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1::ebs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_1, ebs) - 16usize];
};
#[doc = "Items only valid when *alg* is set to trTCM - RFC 2698."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "Committed Information Rate (CIR)\n(bytes per second or packets per second)."]
    pub cir: u64,
    #[doc = "Peak Information Rate (PIR)\n(bytes per second or packets per second)."]
    pub pir: u64,
    #[doc = "Committed Burst Size (CBS) (bytes or packets)."]
    pub cbs: u64,
    #[doc = "Peak Burst Size (PBS) (bytes or packets)."]
    pub pbs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2>() - 32usize];
    ["Alignment of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2::cir"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2, cir) - 0usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2::pir"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2, pir) - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2::cbs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2, cbs) - 16usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2::pbs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_2, pbs) - 24usize];
};
#[doc = "Items only valid when *alg* is set to trTCM - RFC 4115."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3 {
    #[doc = "Committed Information Rate (CIR)\n(bytes per second or packets per second)."]
    pub cir: u64,
    #[doc = "Excess Information Rate (EIR)\n(bytes per second or packets per second)."]
    pub eir: u64,
    #[doc = "Committed Burst Size (CBS) (bytes or packets)."]
    pub cbs: u64,
    #[doc = "Excess Burst Size (EBS) (bytes or packets)."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3"]
        [::core::mem::size_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3>() - 32usize];
    ["Alignment of rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3"]
        [::core::mem::align_of::<rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3>() - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3::cir"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3, cir) - 0usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3::eir"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3, eir) - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3::cbs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3, cbs) - 16usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3::ebs"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1__bindgen_ty_3, ebs) - 24usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_profile__bindgen_ty_1"]
        [::core::mem::size_of::<rte_mtr_meter_profile__bindgen_ty_1>() - 32usize];
    ["Alignment of rte_mtr_meter_profile__bindgen_ty_1"]
        [::core::mem::align_of::<rte_mtr_meter_profile__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1::srtcm_rfc2697"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1, srtcm_rfc2697) - 0usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1::trtcm_rfc2698"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1, trtcm_rfc2698) - 0usize];
    ["Offset of field: rte_mtr_meter_profile__bindgen_ty_1::trtcm_rfc4115"]
        [::core::mem::offset_of!(rte_mtr_meter_profile__bindgen_ty_1, trtcm_rfc4115) - 0usize];
};
impl Default for rte_mtr_meter_profile__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_profile"][::core::mem::size_of::<rte_mtr_meter_profile>() - 48usize];
    ["Alignment of rte_mtr_meter_profile"]
        [::core::mem::align_of::<rte_mtr_meter_profile>() - 8usize];
    ["Offset of field: rte_mtr_meter_profile::alg"]
        [::core::mem::offset_of!(rte_mtr_meter_profile, alg) - 0usize];
    ["Offset of field: rte_mtr_meter_profile::packet_mode"]
        [::core::mem::offset_of!(rte_mtr_meter_profile, packet_mode) - 40usize];
};
impl Default for rte_mtr_meter_profile {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Meter policy"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mtr_meter_policy_params {
    #[doc = "Policy action list per color.\nactions[i] potentially represents a chain of rte_flow actions\nterminated by the END action, exactly as specified by the rte_flow\nAPI for the flow definition, and not just a single action."]
    pub actions: [*const rte_flow_action; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_meter_policy_params"]
        [::core::mem::size_of::<rte_mtr_meter_policy_params>() - 24usize];
    ["Alignment of rte_mtr_meter_policy_params"]
        [::core::mem::align_of::<rte_mtr_meter_policy_params>() - 8usize];
    ["Offset of field: rte_mtr_meter_policy_params::actions"]
        [::core::mem::offset_of!(rte_mtr_meter_policy_params, actions) - 0usize];
};
impl Default for rte_mtr_meter_policy_params {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_mtr_color_in_protocol {
    #[doc = "Input color protocol method\nMore than one of the method can be enabled for a given meter.\nEven if enabled, a method might not be applicable to each input packet,\nin case the associated protocol header is not present in the packet.\nThe highest priority method that is both enabled for the meter and also\napplicable for the current input packet wins;\nif none is both enabled and applicable, the default input color is used.\n\n# See also\n\n> [`function`] rte_mtr_color_in_protocol_set()"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Enable the detection of the packet input color based on the outermost\nVLAN header fields DEI (1 bit) and PCP (3 bits).\nThese fields are used as index into the VLAN table.\n\n# See also\n\n> [`struct`] rte_mtr_params::vlan_table"]
    pub const RTE_MTR_COLOR_IN_PROTO_OUTER_VLAN: Type = 1;
    #[doc = "Enable the detection of the packet input color based on the innermost\nVLAN header fields DEI (1 bit) and PCP (3 bits).\nThese fields are used as index into the VLAN table.\n\n# See also\n\n> [`struct`] rte_mtr_params::vlan_table"]
    pub const RTE_MTR_COLOR_IN_PROTO_INNER_VLAN: Type = 2;
    #[doc = "Enable the detection of the packet input color based on the outermost\nIP DSCP field. These fields are used as index into the DSCP table.\n\n# See also\n\n> [`struct`] rte_mtr_params::dscp_table"]
    pub const RTE_MTR_COLOR_IN_PROTO_OUTER_IP: Type = 4;
    #[doc = "Enable the detection of the packet input color based on the innermost\nIP DSCP field. These fields are used as index into the DSCP table.\n\n# See also\n\n> [`struct`] rte_mtr_params::dscp_table"]
    pub const RTE_MTR_COLOR_IN_PROTO_INNER_IP: Type = 8;
}
#[doc = "Parameters for each traffic metering & policing object\n\n# See also\n\n> [`enum`] rte_mtr_stats_type"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mtr_params {
    #[doc = "Meter profile ID. # See also\n\n> [`rte_mtr_meter_profile_add()`]"]
    pub meter_profile_id: u32,
    #[doc = "Meter input color in case of MTR object chaining. When non-zero: if\na previous MTR object is enabled in the same flow, then the color\ndetermined by the latest MTR object in the same flow is used as the\ninput color by the current MTR object, otherwise the current MTR\nobject uses the *dscp_table* to determine the input color. When zero:\nthe color determined by any previous MTR object in same flow is\nignored by the current MTR object, which uses the *dscp_table* to\ndetermine the input color."]
    pub use_prev_mtr_color: ::core::ffi::c_int,
    #[doc = "Meter input color based on IP DSCP protocol field.\nValid when *input_color_proto_mask* set to any of the following\nRTE_MTR_COLOR_IN_PROTO_OUTER_IP,\nRTE_MTR_COLOR_IN_PROTO_INNER_IP\nWhen non-NULL: it points to a pre-allocated and\npre-populated table with exactly 64 elements providing the input\ncolor for each value of the IPv4/IPv6 Differentiated Services Code\nPoint (DSCP) input packet field.\nWhen NULL: it is equivalent to setting this parameter to an all-green\npopulated table (i.e. table with all the 64 elements set to green\ncolor). The color blind mode is configured by setting\n*use_prev_mtr_color* to 0 and *dscp_table* to either NULL or to an\nall-green populated table.\nWhen *use_prev_mtr_color* is non-zero value or when *dscp_table*\ncontains at least one yellow or red color element, then the color\naware mode is configured.\n\n# See also\n\n> [`enum`] rte_mtr_color_in_protocol::RTE_MTR_COLOR_IN_PROTO_OUTER_IP\n> [`enum`] rte_mtr_color_in_protocol::RTE_MTR_COLOR_IN_PROTO_INNER_IP\n> [`struct`] rte_mtr_params::input_color_proto_mask"]
    pub dscp_table: *mut rte_color::Type,
    #[doc = "Meter input color based on VLAN DEI(1bit), PCP(3 bits) protocol\nfields.\nValid when *input_color_proto_mask* set to any of the following\nRTE_MTR_COLOR_IN_PROTO_OUTER_VLAN,\nRTE_MTR_COLOR_IN_PROTO_INNER_VLAN\nWhen non-NULL: it points to a pre-allocated and pre-populated\ntable with exactly 16 elements providing the input color for\neach value of the DEI(1bit), PCP(3 bits) input packet field.\nWhen NULL: it is equivalent to setting this parameter to an\nall-green populated table (i.e. table with\nall the 16 elements set to green color). The color blind mode\nis configured by setting *use_prev_mtr_color* to 0 and\n*vlan_table* to either NULL or to an all-green populated table.\nWhen *use_prev_mtr_color* is non-zero value\nor when *vlan_table* contains at least one yellow or\nred color element, then the color aware mode is configured.\n\n# See also\n\n> [`enum`] rte_mtr_color_in_protocol::RTE_MTR_COLOR_IN_PROTO_OUTER_VLAN\n> [`enum`] rte_mtr_color_in_protocol::RTE_MTR_COLOR_IN_PROTO_INNER_VLAN\n> [`struct`] rte_mtr_params::input_color_proto_mask"]
    pub vlan_table: *mut rte_color::Type,
    #[doc = "Non-zero to enable the meter, zero to disable the meter at the time\nof MTR object creation. Ignored when the meter profile indicated by\n*meter_profile_id* is set to NONE.\n\n# See also\n\n> [`rte_mtr_meter_disable()`]"]
    pub meter_enable: ::core::ffi::c_int,
    #[doc = "Set of stats counters to be enabled.\n\n# See also\n\n> [`enum`] rte_mtr_stats_type"]
    pub stats_mask: u64,
    #[doc = "Meter policy ID. # See also\n\n> [`rte_mtr_meter_policy_add()`]"]
    pub meter_policy_id: u32,
    #[doc = "Input color to be set for the input packet when none of the\nenabled input color methods is applicable to the input packet.\nIgnored when this when *input_color_proto_mask* set to zero."]
    pub default_input_color: rte_color::Type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_params"][::core::mem::size_of::<rte_mtr_params>() - 48usize];
    ["Alignment of rte_mtr_params"][::core::mem::align_of::<rte_mtr_params>() - 8usize];
    ["Offset of field: rte_mtr_params::meter_profile_id"]
        [::core::mem::offset_of!(rte_mtr_params, meter_profile_id) - 0usize];
    ["Offset of field: rte_mtr_params::use_prev_mtr_color"]
        [::core::mem::offset_of!(rte_mtr_params, use_prev_mtr_color) - 4usize];
    ["Offset of field: rte_mtr_params::dscp_table"]
        [::core::mem::offset_of!(rte_mtr_params, dscp_table) - 8usize];
    ["Offset of field: rte_mtr_params::vlan_table"]
        [::core::mem::offset_of!(rte_mtr_params, vlan_table) - 16usize];
    ["Offset of field: rte_mtr_params::meter_enable"]
        [::core::mem::offset_of!(rte_mtr_params, meter_enable) - 24usize];
    ["Offset of field: rte_mtr_params::stats_mask"]
        [::core::mem::offset_of!(rte_mtr_params, stats_mask) - 32usize];
    ["Offset of field: rte_mtr_params::meter_policy_id"]
        [::core::mem::offset_of!(rte_mtr_params, meter_policy_id) - 40usize];
    ["Offset of field: rte_mtr_params::default_input_color"]
        [::core::mem::offset_of!(rte_mtr_params, default_input_color) - 44usize];
};
impl Default for rte_mtr_params {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "MTR capabilities"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_mtr_capabilities {
    #[doc = "Maximum number of MTR objects."]
    pub n_max: u32,
    #[doc = "Maximum number of MTR objects that can be shared by multiple flows.\nThe value of zero indicates that shared MTR objects are not\nsupported. The maximum value is *n_max*."]
    pub n_shared_max: u32,
    #[doc = "When non-zero, this flag indicates that all the MTR objects that\ncannot be shared by multiple flows have identical capability set."]
    pub identical: ::core::ffi::c_int,
    #[doc = "When non-zero, this flag indicates that all the MTR objects that\ncan be shared by multiple flows have identical capability set."]
    pub shared_identical: ::core::ffi::c_int,
    #[doc = "Maximum number of flows that can share the same MTR object. The\nvalue of zero is invalid. The value of 1 means that shared MTR\nobjects not supported."]
    pub shared_n_flows_per_mtr_max: u32,
    #[doc = "Maximum number of MTR objects that can be part of the same flow. The\nvalue of zero is invalid. The value of 1 indicates that MTR object\nchaining is not supported. The maximum value is *n_max*."]
    pub chaining_n_mtrs_per_flow_max: u32,
    #[doc = "When non-zero, it indicates that the packet color identified by one\nMTR object can be used as the packet input color by any subsequent\nMTR object from the same flow. When zero, it indicates that the color\ndetermined by one MTR object is always ignored by any subsequent MTR\nobject from the same flow. Only valid when MTR chaining is supported,\ni.e. *chaining_n_mtrs_per_flow_max* is greater than 1. When non-zero,\nit also means that the color aware mode is supported by at least one\nmetering algorithm."]
    pub chaining_use_prev_mtr_color_supported: ::core::ffi::c_int,
    #[doc = "When non-zero, it indicates that the packet color identified by one\nMTR object is always used as the packet input color by any subsequent\nMTR object that is part of the same flow. When zero, it indicates\nthat whether the color determined by one MTR object is either ignored\nor used as the packet input color by any subsequent MTR object from\nthe same flow is individually configurable for each MTR object. Only\nvalid when *chaining_use_prev_mtr_color_supported* is non-zero."]
    pub chaining_use_prev_mtr_color_enforced: ::core::ffi::c_int,
    #[doc = "Maximum number of MTR objects that can have their meter configured\nto run the srTCM RFC 2697 algorithm. The value of 0 indicates this\nmetering algorithm is not supported. The maximum value is *n_max*."]
    pub meter_srtcm_rfc2697_n_max: u32,
    #[doc = "Maximum number of MTR objects that can have their meter configured\nto run the trTCM RFC 2698 algorithm. The value of 0 indicates this\nmetering algorithm is not supported. The maximum value is *n_max*."]
    pub meter_trtcm_rfc2698_n_max: u32,
    #[doc = "Maximum number of MTR objects that can have their meter configured\nto run the trTCM RFC 4115 algorithm. The value of 0 indicates this\nmetering algorithm is not supported. The maximum value is *n_max*."]
    pub meter_trtcm_rfc4115_n_max: u32,
    #[doc = "Maximum traffic rate that can be metered by a single MTR object. For\nsrTCM RFC 2697, this is the maximum CIR rate. For trTCM RFC 2698,\nthis is the maximum PIR rate. For trTCM RFC 4115, this is the maximum\nvalue for the sum of PIR and EIR rates."]
    pub meter_rate_max: u64,
    #[doc = "Maximum number of policy objects that can have.\nThe value of 0 is invalid. Policy must be supported for meter.\nThe maximum value is *n_max*."]
    pub meter_policy_n_max: u64,
    #[doc = "When non-zero, it indicates that color aware mode is supported for\nthe srTCM RFC 2697 metering algorithm."]
    pub color_aware_srtcm_rfc2697_supported: ::core::ffi::c_int,
    #[doc = "When non-zero, it indicates that color aware mode is supported for\nthe trTCM RFC 2698 metering algorithm."]
    pub color_aware_trtcm_rfc2698_supported: ::core::ffi::c_int,
    #[doc = "When non-zero, it indicates that color aware mode is supported for\nthe trTCM RFC 4115 metering algorithm."]
    pub color_aware_trtcm_rfc4115_supported: ::core::ffi::c_int,
    #[doc = "srTCM rfc2697 byte mode supported.\nWhen non-zero, it indicates that byte mode is supported for\nthe srTCM RFC 2697 metering algorithm."]
    pub srtcm_rfc2697_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "srTCM rfc2697 packet mode supported.\nWhen non-zero, it indicates that packet mode is supported for\nthe srTCM RFC 2697 metering algorithm."]
    pub srtcm_rfc2697_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "trTCM rfc2698 byte mode supported.\nWhen non-zero, it indicates that byte mode is supported for\nthe trTCM RFC 2698 metering algorithm."]
    pub trtcm_rfc2698_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "trTCM rfc2698 packet mode supported.\nWhen non-zero, it indicates that packet mode is supported for\nthe trTCM RFC 2698 metering algorithm."]
    pub trtcm_rfc2698_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "trTCM rfc4115 byte mode supported.\nWhen non-zero, it indicates that byte mode is supported for\nthe trTCM RFC 4115 metering algorithm."]
    pub trtcm_rfc4115_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "trTCM rfc4115 packet mode supported.\nWhen non-zero, it indicates that packet mode is supported for\nthe trTCM RFC 4115 metering algorithm."]
    pub trtcm_rfc4115_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Set of supported statistics counter types.\n\n# See also\n\n> [`enum`] rte_mtr_stats_type"]
    pub stats_mask: u64,
    #[doc = "Set of supported input color protocol.\n\n# See also\n\n> [`enum`] rte_mtr_color_in_protocol"]
    pub input_color_proto_mask: u64,
    #[doc = "When non-zero, it indicates that driver supports separate\ninput color table for given ethdev port."]
    pub separate_input_color_table_per_port: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_capabilities"][::core::mem::size_of::<rte_mtr_capabilities>() - 128usize];
    ["Alignment of rte_mtr_capabilities"][::core::mem::align_of::<rte_mtr_capabilities>() - 8usize];
    ["Offset of field: rte_mtr_capabilities::n_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, n_max) - 0usize];
    ["Offset of field: rte_mtr_capabilities::n_shared_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, n_shared_max) - 4usize];
    ["Offset of field: rte_mtr_capabilities::identical"]
        [::core::mem::offset_of!(rte_mtr_capabilities, identical) - 8usize];
    ["Offset of field: rte_mtr_capabilities::shared_identical"]
        [::core::mem::offset_of!(rte_mtr_capabilities, shared_identical) - 12usize];
    ["Offset of field: rte_mtr_capabilities::shared_n_flows_per_mtr_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, shared_n_flows_per_mtr_max) - 16usize];
    ["Offset of field: rte_mtr_capabilities::chaining_n_mtrs_per_flow_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, chaining_n_mtrs_per_flow_max) - 20usize];
    ["Offset of field: rte_mtr_capabilities::chaining_use_prev_mtr_color_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        chaining_use_prev_mtr_color_supported
    ) - 24usize];
    ["Offset of field: rte_mtr_capabilities::chaining_use_prev_mtr_color_enforced"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        chaining_use_prev_mtr_color_enforced
    ) - 28usize];
    ["Offset of field: rte_mtr_capabilities::meter_srtcm_rfc2697_n_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, meter_srtcm_rfc2697_n_max) - 32usize];
    ["Offset of field: rte_mtr_capabilities::meter_trtcm_rfc2698_n_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, meter_trtcm_rfc2698_n_max) - 36usize];
    ["Offset of field: rte_mtr_capabilities::meter_trtcm_rfc4115_n_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, meter_trtcm_rfc4115_n_max) - 40usize];
    ["Offset of field: rte_mtr_capabilities::meter_rate_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, meter_rate_max) - 48usize];
    ["Offset of field: rte_mtr_capabilities::meter_policy_n_max"]
        [::core::mem::offset_of!(rte_mtr_capabilities, meter_policy_n_max) - 56usize];
    ["Offset of field: rte_mtr_capabilities::color_aware_srtcm_rfc2697_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        color_aware_srtcm_rfc2697_supported
    ) - 64usize];
    ["Offset of field: rte_mtr_capabilities::color_aware_trtcm_rfc2698_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        color_aware_trtcm_rfc2698_supported
    ) - 68usize];
    ["Offset of field: rte_mtr_capabilities::color_aware_trtcm_rfc4115_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        color_aware_trtcm_rfc4115_supported
    ) - 72usize];
    ["Offset of field: rte_mtr_capabilities::srtcm_rfc2697_byte_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        srtcm_rfc2697_byte_mode_supported
    ) - 76usize];
    ["Offset of field: rte_mtr_capabilities::srtcm_rfc2697_packet_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        srtcm_rfc2697_packet_mode_supported
    ) - 80usize];
    ["Offset of field: rte_mtr_capabilities::trtcm_rfc2698_byte_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        trtcm_rfc2698_byte_mode_supported
    ) - 84usize];
    ["Offset of field: rte_mtr_capabilities::trtcm_rfc2698_packet_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        trtcm_rfc2698_packet_mode_supported
    ) - 88usize];
    ["Offset of field: rte_mtr_capabilities::trtcm_rfc4115_byte_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        trtcm_rfc4115_byte_mode_supported
    ) - 92usize];
    ["Offset of field: rte_mtr_capabilities::trtcm_rfc4115_packet_mode_supported"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        trtcm_rfc4115_packet_mode_supported
    ) - 96usize];
    ["Offset of field: rte_mtr_capabilities::stats_mask"]
        [::core::mem::offset_of!(rte_mtr_capabilities, stats_mask) - 104usize];
    ["Offset of field: rte_mtr_capabilities::input_color_proto_mask"]
        [::core::mem::offset_of!(rte_mtr_capabilities, input_color_proto_mask) - 112usize];
    ["Offset of field: rte_mtr_capabilities::separate_input_color_table_per_port"][::core::mem::offset_of!(
        rte_mtr_capabilities,
        separate_input_color_table_per_port
    ) - 120usize];
};
pub mod rte_mtr_error_type {
    #[doc = "Verbose error types.\nMost of them provide the type of the object referenced by struct\nrte_mtr_error::cause."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< No error."]
    pub const RTE_MTR_ERROR_TYPE_NONE: Type = 0;
    #[doc = "< Cause unspecified."]
    pub const RTE_MTR_ERROR_TYPE_UNSPECIFIED: Type = 1;
    pub const RTE_MTR_ERROR_TYPE_METER_PROFILE_ID: Type = 2;
    pub const RTE_MTR_ERROR_TYPE_METER_PROFILE: Type = 3;
    pub const RTE_MTR_ERROR_TYPE_METER_PROFILE_PACKET_MODE: Type = 4;
    pub const RTE_MTR_ERROR_TYPE_MTR_ID: Type = 5;
    pub const RTE_MTR_ERROR_TYPE_MTR_PARAMS: Type = 6;
    pub const RTE_MTR_ERROR_TYPE_POLICER_ACTION_GREEN: Type = 7;
    pub const RTE_MTR_ERROR_TYPE_POLICER_ACTION_YELLOW: Type = 8;
    pub const RTE_MTR_ERROR_TYPE_POLICER_ACTION_RED: Type = 9;
    pub const RTE_MTR_ERROR_TYPE_STATS_MASK: Type = 10;
    pub const RTE_MTR_ERROR_TYPE_STATS: Type = 11;
    pub const RTE_MTR_ERROR_TYPE_SHARED: Type = 12;
    pub const RTE_MTR_ERROR_TYPE_METER_POLICY_ID: Type = 13;
    pub const RTE_MTR_ERROR_TYPE_METER_POLICY: Type = 14;
}
#[doc = "Verbose error structure definition.\nThis object is normally allocated by applications and set by PMDs, the\nmessage points to a constant string which does not need to be freed by\nthe application, however its pointer can be considered valid only as long\nas its associated DPDK port remains configured. Closing the underlying\ndevice or unloading the PMD invalidates it.\nBoth cause and message may be NULL regardless of the error type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mtr_error {
    #[doc = "< Cause field and error type."]
    pub type_: rte_mtr_error_type::Type,
    #[doc = "< Object responsible for the error."]
    pub cause: *const ::core::ffi::c_void,
    #[doc = "< Human-readable error message."]
    pub message: *const ::core::ffi::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mtr_error"][::core::mem::size_of::<rte_mtr_error>() - 24usize];
    ["Alignment of rte_mtr_error"][::core::mem::align_of::<rte_mtr_error>() - 8usize];
    ["Offset of field: rte_mtr_error::type_"]
        [::core::mem::offset_of!(rte_mtr_error, type_) - 0usize];
    ["Offset of field: rte_mtr_error::cause"]
        [::core::mem::offset_of!(rte_mtr_error, cause) - 8usize];
    ["Offset of field: rte_mtr_error::message"]
        [::core::mem::offset_of!(rte_mtr_error, message) - 16usize];
};
impl Default for rte_mtr_error {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "MTR capabilities get\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `cap` [out]  -\nMTR capabilities. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_capabilities_get(
        port_id: u16,
        cap: *mut rte_mtr_capabilities,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Meter profile add\nCreate a new meter profile with ID set to *meter_profile_id*. The new profile\nis used to create one or several MTR objects.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `meter_profile_id` [in]  -\nID for the new meter profile. Needs to be unused by any of the existing\nmeter profiles added for the current port.\n* `profile` [in]  -\nMeter profile parameters. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_profile_add(
        port_id: u16,
        meter_profile_id: u32,
        profile: *mut rte_mtr_meter_profile,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Meter profile delete\nDelete an existing meter profile. This operation fails when there is\ncurrently at least one user (i.e. MTR object) of this profile.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `meter_profile_id` [in]  -\nMeter profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_profile_delete(
        port_id: u16,
        meter_profile_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Meter profile object get\nGet meter profile object for a given meter profile ID.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `meter_profile_id` [in]  -\nMeter profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise."]
    pub fn rte_mtr_meter_profile_get(
        port_id: u16,
        meter_profile_id: u32,
        error: *mut rte_mtr_error,
    ) -> *mut rte_flow_meter_profile;
}
unsafe extern "C" {
    #[doc = "Check whether a meter policy can be created on a given port.\nThe meter policy is validated for correctness and\nwhether it could be accepted by the device given sufficient resources.\nThe policy is checked against the current capability information\nmeter_policy_n_max configuration.\nThe policy may also optionally be validated against existing\ndevice policy resources.\nThis function has no effect on the target device.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `policy` [in]  -\nAssociated action list per color.\nlist NULL is legal and means no special action.\n(list terminated by the END action).\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_policy_validate(
        port_id: u16,
        policy: *mut rte_mtr_meter_policy_params,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Meter policy add\nCreate a new meter policy. The new policy\nis used to create single or multiple MTR objects.\nThe same policy can be used to create multiple MTR objects.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `policy_id` [in]  -\nPolicy identifier for the new meter policy.\n* `policy` [in]  -\nAssociated actions per color.\nlist NULL is legal and means no special action.\nNon-NULL list must be terminated.\n(list terminated by the END action).\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_policy_add(
        port_id: u16,
        policy_id: u32,
        policy: *mut rte_mtr_meter_policy_params,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Meter policy object get\nGet meter policy object for a given meter policy ID.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `policy_id` [in]  -\nMeter policy ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\nA valid handle in case of success, NULL otherwise."]
    pub fn rte_mtr_meter_policy_get(
        port_id: u16,
        policy_id: u32,
        error: *mut rte_mtr_error,
    ) -> *mut rte_flow_meter_policy;
}
unsafe extern "C" {
    #[doc = "Meter policy delete\nDelete an existing meter policy. This operation fails when there is\ncurrently at least one user (i.e. MTR object) of this policy.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `policy_id` [in]  -\nPolicy identifier.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_policy_delete(
        port_id: u16,
        policy_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object create\nCreate a new MTR object for the current port. This object is run as part of\nassociated flow action for traffic metering and policing.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be unused by any of the existing MTR objects.\ncreated for the current port.\n* `params` [in]  -\nMTR object params. Needs to be pre-allocated and valid.\n* `shared` [in]  -\nNon-zero when this MTR object can be shared by multiple flows, zero when\nthis MTR object can be used by a single flow.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`enum`] rte_flow_action_type::RTE_FLOW_ACTION_TYPE_METER"]
    pub fn rte_mtr_create(
        port_id: u16,
        mtr_id: u32,
        params: *mut rte_mtr_params,
        shared: ::core::ffi::c_int,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object destroy\nDelete an existing MTR object. This operation fails when there is currently\nat least one user (i.e. flow) of this MTR object.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\ncreated for the current port.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_destroy(
        port_id: u16,
        mtr_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object meter disable\nDisable the meter of an existing MTR object. In disabled state, the meter of\nthe current MTR object works in pass-through mode, meaning that for each\ninput packet the meter output color is always the same as the input color. In\nparticular, when the meter of the current MTR object is configured in color\nblind mode, the input color is always green, so the meter output color is\nalso always green. Note that the policer and the statistics of the current\nMTR object are working as usual while the meter is disabled. No action is\ntaken and this function returns successfully when the meter of the current\nMTR object is already disabled.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_disable(
        port_id: u16,
        mtr_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object meter enable\nEnable the meter of an existing MTR object. If the MTR object has its meter\nalready enabled, then no action is taken and this function returns\nsuccessfully.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_enable(
        port_id: u16,
        mtr_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object meter profile update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `meter_profile_id` [in]  -\nMeter profile ID for the current MTR object. Needs to be valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_profile_update(
        port_id: u16,
        mtr_id: u32,
        meter_profile_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object meter policy update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `meter_policy_id` [in]  -\nMeter policy ID for the current MTR object. Needs to be valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_policy_update(
        port_id: u16,
        mtr_id: u32,
        meter_policy_id: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object DSCP table update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `proto` [in]  -\nInput color protocol.\n* `dscp_table` [in]  -\nWhen non-NULL: it points to a pre-allocated and pre-populated table with\nexactly 64 elements providing the input color for each value of the\nIPv4/IPv6 Differentiated Services Code Point (DSCP) input packet field.\nWhen NULL: it is equivalent to setting this parameter to an \"all-green\"\npopulated table (i.e. table with all the 64 elements set to green color).\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_dscp_table_update(
        port_id: u16,
        mtr_id: u32,
        proto: rte_mtr_color_in_protocol::Type,
        dscp_table: *mut rte_color::Type,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object VLAN table update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `proto` [in]  -\nInput color protocol.\n* `vlan_table` [in]  -\nWhen non-NULL: it points to a pre-allocated and pre-populated table with\nexactly 16 elements providing the input color for each value of the\neach value of the DEI(1bit), PCP(3 bits) input packet field.\nWhen NULL: it is equivalent to setting this parameter to an \"all-green\"\npopulated table (i.e. table with all the 16 elements set to green color).\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_meter_vlan_table_update(
        port_id: u16,
        mtr_id: u32,
        proto: rte_mtr_color_in_protocol::Type,
        vlan_table: *mut rte_color::Type,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set the input color protocol for a given MTR object\nMore than one of the method can be enabled for a given meter.\nEven if enabled, a method might not be applicable to each input packet,\nin case the associated protocol header is not present in the packet.\nThe highest priority method that is both enabled for the meter and also\napplicable for the current input packet wins;\nif none is both enabled and applicable, the default input color is used.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `proto` [in]  -\nInput color protocol.\n* `priority` [in]  -\nInput color protocol priority. Value zero indicates\nthe highest priority.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_color_in_protocol_set(
        port_id: u16,
        mtr_id: u32,
        proto: rte_mtr_color_in_protocol::Type,
        priority: u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the input color protocol for a given MTR object\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `proto_mask` [out]  -\nSelected input color protocols as bit mask.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_color_in_protocol_get(
        port_id: u16,
        mtr_id: u32,
        proto_mask: *mut u64,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get the priority associated with input color protocol for a given MTR object\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `proto` [in]  -\nInput color protocol.\n* `priority` [out]  -\nInput color protocol priority associated with proto.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_mtr_color_in_protocol_priority_get(
        port_id: u16,
        mtr_id: u32,
        proto: rte_mtr_color_in_protocol::Type,
        priority: *mut u32,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object enabled statistics counters update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `stats_mask` [in]  -\nMask of statistics counter types to be enabled for the current MTR object.\nAny statistics counter type not included in this set is to be disabled for\nthe current MTR object.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`enum`] rte_mtr_stats_type"]
    pub fn rte_mtr_stats_update(
        port_id: u16,
        mtr_id: u32,
        stats_mask: u64,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "MTR object statistics counters read\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mtr_id` [in]  -\nMTR object ID. Needs to be valid.\n* `stats` [out]  -\nWhen non-NULL, it contains the current value for the statistics counters\nenabled for the current MTR object.\n* `stats_mask` [out]  -\nWhen non-NULL, it contains the mask of statistics counter types that are\ncurrently enabled for this MTR object, indicating which of the counters\nretrieved with the *stats* structure are valid.\n* `clear` [in]  -\nWhen this parameter has a non-zero value, the statistics counters are\ncleared (i.e. set to zero) immediately after they have been read,\notherwise the statistics counters are left untouched.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`enum`] rte_mtr_stats_type"]
    pub fn rte_mtr_stats_read(
        port_id: u16,
        mtr_id: u32,
        stats: *mut rte_mtr_stats,
        stats_mask: *mut u64,
        clear: ::core::ffi::c_int,
        error: *mut rte_mtr_error,
    ) -> ::core::ffi::c_int;
}
#[doc = "Structure containing header lengths associated to a packet, filled\nby rte_net_get_ptype()."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_net_hdr_lens {
    pub l2_len: u8,
    pub inner_l2_len: u8,
    pub l3_len: u16,
    pub inner_l3_len: u16,
    pub tunnel_len: u16,
    pub l4_len: u8,
    pub inner_l4_len: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_net_hdr_lens"][::core::mem::size_of::<rte_net_hdr_lens>() - 10usize];
    ["Alignment of rte_net_hdr_lens"][::core::mem::align_of::<rte_net_hdr_lens>() - 2usize];
    ["Offset of field: rte_net_hdr_lens::l2_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, l2_len) - 0usize];
    ["Offset of field: rte_net_hdr_lens::inner_l2_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, inner_l2_len) - 1usize];
    ["Offset of field: rte_net_hdr_lens::l3_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, l3_len) - 2usize];
    ["Offset of field: rte_net_hdr_lens::inner_l3_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, inner_l3_len) - 4usize];
    ["Offset of field: rte_net_hdr_lens::tunnel_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, tunnel_len) - 6usize];
    ["Offset of field: rte_net_hdr_lens::l4_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, l4_len) - 8usize];
    ["Offset of field: rte_net_hdr_lens::inner_l4_len"]
        [::core::mem::offset_of!(rte_net_hdr_lens, inner_l4_len) - 9usize];
};
unsafe extern "C" {
    #[doc = "Skip IPv6 header extensions.\nThis function skips all IPv6 extensions, returning size of\ncomplete header including options and final protocol value.\n\n# Arguments\n\n* `proto` -\nProtocol field of IPv6 header.\n* `m` -\nThe packet mbuf to be parsed.\n* `off` -\nOn input, must contain the offset to the first byte following\nIPv6 header, on output, contains offset to the first byte\nof next layer (after any IPv6 extension header)\n* `frag` -\nContains 1 in output if packet is an IPv6 fragment.\n\n# Returns\n\nProtocol that follows IPv6 header.\n-1 if an error occurs during mbuf parsing."]
    pub fn rte_net_skip_ip6_ext(
        proto: u16,
        m: *const rte_mbuf,
        off: *mut u32,
        frag: *mut ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Parse an Ethernet packet to get its packet type.\nThis function parses the network headers in mbuf data and return its\npacket type.\nIf it is provided by the user, it also fills a rte_net_hdr_lens\nstructure that contains the lengths of the parsed network\nheaders. Each length field is valid only if the associated packet\ntype is set. For instance, hdr_lens->l2_len is valid only if\n(retval & RTE_PTYPE_L2_MASK) != RTE_PTYPE_UNKNOWN.\nSupported packet types are:\nL2: Ether, Vlan, QinQ\nL3: IPv4, IPv6\nL4: TCP, UDP, SCTP\nTunnels: IPv4, IPv6, Gre, Nvgre\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be parsed.\n* `hdr_lens` -\nA pointer to a structure where the header lengths will be returned,\nor NULL.\n* `layers` -\nList of layers to parse. The function will stop at the first\nempty layer. Examples:\n- To parse all known layers, use RTE_PTYPE_ALL_MASK.\n- To parse only L2 and L3, use RTE_PTYPE_L2_MASK | RTE_PTYPE_L3_MASK\n\n# Returns\n\nThe packet type of the packet."]
    pub fn rte_net_get_ptype(
        m: *const rte_mbuf,
        hdr_lens: *mut rte_net_hdr_lens,
        layers: u32,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Prepare pseudo header checksum\nThis function prepares pseudo header checksum for TSO and non-TSO tcp/udp in\nprovided mbufs packet data and based on the requested offload flags.\n- for non-TSO tcp/udp packets full pseudo-header checksum is counted and set\nin packet data,\n- for TSO the IP payload length is not included in pseudo header.\nThis function expects that used headers are in the first data segment of\nmbuf, are not fragmented and can be safely modified.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be fixed.\n* `ol_flags` -\nTX offloads flags to use with this packet.\n\n# Returns\n\n0 if checksum is initialized properly"]
    #[link_name = "rte_net_intel_cksum_flags_prepare_w"]
    pub fn rte_net_intel_cksum_flags_prepare(m: *mut rte_mbuf, ol_flags: u64)
    -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Prepare pseudo header checksum\nThis function prepares pseudo header checksum for TSO and non-TSO tcp/udp in\nprovided mbufs packet data.\n- for non-TSO tcp/udp packets full pseudo-header checksum is counted and set\nin packet data,\n- for TSO the IP payload length is not included in pseudo header.\nThis function expects that used headers are in the first data segment of\nmbuf, are not fragmented and can be safely modified.\n\n# Arguments\n\n* `m` -\nThe packet mbuf to be fixed.\n\n# Returns\n\n0 if checksum is initialized properly"]
    #[link_name = "rte_net_intel_cksum_prepare_w"]
    pub fn rte_net_intel_cksum_prepare(m: *mut rte_mbuf) -> ::core::ffi::c_int;
}
pub mod rte_net_crc_type {
    #[doc = "CRC types"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_NET_CRC16_CCITT: Type = 0;
    pub const RTE_NET_CRC32_ETH: Type = 1;
    pub const RTE_NET_CRC_REQS: Type = 2;
}
pub mod rte_net_crc_alg {
    #[doc = "CRC compute algorithm"]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_NET_CRC_SCALAR: Type = 0;
    pub const RTE_NET_CRC_SSE42: Type = 1;
    pub const RTE_NET_CRC_NEON: Type = 2;
    pub const RTE_NET_CRC_AVX512: Type = 3;
}
#[doc = "CRC context (algorithm, type)"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_net_crc {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Frees the memory space pointed to by the CRC context pointer.\nIf the pointer is NULL, the function does nothing.\n\n# Arguments\n\n* `ctx` -\nPointer to the CRC context"]
    pub fn rte_net_crc_free(crc: *mut rte_net_crc);
}
unsafe extern "C" {
    #[doc = "Set the CRC context (i.e. scalar version,\nx86 64-bit sse4.2 intrinsic version, etc.) and internal data\nstructure.\n\n# Arguments\n\n* `alg` -\nThis parameter is used to select the CRC implementation version.\n- RTE_NET_CRC_SCALAR\n- RTE_NET_CRC_SSE42 (Use 64-bit SSE4.2 intrinsic)\n- RTE_NET_CRC_NEON (Use ARM Neon intrinsic)\n- RTE_NET_CRC_AVX512 (Use 512-bit AVX intrinsic)\n* `type` -\nCRC type (enum rte_net_crc_type)\n\n# Returns\n\nPointer to the CRC context"]
    pub fn rte_net_crc_set_alg(
        alg: rte_net_crc_alg::Type,
        type_: rte_net_crc_type::Type,
    ) -> *mut rte_net_crc;
}
unsafe extern "C" {
    #[doc = "CRC compute API\nNote:\nThe command line argument --force-max-simd-bitwidth will be ignored\nby processes that have not created this CRC context.\n\n# Arguments\n\n* `ctx` -\nPointer to the CRC context\n* `data` -\nPointer to the packet data for CRC computation\n* `data_len` -\nData length for CRC computation\n\n# Returns\n\nCRC value"]
    pub fn rte_net_crc_calc(
        ctx: *const rte_net_crc,
        data: *const ::core::ffi::c_void,
        data_len: u32,
    ) -> u32;
}
pub mod rte_pdcp_ctrl_pdu_type {
    #[doc = "Indicate type of control information included in the corresponding PDCP\nControl PDU."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_PDCP_CTRL_PDU_TYPE_STATUS_REPORT: Type = 0;
    pub const RTE_PDCP_CTRL_PDU_TYPE_ROHC_FEEDBACK: Type = 1;
    pub const RTE_PDCP_CTRL_PDU_TYPE_EHC_FEEDBACK: Type = 2;
    pub const RTE_PDCP_CRTL_PDU_TYPE_UDC_FEEDBACK: Type = 3;
}
pub mod rte_pdcp_pdu_type {
    #[doc = "6.3.7 D/C\nThis field indicates whether the corresponding PDCP PDU is a\nPDCP Data PDU or a PDCP Control PDU."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_PDCP_PDU_TYPE_CTRL: Type = 0;
    pub const RTE_PDCP_PDU_TYPE_DATA: Type = 1;
}
#[doc = "6.2.2.1 Data PDU for SRBs"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pdcp_cp_data_pdu_sn_12_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Sequence number bits 0-7"]
    pub sn_7_0: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pdcp_cp_data_pdu_sn_12_hdr"]
        [::core::mem::size_of::<rte_pdcp_cp_data_pdu_sn_12_hdr>() - 2usize];
    ["Alignment of rte_pdcp_cp_data_pdu_sn_12_hdr"]
        [::core::mem::align_of::<rte_pdcp_cp_data_pdu_sn_12_hdr>() - 1usize];
    ["Offset of field: rte_pdcp_cp_data_pdu_sn_12_hdr::sn_7_0"]
        [::core::mem::offset_of!(rte_pdcp_cp_data_pdu_sn_12_hdr, sn_7_0) - 1usize];
};
impl rte_pdcp_cp_data_pdu_sn_12_hdr {
    #[inline]
    pub fn sn_11_8(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_sn_11_8(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sn_11_8_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_sn_11_8_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn r(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_r(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn r_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_r_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(sn_11_8: u8, r: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let sn_11_8: u8 = unsafe { ::core::mem::transmute(sn_11_8) };
            sn_11_8 as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let r: u8 = unsafe { ::core::mem::transmute(r) };
            r as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "6.2.2.2 Data PDU for DRBs and MRBs with 12 bits PDCP SN"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pdcp_up_data_pdu_sn_12_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Sequence number bits 0-7"]
    pub sn_7_0: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pdcp_up_data_pdu_sn_12_hdr"]
        [::core::mem::size_of::<rte_pdcp_up_data_pdu_sn_12_hdr>() - 2usize];
    ["Alignment of rte_pdcp_up_data_pdu_sn_12_hdr"]
        [::core::mem::align_of::<rte_pdcp_up_data_pdu_sn_12_hdr>() - 1usize];
    ["Offset of field: rte_pdcp_up_data_pdu_sn_12_hdr::sn_7_0"]
        [::core::mem::offset_of!(rte_pdcp_up_data_pdu_sn_12_hdr, sn_7_0) - 1usize];
};
impl rte_pdcp_up_data_pdu_sn_12_hdr {
    #[inline]
    pub fn sn_11_8(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_sn_11_8(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sn_11_8_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_sn_11_8_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn r(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 3u8) as u8) }
    }
    #[inline]
    pub fn set_r(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn r_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                3u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_r_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn d_c(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_d_c(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn d_c_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_d_c_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(sn_11_8: u8, r: u8, d_c: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let sn_11_8: u8 = unsafe { ::core::mem::transmute(sn_11_8) };
            sn_11_8 as u64
        });
        __bindgen_bitfield_unit.set(4usize, 3u8, {
            let r: u8 = unsafe { ::core::mem::transmute(r) };
            r as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let d_c: u8 = unsafe { ::core::mem::transmute(d_c) };
            d_c as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "6.2.2.3 Data PDU for DRBs and MRBs with 18 bits PDCP SN"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pdcp_up_data_pdu_sn_18_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Sequence number bits 8-15"]
    pub sn_15_8: u8,
    #[doc = "< Sequence number bits 0-7"]
    pub sn_7_0: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pdcp_up_data_pdu_sn_18_hdr"]
        [::core::mem::size_of::<rte_pdcp_up_data_pdu_sn_18_hdr>() - 3usize];
    ["Alignment of rte_pdcp_up_data_pdu_sn_18_hdr"]
        [::core::mem::align_of::<rte_pdcp_up_data_pdu_sn_18_hdr>() - 1usize];
    ["Offset of field: rte_pdcp_up_data_pdu_sn_18_hdr::sn_15_8"]
        [::core::mem::offset_of!(rte_pdcp_up_data_pdu_sn_18_hdr, sn_15_8) - 1usize];
    ["Offset of field: rte_pdcp_up_data_pdu_sn_18_hdr::sn_7_0"]
        [::core::mem::offset_of!(rte_pdcp_up_data_pdu_sn_18_hdr, sn_7_0) - 2usize];
};
impl rte_pdcp_up_data_pdu_sn_18_hdr {
    #[inline]
    pub fn sn_17_16(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 2u8) as u8) }
    }
    #[inline]
    pub fn set_sn_17_16(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 2u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn sn_17_16_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                2u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_sn_17_16_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                2u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn r(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(2usize, 5u8) as u8) }
    }
    #[inline]
    pub fn set_r(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(2usize, 5u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn r_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                5u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_r_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                5u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn d_c(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_d_c(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn d_c_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_d_c_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(sn_17_16: u8, r: u8, d_c: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 2u8, {
            let sn_17_16: u8 = unsafe { ::core::mem::transmute(sn_17_16) };
            sn_17_16 as u64
        });
        __bindgen_bitfield_unit.set(2usize, 5u8, {
            let r: u8 = unsafe { ::core::mem::transmute(r) };
            r as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let d_c: u8 = unsafe { ::core::mem::transmute(d_c) };
            d_c as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "6.2.3.1 Control PDU for PDCP status report"]
#[repr(C, packed)]
pub struct rte_pdcp_up_ctrl_pdu_hdr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "6.3.9 FMC\nFirst Missing COUNT. This field indicates the COUNT value of the\nfirst missing PDCP SDU within the reordering window, i.e. RX_DELIV."]
    pub fmc: rte_be32_t,
    #[doc = "6.3.10 Bitmap\nLength: Variable. The length of the bitmap field can be 0.\nThis field indicates which SDUs are missing and which SDUs are\ncorrectly received in the receiving PDCP entity. The bit position of\nNth bit in the Bitmap is N, i.e., the bit position of the first bit\nin the Bitmap is 1."]
    pub bitmap: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pdcp_up_ctrl_pdu_hdr"]
        [::core::mem::size_of::<rte_pdcp_up_ctrl_pdu_hdr>() - 5usize];
    ["Alignment of rte_pdcp_up_ctrl_pdu_hdr"]
        [::core::mem::align_of::<rte_pdcp_up_ctrl_pdu_hdr>() - 1usize];
    ["Offset of field: rte_pdcp_up_ctrl_pdu_hdr::fmc"]
        [::core::mem::offset_of!(rte_pdcp_up_ctrl_pdu_hdr, fmc) - 1usize];
    ["Offset of field: rte_pdcp_up_ctrl_pdu_hdr::bitmap"]
        [::core::mem::offset_of!(rte_pdcp_up_ctrl_pdu_hdr, bitmap) - 5usize];
};
impl Default for rte_pdcp_up_ctrl_pdu_hdr {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
impl rte_pdcp_up_ctrl_pdu_hdr {
    #[inline]
    pub fn r(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_r(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn r_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_r_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn pdu_type(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(4usize, 3u8) as u8) }
    }
    #[inline]
    pub fn set_pdu_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(4usize, 3u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn pdu_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                3u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_pdu_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                3u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn d_c(&self) -> u8 {
        unsafe { ::core::mem::transmute(self._bitfield_1.get(7usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_d_c(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            self._bitfield_1.set(7usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn d_c_raw(this: *const Self) -> u8 {
        unsafe {
            ::core::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::core::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_d_c_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::core::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::core::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(r: u8, pdu_type: u8, d_c: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let r: u8 = unsafe { ::core::mem::transmute(r) };
            r as u64
        });
        __bindgen_bitfield_unit.set(4usize, 3u8, {
            let pdu_type: u8 = unsafe { ::core::mem::transmute(pdu_type) };
            pdu_type as u64
        });
        __bindgen_bitfield_unit.set(7usize, 1u8, {
            let d_c: u8 = unsafe { ::core::mem::transmute(d_c) };
            d_c as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "The rte_pflock_t type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pflock {
    pub rd: rte_pflock__bindgen_ty_1,
    pub wr: rte_pflock__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_pflock__bindgen_ty_1 {
    pub in_: u16,
    pub out: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pflock__bindgen_ty_1"]
        [::core::mem::size_of::<rte_pflock__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_pflock__bindgen_ty_1"]
        [::core::mem::align_of::<rte_pflock__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_pflock__bindgen_ty_1::in_"]
        [::core::mem::offset_of!(rte_pflock__bindgen_ty_1, in_) - 0usize];
    ["Offset of field: rte_pflock__bindgen_ty_1::out"]
        [::core::mem::offset_of!(rte_pflock__bindgen_ty_1, out) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pflock"][::core::mem::size_of::<rte_pflock>() - 8usize];
    ["Alignment of rte_pflock"][::core::mem::align_of::<rte_pflock>() - 2usize];
    ["Offset of field: rte_pflock::rd"][::core::mem::offset_of!(rte_pflock, rd) - 0usize];
    ["Offset of field: rte_pflock::wr"][::core::mem::offset_of!(rte_pflock, wr) - 4usize];
};
#[doc = "The rte_pflock_t type."]
pub type rte_pflock_t = rte_pflock;
unsafe extern "C" {
    #[doc = "Initialize the pflock to an unlocked state.\n\n# Arguments\n\n* `pf` -\nA pointer to the pflock."]
    #[link_name = "rte_pflock_init_w"]
    pub fn rte_pflock_init(pf: *mut rte_pflock);
}
unsafe extern "C" {
    #[doc = "Take a pflock for read.\n\n# Arguments\n\n* `pf` -\nA pointer to a pflock structure."]
    #[link_name = "rte_pflock_read_lock_w"]
    pub fn rte_pflock_read_lock(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    #[doc = "Release a pflock locked for reading.\n\n# Arguments\n\n* `pf` -\nA pointer to the pflock structure."]
    #[link_name = "rte_pflock_read_unlock_w"]
    pub fn rte_pflock_read_unlock(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    #[doc = "Take the pflock for write.\n\n# Arguments\n\n* `pf` -\nA pointer to the pflock structure."]
    #[link_name = "rte_pflock_write_lock_w"]
    pub fn rte_pflock_write_lock(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    #[doc = "Release a pflock held for writing.\n\n# Arguments\n\n* `pf` -\nA pointer to a pflock structure."]
    #[link_name = "rte_pflock_write_unlock_w"]
    pub fn rte_pflock_write_unlock(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    #[doc = "Returns the dynamic flags name, that are supported.\n\n# Arguments\n\n* `names` [out]  -\nArray that is used to return the supported dynamic flags names.\n* `n` [in]  -\nThe number of elements in the names array.\n\n# Returns\n\nThe number of dynamic flags that were copied if not negative.\nOtherwise:\n- ENOMEM - not enough entries in the array\n- EINVAL - invalid array entry"]
    pub fn rte_pmd_mlx5_get_dyn_flag_names(
        names: *mut *mut ::core::ffi::c_char,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Synchronize the flows to make them take effort on hardware.\nIt only supports DR flows now. For DV and Verbs flows, there is no need to\ncall this function, and a success will return directly in case of Verbs.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `domains` [in]  -\nRefer to \"/usr/include/infiniband/mlx5dv.h\".\nBitmask of domains in which the synchronization will be done.\nRTE_PMD_MLX5_DOMAIN_BIT_* macros are used to specify the domains.\nAn ADD or OR operation could be used to synchronize flows in more than\none domain per call.\n\n# Returns\n\n- (0) if successful.\n- Negative value if an error."]
    pub fn rte_pmd_mlx5_sync_flow(port_id: u16, domains: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Update mapping between rte_flow queue index (16 bits) and HW queue index (32\nbits) for RxQs which is created outside the PMD.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `dpdk_idx` [in]  -\nQueue index in rte_flow.\n* `hw_idx` [in]  -\nQueue index in hardware.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EEXIST - a mapping with the same rte_flow index already exists.\n- EINVAL - invalid rte_flow index, out of range.\n- ENODEV - there is no Ethernet device for this port id.\n- ENOTSUP - the port doesn't support external RxQ."]
    pub fn rte_pmd_mlx5_external_rx_queue_id_map(
        port_id: u16,
        dpdk_idx: u16,
        hw_idx: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove mapping between rte_flow queue index (16 bits) and HW queue index (32\nbits) for RxQs which is created outside the PMD.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `dpdk_idx` [in]  -\nQueue index in rte_flow.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EINVAL - invalid index, out of range, still referenced or doesn't exist.\n- ENODEV - there is no Ethernet device for this port id.\n- ENOTSUP - the port doesn't support external RxQ."]
    pub fn rte_pmd_mlx5_external_rx_queue_id_unmap(
        port_id: u16,
        dpdk_idx: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Update mapping between rte_flow Tx queue index (16 bits) and HW queue index (32\nbits) for TxQs which is created outside the PMD.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `dpdk_idx` [in]  -\nQueue index in rte_flow.\n* `hw_idx` [in]  -\nQueue index in hardware.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EEXIST - a mapping with the same rte_flow index already exists.\n- EINVAL - invalid rte_flow index, out of range.\n- ENODEV - there is no Ethernet device for this port id.\n- ENOTSUP - the port doesn't support external TxQ."]
    pub fn rte_pmd_mlx5_external_tx_queue_id_map(
        port_id: u16,
        dpdk_idx: u16,
        hw_idx: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove mapping between rte_flow Tx queue index (16 bits) and HW queue index (32\nbits) for TxQs which is created outside the PMD.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `dpdk_idx` [in]  -\nQueue index in rte_flow.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EINVAL - invalid index, out of range, still referenced or doesn't exist.\n- ENODEV - there is no Ethernet device for this port id.\n- ENOTSUP - the port doesn't support external TxQ."]
    pub fn rte_pmd_mlx5_external_tx_queue_id_unmap(
        port_id: u16,
        dpdk_idx: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Configure a HW shaper to limit Tx rate for a host port.\nThe configuration will affect all the ethdev ports belonging to\nthe same rte_device.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `rate` [in]  -\nUnit is 100Mbps, setting the rate to 0 disables the shaper.\n* `flags` [in]  -\nHost shaper flags (see RTE_PMD_MLX5_HOST_SHAPER_FLAG_*).\n\n# Returns\n\n0 : operation success.\nOtherwise:\n- ENOENT - no ibdev interface.\n- EBUSY  - the register access unit is busy.\n- EIO    - the register access command meets IO error."]
    pub fn rte_pmd_mlx5_host_shaper_config(
        port_id: ::core::ffi::c_int,
        rate: u8,
        flags: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable traffic for external SQ.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `sq_num` [in]  -\nSQ HW number.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EINVAL - invalid sq_number or port type.\n- ENODEV - there is no Ethernet device for this port id."]
    pub fn rte_pmd_mlx5_external_sq_enable(port_id: u16, sq_num: u32) -> ::core::ffi::c_int;
}
pub mod rte_pmd_mlx5_flow_engine_mode {
    #[doc = "MLX5 flow engine mode definition for live migration."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "active means high priority, effective in HW."]
    pub const RTE_PMD_MLX5_FLOW_ENGINE_MODE_ACTIVE: Type = 0;
    #[doc = "standby mode with lower priority flow rules."]
    pub const RTE_PMD_MLX5_FLOW_ENGINE_MODE_STANDBY: Type = 1;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice\nSet the flow engine mode of the process to active or standby,\naffecting network traffic handling.\nIf one device does not support this operation or fails,\nthe whole operation is failed and rolled back.\nIt is forbidden to have multiple flow engines with the same mode\nunless only one of them is configured to handle the traffic.\nThe application's flow engine is active by default.\nThe configuration from the active flow engine is effective immediately\nwhile the configuration from the standby flow engine is queued by hardware.\nWhen configuring the device from a standby flow engine,\nit has no effect except for below situations:\n- traffic not handled by the active flow engine configuration\n- no active flow engine\nWhen flow engine of a process is changed from a standby to an active mode,\nall preceding configurations that are queued by hardware\nshould become effective immediately.\nBefore mode transition, all the traffic handling configurations\nset by the active flow engine should be flushed first.\nIn summary, the operations are expected to happen in this order\nin \"old\" and \"new\" applications:\ndevice: already configured by the old application\nnew:    start as active\nnew:    probe the same device\nnew:    set as standby\nnew:    configure the device\ndevice: has configurations from old and new applications\nold:    clear its device configuration\ndevice: has only 1 configuration from new application\nnew:    set as active\ndevice: downtime for connecting all to the new application\nold:    shutdown\n\n# Arguments\n\n* `mode` -\nThe desired mode (see rte_pmd_mlx5_flow_engine_mode).\n* `flags` -\nMode specific flags (see RTE_PMD_MLX5_FLOW_ENGINE_FLAG_*).\n\n# Returns\n\nPositive value on success, -rte_errno value on error:\n- (> 0) Number of switched devices.\n- (-EINVAL) if error happen and rollback internally.\n- (-EPERM) if operation failed and can't recover."]
    pub fn rte_pmd_mlx5_flow_engine_set_mode(
        mode: rte_pmd_mlx5_flow_engine_mode::Type,
        flags: u32,
    ) -> ::core::ffi::c_int;
}
#[doc = "User configuration structure using to create parser for single GENEVE TLV option."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pmd_mlx5_geneve_tlv {
    #[doc = "The class of the GENEVE TLV option.\nRelevant only when 'match_on_class_mode' is 1."]
    pub option_class: rte_be16_t,
    #[doc = "The type of the GENEVE TLV option.\nThis field is the identifier of the option."]
    pub option_type: u8,
    #[doc = "The length of the GENEVE TLV option data excluding the option header\nin DW granularity."]
    pub option_len: u8,
    #[doc = "Indicator about class field role in this option:\n0 - class is ignored.\n1 - class is fixed (the class defines the option along with the type).\n2 - class matching per flow."]
    pub match_on_class_mode: u8,
    #[doc = "The offset of the first sample in DW granularity.\nThis offset is relative to first of option data.\nThe 'match_data_mask' corresponds to option data since this offset."]
    pub offset: u8,
    #[doc = "The number of DW to sample.\nThis field describes the length of 'match_data_mask' in DW\ngranularity."]
    pub sample_len: u8,
    #[doc = "Array of DWs which each bit marks if this bit should be sampled.\nEach nonzero DW consumes one DW from maximum 7 DW in total."]
    pub match_data_mask: *mut rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pmd_mlx5_geneve_tlv"]
        [::core::mem::size_of::<rte_pmd_mlx5_geneve_tlv>() - 16usize];
    ["Alignment of rte_pmd_mlx5_geneve_tlv"]
        [::core::mem::align_of::<rte_pmd_mlx5_geneve_tlv>() - 8usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::option_class"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, option_class) - 0usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::option_type"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, option_type) - 2usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::option_len"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, option_len) - 3usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::match_on_class_mode"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, match_on_class_mode) - 4usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::offset"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, offset) - 5usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::sample_len"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, sample_len) - 6usize];
    ["Offset of field: rte_pmd_mlx5_geneve_tlv::match_data_mask"]
        [::core::mem::offset_of!(rte_pmd_mlx5_geneve_tlv, match_data_mask) - 8usize];
};
impl Default for rte_pmd_mlx5_geneve_tlv {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Creates GENEVE TLV parser for the selected port.\nThis function must be called before first use of GENEVE option.\nThis API is port oriented, but the configuration is done once for all ports\nunder the same physical device. Each port should call this API before using\nGENEVE OPT item, but it must use the same options in the same order inside\nthe list.\nEach physical device has 7 DWs for GENEVE TLV options. Each nonzero element\nin 'match_data_mask' array consumes one DW, and choosing matchable mode for\nclass consumes additional one.\nCalling this API for second port under same physical device doesn't consume\nmore DW, it uses same configuration.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `tlv_list` [in]  -\nA list of GENEVE TLV options to create parser for them.\n* `nb_options` [in]  -\nThe number of options in TLV list.\n\n# Returns\n\nA pointer to TLV handle on success, NULL otherwise and rte_errno is set.\nPossible values for rte_errno:\n- ENOMEM - not enough memory to create GENEVE TLV parser.\n- EEXIST - this port already has GENEVE TLV parser or another port under\nsame physical device has already prepared a different parser.\n- EINVAL - invalid GENEVE TLV requested.\n- ENODEV - there is no Ethernet device for this port id.\n- ENOTSUP - the port doesn't support GENEVE TLV parsing."]
    pub fn rte_pmd_mlx5_create_geneve_tlv_parser(
        port_id: u16,
        tlv_list: *const rte_pmd_mlx5_geneve_tlv,
        nb_options: u8,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    #[doc = "Destroy GENEVE TLV parser for the selected port.\nThis function must be called after last use of GENEVE option and before port\nclosing.\n\n# Arguments\n\n* `handle` [in]  -\nHandle for the GENEVE TLV parser object to be destroyed.\n\n# Returns\n\n0 on success, a negative errno value otherwise and rte_errno is set.\nPossible values for rte_errno:\n- EINVAL - invalid handle.\n- ENOENT - there is no valid GENEVE TLV parser in this handle.\n- EBUSY - one of options is in used by template table."]
    pub fn rte_pmd_mlx5_destroy_geneve_tlv_parser(
        handle: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump Rx Queue Context for a given port/queue\n\n# Arguments\n\n* `port_id` [in]  -\nPort ID\n* `queue_id` [in]  -\nQueue ID\n* `filename` [in]  -\nName of file to dump the Rx Queue Context\n\n# Returns\n\n0 for success, non-zero value depending on failure type"]
    pub fn rte_pmd_mlx5_rxq_dump_contexts(
        port_id: u16,
        queue_id: u16,
        filename: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Dump Tx Queue Context for a given port/queue\n\n# Arguments\n\n* `port_id` [in]  -\nPort ID\n* `queue_id` [in]  -\nQueue ID\n* `filename` [in]  -\nName of file to dump the Tx Queue Context\n\n# Returns\n\n0 for success, non-zero value depending on failure type"]
    pub fn rte_pmd_mlx5_txq_dump_contexts(
        port_id: u16,
        queue_id: u16,
        filename: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_reciprocal {
    pub m: u32,
    pub sh1: u8,
    pub sh2: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_reciprocal"][::core::mem::size_of::<rte_reciprocal>() - 8usize];
    ["Alignment of rte_reciprocal"][::core::mem::align_of::<rte_reciprocal>() - 4usize];
    ["Offset of field: rte_reciprocal::m"][::core::mem::offset_of!(rte_reciprocal, m) - 0usize];
    ["Offset of field: rte_reciprocal::sh1"][::core::mem::offset_of!(rte_reciprocal, sh1) - 4usize];
    ["Offset of field: rte_reciprocal::sh2"][::core::mem::offset_of!(rte_reciprocal, sh2) - 5usize];
};
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_reciprocal_u64 {
    pub m: u64,
    pub sh1: u8,
    pub sh2: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_reciprocal_u64"][::core::mem::size_of::<rte_reciprocal_u64>() - 16usize];
    ["Alignment of rte_reciprocal_u64"][::core::mem::align_of::<rte_reciprocal_u64>() - 8usize];
    ["Offset of field: rte_reciprocal_u64::m"]
        [::core::mem::offset_of!(rte_reciprocal_u64, m) - 0usize];
    ["Offset of field: rte_reciprocal_u64::sh1"]
        [::core::mem::offset_of!(rte_reciprocal_u64, sh1) - 8usize];
    ["Offset of field: rte_reciprocal_u64::sh2"]
        [::core::mem::offset_of!(rte_reciprocal_u64, sh2) - 9usize];
};
unsafe extern "C" {
    #[link_name = "rte_reciprocal_divide_w"]
    pub fn rte_reciprocal_divide(a: u32, R: rte_reciprocal) -> u32;
}
unsafe extern "C" {
    #[link_name = "rte_reciprocal_divide_u64_w"]
    pub fn rte_reciprocal_divide_u64(a: u64, R: *const rte_reciprocal_u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_reciprocal_value(d: u32) -> rte_reciprocal;
}
unsafe extern "C" {
    pub fn rte_reciprocal_value_u64(d: u64) -> rte_reciprocal_u64;
}
#[doc = "The RTE seqcount type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_seqcount_t {
    #[doc = "< A sequence number for the protected data."]
    pub sn: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_seqcount_t"][::core::mem::size_of::<rte_seqcount_t>() - 4usize];
    ["Alignment of rte_seqcount_t"][::core::mem::align_of::<rte_seqcount_t>() - 4usize];
    ["Offset of field: rte_seqcount_t::sn"][::core::mem::offset_of!(rte_seqcount_t, sn) - 0usize];
};
unsafe extern "C" {
    #[doc = "Initialize the sequence counter.\n\n# Arguments\n\n* `seqcount` -\nA pointer to the sequence counter."]
    #[link_name = "rte_seqcount_init_w"]
    pub fn rte_seqcount_init(seqcount: *mut rte_seqcount_t);
}
unsafe extern "C" {
    #[doc = "Begin a read-side critical section.\nA call to this function marks the beginning of a read-side critical\nsection, for `seqcount.`\nrte_seqcount_read_begin() returns a sequence number, which is later\nused in rte_seqcount_read_retry() to check if the protected data\nunderwent any modifications during the read transaction.\nAfter (in program order) rte_seqcount_read_begin() has been called,\nthe calling thread reads the protected data, for later use. The\nprotected data read *must* be copied (either in pristine form, or\nin the form of some derivative), since the caller may only read the\ndata from within the read-side critical section (i.e., after\nrte_seqcount_read_begin() and before rte_seqcount_read_retry()),\nbut must not act upon the retrieved data while in the critical\nsection, since it does not yet know if it is consistent.\nThe protected data may be read using atomic and/or non-atomic\noperations.\nAfter (in program order) all required data loads have been\nperformed, rte_seqcount_read_retry() should be called, marking\nthe end of the read-side critical section.\nIf rte_seqcount_read_retry() returns true, the just-read data is\ninconsistent and should be discarded. The caller has the option to\neither restart the whole procedure right away (i.e., calling\nrte_seqcount_read_begin() again), or do the same at some later time.\nIf rte_seqcount_read_retry() returns false, the data was read\natomically and the copied data is consistent.\n\n# Arguments\n\n* `seqcount` -\nA pointer to the sequence counter.\n\n# Returns\n\nThe seqcount sequence number for this critical section, to\nlater be passed to rte_seqcount_read_retry().\n\n# See also\n\n> [`rte_seqcount_read_retry()`]"]
    #[link_name = "rte_seqcount_read_begin_w"]
    pub fn rte_seqcount_read_begin(seqcount: *const rte_seqcount_t) -> u32;
}
unsafe extern "C" {
    #[doc = "End a read-side critical section.\nA call to this function marks the end of a read-side critical\nsection, for `seqcount.` The application must supply the sequence\nnumber produced by the corresponding rte_seqcount_read_begin() call.\nAfter this function has been called, the caller should not access\nthe protected data.\nIn case rte_seqcount_read_retry() returns true, the just-read data\nwas modified as it was being read and may be inconsistent, and thus\nshould be discarded.\nIn case this function returns false, the data is consistent and the\nset of atomic and non-atomic load operations performed between\nrte_seqcount_read_begin() and rte_seqcount_read_retry() were atomic,\nas a whole.\n\n# Arguments\n\n* `seqcount` -\nA pointer to the sequence counter.\n* `begin_sn` -\nThe sequence number returned by rte_seqcount_read_begin().\n\n# Returns\n\ntrue or false, if the just-read seqcount-protected data was\ninconsistent or consistent, respectively, at the time it was\nread.\n\n# See also\n\n> [`rte_seqcount_read_begin()`]"]
    #[link_name = "rte_seqcount_read_retry_w"]
    pub fn rte_seqcount_read_retry(seqcount: *const rte_seqcount_t, begin_sn: u32) -> bool;
}
unsafe extern "C" {
    #[doc = "Begin a write-side critical section.\nA call to this function marks the beginning of a write-side\ncritical section, after which the caller may go on to modify (both\nread and write) the protected data, in an atomic or non-atomic\nmanner.\nAfter the necessary updates have been performed, the application\ncalls rte_seqcount_write_end().\nMultiple, parallel writers must use some external serialization.\nThis function is not preemption-safe in the sense that preemption\nof the calling thread may block reader progress until the writer\nthread is rescheduled.\n\n# Arguments\n\n* `seqcount` -\nA pointer to the sequence counter.\n\n# See also\n\n> [`rte_seqcount_write_end()`]"]
    #[link_name = "rte_seqcount_write_begin_w"]
    pub fn rte_seqcount_write_begin(seqcount: *mut rte_seqcount_t);
}
unsafe extern "C" {
    #[doc = "End a write-side critical section.\nA call to this function marks the end of the write-side critical\nsection, for `seqcount.` After this call has been made, the\nprotected data may no longer be modified.\n\n# Arguments\n\n* `seqcount` -\nA pointer to the sequence counter.\n\n# See also\n\n> [`rte_seqcount_write_begin()`]"]
    #[link_name = "rte_seqcount_write_end_w"]
    pub fn rte_seqcount_write_end(seqcount: *mut rte_seqcount_t);
}
#[doc = "The RTE seqlock type."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_seqlock_t {
    #[doc = "< Sequence count for the protected data."]
    pub count: rte_seqcount_t,
    #[doc = "< Spinlock used to serialize writers."]
    pub lock: rte_spinlock_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_seqlock_t"][::core::mem::size_of::<rte_seqlock_t>() - 8usize];
    ["Alignment of rte_seqlock_t"][::core::mem::align_of::<rte_seqlock_t>() - 4usize];
    ["Offset of field: rte_seqlock_t::count"]
        [::core::mem::offset_of!(rte_seqlock_t, count) - 0usize];
    ["Offset of field: rte_seqlock_t::lock"][::core::mem::offset_of!(rte_seqlock_t, lock) - 4usize];
};
unsafe extern "C" {
    #[doc = "Initialize the seqlock.\nThis function initializes the seqlock, and leaves the writer-side\nspinlock unlocked.\n\n# Arguments\n\n* `seqlock` -\nA pointer to the seqlock."]
    #[link_name = "rte_seqlock_init_w"]
    pub fn rte_seqlock_init(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    #[doc = "Begin a read-side critical section.\nSee rte_seqcount_read_retry() for details.\n\n# Arguments\n\n* `seqlock` -\nA pointer to the seqlock.\n\n# Returns\n\nThe seqlock sequence number for this critical section, to\nlater be passed to rte_seqlock_read_retry().\n\n# See also\n\n> [`rte_seqlock_read_retry()`]\n> [`rte_seqcount_read_retry()`]"]
    #[link_name = "rte_seqlock_read_begin_w"]
    pub fn rte_seqlock_read_begin(seqlock: *const rte_seqlock_t) -> u32;
}
unsafe extern "C" {
    #[doc = "End a read-side critical section.\nSee rte_seqcount_read_retry() for details.\n\n# Arguments\n\n* `seqlock` -\nA pointer to the seqlock.\n* `begin_sn` -\nThe seqlock sequence number returned by rte_seqlock_read_begin().\n\n# Returns\n\ntrue or false, if the just-read seqlock-protected data was\ninconsistent or consistent, respectively, at the time it was\nread.\n\n# See also\n\n> [`rte_seqlock_read_begin()`]"]
    #[link_name = "rte_seqlock_read_retry_w"]
    pub fn rte_seqlock_read_retry(seqlock: *const rte_seqlock_t, begin_sn: u32) -> bool;
}
unsafe extern "C" {
    #[doc = "Begin a write-side critical section.\nA call to this function acquires the write lock associated `seqlock,` and marks the beginning of a write-side critical section.\nAfter having called this function, the caller may go on to modify\n(both read and write) the protected data, in an atomic or\nnon-atomic manner.\nAfter the necessary updates have been performed, the application\ncalls rte_seqlock_write_unlock().\nThis function is not preemption-safe in the sense that preemption\nof the calling thread may block reader progress until the writer\nthread is rescheduled.\nUnlike rte_seqlock_read_begin(), each call made to\nrte_seqlock_write_lock() must be matched with an unlock call.\n\n# Arguments\n\n* `seqlock` -\nA pointer to the seqlock.\n\n# See also\n\n> [`rte_seqlock_write_unlock()`]"]
    #[link_name = "rte_seqlock_write_lock_w"]
    pub fn rte_seqlock_write_lock(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    #[doc = "End a write-side critical section.\nA call to this function marks the end of the write-side critical\nsection, for `seqlock.` After this call has been made, the protected\ndata may no longer be modified.\n\n# Arguments\n\n* `seqlock` -\nA pointer to the seqlock.\n\n# See also\n\n> [`rte_seqlock_write_lock()`]"]
    #[link_name = "rte_seqlock_write_unlock_w"]
    pub fn rte_seqlock_write_unlock(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    #[doc = "Return the number of services registered.\n\n# Returns\n\nThe number of services registered."]
    pub fn rte_service_get_count() -> u32;
}
unsafe extern "C" {
    #[doc = "Return the id of a service by name.\nThis function provides the id of the service using the service name as\nlookup key. The service id is to be passed to other functions in the\nrte_service_* API.\nExample usage:\n@code uint32_t service_id;\nint32_t ret = rte_service_get_by_name(\"service_X\", &service_id);\nif (ret) {\n// handle error\n}\n@endcode # Arguments\n\n* `name` - The name of the service to retrieve\n* `service_id` [out]  - A pointer to a uint32_t, to be filled in with the id.\n@retval 0 Success. The service id is provided in *service_id*.\n@retval -EINVAL Null *service_id* pointer provided\n@retval -ENODEV No such service registered"]
    pub fn rte_service_get_by_name(name: *const ::core::ffi::c_char, service_id: *mut u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Return the name of the service.\n\n# Returns\n\nA pointer to the name of the service. The returned pointer remains\nin ownership of the service, and the application must not free it."]
    pub fn rte_service_get_name(id: u32) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Check if a service has a specific capability.\nThis function returns if *service* has implements *capability*.\nSee RTE_SERVICE_CAP_* defines for a list of valid capabilities.\n@retval 1 Capability supported by this service instance\n@retval 0 Capability not supported by this service instance"]
    pub fn rte_service_probe_capability(id: u32, capability: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Map or unmap a lcore to a service.\nEach core can be added or removed from running a specific service. This\nfunction enables or disables *lcore* to run *service_id*.\nIf multiple cores are enabled on a service, a lock is used to ensure that\nonly one core runs the service at a time. The exception to this is when\na service indicates that it is multi-thread safe by setting the capability\ncalled RTE_SERVICE_CAP_MT_SAFE. With the multi-thread safe capability set,\nthe service function can be run on multiple threads at the same time.\nIf the service is known to be mapped to a single lcore, setting the\ncapability of the service to RTE_SERVICE_CAP_MT_SAFE can achieve\nbetter performance by avoiding the use of lock.\n\n# Arguments\n\n* `service_id` - the service to apply the lcore to\n* `lcore` - The lcore that will be mapped to service\n* `enable` - Zero to unmap or disable the core, non-zero to enable\n@retval 0 lcore map updated successfully\n@retval -EINVAL An invalid service or lcore was provided."]
    pub fn rte_service_map_lcore_set(service_id: u32, lcore: u32, enable: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Retrieve the mapping of an lcore to a service.\n\n# Arguments\n\n* `service_id` - the service to apply the lcore to\n* `lcore` - The lcore that will be mapped to service\n@retval 1 lcore is mapped to service\n@retval 0 lcore is not mapped to service\n@retval -EINVAL An invalid service or lcore was provided."]
    pub fn rte_service_map_lcore_get(service_id: u32, lcore: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Set the runstate of the service.\nEach service is either running or stopped. Setting a non-zero runstate\nenables the service to run, while setting runstate zero disables it.\n\n# Arguments\n\n* `id` - The id of the service\n* `runstate` - The run state to apply to the service\n@retval 0 The service was successfully started\n@retval -EINVAL Invalid service id"]
    pub fn rte_service_runstate_set(id: u32, runstate: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Get the runstate for the service with *id*. See rte_service_runstate_set()\nfor details of runstates. A service can call this function to ensure that\nthe application has indicated that it will receive CPU cycles. Either a\nservice-core is mapped (default case), or the application has explicitly\ndisabled the check that a service-cores is mapped to the service and takes\nresponsibility to run the service manually using the available function\nrte_service_run_iter_on_app_lcore() to do so.\n@retval 1 Service is running\n@retval 0 Service is stopped\n@retval -EINVAL Invalid service id"]
    pub fn rte_service_runstate_get(id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "This function returns whether the service may be currently executing on\nat least one lcore, or definitely is not. This function can be used to\ndetermine if, after setting the service runstate to stopped, the service\nis still executing a service lcore.\nCare must be taken if calling this function when the service runstate is\nrunning, since the result of this function may be incorrect by the time the\nfunction returns due to service cores running in parallel.\n@retval 1 Service may be running on one or more lcores\n@retval 0 Service is not running on any lcore\n@retval -EINVAL Invalid service id"]
    pub fn rte_service_may_be_active(id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Enable or disable the check for a service-core being mapped to the service.\nAn application can disable the check when takes the responsibility to run a\nservice itself using rte_service_run_iter_on_app_lcore().\n\n# Arguments\n\n* `id` - The id of the service to set the check on\n* `enable` - When zero, the check is disabled. Non-zero enables the check.\n@retval 0 Success\n@retval -EINVAL Invalid service ID"]
    pub fn rte_service_set_runstate_mapped_check(id: u32, enable: i32) -> i32;
}
unsafe extern "C" {
    #[doc = "This function runs a service callback from a non-service lcore.\nThis function is designed to enable gradual porting to service cores, and\nto enable unit tests to verify a service behaves as expected.\nWhen called, this function ensures that the service identified by *id* is\nsafe to run on this lcore. Multi-thread safe services are invoked even if\nother cores are simultaneously running them as they are multi-thread safe.\nMulti-thread unsafe services are handled depending on the variable\n*serialize_multithread_unsafe*:\n- When set, the function will check if a service is already being invoked\non another lcore, refusing to run it and returning -EBUSY.\n- When zero, the application takes responsibility to ensure that the service\nindicated by *id* is not going to be invoked by another lcore. This setting\navoids atomic operations, so is likely to be more performant.\n\n# Arguments\n\n* `id` - The ID of the service to run\n* `serialize_multithread_unsafe` - This parameter indicates to the service\ncores library if it is required to use atomics to serialize access\nto mult-thread unsafe services. As there is an overhead in using\natomics, applications can choose to enable or disable this feature\nNote that any thread calling this function MUST be a DPDK EAL thread, as\nthe rte_lcore_id() function is used to access internal data structures.\n@retval 0 Service was run on the calling thread successfully\n@retval -EBUSY Another lcore is executing the service, and it is not a\nmulti-thread safe service, so the service was not run on this lcore\n@retval -ENOEXEC Service is not in a run-able state\n@retval -EINVAL Invalid service id"]
    pub fn rte_service_run_iter_on_app_lcore(id: u32, serialize_multithread_unsafe: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Start a service core.\nStarting a core makes the core begin polling. Any services assigned to it\nwill be run as fast as possible. The application must ensure that the lcore\nis in a launchable state: e.g. call rte_eal_lcore_wait() on the lcore_id\nbefore calling this function.\n@retval 0 Success\n@retval -EINVAL Failed to start core. The *lcore_id* passed in is not\ncurrently assigned to be a service core."]
    pub fn rte_service_lcore_start(lcore_id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Stop a service core.\nStopping a core makes the core become idle, but remains  assigned as a\nservice core. Note that the service lcore thread may not have returned from\nthe service it is running when this API returns.\nThe rte_service_lcore_may_be_active() API can be used to check if the\nservice lcore is * still active.\n@retval 0 Success\n@retval -EINVAL Invalid *lcore_id* provided\n@retval -EALREADY Already stopped core\n@retval -EBUSY Failed to stop core, as it would cause a service to not\nbe run, as this is the only core currently running the service.\nThe application must stop the service first, and then stop the\nlcore."]
    pub fn rte_service_lcore_stop(lcore_id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Reports if a service lcore is currently running.\nThis function returns if the core has finished service cores code, and has\nreturned to EAL control. If rte_service_lcore_stop() has been called but\nthe lcore has not returned to EAL yet, it might be required to wait and call\nthis function again. The amount of time to wait before the core returns\ndepends on the duration of the services being run.\n@retval 0 Service thread is not active, and lcore has been returned to EAL.\n@retval 1 Service thread is in the service core polling loop.\n@retval -EINVAL Invalid *lcore_id* provided."]
    pub fn rte_service_lcore_may_be_active(lcore_id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Adds lcore to the list of service cores.\nThis functions can be used at runtime in order to modify the service core\nmask.\n@retval 0 Success\n@retval -EBUSY lcore is busy, and not available for service core duty\n@retval -EALREADY lcore is already added to the service core list\n@retval -EINVAL Invalid lcore provided"]
    pub fn rte_service_lcore_add(lcore: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Removes lcore from the list of service cores.\nThis can fail if the core is not stopped, see rte_service_core_stop().\n@retval 0 Success\n@retval -EBUSY Lcore is not stopped, stop service core before removing.\n@retval -EINVAL failed to add lcore to service core mask."]
    pub fn rte_service_lcore_del(lcore: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Retrieve the number of service cores currently available.\nThis function returns the integer count of service cores available. The\nservice core count can be used in mapping logic when creating mappings\nfrom service cores to services.\nSee rte_service_lcore_list() for details on retrieving the lcore_id of each\nservice core.\n\n# Returns\n\nThe number of service cores currently configured."]
    pub fn rte_service_lcore_count() -> i32;
}
unsafe extern "C" {
    #[doc = "Resets all service core mappings. This does not remove the service cores\nfrom duty, just unmaps all services / cores, and stops() the service cores.\nThe runstate of services is not modified.\nThe cores that are stopped with this call, are in WAIT state.\n@retval 0 Success"]
    pub fn rte_service_lcore_reset_all() -> i32;
}
unsafe extern "C" {
    #[doc = "Enable or disable statistics collection for *service*.\nThis function enables per core, per-service cycle count collection.\n\n# Arguments\n\n* `id` - The service to enable statistics gathering on.\n* `enable` - Zero to disable statistics, non-zero to enable.\n@retval 0 Success\n@retval -EINVAL Invalid service pointer passed"]
    pub fn rte_service_set_stats_enable(id: u32, enable: i32) -> i32;
}
unsafe extern "C" {
    #[doc = "Retrieve the list of currently enabled service cores.\nThis function fills in an application supplied array, with each element\nindicating the lcore_id of a service core.\nAdding and removing service cores can be performed using\nrte_service_lcore_add() and rte_service_lcore_del().\n\n# Arguments\n\n* `array` [out]  - An array of at least rte_service_lcore_count() items.\nIf statically allocating the buffer, use RTE_MAX_LCORE.\n* `n` [out]  - The size of *array*.\n@retval >=0 Number of service cores that have been populated in the array\n@retval -ENOMEM The provided array is not large enough to fill in the\nservice core list. No items have been populated, call this function\nwith a size of at least rte_service_core_count() items."]
    pub fn rte_service_lcore_list(array: *mut u32, n: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Get the number of services running on the supplied lcore.\n\n# Arguments\n\n* `lcore` - Id of the service core.\n@retval >=0 Number of services registered to this core.\n@retval -EINVAL Invalid lcore provided\n@retval -ENOTSUP The provided lcore is not a service core."]
    pub fn rte_service_lcore_count_services(lcore: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Dumps any information available about the service. When id is UINT32_MAX,\nthis function dumps info for all services.\n@retval 0 Statistics have been successfully dumped\n@retval -EINVAL Invalid service id provided"]
    pub fn rte_service_dump(f: *mut FILE, id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Get an attribute from a service.\n@retval 0 Success, the attribute value has been written to *attr_value*.\n-EINVAL Invalid id, attr_id or attr_value was NULL."]
    pub fn rte_service_attr_get(id: u32, attr_id: u32, attr_value: *mut u64) -> i32;
}
unsafe extern "C" {
    #[doc = "Reset all attribute values of a service.\n\n# Arguments\n\n* `id` - The service to reset all statistics of\n@retval 0 Successfully reset attributes\n-EINVAL Invalid service id provided"]
    pub fn rte_service_attr_reset_all(id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Get an attribute from a service core.\n\n# Arguments\n\n* `lcore` - Id of the service core.\n* `attr_id` - Id of the attribute to be retrieved.\n* `attr_value` [out]  - Pointer to storage in which to write retrieved value.\n@retval 0 Success, the attribute value has been written to *attr_value*.\n-EINVAL Invalid lcore, attr_id or attr_value was NULL.\n-ENOTSUP lcore is not a service core."]
    pub fn rte_service_lcore_attr_get(lcore: u32, attr_id: u32, attr_value: *mut u64) -> i32;
}
unsafe extern "C" {
    #[doc = "Reset all attribute values of a service core.\n\n# Arguments\n\n* `lcore` - The service core to reset all the statistics of\n@retval 0 Successfully reset attributes\n-EINVAL Invalid service id provided\n-ENOTSUP lcore is not a service core."]
    pub fn rte_service_lcore_attr_reset_all(lcore: u32) -> i32;
}
#[doc = "Signature of callback function to run a service.\nA service function call resulting in no actual work being\nperformed, should return -EAGAIN. In that case, the (presumbly few)\ncycles spent will not be counted toward the lcore or service-level\ncycles attributes."]
pub type rte_service_func =
    ::core::option::Option<unsafe extern "C" fn(args: *mut ::core::ffi::c_void) -> i32>;
#[doc = "The specification of a service.\nThis struct contains metadata about the service itself, the callback\nfunction to run one iteration of the service, a userdata pointer, flags etc."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_service_spec {
    #[doc = "The name of the service. This should be used by the application to\nunderstand what purpose this service provides."]
    pub name: [::core::ffi::c_char; 32usize],
    #[doc = "The callback to invoke to run one iteration of the service."]
    pub callback: rte_service_func,
    #[doc = "The userdata pointer provided to the service callback."]
    pub callback_userdata: *mut ::core::ffi::c_void,
    #[doc = "Flags to indicate the capabilities of this service. See defines in\nthe public header file for values of RTE_SERVICE_CAP_*"]
    pub capabilities: u32,
    #[doc = "NUMA socket ID that this service is affinitized to"]
    pub socket_id: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_service_spec"][::core::mem::size_of::<rte_service_spec>() - 56usize];
    ["Alignment of rte_service_spec"][::core::mem::align_of::<rte_service_spec>() - 8usize];
    ["Offset of field: rte_service_spec::name"]
        [::core::mem::offset_of!(rte_service_spec, name) - 0usize];
    ["Offset of field: rte_service_spec::callback"]
        [::core::mem::offset_of!(rte_service_spec, callback) - 32usize];
    ["Offset of field: rte_service_spec::callback_userdata"]
        [::core::mem::offset_of!(rte_service_spec, callback_userdata) - 40usize];
    ["Offset of field: rte_service_spec::capabilities"]
        [::core::mem::offset_of!(rte_service_spec, capabilities) - 48usize];
    ["Offset of field: rte_service_spec::socket_id"]
        [::core::mem::offset_of!(rte_service_spec, socket_id) - 52usize];
};
impl Default for rte_service_spec {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Register a new service.\nA service represents a component that requires CPU time periodically to\nachieve its purpose.\nFor example the eventdev SW PMD requires CPU cycles to perform its\nscheduling. This can be achieved by registering it as a service, and the\napplication can then assign CPU resources to that service.\nNote that when a service component registers itself, it is not permitted to\nadd or remove service-core threads, or modify lcore-to-service mappings. The\nonly API that may be called by the service-component is\n*rte_service_component_runstate_set*, which indicates that the service\ncomponent is ready to be executed.\nIf the service is known to be mapped to a single lcore, setting the\ncapability of the service to RTE_SERVICE_CAP_MT_SAFE can achieve\nbetter performance.\n\n# Arguments\n\n* `spec` - The specification of the service to register\n* `service_id` [out]  - A pointer to a uint32_t, which will be filled in\nduring registration of the service. It is set to the integers\nservice number given to the service. This parameter may be NULL.\n@retval 0 Successfully registered the service.\n-EINVAL Attempted to register an invalid service (eg, no callback\nset)"]
    pub fn rte_service_component_register(
        spec: *const rte_service_spec,
        service_id: *mut u32,
    ) -> i32;
}
unsafe extern "C" {
    #[doc = "Unregister a service component.\nThe service being removed must be stopped before calling this function.\n@retval 0 The service was successfully unregistered.\n@retval -EBUSY The service is currently running, stop the service before\ncalling unregister. No action has been taken."]
    pub fn rte_service_component_unregister(id: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Private function to allow EAL to initialized default mappings.\nThis function iterates all the services, and maps then to the available\ncores. Based on the capabilities of the services, they are set to run on the\navailable cores in a round-robin manner.\n@retval 0 Success\n@retval -ENOTSUP No service lcores in use\n@retval -EINVAL Error while iterating over services\n@retval -ENODEV Error in enabling service lcore on a service\n@retval -ENOEXEC Error when starting services"]
    pub fn rte_service_start_with_defaults() -> i32;
}
unsafe extern "C" {
    #[doc = "Set the backend runstate of a component.\nThis function allows services to be registered at startup, but not yet\nenabled to run by default. When the service has been configured (via the\nusual method; eg rte_eventdev_configure, the service can mark itself as\nready to run. The differentiation between backend runstate and\nservice_runstate is that the backend runstate is set by the service\ncomponent while the service runstate is reserved for application usage.\n@retval 0 Success"]
    pub fn rte_service_component_runstate_set(id: u32, runstate: u32) -> i32;
}
unsafe extern "C" {
    #[doc = "Initialize the service library.\nIn order to use the service library, it must be initialized. EAL initializes\nthe library at startup.\n@retval 0 Success\n@retval -EALREADY Service library is already initialized"]
    pub fn rte_service_init() -> i32;
}
unsafe extern "C" {
    #[doc = "@internal Free up the memory that has been initialized.\nThis routine is to be invoked prior to process termination.\n@retval None"]
    pub fn rte_service_finalize();
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_stack_lf_elem {
    #[doc = "< Data pointer"]
    pub data: *mut ::core::ffi::c_void,
    #[doc = "< Next pointer"]
    pub next: *mut rte_stack_lf_elem,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack_lf_elem"][::core::mem::size_of::<rte_stack_lf_elem>() - 16usize];
    ["Alignment of rte_stack_lf_elem"][::core::mem::align_of::<rte_stack_lf_elem>() - 8usize];
    ["Offset of field: rte_stack_lf_elem::data"]
        [::core::mem::offset_of!(rte_stack_lf_elem, data) - 0usize];
    ["Offset of field: rte_stack_lf_elem::next"]
        [::core::mem::offset_of!(rte_stack_lf_elem, next) - 8usize];
};
impl Default for rte_stack_lf_elem {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_stack_lf_head {
    #[doc = "< Stack top"]
    pub top: *mut rte_stack_lf_elem,
    #[doc = "< Modification counter for avoiding ABA problem"]
    pub cnt: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack_lf_head"][::core::mem::size_of::<rte_stack_lf_head>() - 16usize];
    ["Alignment of rte_stack_lf_head"][::core::mem::align_of::<rte_stack_lf_head>() - 8usize];
    ["Offset of field: rte_stack_lf_head::top"]
        [::core::mem::offset_of!(rte_stack_lf_head, top) - 0usize];
    ["Offset of field: rte_stack_lf_head::cnt"]
        [::core::mem::offset_of!(rte_stack_lf_head, cnt) - 8usize];
};
impl Default for rte_stack_lf_head {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[repr(align(16))]
#[derive(Debug, Copy, Clone)]
pub struct rte_stack_lf_list {
    #[doc = "List head"]
    pub head: rte_stack_lf_head,
    #[doc = "List len"]
    pub len: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack_lf_list"][::core::mem::size_of::<rte_stack_lf_list>() - 32usize];
    ["Alignment of rte_stack_lf_list"][::core::mem::align_of::<rte_stack_lf_list>() - 16usize];
    ["Offset of field: rte_stack_lf_list::head"]
        [::core::mem::offset_of!(rte_stack_lf_list, head) - 0usize];
    ["Offset of field: rte_stack_lf_list::len"]
        [::core::mem::offset_of!(rte_stack_lf_list, len) - 16usize];
};
impl Default for rte_stack_lf_list {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Structure containing two lock-free LIFO lists: the stack itself and a list\nof free linked-list elements."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug)]
pub struct rte_stack_lf {
    #[doc = "LIFO list of elements"]
    pub used: rte_stack_lf_list,
    pub __bindgen_padding_0: [u64; 4usize],
    #[doc = "LIFO list of free elements"]
    pub free: rte_stack_lf_list,
    pub __bindgen_padding_1: [u64; 4usize],
    #[doc = "LIFO elements"]
    pub elems: __IncompleteArrayField<rte_stack_lf_elem>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack_lf"][::core::mem::size_of::<rte_stack_lf>() - 128usize];
    ["Alignment of rte_stack_lf"][::core::mem::align_of::<rte_stack_lf>() - 64usize];
    ["Offset of field: rte_stack_lf::used"][::core::mem::offset_of!(rte_stack_lf, used) - 0usize];
    ["Offset of field: rte_stack_lf::free"][::core::mem::offset_of!(rte_stack_lf, free) - 64usize];
    ["Offset of field: rte_stack_lf::elems"]
        [::core::mem::offset_of!(rte_stack_lf, elems) - 128usize];
};
impl Default for rte_stack_lf {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Structure containing the LIFO, its current length, and a lock for mutual\nexclusion."]
#[repr(C)]
#[derive(Debug)]
pub struct rte_stack_std {
    #[doc = "< LIFO lock"]
    pub lock: rte_spinlock_t,
    #[doc = "< LIFO len"]
    pub len: u32,
    #[doc = "< LIFO pointer table"]
    pub objs: __IncompleteArrayField<*mut ::core::ffi::c_void>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack_std"][::core::mem::size_of::<rte_stack_std>() - 8usize];
    ["Alignment of rte_stack_std"][::core::mem::align_of::<rte_stack_std>() - 8usize];
    ["Offset of field: rte_stack_std::lock"][::core::mem::offset_of!(rte_stack_std, lock) - 0usize];
    ["Offset of field: rte_stack_std::len"][::core::mem::offset_of!(rte_stack_std, len) - 4usize];
    ["Offset of field: rte_stack_std::objs"][::core::mem::offset_of!(rte_stack_std, objs) - 8usize];
};
impl Default for rte_stack_std {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "The RTE stack structure contains the LIFO structure itself, plus metadata\nsuch as its name and memzone pointer."]
#[repr(C)]
#[repr(align(64))]
pub struct rte_stack {
    #[doc = "Name of the stack."]
    pub name: [::core::ffi::c_char; 28usize],
    #[doc = "Memzone containing the rte_stack structure."]
    pub memzone: *const rte_memzone,
    #[doc = "< Usable size of the stack."]
    pub capacity: u32,
    #[doc = "< Flags supplied at creation."]
    pub flags: u32,
    pub __bindgen_padding_0: [u64; 2usize],
    pub anon1: rte_stack__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(64))]
pub struct rte_stack__bindgen_ty_1 {
    #[doc = "< Lock-free LIFO structure."]
    pub stack_lf: __BindgenUnionField<rte_stack_lf>,
    #[doc = "< LIFO structure."]
    pub stack_std: __BindgenUnionField<rte_stack_std>,
    pub bindgen_union_field: [u8; 128usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack__bindgen_ty_1"]
        [::core::mem::size_of::<rte_stack__bindgen_ty_1>() - 128usize];
    ["Alignment of rte_stack__bindgen_ty_1"]
        [::core::mem::align_of::<rte_stack__bindgen_ty_1>() - 64usize];
    ["Offset of field: rte_stack__bindgen_ty_1::stack_lf"]
        [::core::mem::offset_of!(rte_stack__bindgen_ty_1, stack_lf) - 0usize];
    ["Offset of field: rte_stack__bindgen_ty_1::stack_std"]
        [::core::mem::offset_of!(rte_stack__bindgen_ty_1, stack_std) - 0usize];
};
impl Default for rte_stack__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_stack"][::core::mem::size_of::<rte_stack>() - 192usize];
    ["Alignment of rte_stack"][::core::mem::align_of::<rte_stack>() - 64usize];
    ["Offset of field: rte_stack::name"][::core::mem::offset_of!(rte_stack, name) - 0usize];
    ["Offset of field: rte_stack::memzone"][::core::mem::offset_of!(rte_stack, memzone) - 32usize];
    ["Offset of field: rte_stack::capacity"]
        [::core::mem::offset_of!(rte_stack, capacity) - 40usize];
    ["Offset of field: rte_stack::flags"][::core::mem::offset_of!(rte_stack, flags) - 44usize];
};
impl Default for rte_stack {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "@internal Initialize a standard stack.\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure."]
    pub fn rte_stack_std_init(s: *mut rte_stack);
}
unsafe extern "C" {
    #[doc = "@internal Return the memory required for a standard stack.\n\n# Arguments\n\n* `count` -\nThe size of the stack.\n\n# Returns\n\nThe bytes to allocate for a standard stack."]
    pub fn rte_stack_std_get_memsize(count: ::core::ffi::c_uint) -> isize;
}
unsafe extern "C" {
    #[doc = "@internal Initialize a lock-free stack.\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure.\n* `count` -\nThe size of the stack."]
    pub fn rte_stack_lf_init(s: *mut rte_stack, count: ::core::ffi::c_uint);
}
unsafe extern "C" {
    #[doc = "@internal Return the memory required for a lock-free stack.\n\n# Arguments\n\n* `count` -\nThe size of the stack.\n\n# Returns\n\nThe bytes to allocate for a lock-free stack."]
    pub fn rte_stack_lf_get_memsize(count: ::core::ffi::c_uint) -> isize;
}
unsafe extern "C" {
    #[doc = "Push several objects on the stack (MT-safe).\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to push on the stack from the obj_table.\n\n# Returns\n\nActual number of objects pushed (either 0 or *n*)."]
    #[link_name = "rte_stack_push_w"]
    pub fn rte_stack_push(
        s: *mut rte_stack,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Pop several objects from the stack (MT-safe).\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure.\n* `obj_table` -\nA pointer to a table of void * pointers (objects).\n* `n` -\nThe number of objects to pull from the stack.\n\n# Returns\n\nActual number of objects popped (either 0 or *n*)."]
    #[link_name = "rte_stack_pop_w"]
    pub fn rte_stack_pop(
        s: *mut rte_stack,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of used entries in a stack.\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure.\n\n# Returns\n\nThe number of used entries in the stack."]
    #[link_name = "rte_stack_count_w"]
    pub fn rte_stack_count(s: *mut rte_stack) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of free entries in a stack.\n\n# Arguments\n\n* `s` -\nA pointer to the stack structure.\n\n# Returns\n\nThe number of free entries in the stack."]
    #[link_name = "rte_stack_free_count_w"]
    pub fn rte_stack_free_count(s: *mut rte_stack) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Create a new stack named *name* in memory.\nThis function uses ``memzone_reserve()`` to allocate memory for a stack of\nsize *count*. The behavior of the stack is controlled by the *flags*.\n\n# Arguments\n\n* `name` -\nThe name of the stack.\n* `count` -\nThe size of the stack.\n* `socket_id` -\nThe *socket_id* argument is the socket identifier in case of\nNUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\nconstraint for the reserved zone.\n* `flags` -\nAn OR of the following:\n- RTE_STACK_F_LF: If this flag is set, the stack uses lock-free\nvariants of the push and pop functions. Otherwise, it achieves\nthread-safety using a lock.\n\n# Returns\n\nOn success, the pointer to the new allocated stack. NULL on error with\nrte_errno set appropriately. Possible errno values include:\n- ENOSPC - the maximum number of memzones has already been allocated\n- EEXIST - a stack with the same name already exists\n- ENOMEM - insufficient memory to create the stack\n- ENAMETOOLONG - name size exceeds RTE_STACK_NAMESIZE\n- ENOTSUP - platform does not support given flags combination."]
    pub fn rte_stack_create(
        name: *const ::core::ffi::c_char,
        count: ::core::ffi::c_uint,
        socket_id: ::core::ffi::c_int,
        flags: u32,
    ) -> *mut rte_stack;
}
unsafe extern "C" {
    #[doc = "Free all memory used by the stack.\n\n# Arguments\n\n* `s` -\nPointer to stack created with rte_stack_create().\nIf s is NULL, no operation is performed."]
    pub fn rte_stack_free(s: *mut rte_stack);
}
unsafe extern "C" {
    #[doc = "Lookup a stack by its name.\n\n# Arguments\n\n* `name` -\nThe name of the stack.\n\n# Returns\n\nThe pointer to the stack matching the name, or NULL if not found,\nwith rte_errno set appropriately. Possible rte_errno values include:\n- ENOENT - Stack with name *name* not found.\n- EINVAL - *name* pointer is NULL."]
    pub fn rte_stack_lookup(name: *const ::core::ffi::c_char) -> *mut rte_stack;
}
#[doc = "dummy structure type used by the rte_tailq APIs"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_entry {
    #[doc = "< Pointer entries for a tailq list"]
    pub next: rte_tailq_entry__bindgen_ty_1,
    #[doc = "< Pointer to the data referenced by this tailq entry"]
    pub data: *mut ::core::ffi::c_void,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_entry__bindgen_ty_1 {
    pub tqe_next: *mut rte_tailq_entry,
    pub tqe_prev: *mut *mut rte_tailq_entry,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_entry__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tailq_entry__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_tailq_entry__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tailq_entry__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tailq_entry__bindgen_ty_1::tqe_next"]
        [::core::mem::offset_of!(rte_tailq_entry__bindgen_ty_1, tqe_next) - 0usize];
    ["Offset of field: rte_tailq_entry__bindgen_ty_1::tqe_prev"]
        [::core::mem::offset_of!(rte_tailq_entry__bindgen_ty_1, tqe_prev) - 8usize];
};
impl Default for rte_tailq_entry__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_entry"][::core::mem::size_of::<rte_tailq_entry>() - 24usize];
    ["Alignment of rte_tailq_entry"][::core::mem::align_of::<rte_tailq_entry>() - 8usize];
    ["Offset of field: rte_tailq_entry::next"]
        [::core::mem::offset_of!(rte_tailq_entry, next) - 0usize];
    ["Offset of field: rte_tailq_entry::data"]
        [::core::mem::offset_of!(rte_tailq_entry, data) - 16usize];
};
impl Default for rte_tailq_entry {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "dummy"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_entry_head {
    pub tqh_first: *mut rte_tailq_entry,
    pub tqh_last: *mut *mut rte_tailq_entry,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_entry_head"][::core::mem::size_of::<rte_tailq_entry_head>() - 16usize];
    ["Alignment of rte_tailq_entry_head"][::core::mem::align_of::<rte_tailq_entry_head>() - 8usize];
    ["Offset of field: rte_tailq_entry_head::tqh_first"]
        [::core::mem::offset_of!(rte_tailq_entry_head, tqh_first) - 0usize];
    ["Offset of field: rte_tailq_entry_head::tqh_last"]
        [::core::mem::offset_of!(rte_tailq_entry_head, tqh_last) - 8usize];
};
impl Default for rte_tailq_entry_head {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "The structure defining a tailq header entry for storing\nin the rte_config structure in shared memory. Each tailq\nis identified by name.\nAny library storing a set of objects e.g. rings, mempools, hash-tables,\nis recommended to use an entry here, so as to make it easy for\na multi-process app to find already-created elements in shared memory."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_head {
    #[doc = "< NOTE: must be first element"]
    pub tailq_head: rte_tailq_entry_head,
    pub name: [::core::ffi::c_char; 32usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_head"][::core::mem::size_of::<rte_tailq_head>() - 48usize];
    ["Alignment of rte_tailq_head"][::core::mem::align_of::<rte_tailq_head>() - 8usize];
    ["Offset of field: rte_tailq_head::tailq_head"]
        [::core::mem::offset_of!(rte_tailq_head, tailq_head) - 0usize];
    ["Offset of field: rte_tailq_head::name"]
        [::core::mem::offset_of!(rte_tailq_head, name) - 16usize];
};
impl Default for rte_tailq_head {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_elem {
    #[doc = "Reference to head in shared mem, updated at init time by\nrte_eal_tailqs_init()"]
    pub head: *mut rte_tailq_head,
    pub next: rte_tailq_elem__bindgen_ty_1,
    pub name: [::core::ffi::c_char; 32usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tailq_elem__bindgen_ty_1 {
    pub tqe_next: *mut rte_tailq_elem,
    pub tqe_prev: *mut *mut rte_tailq_elem,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_elem__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tailq_elem__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_tailq_elem__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tailq_elem__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tailq_elem__bindgen_ty_1::tqe_next"]
        [::core::mem::offset_of!(rte_tailq_elem__bindgen_ty_1, tqe_next) - 0usize];
    ["Offset of field: rte_tailq_elem__bindgen_ty_1::tqe_prev"]
        [::core::mem::offset_of!(rte_tailq_elem__bindgen_ty_1, tqe_prev) - 8usize];
};
impl Default for rte_tailq_elem__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tailq_elem"][::core::mem::size_of::<rte_tailq_elem>() - 56usize];
    ["Alignment of rte_tailq_elem"][::core::mem::align_of::<rte_tailq_elem>() - 8usize];
    ["Offset of field: rte_tailq_elem::head"]
        [::core::mem::offset_of!(rte_tailq_elem, head) - 0usize];
    ["Offset of field: rte_tailq_elem::next"]
        [::core::mem::offset_of!(rte_tailq_elem, next) - 8usize];
    ["Offset of field: rte_tailq_elem::name"]
        [::core::mem::offset_of!(rte_tailq_elem, name) - 24usize];
};
impl Default for rte_tailq_elem {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Dump tail queues to a file.\n\n# Arguments\n\n* `f` -\nA pointer to a file for output"]
    pub fn rte_dump_tailq(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = "Lookup for a tail queue.\nGet a pointer to a tail queue header of a tail\nqueue identified by the name given as an argument.\nNote: this function is not multi-thread safe, and should only be called from\na single thread at a time\n\n# Arguments\n\n* `name` -\nThe name of the queue.\n\n# Returns\n\nA pointer to the tail queue head structure."]
    pub fn rte_eal_tailq_lookup(name: *const ::core::ffi::c_char) -> *mut rte_tailq_head;
}
unsafe extern "C" {
    #[doc = "Register a tail queue.\nRegister a tail queue from shared memory.\nThis function is mainly used by EAL_REGISTER_TAILQ macro which is used to\nregister tailq from the different dpdk libraries. Since this macro is a\nconstructor, the function has no access to dpdk shared memory, so the\nregistered tailq can not be used before call to rte_eal_init() which calls\nrte_eal_tailqs_init().\n\n# Arguments\n\n* `t` -\nThe tailq element which contains the name of the tailq you want to\ncreate (/retrieve when in secondary process).\n\n# Returns\n\n0 on success or -1 in case of an error."]
    pub fn rte_eal_tailq_register(t: *mut rte_tailq_elem) -> ::core::ffi::c_int;
}
#[doc = "opaque structure used internally for managing data from callbacks"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tel_data {
    _unused: [u8; 0],
}
pub mod rte_tel_value_type {
    #[doc = "The types of data that can be managed in arrays or dicts.\nFor arrays, this must be specified at creation time, while for\ndicts this is specified implicitly each time an element is added\nvia calling a type-specific function."]
    pub type Type = ::core::ffi::c_uint;
    pub const RTE_TEL_STRING_VAL: Type = 0;
    #[doc = "a string value"]
    pub const RTE_TEL_INT_VAL: Type = 1;
    #[doc = "a signed 64-bit int value"]
    pub const RTE_TEL_UINT_VAL: Type = 2;
    #[doc = "an unsigned 64-bit int value"]
    pub const RTE_TEL_CONTAINER: Type = 3;
}
unsafe extern "C" {
    #[doc = "Start an array of the specified type for returning from a callback\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `type` -\nThe type of the array of data\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_start_array(
        d: *mut rte_tel_data,
        type_: rte_tel_value_type::Type,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Start a dictionary of values for returning from a callback\nDictionaries consist of key-values pairs to be returned, where the keys,\nor names, are strings and the values can be any of the types supported by telemetry.\nName strings may only contain alphanumeric characters as well as '_' or '/'\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_start_dict(d: *mut rte_tel_data) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Set a string for returning from a callback\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `str` -\nThe string to be returned in the data structure\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation"]
    pub fn rte_tel_data_string(
        d: *mut rte_tel_data,
        str_: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a string to an array.\nThe array must have been started by rte_tel_data_start_array() with\nRTE_TEL_STRING_VAL as the type parameter.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `str` -\nThe string to be returned in the array\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation"]
    pub fn rte_tel_data_add_array_string(
        d: *mut rte_tel_data,
        str_: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add an int to an array.\nThe array must have been started by rte_tel_data_start_array() with\nRTE_TEL_INT_VAL as the type parameter.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `x` -\nThe number to be returned in the array\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_add_array_int(d: *mut rte_tel_data, x: i64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add an unsigned value to an array.\nThe array must have been started by rte_tel_data_start_array() with\nRTE_TEL_UINT_VAL as the type parameter.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `x` -\nThe number to be returned in the array\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_add_array_uint(d: *mut rte_tel_data, x: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a uint64_t to an array.\nThe array must have been started by rte_tel_data_start_array() with\nRTE_TEL_UINT_VAL as the type parameter.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `x` -\nThe number to be returned in the array\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_add_array_u64(d: *mut rte_tel_data, x: u64) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a container to an array. A container is an existing telemetry data\narray. The array the container is to be added to must have been started by\nrte_tel_data_start_array() with RTE_TEL_CONTAINER as the type parameter.\nThe container type must be an array of type uint64_t/int/string.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `val` -\nThe pointer to the container to be stored in the array.\n* `keep` -\nFlag to indicate that the container memory should not be automatically\nfreed by the telemetry library once it has finished with the data.\n1 = keep, 0 = free.\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_add_array_container(
        d: *mut rte_tel_data,
        val: *mut rte_tel_data,
        keep: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Convert an unsigned integer to hexadecimal encoded strings\nand add this string to an array.\nThe array must have been started by rte_tel_data_start_array()\nwith RTE_TEL_STRING_VAL as the type parameter.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback.\n* `val` -\nThe number to be returned in the array as a hexadecimal encoded strings.\n* `display_bitwidth` -\nThe display bit width of the 'val'. If 'display_bitwidth' is zero, the\nvalue is stored in the array as no-padding zero hexadecimal encoded string,\nor the value is stored as padding zero to specified hexadecimal width.\n\n# Returns\n\n0 on success, negative errno on error."]
    pub fn rte_tel_data_add_array_uint_hex(
        d: *mut rte_tel_data,
        val: u64,
        display_bitwidth: u8,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a string value to a dictionary.\nThe dict must have been started by rte_tel_data_start_dict().\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `name` -\nThe name the value is to be stored under in the dict\nMust contain only alphanumeric characters or the symbols: '_' or '/'\n* `val` -\nThe string to be stored in the dict\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation of\neither name or value."]
    pub fn rte_tel_data_add_dict_string(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add an int value to a dictionary.\nThe dict must have been started by rte_tel_data_start_dict().\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `name` -\nThe name the value is to be stored under in the dict\nMust contain only alphanumeric characters or the symbols: '_' or '/'\n* `val` -\nThe number to be stored in the dict\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation of name."]
    pub fn rte_tel_data_add_dict_int(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: i64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add an unsigned value to a dictionary.\nThe dict must have been started by rte_tel_data_start_dict().\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `name` -\nThe name the value is to be stored under in the dict\nMust contain only alphanumeric characters or the symbols: '_' or '/'\n* `val` -\nThe number to be stored in the dict\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation of name."]
    pub fn rte_tel_data_add_dict_uint(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a uint64_t value to a dictionary.\nThe dict must have been started by rte_tel_data_start_dict().\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `name` -\nThe name the value is to be stored under in the dict\nMust contain only alphanumeric characters or the symbols: '_' or '/'\n* `val` -\nThe number to be stored in the dict\n\n# Returns\n\n0 on success, negative errno on error, E2BIG on string truncation of name."]
    pub fn rte_tel_data_add_dict_u64(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Add a container to a dictionary. A container is an existing telemetry data\narray. The dict the container is to be added to must have been started by\nrte_tel_data_start_dict(). The container must be an array of type\nuint64_t/int/string.\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback\n* `name` -\nThe name the value is to be stored under in the dict.\nMust contain only alphanumeric characters or the symbols: '_' or '/'\n* `val` -\nThe pointer to the container to be stored in the dict.\n* `keep` -\nFlag to indicate that the container memory should not be automatically\nfreed by the telemetry library once it has finished with the data.\n1 = keep, 0 = free.\n\n# Returns\n\n0 on success, negative errno on error"]
    pub fn rte_tel_data_add_dict_container(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: *mut rte_tel_data,
        keep: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Convert an unsigned integer to hexadecimal encoded strings\nand add this string to an dictionary.\nThe dict must have been started by rte_tel_data_start_dict().\n\n# Arguments\n\n* `d` -\nThe data structure passed to the callback.\n* `name` -\nThe name of the value is to be stored in the dict.\nMust contain only alphanumeric characters or the symbols: '_' or '/'.\n* `val` -\nThe number to be stored in the dict as a hexadecimal encoded strings.\n* `display_bitwidth` -\nThe display bit width of the 'val'. If 'display_bitwidth' is zero, the\nvalue is stored in the array as no-padding zero hexadecimal encoded string,\nor the value is stored as padding zero to specified hexadecimal width.\n\n# Returns\n\n0 on success, negative errno on error."]
    pub fn rte_tel_data_add_dict_uint_hex(
        d: *mut rte_tel_data,
        name: *const ::core::ffi::c_char,
        val: u64,
        display_bitwidth: u8,
    ) -> ::core::ffi::c_int;
}
#[doc = "This telemetry callback is used when registering a telemetry command.\nIt handles getting and formatting information to be returned to telemetry\nwhen requested.\n\n# Arguments\n\n* `cmd` -\nThe cmd that was requested by the client.\n* `params` -\nContains data required by the callback function.\n* `info` -\nThe information to be returned to the caller.\n\n# Returns\n\nLength of buffer used on success.\nNegative integer on error."]
pub type telemetry_cb = ::core::option::Option<
    unsafe extern "C" fn(
        cmd: *const ::core::ffi::c_char,
        params: *const ::core::ffi::c_char,
        info: *mut rte_tel_data,
    ) -> ::core::ffi::c_int,
>;
#[doc = "This telemetry callback is used when registering a telemetry command with\nrte_telemetry_register_cmd_arg().\nIt handles getting and formatting information to be returned to telemetry\nwhen requested.\n\n# Arguments\n\n* `cmd` -\nThe cmd that was requested by the client.\n* `params` -\nContains data required by the callback function.\n* `arg` -\nThe opaque value that was passed to rte_telemetry_register_cmd_arg().\n* `info` -\nThe information to be returned to the caller.\n\n# Returns\n\nLength of buffer used on success.\nNegative integer on error."]
pub type telemetry_arg_cb = ::core::option::Option<
    unsafe extern "C" fn(
        cmd: *const ::core::ffi::c_char,
        params: *const ::core::ffi::c_char,
        arg: *mut ::core::ffi::c_void,
        info: *mut rte_tel_data,
    ) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Used when registering a command and callback function with telemetry.\n\n# Arguments\n\n* `cmd` -\nThe command to register with telemetry.\n* `fn` -\nCallback function to be called when the command is requested.\n* `help` -\nHelp text for the command.\n\n# Returns\n\n0 on success.\n-EINVAL for invalid parameters failure.\n-ENOMEM for mem allocation failure."]
    pub fn rte_telemetry_register_cmd(
        cmd: *const ::core::ffi::c_char,
        fn_: telemetry_cb,
        help: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Used when registering a command and callback function with telemetry.\n\n# Arguments\n\n* `cmd` -\nThe command to register with telemetry.\n* `fn` -\nCallback function to be called when the command is requested.\n* `arg` -\nAn opaque value that will be passed to the callback function.\n* `help` -\nHelp text for the command.\n\n# Returns\n\n0 on success.\n-EINVAL for invalid parameters failure.\n-ENOMEM for mem allocation failure."]
    pub fn rte_telemetry_register_cmd_arg(
        cmd: *const ::core::ffi::c_char,
        fn_: telemetry_arg_cb,
        arg: *mut ::core::ffi::c_void,
        help: *const ::core::ffi::c_char,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@internal Free a container that has memory allocated.\n\n# Arguments\n\n* `data` -\nPointer to container.\nIf data is NULL, no operation is performed."]
    pub fn rte_tel_data_free(data: *mut rte_tel_data);
}
unsafe extern "C" {
    #[doc = "Get a pointer to a container with memory allocated. The container is to be\nused embedded within an existing telemetry dict/array.\n\n# Returns\n\nPointer to a container."]
    pub fn rte_tel_data_alloc() -> *mut rte_tel_data;
}
unsafe extern "C" {
    #[doc = "@internal Stubs only used when GFNI is not available."]
    pub fn rte_thash_gfni_stub(mtrx: *const u64, key: *const u8, len: ::core::ffi::c_int) -> u32;
}
unsafe extern "C" {
    pub fn rte_thash_gfni_bulk_stub(
        mtrx: *const u64,
        len: ::core::ffi::c_int,
        tuple: *mut *mut u8,
        val: *mut u32,
        num: u32,
    );
}
unsafe extern "C" {
    #[doc = "Calculate Toeplitz hash.\n\n# Arguments\n\n* `m` -\nPointer to the matrices generated from the corresponding\nRSS hash key using rte_thash_complete_matrix().\n* `tuple` -\nPointer to the data to be hashed. Data must be in network byte order.\n* `len` -\nLength of the data to be hashed.\n\n# Returns\n\nCalculated Toeplitz hash value."]
    #[link_name = "rte_thash_gfni_w"]
    pub fn rte_thash_gfni(mtrx: *const u64, key: *const u8, len: ::core::ffi::c_int) -> u32;
}
unsafe extern "C" {
    #[doc = "Bulk implementation for Toeplitz hash.\n\n# Arguments\n\n* `m` -\nPointer to the matrices generated from the corresponding\nRSS hash key using rte_thash_complete_matrix().\n* `len` -\nLength of the largest data buffer to be hashed.\n* `tuple` -\nArray of the pointers on data to be hashed.\nData must be in network byte order.\n* `val` -\nArray of uint32_t where to put calculated Toeplitz hash values\n* `num` -\nNumber of tuples to hash."]
    #[link_name = "rte_thash_gfni_bulk_w"]
    pub fn rte_thash_gfni_bulk(
        mtrx: *const u64,
        len: ::core::ffi::c_int,
        tuple: *mut *mut u8,
        val: *mut u32,
        num: u32,
    );
}
#[doc = "IPv4 tuple\naddresses and ports/sctp_tag have to be CPU byte order"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ipv4_tuple {
    pub src_addr: u32,
    pub dst_addr: u32,
    pub anon1: rte_ipv4_tuple__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv4_tuple__bindgen_ty_1 {
    pub anon1: rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1,
    pub sctp_tag: u32,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1 {
    pub dport: u16,
    pub sport: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1::dport"]
        [::core::mem::offset_of!(rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1, dport) - 0usize];
    ["Offset of field: rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1::sport"]
        [::core::mem::offset_of!(rte_ipv4_tuple__bindgen_ty_1__bindgen_ty_1, sport) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_tuple__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv4_tuple__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv4_tuple__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv4_tuple__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ipv4_tuple__bindgen_ty_1::sctp_tag"]
        [::core::mem::offset_of!(rte_ipv4_tuple__bindgen_ty_1, sctp_tag) - 0usize];
};
impl Default for rte_ipv4_tuple__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_tuple"][::core::mem::size_of::<rte_ipv4_tuple>() - 12usize];
    ["Alignment of rte_ipv4_tuple"][::core::mem::align_of::<rte_ipv4_tuple>() - 4usize];
    ["Offset of field: rte_ipv4_tuple::src_addr"]
        [::core::mem::offset_of!(rte_ipv4_tuple, src_addr) - 0usize];
    ["Offset of field: rte_ipv4_tuple::dst_addr"]
        [::core::mem::offset_of!(rte_ipv4_tuple, dst_addr) - 4usize];
};
impl Default for rte_ipv4_tuple {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "IPv6 tuple\nAddresses have to be filled by rte_thash_load_v6_addr()\nports/sctp_tag have to be CPU byte order"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ipv6_tuple {
    pub src_addr: rte_ipv6_addr,
    pub dst_addr: rte_ipv6_addr,
    pub anon1: rte_ipv6_tuple__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv6_tuple__bindgen_ty_1 {
    pub anon1: rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1,
    pub sctp_tag: u32,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1 {
    pub dport: u16,
    pub sport: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1::dport"]
        [::core::mem::offset_of!(rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1, dport) - 0usize];
    ["Offset of field: rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1::sport"]
        [::core::mem::offset_of!(rte_ipv6_tuple__bindgen_ty_1__bindgen_ty_1, sport) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_tuple__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ipv6_tuple__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ipv6_tuple__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ipv6_tuple__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ipv6_tuple__bindgen_ty_1::sctp_tag"]
        [::core::mem::offset_of!(rte_ipv6_tuple__bindgen_ty_1, sctp_tag) - 0usize];
};
impl Default for rte_ipv6_tuple__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_tuple"][::core::mem::size_of::<rte_ipv6_tuple>() - 36usize];
    ["Alignment of rte_ipv6_tuple"][::core::mem::align_of::<rte_ipv6_tuple>() - 4usize];
    ["Offset of field: rte_ipv6_tuple::src_addr"]
        [::core::mem::offset_of!(rte_ipv6_tuple, src_addr) - 0usize];
    ["Offset of field: rte_ipv6_tuple::dst_addr"]
        [::core::mem::offset_of!(rte_ipv6_tuple, dst_addr) - 16usize];
};
impl Default for rte_ipv6_tuple {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_thash_tuple {
    pub v4: rte_ipv4_tuple,
    pub v6: rte_ipv6_tuple,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_thash_tuple"][::core::mem::size_of::<rte_thash_tuple>() - 48usize];
    ["Alignment of rte_thash_tuple"][::core::mem::align_of::<rte_thash_tuple>() - 16usize];
    ["Offset of field: rte_thash_tuple::v4"][::core::mem::offset_of!(rte_thash_tuple, v4) - 0usize];
    ["Offset of field: rte_thash_tuple::v6"][::core::mem::offset_of!(rte_thash_tuple, v6) - 0usize];
};
impl Default for rte_thash_tuple {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Prepare special converted key to use with rte_softrss_be()\n\n# Arguments\n\n* `orig` -\npointer to original RSS key\n* `targ` -\npointer to target RSS key\n* `len` -\nRSS key length"]
    #[link_name = "rte_convert_rss_key_w"]
    pub fn rte_convert_rss_key(orig: *const u32, targ: *mut u32, len: ::core::ffi::c_int);
}
unsafe extern "C" {
    #[doc = "Prepare and load IPv6 addresses (src and dst)\ninto target tuple\n\n# Arguments\n\n* `orig` -\nPointer to ipv6 header of the original packet\n* `targ` -\nPointer to rte_ipv6_tuple structure"]
    #[link_name = "rte_thash_load_v6_addrs_w"]
    pub fn rte_thash_load_v6_addrs(orig: *const rte_ipv6_hdr, targ: *mut rte_thash_tuple);
}
unsafe extern "C" {
    #[doc = "Generic implementation. Can be used with original rss_key\n\n# Arguments\n\n* `input_tuple` -\nPointer to input tuple\n* `input_len` -\nLength of input_tuple in 4-bytes chunks\n* `rss_key` -\nPointer to RSS hash key.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_softrss_w"]
    pub fn rte_softrss(input_tuple: *mut u32, input_len: u32, rss_key: *const u8) -> u32;
}
unsafe extern "C" {
    #[doc = "Optimized implementation.\nIf you want the calculated hash value matches NIC RSS value\nyou have to use special converted key with rte_convert_rss_key() fn.\n\n# Arguments\n\n* `input_tuple` -\nPointer to input tuple\n* `input_len` -\nLength of input_tuple in 4-bytes chunks\n* `*rss_key` -\nPointer to RSS hash key.\n\n# Returns\n\nCalculated hash value."]
    #[link_name = "rte_softrss_be_w"]
    pub fn rte_softrss_be(input_tuple: *mut u32, input_len: u32, rss_key: *const u8) -> u32;
}
unsafe extern "C" {
    #[doc = "Indicates if GFNI implementations of the Toeplitz hash are supported.\n\n# Returns\n\n1 if GFNI is supported\n0 otherwise"]
    pub fn rte_thash_gfni_supported() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Converts Toeplitz hash key (RSS key) into matrixes required\nfor GFNI implementation\n\n# Arguments\n\n* `matrixes` -\npointer to the memory where matrices will be written.\nNote: the size of this memory must be equal to size * 8\n* `rss_key` -\npointer to the Toeplitz hash key\n* `size` -\nSize of the rss_key in bytes."]
    pub fn rte_thash_complete_matrix(
        matrixes: *mut u64,
        rss_key: *const u8,
        size: ::core::ffi::c_int,
    );
}
#[doc = "@internal thash context structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thash_ctx {
    _unused: [u8; 0],
}
#[doc = "@internal thash helper structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thash_subtuple_helper {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = "Create a new thash context.\n\n# Arguments\n\n* `name` -\nContext name\n* `key_len` -\nLength of the toeplitz hash key\n* `reta_sz` -\nLogarithm of the NIC's Redirection Table (ReTa) size,\ni.e. number of the LSBs if the hash used to determine\nthe reta entry.\n* `key` -\nPointer to the key used to init an internal key state.\nCould be NULL, in this case internal key will be inited with random.\n* `flags` -\nSupported flags are:\nRTE_THASH_IGNORE_PERIOD_OVERFLOW\nRTE_THASH_MINIMAL_SEQ\n\n# Returns\n\nA pointer to the created context on success\nNULL otherwise"]
    pub fn rte_thash_init_ctx(
        name: *const ::core::ffi::c_char,
        key_len: u32,
        reta_sz: u32,
        key: *mut u8,
        flags: u32,
    ) -> *mut rte_thash_ctx;
}
unsafe extern "C" {
    #[doc = "Find an existing thash context and return a pointer to it.\n\n# Arguments\n\n* `name` -\nName of the thash context\n\n# Returns\n\nPointer to the thash context or NULL if it was not found with rte_errno\nset appropriately. Possible rte_errno values include:\n- ENOENT - required entry not available to return."]
    pub fn rte_thash_find_existing(name: *const ::core::ffi::c_char) -> *mut rte_thash_ctx;
}
unsafe extern "C" {
    #[doc = "Free a thash context object\n\n# Arguments\n\n* `ctx` -\nThash context"]
    pub fn rte_thash_free_ctx(ctx: *mut rte_thash_ctx);
}
unsafe extern "C" {
    #[doc = "Add a special properties to the toeplitz hash key inside a thash context.\nCreates an internal helper struct which has a complementary table\nto calculate toeplitz hash collisions.\nThis function is not multi-thread safe.\n\n# Arguments\n\n* `ctx` -\nThash context\n* `name` -\nName of the helper\n* `len` -\nLength in bits of the target subtuple\nMust be no shorter than reta_sz passed on rte_thash_init_ctx().\n* `offset` -\nOffset in bits of the subtuple\n\n# Returns\n\n0 on success\nnegative on error"]
    pub fn rte_thash_add_helper(
        ctx: *mut rte_thash_ctx,
        name: *const ::core::ffi::c_char,
        len: u32,
        offset: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Find a helper in the context by the given name\n\n# Arguments\n\n* `ctx` -\nThash context\n* `name` -\nName of the helper\n\n# Returns\n\nPointer to the thash helper or NULL if it was not found."]
    pub fn rte_thash_get_helper(
        ctx: *mut rte_thash_ctx,
        name: *const ::core::ffi::c_char,
    ) -> *mut rte_thash_subtuple_helper;
}
unsafe extern "C" {
    #[doc = "Get a complementary value for the subtuple to produce a\npartial toeplitz hash collision. It must be XOR'ed with the\nsubtuple to produce the hash value with the desired hash LSB's\nThis function is multi-thread safe.\n\n# Arguments\n\n* `h` -\nPointer to the helper struct\n* `hash` -\nToeplitz hash value calculated for the given tuple\n* `desired_hash` -\nDesired hash value to find a collision for\n\n# Returns\n\nA complementary value which must be xored with the corresponding subtuple"]
    pub fn rte_thash_get_complement(
        h: *mut rte_thash_subtuple_helper,
        hash: u32,
        desired_hash: u32,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Get a pointer to the toeplitz hash contained in the context.\nIt changes after each addition of a helper. It should be installed to\nthe NIC.\n\n# Arguments\n\n* `ctx` -\nThash context\n\n# Returns\n\nA pointer to the toeplitz hash key"]
    pub fn rte_thash_get_key(ctx: *mut rte_thash_ctx) -> *const u8;
}
unsafe extern "C" {
    #[doc = "Get a pointer to the toeplitz hash matrices contained in the context.\nThese matrices could be used with fast toeplitz hash implementation if\nCPU supports GFNI.\nMatrices changes after each addition of a helper.\n\n# Arguments\n\n* `ctx` -\nThash context\n\n# Returns\n\nA pointer to the toeplitz hash key matrices on success\nNULL if GFNI is not supported."]
    pub fn rte_thash_get_gfni_matrices(ctx: *mut rte_thash_ctx) -> *const u64;
}
#[doc = "Function prototype for the rte_thash_adjust_tuple\nto check if adjusted tuple could be used.\nGenerally it is some kind of lookup function to check\nif adjusted tuple is already in use.\n\n# Arguments\n\n* `userdata` -\nPointer to the userdata. It could be a pointer to the\ntable with used tuples to search.\n* `tuple` -\nPointer to the tuple to check\n\n# Returns\n\n1 on success\n0 otherwise"]
pub type rte_thash_check_tuple_t = ::core::option::Option<
    unsafe extern "C" fn(userdata: *mut ::core::ffi::c_void, tuple: *mut u8) -> ::core::ffi::c_int,
>;
unsafe extern "C" {
    #[doc = "Adjusts tuple in the way to make Toeplitz hash has\ndesired least significant bits.\nThis function is multi-thread safe.\n\n# Arguments\n\n* `ctx` -\nThash context\n* `h` -\nPointer to the helper struct\n* `tuple` -\nPointer to the tuple to be adjusted\n* `tuple_len` -\nLength of the tuple. Must be multiple of 4.\n* `desired_value` -\nDesired value of least significant bits of the hash\n* `attempts` -\nNumber of attempts to adjust tuple with fn() calling\n* `fn` -\nCallback function to check adjusted tuple. Could be NULL\n* `userdata` -\nPointer to the userdata to be passed to fn(). Could be NULL\n\n# Returns\n\n0 on success\nnegative otherwise"]
    pub fn rte_thash_adjust_tuple(
        ctx: *mut rte_thash_ctx,
        h: *mut rte_thash_subtuple_helper,
        tuple: *mut u8,
        tuple_len: ::core::ffi::c_uint,
        desired_value: u32,
        attempts: ::core::ffi::c_uint,
        fn_: rte_thash_check_tuple_t,
        userdata: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "@warning **EXPERIMENTAL:** this API may change without prior notice.\nModify RSS hash key such that subtuple bits corresponding to `entropy_sz`\nbits starting from `entropy_start` will have the most even distribution with\nthis key with a given ReTa size.\n\n# Arguments\n\n* `key` -\nPointer to the RSS hash key.\n* `key_len` -\nLength of the key.\n* `reta_sz_log` -\nLog2 of the size of RSS redirection table,\ni.e. number of bits of the RSS hash value used to identify RSS ReTa entry.\n* `entropy_start` -\nBit offset from the beginning of the tuple\nwhere user expects best distribution of the subtuple values.\n* `entropy_sz` -\nSize in bits of the part of subtuple.\n\n# Returns\n\n0 on success negative otherwise"]
    pub fn rte_thash_gen_key(
        key: *mut u8,
        key_len: usize,
        reta_sz_log: usize,
        entropy_start: u32,
        entropy_sz: usize,
    ) -> ::core::ffi::c_int;
}
#[doc = "The rte_ticketlock_t type."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ticketlock_t {
    pub tickets: u32,
    pub s: rte_ticketlock_t__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_ticketlock_t__bindgen_ty_1 {
    pub current: u16,
    pub next: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ticketlock_t__bindgen_ty_1"]
        [::core::mem::size_of::<rte_ticketlock_t__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ticketlock_t__bindgen_ty_1"]
        [::core::mem::align_of::<rte_ticketlock_t__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_ticketlock_t__bindgen_ty_1::current"]
        [::core::mem::offset_of!(rte_ticketlock_t__bindgen_ty_1, current) - 0usize];
    ["Offset of field: rte_ticketlock_t__bindgen_ty_1::next"]
        [::core::mem::offset_of!(rte_ticketlock_t__bindgen_ty_1, next) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ticketlock_t"][::core::mem::size_of::<rte_ticketlock_t>() - 4usize];
    ["Alignment of rte_ticketlock_t"][::core::mem::align_of::<rte_ticketlock_t>() - 4usize];
    ["Offset of field: rte_ticketlock_t::tickets"]
        [::core::mem::offset_of!(rte_ticketlock_t, tickets) - 0usize];
    ["Offset of field: rte_ticketlock_t::s"][::core::mem::offset_of!(rte_ticketlock_t, s) - 0usize];
};
impl Default for rte_ticketlock_t {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Initialize the ticketlock to an unlocked state.\n\n# Arguments\n\n* `tl` -\nA pointer to the ticketlock."]
    #[link_name = "rte_ticketlock_init_w"]
    pub fn rte_ticketlock_init(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    #[doc = "Take the ticketlock.\n\n# Arguments\n\n* `tl` -\nA pointer to the ticketlock."]
    #[link_name = "rte_ticketlock_lock_w"]
    pub fn rte_ticketlock_lock(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    #[doc = "Release the ticketlock.\n\n# Arguments\n\n* `tl` -\nA pointer to the ticketlock."]
    #[link_name = "rte_ticketlock_unlock_w"]
    pub fn rte_ticketlock_unlock(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take the lock.\n\n# Arguments\n\n* `tl` -\nA pointer to the ticketlock.\n\n# Returns\n\n1 if the lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_ticketlock_trylock_w"]
    pub fn rte_ticketlock_trylock(tl: *mut rte_ticketlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the lock is taken.\n\n# Arguments\n\n* `tl` -\nA pointer to the ticketlock.\n\n# Returns\n\n1 if the lock is currently taken; 0 otherwise."]
    #[link_name = "rte_ticketlock_is_locked_w"]
    pub fn rte_ticketlock_is_locked(tl: *mut rte_ticketlock_t) -> ::core::ffi::c_int;
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ticketlock_recursive_t {
    #[doc = "< the actual ticketlock"]
    pub tl: rte_ticketlock_t,
    #[doc = "< core id using lock, TICKET_LOCK_INVALID_ID for unused"]
    pub user: ::core::ffi::c_int,
    #[doc = "< count of time this lock has been called"]
    pub count: ::core::ffi::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ticketlock_recursive_t"]
        [::core::mem::size_of::<rte_ticketlock_recursive_t>() - 12usize];
    ["Alignment of rte_ticketlock_recursive_t"]
        [::core::mem::align_of::<rte_ticketlock_recursive_t>() - 4usize];
    ["Offset of field: rte_ticketlock_recursive_t::tl"]
        [::core::mem::offset_of!(rte_ticketlock_recursive_t, tl) - 0usize];
    ["Offset of field: rte_ticketlock_recursive_t::user"]
        [::core::mem::offset_of!(rte_ticketlock_recursive_t, user) - 4usize];
    ["Offset of field: rte_ticketlock_recursive_t::count"]
        [::core::mem::offset_of!(rte_ticketlock_recursive_t, count) - 8usize];
};
impl Default for rte_ticketlock_recursive_t {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Initialize the recursive ticketlock to an unlocked state.\n\n# Arguments\n\n* `tlr` -\nA pointer to the recursive ticketlock."]
    #[link_name = "rte_ticketlock_recursive_init_w"]
    pub fn rte_ticketlock_recursive_init(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Take the recursive ticketlock.\n\n# Arguments\n\n* `tlr` -\nA pointer to the recursive ticketlock."]
    #[link_name = "rte_ticketlock_recursive_lock_w"]
    pub fn rte_ticketlock_recursive_lock(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Release the recursive ticketlock.\n\n# Arguments\n\n* `tlr` -\nA pointer to the recursive ticketlock."]
    #[link_name = "rte_ticketlock_recursive_unlock_w"]
    pub fn rte_ticketlock_recursive_unlock(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Try to take the recursive lock.\n\n# Arguments\n\n* `tlr` -\nA pointer to the recursive ticketlock.\n\n# Returns\n\n1 if the lock is successfully taken; 0 otherwise."]
    #[link_name = "rte_ticketlock_recursive_trylock_w"]
    pub fn rte_ticketlock_recursive_trylock(
        tlr: *mut rte_ticketlock_recursive_t,
    ) -> ::core::ffi::c_int;
}
#[doc = "Structure to hold the parameters of a running cycle counter to assist\nin converting cycles to nanoseconds."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_timecounter {
    #[doc = "Last cycle counter value read."]
    pub cycle_last: u64,
    #[doc = "Nanoseconds count."]
    pub nsec: u64,
    #[doc = "Bitmask separating nanosecond and sub-nanoseconds."]
    pub nsec_mask: u64,
    #[doc = "Sub-nanoseconds count."]
    pub nsec_frac: u64,
    #[doc = "Bitmask for two's complement subtraction of non-64 bit counters."]
    pub cc_mask: u64,
    #[doc = "Cycle to nanosecond divisor (power of two)."]
    pub cc_shift: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_timecounter"][::core::mem::size_of::<rte_timecounter>() - 48usize];
    ["Alignment of rte_timecounter"][::core::mem::align_of::<rte_timecounter>() - 8usize];
    ["Offset of field: rte_timecounter::cycle_last"]
        [::core::mem::offset_of!(rte_timecounter, cycle_last) - 0usize];
    ["Offset of field: rte_timecounter::nsec"]
        [::core::mem::offset_of!(rte_timecounter, nsec) - 8usize];
    ["Offset of field: rte_timecounter::nsec_mask"]
        [::core::mem::offset_of!(rte_timecounter, nsec_mask) - 16usize];
    ["Offset of field: rte_timecounter::nsec_frac"]
        [::core::mem::offset_of!(rte_timecounter, nsec_frac) - 24usize];
    ["Offset of field: rte_timecounter::cc_mask"]
        [::core::mem::offset_of!(rte_timecounter, cc_mask) - 32usize];
    ["Offset of field: rte_timecounter::cc_shift"]
        [::core::mem::offset_of!(rte_timecounter, cc_shift) - 40usize];
};
unsafe extern "C" {
    #[doc = "Converts cyclecounter cycles to nanoseconds."]
    #[link_name = "rte_cyclecounter_cycles_to_ns_w"]
    pub fn rte_cyclecounter_cycles_to_ns(tc: *mut rte_timecounter, cycles: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Update the internal nanosecond count in the structure."]
    #[link_name = "rte_timecounter_update_w"]
    pub fn rte_timecounter_update(tc: *mut rte_timecounter, cycle_now: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Convert from timespec structure into nanosecond units."]
    #[link_name = "rte_timespec_to_ns_w"]
    pub fn rte_timespec_to_ns(ts: *const timespec) -> u64;
}
unsafe extern "C" {
    #[doc = "Convert from nanosecond units into timespec structure."]
    #[link_name = "rte_ns_to_timespec_w"]
    pub fn rte_ns_to_timespec(nsec: u64) -> timespec;
}
#[doc = "TLS Header"]
#[repr(C, packed)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tls_hdr {
    #[doc = "Content type of TLS packet. Defined as RTE_TLS_TYPE_*."]
    pub type_: u8,
    #[doc = "TLS Version defined as RTE_TLS_VERSION*."]
    pub version: rte_be16_t,
    #[doc = "The length (in bytes) of the following TLS packet."]
    pub length: rte_be16_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tls_hdr"][::core::mem::size_of::<rte_tls_hdr>() - 5usize];
    ["Alignment of rte_tls_hdr"][::core::mem::align_of::<rte_tls_hdr>() - 1usize];
    ["Offset of field: rte_tls_hdr::type_"][::core::mem::offset_of!(rte_tls_hdr, type_) - 0usize];
    ["Offset of field: rte_tls_hdr::version"]
        [::core::mem::offset_of!(rte_tls_hdr, version) - 1usize];
    ["Offset of field: rte_tls_hdr::length"][::core::mem::offset_of!(rte_tls_hdr, length) - 3usize];
};
pub mod rte_tm_stats_type {
    #[doc = "Node statistics counter type"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Number of packets scheduled from current node."]
    pub const RTE_TM_STATS_N_PKTS: Type = 1;
    #[doc = "Number of bytes scheduled from current node."]
    pub const RTE_TM_STATS_N_BYTES: Type = 2;
    #[doc = "Number of green packets dropped by current leaf node."]
    pub const RTE_TM_STATS_N_PKTS_GREEN_DROPPED: Type = 4;
    #[doc = "Number of yellow packets dropped by current leaf node."]
    pub const RTE_TM_STATS_N_PKTS_YELLOW_DROPPED: Type = 8;
    #[doc = "Number of red packets dropped by current leaf node."]
    pub const RTE_TM_STATS_N_PKTS_RED_DROPPED: Type = 16;
    #[doc = "Number of green bytes dropped by current leaf node."]
    pub const RTE_TM_STATS_N_BYTES_GREEN_DROPPED: Type = 32;
    #[doc = "Number of yellow bytes dropped by current leaf node."]
    pub const RTE_TM_STATS_N_BYTES_YELLOW_DROPPED: Type = 64;
    #[doc = "Number of red bytes dropped by current leaf node."]
    pub const RTE_TM_STATS_N_BYTES_RED_DROPPED: Type = 128;
    #[doc = "Number of packets currently waiting in the packet queue of current\nleaf node."]
    pub const RTE_TM_STATS_N_PKTS_QUEUED: Type = 256;
    #[doc = "Number of bytes currently waiting in the packet queue of current\nleaf node."]
    pub const RTE_TM_STATS_N_BYTES_QUEUED: Type = 512;
}
#[doc = "Node statistics counters"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_node_stats {
    #[doc = "Number of packets scheduled from current node."]
    pub n_pkts: u64,
    #[doc = "Number of bytes scheduled from current node."]
    pub n_bytes: u64,
    pub leaf: rte_tm_node_stats__bindgen_ty_1,
}
#[doc = "Statistics counters for leaf nodes only."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_node_stats__bindgen_ty_1 {
    #[doc = "Number of packets dropped by current leaf node per each\ncolor."]
    pub n_pkts_dropped: [u64; 3usize],
    #[doc = "Number of bytes dropped by current leaf node per each\ncolor."]
    pub n_bytes_dropped: [u64; 3usize],
    #[doc = "Number of packets currently waiting in the packet queue of\ncurrent leaf node."]
    pub n_pkts_queued: u64,
    #[doc = "Number of bytes currently waiting in the packet queue of\ncurrent leaf node."]
    pub n_bytes_queued: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_stats__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_node_stats__bindgen_ty_1>() - 64usize];
    ["Alignment of rte_tm_node_stats__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_stats__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tm_node_stats__bindgen_ty_1::n_pkts_dropped"]
        [::core::mem::offset_of!(rte_tm_node_stats__bindgen_ty_1, n_pkts_dropped) - 0usize];
    ["Offset of field: rte_tm_node_stats__bindgen_ty_1::n_bytes_dropped"]
        [::core::mem::offset_of!(rte_tm_node_stats__bindgen_ty_1, n_bytes_dropped) - 24usize];
    ["Offset of field: rte_tm_node_stats__bindgen_ty_1::n_pkts_queued"]
        [::core::mem::offset_of!(rte_tm_node_stats__bindgen_ty_1, n_pkts_queued) - 48usize];
    ["Offset of field: rte_tm_node_stats__bindgen_ty_1::n_bytes_queued"]
        [::core::mem::offset_of!(rte_tm_node_stats__bindgen_ty_1, n_bytes_queued) - 56usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_stats"][::core::mem::size_of::<rte_tm_node_stats>() - 80usize];
    ["Alignment of rte_tm_node_stats"][::core::mem::align_of::<rte_tm_node_stats>() - 8usize];
    ["Offset of field: rte_tm_node_stats::n_pkts"]
        [::core::mem::offset_of!(rte_tm_node_stats, n_pkts) - 0usize];
    ["Offset of field: rte_tm_node_stats::n_bytes"]
        [::core::mem::offset_of!(rte_tm_node_stats, n_bytes) - 8usize];
    ["Offset of field: rte_tm_node_stats::leaf"]
        [::core::mem::offset_of!(rte_tm_node_stats, leaf) - 16usize];
};
pub mod rte_tm_dynamic_update_type {
    #[doc = "Traffic manager dynamic updates"]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "Dynamic parent node update. The new parent node is located on same\nhierarchy level as the former parent node. Consequently, the node\nwhose parent is changed preserves its hierarchy level."]
    pub const RTE_TM_UPDATE_NODE_PARENT_KEEP_LEVEL: Type = 1;
    #[doc = "Dynamic parent node update. The new parent node is located on\ndifferent hierarchy level than the former parent node. Consequently,\nthe node whose parent is changed also changes its hierarchy level."]
    pub const RTE_TM_UPDATE_NODE_PARENT_CHANGE_LEVEL: Type = 2;
    #[doc = "Dynamic node add/delete."]
    pub const RTE_TM_UPDATE_NODE_ADD_DELETE: Type = 4;
    #[doc = "Suspend/resume nodes."]
    pub const RTE_TM_UPDATE_NODE_SUSPEND_RESUME: Type = 8;
    #[doc = "Dynamic switch between byte-based and packet-based WFQ weights."]
    pub const RTE_TM_UPDATE_NODE_WFQ_WEIGHT_MODE: Type = 16;
    #[doc = "Dynamic update on number of SP priorities."]
    pub const RTE_TM_UPDATE_NODE_N_SP_PRIORITIES: Type = 32;
    #[doc = "Dynamic update of congestion management mode for leaf nodes."]
    pub const RTE_TM_UPDATE_NODE_CMAN: Type = 64;
    #[doc = "Dynamic update of the set of enabled stats counter types."]
    pub const RTE_TM_UPDATE_NODE_STATS: Type = 128;
}
#[doc = "Traffic manager capabilities"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_capabilities {
    #[doc = "Maximum number of nodes."]
    pub n_nodes_max: u32,
    #[doc = "Maximum number of levels (i.e. number of nodes connecting the root\nnode with any leaf node, including the root and the leaf)."]
    pub n_levels_max: u32,
    #[doc = "When non-zero, this flag indicates that all the non-leaf nodes\n(with the exception of the root node) have identical capability set."]
    pub non_leaf_nodes_identical: ::core::ffi::c_int,
    #[doc = "When non-zero, this flag indicates that all the leaf nodes have\nidentical capability set."]
    pub leaf_nodes_identical: ::core::ffi::c_int,
    #[doc = "Maximum number of shapers, either private or shared. In case the\nimplementation does not share any resources between private and\nshared shapers, it is typically equal to the sum of\n*shaper_private_n_max* and *shaper_shared_n_max*. The\nvalue of zero indicates that traffic shaping is not supported."]
    pub shaper_n_max: u32,
    #[doc = "Maximum number of private shapers. Indicates the maximum number of\nnodes that can concurrently have their private shaper enabled. The\nvalue of zero indicates that private shapers are not supported."]
    pub shaper_private_n_max: u32,
    #[doc = "Maximum number of private shapers that support dual rate shaping.\nIndicates the maximum number of nodes that can concurrently have\ntheir private shaper enabled with dual rate support. Only valid when\nprivate shapers are supported. The value of zero indicates that dual\nrate shaping is not available for private shapers. The maximum value\nis *shaper_private_n_max*."]
    pub shaper_private_dual_rate_n_max: ::core::ffi::c_int,
    #[doc = "Minimum committed/peak rate (bytes per second) for any private\nshaper. Valid only when private shapers are supported."]
    pub shaper_private_rate_min: u64,
    #[doc = "Maximum committed/peak rate (bytes per second) for any private\nshaper. Valid only when private shapers are supported."]
    pub shaper_private_rate_max: u64,
    #[doc = "Shaper private packet mode supported. When non-zero, this parameter\nindicates that there is at least one node that can be configured\nwith packet mode in its private shaper. When shaper is configured\nin packet mode, committed/peak rate provided is interpreted\nin packets per second."]
    pub shaper_private_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper private byte mode supported. When non-zero, this parameter\nindicates that there is at least one node that can be configured\nwith byte mode in its private shaper. When shaper is configured\nin byte mode, committed/peak rate provided is interpreted in\nbytes per second."]
    pub shaper_private_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared shapers. The value of zero indicates that\nshared shapers are not supported."]
    pub shaper_shared_n_max: u32,
    #[doc = "Maximum number of nodes that can share the same shared shaper.\nOnly valid when shared shapers are supported."]
    pub shaper_shared_n_nodes_per_shaper_max: u32,
    #[doc = "Maximum number of shared shapers a node can be part of. This\nparameter indicates that there is at least one node that can be\nconfigured with this many shared shapers, which might not be true for\nall the nodes. Only valid when shared shapers are supported, in which\ncase it ranges from 1 to *shaper_shared_n_max*."]
    pub shaper_shared_n_shapers_per_node_max: u32,
    #[doc = "Maximum number of shared shapers that can be configured with dual\nrate shaping. The value of zero indicates that dual rate shaping\nsupport is not available for shared shapers."]
    pub shaper_shared_dual_rate_n_max: u32,
    #[doc = "Minimum committed/peak rate (bytes per second) for any shared\nshaper. Only valid when shared shapers are supported."]
    pub shaper_shared_rate_min: u64,
    #[doc = "Maximum committed/peak rate (bytes per second) for any shared\nshaper. Only valid when shared shapers are supported."]
    pub shaper_shared_rate_max: u64,
    #[doc = "Shaper shared packet mode supported. When non-zero, this parameter\nindicates a shared shaper can be configured with packet mode.\nWhen shared shaper is configured in packet mode, committed/peak rate\nprovided is interpreted in packets per second."]
    pub shaper_shared_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper shared byte mode supported. When non-zero, this parameter\nindicates that a shared shaper can be configured with byte mode.\nWhen shared shaper is configured in byte mode, committed/peak rate\nprovided is interpreted in bytes per second."]
    pub shaper_shared_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Minimum value allowed for packet length adjustment for any private\nor shared shaper."]
    pub shaper_pkt_length_adjust_min: ::core::ffi::c_int,
    #[doc = "Maximum value allowed for packet length adjustment for any private\nor shared shaper."]
    pub shaper_pkt_length_adjust_max: ::core::ffi::c_int,
    #[doc = "Maximum number of children nodes. This parameter indicates that\nthere is at least one non-leaf node that can be configured with this\nmany children nodes, which might not be true for all the non-leaf\nnodes."]
    pub sched_n_children_max: u32,
    #[doc = "Maximum number of supported priority levels. This parameter\nindicates that there is at least one non-leaf node that can be\nconfigured with this many priority levels for managing its children\nnodes, which might not be true for all the non-leaf nodes. The value\nof zero is invalid. The value of 1 indicates that only priority 0 is\nsupported, which essentially means that Strict Priority (SP)\nalgorithm is not supported."]
    pub sched_sp_n_priorities_max: u32,
    #[doc = "Maximum number of sibling nodes that can have the same priority at\nany given time, i.e. maximum size of the WFQ sibling node group. This\nparameter indicates there is at least one non-leaf node that meets\nthis condition, which might not be true for all the non-leaf nodes.\nThe value of zero is invalid. The value of 1 indicates that WFQ\nalgorithm is not supported. The maximum value is\n*sched_n_children_max*."]
    pub sched_wfq_n_children_per_group_max: u32,
    #[doc = "Maximum number of priority levels that can have more than one child\nnode at any given time, i.e. maximum number of WFQ sibling node\ngroups that have two or more members. This parameter indicates there\nis at least one non-leaf node that meets this condition, which might\nnot be true for all the non-leaf nodes. The value of zero states that\nWFQ algorithm is not supported. The value of 1 indicates that\n(*sched_sp_n_priorities_max* - 1) priority levels have at most one\nchild node, so there can be only one priority level with two or\nmore sibling nodes making up a WFQ group. The maximum value is:\nmin(floor(*sched_n_children_max* / 2), *sched_sp_n_priorities_max*)."]
    pub sched_wfq_n_groups_max: u32,
    #[doc = "Maximum WFQ weight. The value of 1 indicates that all sibling nodes\nwith same priority have the same WFQ weight, so WFQ is reduced to FQ."]
    pub sched_wfq_weight_max: u32,
    #[doc = "WFQ packet mode supported. When non-zero, this parameter indicates\nthat there is at least one non-leaf node that supports packet mode\nfor WFQ among its children. WFQ weights will be applied against\npacket count for scheduling children when a non-leaf node\nis configured appropriately."]
    pub sched_wfq_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WFQ byte mode supported. When non-zero, this parameter indicates\nthat there is at least one non-leaf node that supports byte mode\nfor WFQ among its children. WFQ weights will be applied against\nbytes for scheduling children when a non-leaf node is configured\nappropriately."]
    pub sched_wfq_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "WRED packet mode support. When non-zero, this parameter indicates\nthat there is at least one leaf node that supports the WRED packet\nmode, which might not be true for all the leaf nodes. In packet\nmode, the WRED thresholds specify the queue length in packets, as\nopposed to bytes."]
    pub cman_wred_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WRED byte mode support. When non-zero, this parameter indicates that\nthere is at least one leaf node that supports the WRED byte mode,\nwhich might not be true for all the leaf nodes. In byte mode, the\nWRED thresholds specify the queue length in bytes, as opposed to\npackets."]
    pub cman_wred_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Head drop algorithm support. When non-zero, this parameter\nindicates that there is at least one leaf node that supports the head\ndrop algorithm, which might not be true for all the leaf nodes."]
    pub cman_head_drop_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of WRED contexts, either private or shared. In case\nthe implementation does not share any resources between private and\nshared WRED contexts, it is typically equal to the sum of\n*cman_wred_context_private_n_max* and\n*cman_wred_context_shared_n_max*. The value of zero indicates that\nWRED is not supported."]
    pub cman_wred_context_n_max: u32,
    #[doc = "Maximum number of private WRED contexts. Indicates the maximum\nnumber of leaf nodes that can concurrently have their private WRED\ncontext enabled. The value of zero indicates that private WRED\ncontexts are not supported."]
    pub cman_wred_context_private_n_max: u32,
    #[doc = "Maximum number of shared WRED contexts. The value of zero\nindicates that shared WRED contexts are not supported."]
    pub cman_wred_context_shared_n_max: u32,
    #[doc = "Maximum number of leaf nodes that can share the same WRED context.\nOnly valid when shared WRED contexts are supported."]
    pub cman_wred_context_shared_n_nodes_per_context_max: u32,
    #[doc = "Maximum number of shared WRED contexts a leaf node can be part of.\nThis parameter indicates that there is at least one leaf node that\ncan be configured with this many shared WRED contexts, which might\nnot be true for all the leaf nodes. Only valid when shared WRED\ncontexts are supported, in which case it ranges from 1 to\n*cman_wred_context_shared_n_max*."]
    pub cman_wred_context_shared_n_contexts_per_node_max: u32,
    #[doc = "Support for VLAN DEI packet marking (per color)."]
    pub mark_vlan_dei_supported: [::core::ffi::c_int; 3usize],
    #[doc = "Support for IPv4/IPv6 ECN marking of TCP packets (per color)."]
    pub mark_ip_ecn_tcp_supported: [::core::ffi::c_int; 3usize],
    #[doc = "Support for IPv4/IPv6 ECN marking of SCTP packets (per color)."]
    pub mark_ip_ecn_sctp_supported: [::core::ffi::c_int; 3usize],
    #[doc = "Support for IPv4/IPv6 DSCP packet marking (per color)."]
    pub mark_ip_dscp_supported: [::core::ffi::c_int; 3usize],
    #[doc = "Set of supported dynamic update operations.\n\n# See also\n\n> [`enum`] rte_tm_dynamic_update_type"]
    pub dynamic_update_mask: u64,
    #[doc = "Set of supported statistics counter types.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub stats_mask: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_capabilities"][::core::mem::size_of::<rte_tm_capabilities>() - 232usize];
    ["Alignment of rte_tm_capabilities"][::core::mem::align_of::<rte_tm_capabilities>() - 8usize];
    ["Offset of field: rte_tm_capabilities::n_nodes_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, n_nodes_max) - 0usize];
    ["Offset of field: rte_tm_capabilities::n_levels_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, n_levels_max) - 4usize];
    ["Offset of field: rte_tm_capabilities::non_leaf_nodes_identical"]
        [::core::mem::offset_of!(rte_tm_capabilities, non_leaf_nodes_identical) - 8usize];
    ["Offset of field: rte_tm_capabilities::leaf_nodes_identical"]
        [::core::mem::offset_of!(rte_tm_capabilities, leaf_nodes_identical) - 12usize];
    ["Offset of field: rte_tm_capabilities::shaper_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_n_max) - 16usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_private_n_max) - 20usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_dual_rate_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_private_dual_rate_n_max) - 24usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_rate_min"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_private_rate_min) - 32usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_rate_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_private_rate_max) - 40usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_packet_mode_supported"][::core::mem::offset_of!(
        rte_tm_capabilities,
        shaper_private_packet_mode_supported
    ) - 48usize];
    ["Offset of field: rte_tm_capabilities::shaper_private_byte_mode_supported"][::core::mem::offset_of!(
        rte_tm_capabilities,
        shaper_private_byte_mode_supported
    ) - 52usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_shared_n_max) - 56usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_n_nodes_per_shaper_max"][::core::mem::offset_of!(
        rte_tm_capabilities,
        shaper_shared_n_nodes_per_shaper_max
    ) - 60usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_n_shapers_per_node_max"][::core::mem::offset_of!(
        rte_tm_capabilities,
        shaper_shared_n_shapers_per_node_max
    ) - 64usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_dual_rate_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_shared_dual_rate_n_max) - 68usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_rate_min"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_shared_rate_min) - 72usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_rate_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_shared_rate_max) - 80usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_packet_mode_supported"][::core::mem::offset_of!(
        rte_tm_capabilities,
        shaper_shared_packet_mode_supported
    ) - 88usize];
    ["Offset of field: rte_tm_capabilities::shaper_shared_byte_mode_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_shared_byte_mode_supported) - 92usize];
    ["Offset of field: rte_tm_capabilities::shaper_pkt_length_adjust_min"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_pkt_length_adjust_min) - 96usize];
    ["Offset of field: rte_tm_capabilities::shaper_pkt_length_adjust_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, shaper_pkt_length_adjust_max) - 100usize];
    ["Offset of field: rte_tm_capabilities::sched_n_children_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_n_children_max) - 104usize];
    ["Offset of field: rte_tm_capabilities::sched_sp_n_priorities_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_sp_n_priorities_max) - 108usize];
    ["Offset of field: rte_tm_capabilities::sched_wfq_n_children_per_group_max"][::core::mem::offset_of!(
        rte_tm_capabilities,
        sched_wfq_n_children_per_group_max
    ) - 112usize];
    ["Offset of field: rte_tm_capabilities::sched_wfq_n_groups_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_wfq_n_groups_max) - 116usize];
    ["Offset of field: rte_tm_capabilities::sched_wfq_weight_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_wfq_weight_max) - 120usize];
    ["Offset of field: rte_tm_capabilities::sched_wfq_packet_mode_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_wfq_packet_mode_supported) - 124usize];
    ["Offset of field: rte_tm_capabilities::sched_wfq_byte_mode_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, sched_wfq_byte_mode_supported) - 128usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_packet_mode_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_wred_packet_mode_supported) - 132usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_byte_mode_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_wred_byte_mode_supported) - 136usize];
    ["Offset of field: rte_tm_capabilities::cman_head_drop_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_head_drop_supported) - 140usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_context_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_wred_context_n_max) - 144usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_context_private_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_wred_context_private_n_max) - 148usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_context_shared_n_max"]
        [::core::mem::offset_of!(rte_tm_capabilities, cman_wred_context_shared_n_max) - 152usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_context_shared_n_nodes_per_context_max"][::core::mem::offset_of!(
        rte_tm_capabilities,
        cman_wred_context_shared_n_nodes_per_context_max
    )
        - 156usize];
    ["Offset of field: rte_tm_capabilities::cman_wred_context_shared_n_contexts_per_node_max"][::core::mem::offset_of!(
        rte_tm_capabilities,
        cman_wred_context_shared_n_contexts_per_node_max
    )
        - 160usize];
    ["Offset of field: rte_tm_capabilities::mark_vlan_dei_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, mark_vlan_dei_supported) - 164usize];
    ["Offset of field: rte_tm_capabilities::mark_ip_ecn_tcp_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, mark_ip_ecn_tcp_supported) - 176usize];
    ["Offset of field: rte_tm_capabilities::mark_ip_ecn_sctp_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, mark_ip_ecn_sctp_supported) - 188usize];
    ["Offset of field: rte_tm_capabilities::mark_ip_dscp_supported"]
        [::core::mem::offset_of!(rte_tm_capabilities, mark_ip_dscp_supported) - 200usize];
    ["Offset of field: rte_tm_capabilities::dynamic_update_mask"]
        [::core::mem::offset_of!(rte_tm_capabilities, dynamic_update_mask) - 216usize];
    ["Offset of field: rte_tm_capabilities::stats_mask"]
        [::core::mem::offset_of!(rte_tm_capabilities, stats_mask) - 224usize];
};
#[doc = "Traffic manager level capabilities"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_tm_level_capabilities {
    #[doc = "Maximum number of nodes for the current hierarchy level."]
    pub n_nodes_max: u32,
    #[doc = "Maximum number of non-leaf nodes for the current hierarchy level.\nThe value of 0 indicates that current level only supports leaf\nnodes. The maximum value is *n_nodes_max*."]
    pub n_nodes_nonleaf_max: u32,
    #[doc = "Maximum number of leaf nodes for the current hierarchy level. The\nvalue of 0 indicates that current level only supports non-leaf\nnodes. The maximum value is *n_nodes_max*."]
    pub n_nodes_leaf_max: u32,
    #[doc = "When non-zero, this flag indicates that all the non-leaf nodes on\nthis level have identical capability set. Valid only when\n*n_nodes_nonleaf_max* is non-zero."]
    pub non_leaf_nodes_identical: ::core::ffi::c_int,
    #[doc = "When non-zero, this flag indicates that all the leaf nodes on this\nlevel have identical capability set. Valid only when\n*n_nodes_leaf_max* is non-zero."]
    pub leaf_nodes_identical: ::core::ffi::c_int,
    pub anon1: rte_tm_level_capabilities__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_tm_level_capabilities__bindgen_ty_1 {
    pub nonleaf: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
    pub leaf: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
}
#[doc = "Items valid only for the non-leaf nodes on this level."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "Private shaper support. When non-zero, it indicates\nthere is at least one non-leaf node on this level\nwith private shaper support, which may not be the\ncase for all the non-leaf nodes on this level."]
    pub shaper_private_supported: ::core::ffi::c_int,
    #[doc = "Dual rate support for private shaper. Valid only\nwhen private shaper is supported for the non-leaf\nnodes on the current level. When non-zero, it\nindicates there is at least one non-leaf node on this\nlevel with dual rate private shaper support, which\nmay not be the case for all the non-leaf nodes on\nthis level."]
    pub shaper_private_dual_rate_supported: ::core::ffi::c_int,
    #[doc = "Minimum committed/peak rate (bytes per second) for\nprivate shapers of the non-leaf nodes of this level.\nValid only when private shaper is supported on this\nlevel."]
    pub shaper_private_rate_min: u64,
    #[doc = "Maximum committed/peak rate (bytes per second) for\nprivate shapers of the non-leaf nodes on this level.\nValid only when private shaper is supported on this\nlevel."]
    pub shaper_private_rate_max: u64,
    #[doc = "Shaper private packet mode supported. When non-zero,\nthis parameter indicates there is at least one\nnon-leaf node at this level that can be configured\nwith packet mode in its private shaper. When private\nshaper is configured in packet mode, committed/peak\nrate provided is interpreted in packets per second."]
    pub shaper_private_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper private byte mode supported. When non-zero,\nthis parameter indicates there is at least one\nnon-leaf node at this level that can be configured\nwith byte mode in its private shaper. When private\nshaper is configured in byte mode, committed/peak\nrate provided is interpreted in bytes per second."]
    pub shaper_private_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared shapers that any non-leaf\nnode on this level can be part of. The value of zero\nindicates that shared shapers are not supported by\nthe non-leaf nodes on this level. When non-zero, it\nindicates there is at least one non-leaf node on this\nlevel that meets this condition, which may not be the\ncase for all the non-leaf nodes on this level."]
    pub shaper_shared_n_max: u32,
    #[doc = "Shaper shared packet mode supported. When non-zero,\nthis parameter indicates that there is at least one\nnon-leaf node on this level that can be part of\nshared shapers which work in packet mode."]
    pub shaper_shared_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper shared byte mode supported. When non-zero,\nthis parameter indicates that there is at least one\nnon-leaf node on this level that can be part of\nshared shapers which work in byte mode."]
    pub shaper_shared_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of children nodes. This parameter\nindicates that there is at least one non-leaf node on\nthis level that can be configured with this many\nchildren nodes, which might not be true for all the\nnon-leaf nodes on this level."]
    pub sched_n_children_max: u32,
    #[doc = "Maximum number of supported priority levels. This\nparameter indicates that there is at least one\nnon-leaf node on this level that can be configured\nwith this many priority levels for managing its\nchildren nodes, which might not be true for all the\nnon-leaf nodes on this level. The value of zero is\ninvalid. The value of 1 indicates that only priority\n0 is supported, which essentially means that Strict\nPriority (SP) algorithm is not supported on this\nlevel."]
    pub sched_sp_n_priorities_max: u32,
    #[doc = "Maximum number of sibling nodes that can have the\nsame priority at any given time, i.e. maximum size of\nthe WFQ sibling node group. This parameter indicates\nthere is at least one non-leaf node on this level\nthat meets this condition, which may not be true for\nall the non-leaf nodes on this level. The value of\nzero is invalid. The value of 1 indicates that WFQ\nalgorithm is not supported on this level. The maximum\nvalue is *sched_n_children_max*."]
    pub sched_wfq_n_children_per_group_max: u32,
    #[doc = "Maximum number of priority levels that can have\nmore than one child node at any given time, i.e.\nmaximum number of WFQ sibling node groups that\nhave two or more members. This parameter indicates\nthere is at least one non-leaf node on this level\nthat meets this condition, which might not be true\nfor all the non-leaf nodes. The value of zero states\nthat WFQ algorithm is not supported on this level.\nThe value of 1 indicates that\n(*sched_sp_n_priorities_max* - 1) priority levels on\nthis level have at most one child node, so there can\nbe only one priority level with two or more sibling\nnodes making up a WFQ group on this level. The\nmaximum value is:\nmin(floor(*sched_n_children_max* / 2),\n*sched_sp_n_priorities_max*)."]
    pub sched_wfq_n_groups_max: u32,
    #[doc = "Maximum WFQ weight. The value of 1 indicates that\nall sibling nodes on this level with same priority\nhave the same WFQ weight, so on this level WFQ is\nreduced to FQ."]
    pub sched_wfq_weight_max: u32,
    #[doc = "WFQ packet mode supported. When non-zero, this\nparameter indicates that there is at least one\nnon-leaf node at this level that supports packet\nmode for WFQ among its children. WFQ weights will\nbe applied against packet count for scheduling\nchildren when a non-leaf node is configured\nappropriately."]
    pub sched_wfq_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WFQ byte mode supported. When non-zero, this\nparameter indicates that there is at least one\nnon-leaf node at this level that supports byte\nmode for WFQ among its children. WFQ weights will\nbe applied against bytes for scheduling children\nwhen a non-leaf node is configured appropriately."]
    pub sched_wfq_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Mask of statistics counter types supported by the\nnon-leaf nodes on this level. Every supported\nstatistics counter type is supported by at least one\nnon-leaf node on this level, which may not be true\nfor all the non-leaf nodes on this level.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub stats_mask: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1>() - 80usize];
    ["Alignment of rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_supported
    ) - 0usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_dual_rate_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_dual_rate_supported
    ) - 4usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_rate_min",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_rate_min
    ) - 8usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_rate_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_rate_max
    ) - 16usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_packet_mode_supported
    ) - 24usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_private_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_private_byte_mode_supported
    ) - 28usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_shared_n_max"]
        [::core::mem::offset_of!(
            rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
            shaper_shared_n_max
        ) - 32usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_shared_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_shared_packet_mode_supported
    ) - 36usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::shaper_shared_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        shaper_shared_byte_mode_supported
    ) - 40usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_n_children_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_n_children_max
    ) - 44usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_sp_n_priorities_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_sp_n_priorities_max
    ) - 48usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_n_children_per_group_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_n_children_per_group_max
    ) - 52usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_n_groups_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_n_groups_max
    ) - 56usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_weight_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_weight_max
    ) - 60usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_packet_mode_supported
    ) - 64usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_byte_mode_supported
    ) - 68usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1::stats_mask"][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_1,
        stats_mask
    )
        - 72usize];
};
#[doc = "Items valid only for the leaf nodes on this level."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "Private shaper support. When non-zero, it indicates\nthere is at least one leaf node on this level with\nprivate shaper support, which may not be the case for\nall the leaf nodes on this level."]
    pub shaper_private_supported: ::core::ffi::c_int,
    #[doc = "Dual rate support for private shaper. Valid only\nwhen private shaper is supported for the leaf nodes\non this level. When non-zero, it indicates there is\nat least one leaf node on this level with dual rate\nprivate shaper support, which may not be the case for\nall the leaf nodes on this level."]
    pub shaper_private_dual_rate_supported: ::core::ffi::c_int,
    #[doc = "Minimum committed/peak rate (bytes per second) for\nprivate shapers of the leaf nodes of this level.\nValid only when private shaper is supported for the\nleaf nodes on this level."]
    pub shaper_private_rate_min: u64,
    #[doc = "Maximum committed/peak rate (bytes per second) for\nprivate shapers of the leaf nodes on this level.\nValid only when private shaper is supported for the\nleaf nodes on this level."]
    pub shaper_private_rate_max: u64,
    #[doc = "Shaper private packet mode supported. When non-zero,\nthis parameter indicates there is at least one leaf\nnode at this level that can be configured with\npacket mode in its private shaper. When private\nshaper is configured in packet mode, committed/peak\nrate provided is interpreted in packets per second."]
    pub shaper_private_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper private byte mode supported. When non-zero,\nthis parameter indicates there is at least one leaf\nnode at this level that can be configured with\nbyte mode in its private shaper. When private shaper\nis configured in byte mode, committed/peak rate\nprovided is interpreted in bytes per second."]
    pub shaper_private_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared shapers that any leaf node\non this level can be part of. The value of zero\nindicates that shared shapers are not supported by\nthe leaf nodes on this level. When non-zero, it\nindicates there is at least one leaf node on this\nlevel that meets this condition, which may not be the\ncase for all the leaf nodes on this level."]
    pub shaper_shared_n_max: u32,
    #[doc = "Shaper shared packet mode supported. When non-zero,\nthis parameter indicates that there is at least one\nleaf node on this level that can be part of\nshared shapers which work in packet mode."]
    pub shaper_shared_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper shared byte mode supported. When non-zero,\nthis parameter indicates that there is at least one\nleaf node on this level that can be part of\nshared shapers which work in byte mode."]
    pub shaper_shared_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "WRED packet mode support. When non-zero, this\nparameter indicates that there is at least one leaf\nnode on this level that supports the WRED packet\nmode, which might not be true for all the leaf\nnodes. In packet mode, the WRED thresholds specify\nthe queue length in packets, as opposed to bytes."]
    pub cman_wred_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WRED byte mode support. When non-zero, this\nparameter indicates that there is at least one leaf\nnode on this level that supports the WRED byte mode,\nwhich might not be true for all the leaf nodes. In\nbyte mode, the WRED thresholds specify the queue\nlength in bytes, as opposed to packets."]
    pub cman_wred_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Head drop algorithm support. When non-zero, this\nparameter indicates that there is at least one leaf\nnode on this level that supports the head drop\nalgorithm, which might not be true for all the leaf\nnodes on this level."]
    pub cman_head_drop_supported: ::core::ffi::c_int,
    #[doc = "Private WRED context support. When non-zero, it\nindicates there is at least one node on this level\nwith private WRED context support, which may not be\ntrue for all the leaf nodes on this level."]
    pub cman_wred_context_private_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared WRED contexts that any\nleaf node on this level can be part of. The value of\nzero indicates that shared WRED contexts are not\nsupported by the leaf nodes on this level. When\nnon-zero, it indicates there is at least one leaf\nnode on this level that meets this condition, which\nmay not be the case for all the leaf nodes on this\nlevel."]
    pub cman_wred_context_shared_n_max: u32,
    #[doc = "Mask of statistics counter types supported by the\nleaf nodes on this level. Every supported statistics\ncounter type is supported by at least one leaf node\non this level, which may not be true for all the leaf\nnodes on this level.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub stats_mask: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2>() - 72usize];
    ["Alignment of rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_supported
    ) - 0usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_dual_rate_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_dual_rate_supported
    ) - 4usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_rate_min",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_rate_min
    ) - 8usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_rate_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_rate_max
    ) - 16usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_packet_mode_supported
    ) - 24usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_private_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_private_byte_mode_supported
    ) - 28usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_shared_n_max"]
        [::core::mem::offset_of!(
            rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
            shaper_shared_n_max
        ) - 32usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_shared_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_shared_packet_mode_supported
    ) - 36usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::shaper_shared_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        shaper_shared_byte_mode_supported
    ) - 40usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_packet_mode_supported
    ) - 44usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_byte_mode_supported
    ) - 48usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::cman_head_drop_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_head_drop_supported
    ) - 52usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_context_private_supported",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_context_private_supported
    ) - 56usize];
    [
        "Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_context_shared_n_max",
    ][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_context_shared_n_max
    ) - 60usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2::stats_mask"][::core::mem::offset_of!(
        rte_tm_level_capabilities__bindgen_ty_1__bindgen_ty_2,
        stats_mask
    )
        - 64usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_level_capabilities__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_level_capabilities__bindgen_ty_1>() - 80usize];
    ["Alignment of rte_tm_level_capabilities__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_level_capabilities__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1::nonleaf"]
        [::core::mem::offset_of!(rte_tm_level_capabilities__bindgen_ty_1, nonleaf) - 0usize];
    ["Offset of field: rte_tm_level_capabilities__bindgen_ty_1::leaf"]
        [::core::mem::offset_of!(rte_tm_level_capabilities__bindgen_ty_1, leaf) - 0usize];
};
impl Default for rte_tm_level_capabilities__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_level_capabilities"]
        [::core::mem::size_of::<rte_tm_level_capabilities>() - 104usize];
    ["Alignment of rte_tm_level_capabilities"]
        [::core::mem::align_of::<rte_tm_level_capabilities>() - 8usize];
    ["Offset of field: rte_tm_level_capabilities::n_nodes_max"]
        [::core::mem::offset_of!(rte_tm_level_capabilities, n_nodes_max) - 0usize];
    ["Offset of field: rte_tm_level_capabilities::n_nodes_nonleaf_max"]
        [::core::mem::offset_of!(rte_tm_level_capabilities, n_nodes_nonleaf_max) - 4usize];
    ["Offset of field: rte_tm_level_capabilities::n_nodes_leaf_max"]
        [::core::mem::offset_of!(rte_tm_level_capabilities, n_nodes_leaf_max) - 8usize];
    ["Offset of field: rte_tm_level_capabilities::non_leaf_nodes_identical"]
        [::core::mem::offset_of!(rte_tm_level_capabilities, non_leaf_nodes_identical) - 12usize];
    ["Offset of field: rte_tm_level_capabilities::leaf_nodes_identical"]
        [::core::mem::offset_of!(rte_tm_level_capabilities, leaf_nodes_identical) - 16usize];
};
impl Default for rte_tm_level_capabilities {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Traffic manager node capabilities"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_tm_node_capabilities {
    #[doc = "Private shaper support for the current node."]
    pub shaper_private_supported: ::core::ffi::c_int,
    #[doc = "Dual rate shaping support for private shaper of current node.\nValid only when private shaper is supported by the current node."]
    pub shaper_private_dual_rate_supported: ::core::ffi::c_int,
    #[doc = "Minimum committed/peak rate (bytes per second) for private\nshaper of current node. Valid only when private shaper is supported\nby the current node."]
    pub shaper_private_rate_min: u64,
    #[doc = "Maximum committed/peak rate (bytes per second) for private\nshaper of current node. Valid only when private shaper is supported\nby the current node."]
    pub shaper_private_rate_max: u64,
    #[doc = "Shaper private packet mode supported. When non-zero, this parameter\nindicates private shaper of current node can be configured with\npacket mode. When configured in packet mode, committed/peak rate\nprovided is interpreted in packets per second."]
    pub shaper_private_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper private byte mode supported. When non-zero, this parameter\nindicates private shaper of current node can be configured with\nbyte mode. When configured in byte mode, committed/peak rate\nprovided is interpreted in bytes per second."]
    pub shaper_private_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared shapers the current node can be part of.\nThe value of zero indicates that shared shapers are not supported by\nthe current node."]
    pub shaper_shared_n_max: u32,
    #[doc = "Shaper shared packet mode supported. When non-zero,\nthis parameter indicates that current node can be part of\nshared shapers which work in packet mode."]
    pub shaper_shared_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "Shaper shared byte mode supported. When non-zero,\nthis parameter indicates that current node can be part of\nshared shapers which work in byte mode."]
    pub shaper_shared_byte_mode_supported: ::core::ffi::c_int,
    pub anon1: rte_tm_node_capabilities__bindgen_ty_1,
    #[doc = "Mask of statistics counter types supported by the current node.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub stats_mask: u64,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_tm_node_capabilities__bindgen_ty_1 {
    pub nonleaf: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
    pub leaf: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
}
#[doc = "Items valid only for non-leaf nodes."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "Maximum number of children nodes."]
    pub sched_n_children_max: u32,
    #[doc = "Maximum number of supported priority levels. The\nvalue of zero is invalid. The value of 1 indicates\nthat only priority 0 is supported, which essentially\nmeans that Strict Priority (SP) algorithm is not\nsupported."]
    pub sched_sp_n_priorities_max: u32,
    #[doc = "Maximum number of sibling nodes that can have the\nsame priority at any given time, i.e. maximum size\nof the WFQ sibling node group. The value of zero\nis invalid. The value of 1 indicates that WFQ\nalgorithm is not supported. The maximum value is\n*sched_n_children_max*."]
    pub sched_wfq_n_children_per_group_max: u32,
    #[doc = "Maximum number of priority levels that can have\nmore than one child node at any given time, i.e.\nmaximum number of WFQ sibling node groups that have\ntwo or more members. The value of zero states that\nWFQ algorithm is not supported. The value of 1\nindicates that (*sched_sp_n_priorities_max* - 1)\npriority levels have at most one child node, so there\ncan be only one priority level with two or more\nsibling nodes making up a WFQ group. The maximum\nvalue is: min(floor(*sched_n_children_max* / 2),\n*sched_sp_n_priorities_max*)."]
    pub sched_wfq_n_groups_max: u32,
    #[doc = "Maximum WFQ weight. The value of 1 indicates that\nall sibling nodes with same priority have the same\nWFQ weight, so WFQ is reduced to FQ."]
    pub sched_wfq_weight_max: u32,
    #[doc = "WFQ packet mode supported. When non-zero, this\nparameter indicates that current node supports packet\nmode for WFQ among its children. WFQ weights will be\napplied against packet count for scheduling children\nwhen configured appropriately."]
    pub sched_wfq_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WFQ byte mode supported. When non-zero, this\nparameter indicates that current node supports byte\nmode for WFQ among its children. WFQ weights will be\napplied against  bytes for scheduling children when\nconfigured appropriately."]
    pub sched_wfq_byte_mode_supported: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1>() - 28usize];
    ["Alignment of rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_n_children_max"]
        [::core::mem::offset_of!(
            rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
            sched_n_children_max
        ) - 0usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_sp_n_priorities_max",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_sp_n_priorities_max
    ) - 4usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_n_children_per_group_max",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_n_children_per_group_max
    ) - 8usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_n_groups_max",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_n_groups_max
    ) - 12usize];
    ["Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_weight_max"]
        [::core::mem::offset_of!(
            rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
            sched_wfq_weight_max
        ) - 16usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_packet_mode_supported
    ) - 20usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1::sched_wfq_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_1,
        sched_wfq_byte_mode_supported
    ) - 24usize];
};
#[doc = "Items valid only for leaf nodes."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "WRED packet mode support for current node."]
    pub cman_wred_packet_mode_supported: ::core::ffi::c_int,
    #[doc = "WRED byte mode support for current node."]
    pub cman_wred_byte_mode_supported: ::core::ffi::c_int,
    #[doc = "Head drop algorithm support for current node."]
    pub cman_head_drop_supported: ::core::ffi::c_int,
    #[doc = "Private WRED context support for current node."]
    pub cman_wred_context_private_supported: ::core::ffi::c_int,
    #[doc = "Maximum number of shared WRED contexts the current\nnode can be part of. The value of zero indicates that\nshared WRED contexts are not supported by the current\nnode."]
    pub cman_wred_context_shared_n_max: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2>() - 20usize];
    ["Alignment of rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2>() - 4usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_packet_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_packet_mode_supported
    ) - 0usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_byte_mode_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_byte_mode_supported
    ) - 4usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2::cman_head_drop_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_head_drop_supported
    ) - 8usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_context_private_supported",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_context_private_supported
    ) - 12usize];
    [
        "Offset of field: rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2::cman_wred_context_shared_n_max",
    ][::core::mem::offset_of!(
        rte_tm_node_capabilities__bindgen_ty_1__bindgen_ty_2,
        cman_wred_context_shared_n_max
    ) - 16usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_capabilities__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_node_capabilities__bindgen_ty_1>() - 28usize];
    ["Alignment of rte_tm_node_capabilities__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_capabilities__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_tm_node_capabilities__bindgen_ty_1::nonleaf"]
        [::core::mem::offset_of!(rte_tm_node_capabilities__bindgen_ty_1, nonleaf) - 0usize];
    ["Offset of field: rte_tm_node_capabilities__bindgen_ty_1::leaf"]
        [::core::mem::offset_of!(rte_tm_node_capabilities__bindgen_ty_1, leaf) - 0usize];
};
impl Default for rte_tm_node_capabilities__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_capabilities"]
        [::core::mem::size_of::<rte_tm_node_capabilities>() - 80usize];
    ["Alignment of rte_tm_node_capabilities"]
        [::core::mem::align_of::<rte_tm_node_capabilities>() - 8usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_supported"]
        [::core::mem::offset_of!(rte_tm_node_capabilities, shaper_private_supported) - 0usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_dual_rate_supported"][::core::mem::offset_of!(
        rte_tm_node_capabilities,
        shaper_private_dual_rate_supported
    ) - 4usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_rate_min"]
        [::core::mem::offset_of!(rte_tm_node_capabilities, shaper_private_rate_min) - 8usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_rate_max"]
        [::core::mem::offset_of!(rte_tm_node_capabilities, shaper_private_rate_max) - 16usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_packet_mode_supported"][::core::mem::offset_of!(
        rte_tm_node_capabilities,
        shaper_private_packet_mode_supported
    )
        - 24usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_private_byte_mode_supported"][::core::mem::offset_of!(
        rte_tm_node_capabilities,
        shaper_private_byte_mode_supported
    ) - 28usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_shared_n_max"]
        [::core::mem::offset_of!(rte_tm_node_capabilities, shaper_shared_n_max) - 32usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_shared_packet_mode_supported"][::core::mem::offset_of!(
        rte_tm_node_capabilities,
        shaper_shared_packet_mode_supported
    ) - 36usize];
    ["Offset of field: rte_tm_node_capabilities::shaper_shared_byte_mode_supported"][::core::mem::offset_of!(
        rte_tm_node_capabilities,
        shaper_shared_byte_mode_supported
    ) - 40usize];
    ["Offset of field: rte_tm_node_capabilities::stats_mask"]
        [::core::mem::offset_of!(rte_tm_node_capabilities, stats_mask) - 72usize];
};
impl Default for rte_tm_node_capabilities {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_tm_cman_mode {
    #[doc = "Congestion management (CMAN) mode\nThis is used for controlling the admission of packets into a packet queue or\ngroup of packet queues on congestion. On request of writing a new packet\ninto the current queue while the queue is full, the *tail drop* algorithm\ndrops the new packet while leaving the queue unmodified, as opposed to *head\ndrop* algorithm, which drops the packet at the head of the queue (the oldest\npacket waiting in the queue) and admits the new packet at the tail of the\nqueue.\nThe *Random Early Detection (RED)* algorithm works by proactively dropping\nmore and more input packets as the queue occupancy builds up. When the queue\nis full or almost full, RED effectively works as *tail drop*. The *Weighted\nRED* algorithm uses a separate set of RED thresholds for each packet color."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< Tail drop"]
    pub const RTE_TM_CMAN_TAIL_DROP: Type = 0;
    #[doc = "< Head drop"]
    pub const RTE_TM_CMAN_HEAD_DROP: Type = 1;
    #[doc = "< Weighted Random Early Detection (WRED)"]
    pub const RTE_TM_CMAN_WRED: Type = 2;
}
#[doc = "Random Early Detection (RED) profile"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_red_params {
    #[doc = "Minimum queue threshold"]
    pub min_th: u64,
    #[doc = "Maximum queue threshold"]
    pub max_th: u64,
    #[doc = "Inverse of packet marking probability maximum value (maxp), i.e.\nmaxp_inv = 1 / maxp"]
    pub maxp_inv: u16,
    #[doc = "Negated log2 of queue weight (wq), i.e. wq = 1 / (2 ^ wq_log2)"]
    pub wq_log2: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_red_params"][::core::mem::size_of::<rte_tm_red_params>() - 24usize];
    ["Alignment of rte_tm_red_params"][::core::mem::align_of::<rte_tm_red_params>() - 8usize];
    ["Offset of field: rte_tm_red_params::min_th"]
        [::core::mem::offset_of!(rte_tm_red_params, min_th) - 0usize];
    ["Offset of field: rte_tm_red_params::max_th"]
        [::core::mem::offset_of!(rte_tm_red_params, max_th) - 8usize];
    ["Offset of field: rte_tm_red_params::maxp_inv"]
        [::core::mem::offset_of!(rte_tm_red_params, maxp_inv) - 16usize];
    ["Offset of field: rte_tm_red_params::wq_log2"]
        [::core::mem::offset_of!(rte_tm_red_params, wq_log2) - 18usize];
};
#[doc = "Weighted RED (WRED) profile\nMultiple WRED contexts can share the same WRED profile. Each leaf node with\nWRED enabled as its congestion management mode has zero or one private WRED\ncontext (only one leaf node using it) and/or zero, one or several shared\nWRED contexts (multiple leaf nodes use the same WRED context). A private\nWRED context is used to perform congestion management for a single leaf\nnode, while a shared WRED context is used to perform congestion management\nfor a group of leaf nodes.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_packet_mode_supported\n> [`struct`] rte_tm_capabilities::cman_wred_byte_mode_supported"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_wred_params {
    #[doc = "One set of RED parameters per packet color"]
    pub red_params: [rte_tm_red_params; 3usize],
    #[doc = "When non-zero, the *min_th* and *max_th* thresholds are specified\nin packets (WRED packet mode). When zero, the *min_th* and *max_th*\nthresholds are specified in bytes (WRED byte mode)"]
    pub packet_mode: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_wred_params"][::core::mem::size_of::<rte_tm_wred_params>() - 80usize];
    ["Alignment of rte_tm_wred_params"][::core::mem::align_of::<rte_tm_wred_params>() - 8usize];
    ["Offset of field: rte_tm_wred_params::red_params"]
        [::core::mem::offset_of!(rte_tm_wred_params, red_params) - 0usize];
    ["Offset of field: rte_tm_wred_params::packet_mode"]
        [::core::mem::offset_of!(rte_tm_wred_params, packet_mode) - 72usize];
};
#[doc = "Token bucket"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_token_bucket {
    #[doc = "Token bucket rate (bytes per second or packets per second)"]
    pub rate: u64,
    #[doc = "Token bucket size (bytes or packets), a.k.a. max burst size"]
    pub size: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_token_bucket"][::core::mem::size_of::<rte_tm_token_bucket>() - 16usize];
    ["Alignment of rte_tm_token_bucket"][::core::mem::align_of::<rte_tm_token_bucket>() - 8usize];
    ["Offset of field: rte_tm_token_bucket::rate"]
        [::core::mem::offset_of!(rte_tm_token_bucket, rate) - 0usize];
    ["Offset of field: rte_tm_token_bucket::size"]
        [::core::mem::offset_of!(rte_tm_token_bucket, size) - 8usize];
};
#[doc = "Shaper (rate limiter) profile\nMultiple shaper instances can share the same shaper profile. Each node has\nzero or one private shaper (only one node using it) and/or zero, one or\nseveral shared shapers (multiple nodes use the same shaper instance).\nA private shaper is used to perform traffic shaping for a single node, while\na shared shaper is used to perform traffic shaping for a group of nodes.\nSingle rate shapers use a single token bucket. A single rate shaper can be\nconfigured by setting the rate of the committed bucket to zero, which\neffectively disables this bucket. The peak bucket is used to limit the rate\nand the burst size for the current shaper.\nDual rate shapers use both the committed and the peak token buckets. The\nrate of the peak bucket has to be bigger than zero, as well as greater than\nor equal to the rate of the committed bucket.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_private_packet_mode_supported\n> [`struct`] rte_tm_capabilities::shaper_private_byte_mode_supported\n> [`struct`] rte_tm_capabilities::shaper_shared_packet_mode_supported\n> [`struct`] rte_tm_capabilities::shaper_shared_byte_mode_supported"]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_tm_shaper_params {
    #[doc = "Committed token bucket"]
    pub committed: rte_tm_token_bucket,
    #[doc = "Peak token bucket"]
    pub peak: rte_tm_token_bucket,
    #[doc = "Signed value to be added to the length of each packet for the\npurpose of shaping. Can be used to correct the packet length with\nthe framing overhead bytes that are also consumed on the wire (e.g.\nRTE_TM_ETH_FRAMING_OVERHEAD_FCS).\nThis field is ignored when the profile enables packet mode."]
    pub pkt_length_adjust: i32,
    #[doc = "When zero, the byte mode is enabled for the current profile, so the\n*rate* and *size* fields in both the committed and peak token buckets\nare specified in bytes per second and bytes, respectively.\nWhen non-zero, the packet mode is enabled for the current profile,\nso the *rate* and *size* fields in both the committed and peak token\nbuckets are specified in packets per second and packets,\nrespectively."]
    pub packet_mode: ::core::ffi::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_shaper_params"][::core::mem::size_of::<rte_tm_shaper_params>() - 40usize];
    ["Alignment of rte_tm_shaper_params"][::core::mem::align_of::<rte_tm_shaper_params>() - 8usize];
    ["Offset of field: rte_tm_shaper_params::committed"]
        [::core::mem::offset_of!(rte_tm_shaper_params, committed) - 0usize];
    ["Offset of field: rte_tm_shaper_params::peak"]
        [::core::mem::offset_of!(rte_tm_shaper_params, peak) - 16usize];
    ["Offset of field: rte_tm_shaper_params::pkt_length_adjust"]
        [::core::mem::offset_of!(rte_tm_shaper_params, pkt_length_adjust) - 32usize];
    ["Offset of field: rte_tm_shaper_params::packet_mode"]
        [::core::mem::offset_of!(rte_tm_shaper_params, packet_mode) - 36usize];
};
#[doc = "Node parameters\nEach non-leaf node has multiple inputs (its children nodes) and single output\n(which is input to its parent node). It arbitrates its inputs using Strict\nPriority (SP) and Weighted Fair Queuing (WFQ) algorithms to schedule input\npackets to its output while observing its shaping (rate limiting)\nconstraints.\nAlgorithms such as Weighted Round Robin (WRR), Byte-level WRR, Deficit WRR\n(DWRR), etc. are considered approximations of the WFQ ideal and are\nassimilated to WFQ, although an associated implementation-dependent trade-off\non accuracy, performance and resource usage might exist.\nChildren nodes with different priorities are scheduled using the SP algorithm\nbased on their priority, with zero (0) as the highest priority. Children with\nthe same priority are scheduled using the WFQ algorithm according to their\nweights. The WFQ weight of a given child node is relative to the sum of the\nweights of all its sibling nodes that have the same priority, with one (1) as\nthe lowest weight. For each SP priority, the WFQ weight mode can be set as\neither byte-based or packet-based.\nEach leaf node sits on top of a Tx queue of the current Ethernet port. Hence,\nthe leaf nodes are predefined, with their node IDs set to 0 .. (N-1), where N\nis the number of Tx queues configured for the current Ethernet port. The\nnon-leaf nodes have their IDs generated by the application."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_tm_node_params {
    #[doc = "Shaper profile for the private shaper. The absence of the private\nshaper for the current node is indicated by setting this parameter\nto RTE_TM_SHAPER_PROFILE_ID_NONE."]
    pub shaper_profile_id: u32,
    #[doc = "User allocated array of valid shared shaper IDs."]
    pub shared_shaper_id: *mut u32,
    #[doc = "Number of shared shaper IDs in the *shared_shaper_id* array."]
    pub n_shared_shapers: u32,
    pub anon1: rte_tm_node_params__bindgen_ty_1,
    #[doc = "Mask of statistics counter types to be enabled for this node. This\nneeds to be a subset of the statistics counter types available for\nthe current node. Any statistics counter type not included in this\nset is to be disabled for the current node.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub stats_mask: u64,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_tm_node_params__bindgen_ty_1 {
    pub nonleaf: rte_tm_node_params__bindgen_ty_1__bindgen_ty_1,
    pub leaf: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2,
}
#[doc = "Parameters only valid for non-leaf nodes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tm_node_params__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "WFQ weight mode for each SP priority. When NULL, it\nindicates that WFQ is to be used for all priorities.\nWhen non-NULL, it points to a pre-allocated array of\n*n_sp_priorities* values, with non-zero value for\nbyte-mode and zero for packet-mode.\n\n# See also\n\n> [`struct`] rte_tm_node_capabilities::sched_wfq_packet_mode_supported\n> [`struct`] rte_tm_node_capabilities::sched_wfq_byte_mode_supported"]
    pub wfq_weight_mode: *mut ::core::ffi::c_int,
    #[doc = "Number of SP priorities."]
    pub n_sp_priorities: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_params__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_node_params__bindgen_ty_1__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_tm_node_params__bindgen_ty_1__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_params__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_1::wfq_weight_mode"][::core::mem::offset_of!(
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_1,
        wfq_weight_mode
    )
        - 0usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_1::n_sp_priorities"][::core::mem::offset_of!(
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_1,
        n_sp_priorities
    )
        - 8usize];
};
impl Default for rte_tm_node_params__bindgen_ty_1__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "Parameters only valid for leaf nodes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tm_node_params__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "Congestion management mode"]
    pub cman: rte_tm_cman_mode::Type,
    pub wred: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
}
#[doc = "WRED parameters (only valid when *cman* is set to\nWRED)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    #[doc = "WRED profile for private WRED context. The\nabsence of a private WRED context for the\ncurrent leaf node is indicated by value\nRTE_TM_WRED_PROFILE_ID_NONE."]
    pub wred_profile_id: u32,
    #[doc = "User allocated array of shared WRED context\nIDs. When set to NULL, it indicates that the\ncurrent leaf node should not currently be\npart of any shared WRED contexts."]
    pub shared_wred_context_id: *mut u32,
    #[doc = "Number of elements in the\n*shared_wred_context_id* array. Only valid\nwhen *shared_wred_context_id* is non-NULL,\nin which case it should be non-zero."]
    pub n_shared_wred_contexts: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"][::core::mem::size_of::<
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
    >() - 24usize];
    ["Alignment of rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1>()
            - 8usize];
    [
        "Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::wred_profile_id",
    ][::core::mem::offset_of!(
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        wred_profile_id
    ) - 0usize];
    [
        "Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::shared_wred_context_id",
    ][::core::mem::offset_of!(
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        shared_wred_context_id
    ) - 8usize];
    [
        "Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::n_shared_wred_contexts",
    ][::core::mem::offset_of!(
        rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        n_shared_wred_contexts
    ) - 16usize];
};
impl Default for rte_tm_node_params__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_params__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::size_of::<rte_tm_node_params__bindgen_ty_1__bindgen_ty_2>() - 32usize];
    ["Alignment of rte_tm_node_params__bindgen_ty_1__bindgen_ty_2"]
        [::core::mem::align_of::<rte_tm_node_params__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2::cman"]
        [::core::mem::offset_of!(rte_tm_node_params__bindgen_ty_1__bindgen_ty_2, cman) - 0usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1__bindgen_ty_2::wred"]
        [::core::mem::offset_of!(rte_tm_node_params__bindgen_ty_1__bindgen_ty_2, wred) - 8usize];
};
impl Default for rte_tm_node_params__bindgen_ty_1__bindgen_ty_2 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_params__bindgen_ty_1"]
        [::core::mem::size_of::<rte_tm_node_params__bindgen_ty_1>() - 32usize];
    ["Alignment of rte_tm_node_params__bindgen_ty_1"]
        [::core::mem::align_of::<rte_tm_node_params__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1::nonleaf"]
        [::core::mem::offset_of!(rte_tm_node_params__bindgen_ty_1, nonleaf) - 0usize];
    ["Offset of field: rte_tm_node_params__bindgen_ty_1::leaf"]
        [::core::mem::offset_of!(rte_tm_node_params__bindgen_ty_1, leaf) - 0usize];
};
impl Default for rte_tm_node_params__bindgen_ty_1 {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_node_params"][::core::mem::size_of::<rte_tm_node_params>() - 64usize];
    ["Alignment of rte_tm_node_params"][::core::mem::align_of::<rte_tm_node_params>() - 8usize];
    ["Offset of field: rte_tm_node_params::shaper_profile_id"]
        [::core::mem::offset_of!(rte_tm_node_params, shaper_profile_id) - 0usize];
    ["Offset of field: rte_tm_node_params::shared_shaper_id"]
        [::core::mem::offset_of!(rte_tm_node_params, shared_shaper_id) - 8usize];
    ["Offset of field: rte_tm_node_params::n_shared_shapers"]
        [::core::mem::offset_of!(rte_tm_node_params, n_shared_shapers) - 16usize];
    ["Offset of field: rte_tm_node_params::stats_mask"]
        [::core::mem::offset_of!(rte_tm_node_params, stats_mask) - 56usize];
};
impl Default for rte_tm_node_params {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
pub mod rte_tm_error_type {
    #[doc = "Verbose error types.\nMost of them provide the type of the object referenced by struct\nrte_tm_error::cause."]
    pub type Type = ::core::ffi::c_uint;
    #[doc = "< No error."]
    pub const RTE_TM_ERROR_TYPE_NONE: Type = 0;
    #[doc = "< Cause unspecified."]
    pub const RTE_TM_ERROR_TYPE_UNSPECIFIED: Type = 1;
    pub const RTE_TM_ERROR_TYPE_CAPABILITIES: Type = 2;
    pub const RTE_TM_ERROR_TYPE_LEVEL_ID: Type = 3;
    pub const RTE_TM_ERROR_TYPE_WRED_PROFILE: Type = 4;
    pub const RTE_TM_ERROR_TYPE_WRED_PROFILE_GREEN: Type = 5;
    pub const RTE_TM_ERROR_TYPE_WRED_PROFILE_YELLOW: Type = 6;
    pub const RTE_TM_ERROR_TYPE_WRED_PROFILE_RED: Type = 7;
    pub const RTE_TM_ERROR_TYPE_WRED_PROFILE_ID: Type = 8;
    pub const RTE_TM_ERROR_TYPE_SHARED_WRED_CONTEXT_ID: Type = 9;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE: Type = 10;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_COMMITTED_RATE: Type = 11;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_COMMITTED_SIZE: Type = 12;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_PEAK_RATE: Type = 13;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_PEAK_SIZE: Type = 14;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_PKT_ADJUST_LEN: Type = 15;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_PACKET_MODE: Type = 16;
    pub const RTE_TM_ERROR_TYPE_SHAPER_PROFILE_ID: Type = 17;
    pub const RTE_TM_ERROR_TYPE_SHARED_SHAPER_ID: Type = 18;
    pub const RTE_TM_ERROR_TYPE_NODE_PARENT_NODE_ID: Type = 19;
    pub const RTE_TM_ERROR_TYPE_NODE_PRIORITY: Type = 20;
    pub const RTE_TM_ERROR_TYPE_NODE_WEIGHT: Type = 21;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS: Type = 22;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_SHAPER_PROFILE_ID: Type = 23;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_SHARED_SHAPER_ID: Type = 24;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_N_SHARED_SHAPERS: Type = 25;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_WFQ_WEIGHT_MODE: Type = 26;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_N_SP_PRIORITIES: Type = 27;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_CMAN: Type = 28;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_WRED_PROFILE_ID: Type = 29;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_SHARED_WRED_CONTEXT_ID: Type = 30;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_N_SHARED_WRED_CONTEXTS: Type = 31;
    pub const RTE_TM_ERROR_TYPE_NODE_PARAMS_STATS: Type = 32;
    pub const RTE_TM_ERROR_TYPE_NODE_ID: Type = 33;
}
#[doc = "Verbose error structure definition.\nThis object is normally allocated by applications and set by PMDs, the\nmessage points to a constant string which does not need to be freed by\nthe application, however its pointer can be considered valid only as long\nas its associated DPDK port remains configured. Closing the underlying\ndevice or unloading the PMD invalidates it.\nBoth cause and message may be NULL regardless of the error type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_tm_error {
    #[doc = "< Cause field and error type."]
    pub type_: rte_tm_error_type::Type,
    #[doc = "< Object responsible for the error."]
    pub cause: *const ::core::ffi::c_void,
    #[doc = "< Human-readable error message."]
    pub message: *const ::core::ffi::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_tm_error"][::core::mem::size_of::<rte_tm_error>() - 24usize];
    ["Alignment of rte_tm_error"][::core::mem::align_of::<rte_tm_error>() - 8usize];
    ["Offset of field: rte_tm_error::type_"][::core::mem::offset_of!(rte_tm_error, type_) - 0usize];
    ["Offset of field: rte_tm_error::cause"][::core::mem::offset_of!(rte_tm_error, cause) - 8usize];
    ["Offset of field: rte_tm_error::message"]
        [::core::mem::offset_of!(rte_tm_error, message) - 16usize];
};
impl Default for rte_tm_error {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
unsafe extern "C" {
    #[doc = "Traffic manager get number of leaf nodes\nEach leaf node sits on top of a Tx queue of the current Ethernet port.\nTherefore, the set of leaf nodes is predefined, their number is always equal\nto N (where N is the number of Tx queues configured for the current port)\nand their IDs are 0 .. (N-1).\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `n_leaf_nodes` [out]  -\nNumber of leaf nodes for the current port.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_tm_get_number_of_leaf_nodes(
        port_id: u16,
        n_leaf_nodes: *mut u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node ID validate and type (i.e. leaf or non-leaf) get\nThe leaf nodes have predefined IDs in the range of 0 .. (N-1), where N is\nthe number of Tx queues of the current Ethernet port. The non-leaf nodes\nhave their IDs generated by the application outside of the above range,\nwhich is reserved for leaf nodes.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID value. Needs to be valid.\n* `is_leaf` [out]  -\nSet to non-zero value when node is leaf and to zero otherwise (non-leaf).\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_tm_node_type_get(
        port_id: u16,
        node_id: u32,
        is_leaf: *mut ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager capabilities get\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `cap` [out]  -\nTraffic manager capabilities. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_tm_capabilities_get(
        port_id: u16,
        cap: *mut rte_tm_capabilities,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager level capabilities get\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `level_id` [in]  -\nThe hierarchy level identifier. The value of 0 identifies the level of the\nroot node.\n* `cap` [out]  -\nTraffic manager level capabilities. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_tm_level_capabilities_get(
        port_id: u16,
        level_id: u32,
        cap: *mut rte_tm_level_capabilities,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node capabilities get\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `cap` [out]  -\nTraffic manager node capabilities. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise."]
    pub fn rte_tm_node_capabilities_get(
        port_id: u16,
        node_id: u32,
        cap: *mut rte_tm_node_capabilities,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager WRED profile add\nCreate a new WRED profile with ID set to *wred_profile_id*. The new profile\nis used to create one or several WRED contexts.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `wred_profile_id` [in]  -\nWRED profile ID for the new profile. Needs to be unused.\n* `profile` [in]  -\nWRED profile parameters. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_n_max"]
    pub fn rte_tm_wred_profile_add(
        port_id: u16,
        wred_profile_id: u32,
        profile: *const rte_tm_wred_params,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager WRED profile delete\nDelete an existing WRED profile. This operation fails when there is\ncurrently at least one user (i.e. WRED context) of this WRED profile.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `wred_profile_id` [in]  -\nWRED profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_n_max"]
    pub fn rte_tm_wred_profile_delete(
        port_id: u16,
        wred_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shared WRED context add or update\nWhen *shared_wred_context_id* is invalid, a new WRED context with this ID is\ncreated by using the WRED profile identified by *wred_profile_id*.\nWhen *shared_wred_context_id* is valid, this WRED context is no longer using\nthe profile previously assigned to it and is updated to use the profile\nidentified by *wred_profile_id*.\nA valid shared WRED context can be assigned to several hierarchy leaf nodes\nconfigured to use WRED as the congestion management mode.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shared_wred_context_id` [in]  -\nShared WRED context ID\n* `wred_profile_id` [in]  -\nWRED profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_shared_n_max"]
    pub fn rte_tm_shared_wred_context_add_update(
        port_id: u16,
        shared_wred_context_id: u32,
        wred_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shared WRED context delete\nDelete an existing shared WRED context. This operation fails when there is\ncurrently at least one user (i.e. hierarchy leaf node) of this shared WRED\ncontext.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shared_wred_context_id` [in]  -\nShared WRED context ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_shared_n_max"]
    pub fn rte_tm_shared_wred_context_delete(
        port_id: u16,
        shared_wred_context_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shaper profile add\nCreate a new shaper profile with ID set to *shaper_profile_id*. The new\nshaper profile is used to create one or several shapers.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shaper_profile_id` [in]  -\nShaper profile ID for the new profile. Needs to be unused.\n* `profile` [in]  -\nShaper profile parameters. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_n_max"]
    pub fn rte_tm_shaper_profile_add(
        port_id: u16,
        shaper_profile_id: u32,
        profile: *const rte_tm_shaper_params,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shaper profile delete\nDelete an existing shaper profile. This operation fails when there is\ncurrently at least one user (i.e. shaper) of this shaper profile.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shaper_profile_id` [in]  -\nShaper profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_n_max"]
    pub fn rte_tm_shaper_profile_delete(
        port_id: u16,
        shaper_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shared shaper add or update\nWhen *shared_shaper_id* is not a valid shared shaper ID, a new shared shaper\nwith this ID is created using the shaper profile identified by\n*shaper_profile_id*.\nWhen *shared_shaper_id* is a valid shared shaper ID, this shared shaper is\nno longer using the shaper profile previously assigned to it and is updated\nto use the shaper profile identified by *shaper_profile_id*.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shared_shaper_id` [in]  -\nShared shaper ID\n* `shaper_profile_id` [in]  -\nShaper profile ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_shared_n_max"]
    pub fn rte_tm_shared_shaper_add_update(
        port_id: u16,
        shared_shaper_id: u32,
        shaper_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager shared shaper delete\nDelete an existing shared shaper. This operation fails when there is\ncurrently at least one user (i.e. hierarchy node) of this shared shaper.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `shared_shaper_id` [in]  -\nShared shaper ID. Needs to be the valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_shared_n_max"]
    pub fn rte_tm_shared_shaper_delete(
        port_id: u16,
        shared_shaper_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node add\nCreate new node and connect it as child of an existing node. The new node is\nfurther identified by *node_id*, which needs to be unused by any of the\nexisting nodes. The parent node is identified by *parent_node_id*, which\nneeds to be the valid ID of an existing non-leaf node. The parent node is\ngoing to use the provided SP *priority* and WFQ *weight* to schedule its new\nchild node.\nThis function has to be called for both leaf and non-leaf nodes. In the case\nof leaf nodes (i.e. *node_id* is within the range of 0 .. (N-1), with N as\nthe number of configured Tx queues of the current port), the leaf node is\nconfigured rather than created (as the set of leaf nodes is predefined) and\nit is also connected as child of an existing node.\nThe first node that is added becomes the root node and all the nodes that\nare subsequently added have to be added as descendants of the root node. The\nparent of the root node has to be specified as RTE_TM_NODE_ID_NULL and there\ncan only be one node with this parent ID (i.e. the root node). Further\nrestrictions for root node: needs to be non-leaf, its private shaper profile\nneeds to be valid and single rate, cannot use any shared shapers.\nWhen called before rte_tm_hierarchy_commit() invocation, this function is\ntypically used to define the initial start-up hierarchy for the port.\nProvided that dynamic hierarchy updates are supported by the current port (as\nadvertised in the port capability set), this function can be also called\nafter the rte_tm_hierarchy_commit() invocation.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be unused by any of the existing nodes.\n* `parent_node_id` [in]  -\nParent node ID. Needs to be the valid.\n* `priority` [in]  -\nNode priority. The highest node priority is zero. Used by the SP algorithm\nrunning on the parent of the current node for scheduling this child node.\n* `weight` [in]  -\nNode weight. The node weight is relative to the weight sum of all siblings\nthat have the same priority. The lowest weight is one. Used by the WFQ\nalgorithm running on the parent of the current node for scheduling this\nchild node.\n* `level_id` [in]  -\nLevel ID that should be met by this node. The hierarchy level of the\ncurrent node is already fully specified through its parent node (i.e. the\nlevel of this node is equal to the level of its parent node plus one),\ntherefore the reason for providing this parameter is to enable the\napplication to perform step-by-step checking of the node level during\nsuccessive invocations of this function. When not desired, this check can\nbe disabled by assigning value RTE_TM_NODE_LEVEL_ID_ANY to this parameter.\n* `params` [in]  -\nNode parameters. Needs to be pre-allocated and valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`rte_tm_hierarchy_commit()`]\n> [`RTE_TM_UPDATE_NODE_ADD_DELETE`]\n> [`RTE_TM_NODE_LEVEL_ID_ANY`]\n> [`struct`] rte_tm_capabilities"]
    pub fn rte_tm_node_add(
        port_id: u16,
        node_id: u32,
        parent_node_id: u32,
        priority: u32,
        weight: u32,
        level_id: u32,
        params: *const rte_tm_node_params,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Return information about a traffic management node\nReturn information about a hierarchy node, using the same format of parameters\nas was passed to the rte_rm_node_add() function.\nEach of the \"out\" parameters pointers (except error) may be passed as NULL if the\ninformation is not needed by the caller. For example, to one may check if a node id\nis in use by:\nstruct rte_tm_error error;\nint ret = rte_tm_node_query(port, node_id, NULL, NULL, NULL, NULL, NULL, &error);\nif (ret == ENOENT) ...\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Should be a valid node id.\n* `parent_node_id` [out]  -\nParent node ID.\n* `priority` [out]  -\nNode priority. The highest node priority is zero. Used by the SP algorithm\nrunning on the parent of the current node for scheduling this child node.\n* `weight` [out]  -\nNode weight. The node weight is relative to the weight sum of all siblings\nthat have the same priority. The lowest weight is one. Used by the WFQ\nalgorithm running on the parent of the current node for scheduling this\nchild node.\n* `level_id` [out]  -\nThe node level in the scheduler hierarchy.\n* `params` [out]  -\nNode parameters, as would be used when creating the node.\n* `error` [out]  -\nError details. Filled in only on error. Must not be NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n-EINVAL - port or node id value is invalid\n-ENOENT - no node exists with the provided id on the provided port"]
    pub fn rte_tm_node_query(
        port_id: u16,
        node_id: u32,
        parent_node_id: *mut u32,
        priority: *mut u32,
        weight: *mut u32,
        level_id: *mut u32,
        params: *mut rte_tm_node_params,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node delete\nDelete an existing node. This operation fails when this node currently has\nat least one user (i.e. child node).\nWhen called before rte_tm_hierarchy_commit() invocation, this function is\ntypically used to define the initial start-up hierarchy for the port.\nProvided that dynamic hierarchy updates are supported by the current port (as\nadvertised in the port capability set), this function can be also called\nafter the rte_tm_hierarchy_commit() invocation.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`RTE_TM_UPDATE_NODE_ADD_DELETE`]"]
    pub fn rte_tm_node_delete(
        port_id: u16,
        node_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node suspend\nSuspend an existing node. While the node is in suspended state, no packet is\nscheduled from this node and its descendants. The node exits the suspended\nstate through the node resume operation.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`rte_tm_node_resume()`]\n> [`RTE_TM_UPDATE_NODE_SUSPEND_RESUME`]"]
    pub fn rte_tm_node_suspend(
        port_id: u16,
        node_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node resume\nResume an existing node that is currently in suspended state. The node\nentered the suspended state as result of a previous node suspend operation.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`rte_tm_node_suspend()`]\n> [`RTE_TM_UPDATE_NODE_SUSPEND_RESUME`]"]
    pub fn rte_tm_node_resume(
        port_id: u16,
        node_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager hierarchy commit\nThis function is called during the port initialization phase (before the\nEthernet port is started) to freeze the start-up hierarchy.\nThis function typically performs the following steps:\na) It validates the start-up hierarchy that was previously defined for the\ncurrent port through successive rte_tm_node_add() invocations;\nb) Assuming successful validation, it performs all the necessary port\nspecific configuration operations to install the specified hierarchy on\nthe current port, with immediate effect once the port is started.\nThis function fails when the currently configured hierarchy is not supported\nby the Ethernet port, in which case the user can abort or try out another\nhierarchy configuration (e.g. a hierarchy with less leaf nodes), which can be\nbuild from scratch (when *clear_on_fail* is enabled) or by modifying the\nexisting hierarchy configuration (when *clear_on_fail* is disabled).\nNote that this function can still fail due to other causes (e.g. not enough\nmemory available in the system, etc), even though the specified hierarchy is\nsupported in principle by the current port.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `clear_on_fail` [in]  -\nOn function call failure, hierarchy is cleared when this parameter is\nnon-zero and preserved when this parameter is equal to zero.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`rte_tm_node_add()`]\n> [`rte_tm_node_delete()`]"]
    pub fn rte_tm_hierarchy_commit(
        port_id: u16,
        clear_on_fail: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node parent update\nThis function may be used to move a node and its children to a different\nparent.  Additionally, if the new parent is the same as the current parent,\nthis function will update the priority/weight of an existing node.\nRestriction for root node: its parent cannot be changed.\nThis function can only be called after the rte_tm_hierarchy_commit()\ninvocation. Its success depends on the port support for this operation, as\nadvertised through the port capability set.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `parent_node_id` [in]  -\nNode ID for the new parent. Needs to be valid.\n* `priority` [in]  -\nNode priority. The highest node priority is zero. Used by the SP algorithm\nrunning on the parent of the current node for scheduling this child node.\n* `weight` [in]  -\nNode weight. The node weight is relative to the weight sum of all siblings\nthat have the same priority. The lowest weight is zero. Used by the WFQ\nalgorithm running on the parent of the current node for scheduling this\nchild node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`RTE_TM_UPDATE_NODE_PARENT_KEEP_LEVEL`]\n> [`RTE_TM_UPDATE_NODE_PARENT_CHANGE_LEVEL`]"]
    pub fn rte_tm_node_parent_update(
        port_id: u16,
        node_id: u32,
        parent_node_id: u32,
        priority: u32,
        weight: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node private shaper update\nRestriction for the root node: its private shaper profile needs to be valid\nand single rate.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `shaper_profile_id` [in]  -\nShaper profile ID for the private shaper of the current node. Needs to be\neither valid shaper profile ID or RTE_TM_SHAPER_PROFILE_ID_NONE, with\nthe latter disabling the private shaper of the current node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_private_n_max"]
    pub fn rte_tm_node_shaper_update(
        port_id: u16,
        node_id: u32,
        shaper_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node shared shapers update\nRestriction for root node: cannot use any shared rate shapers.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `shared_shaper_id` [in]  -\nShared shaper ID. Needs to be valid.\n* `add` [in]  -\nSet to non-zero value to add this shared shaper to current node or to zero\nto delete this shared shaper from current node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::shaper_shared_n_max"]
    pub fn rte_tm_node_shared_shaper_update(
        port_id: u16,
        node_id: u32,
        shared_shaper_id: u32,
        add: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node enabled statistics counters update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `stats_mask` [in]  -\nMask of statistics counter types to be enabled for the current node. This\nneeds to be a subset of the statistics counter types available for the\ncurrent node. Any statistics counter type not included in this set is to\nbe disabled for the current node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`enum`] rte_tm_stats_type\n> [`RTE_TM_UPDATE_NODE_STATS`]"]
    pub fn rte_tm_node_stats_update(
        port_id: u16,
        node_id: u32,
        stats_mask: u64,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node WFQ weight mode update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid non-leaf node ID.\n* `wfq_weight_mode` [in]  -\nWFQ weight mode for each SP priority. When NULL, it indicates that WFQ is\nto be used for all priorities. When non-NULL, it points to a pre-allocated\narray of *n_sp_priorities* values, with non-zero value for byte-mode and\nzero for packet-mode.\n* `n_sp_priorities` [in]  -\nNumber of SP priorities.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`RTE_TM_UPDATE_NODE_WFQ_WEIGHT_MODE`]\n> [`RTE_TM_UPDATE_NODE_N_SP_PRIORITIES`]"]
    pub fn rte_tm_node_wfq_weight_mode_update(
        port_id: u16,
        node_id: u32,
        wfq_weight_mode: *mut ::core::ffi::c_int,
        n_sp_priorities: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node congestion management mode update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid leaf node ID.\n* `cman` [in]  -\nCongestion management mode.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`RTE_TM_UPDATE_NODE_CMAN`]"]
    pub fn rte_tm_node_cman_update(
        port_id: u16,
        node_id: u32,
        cman: rte_tm_cman_mode::Type,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node private WRED context update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid leaf node ID.\n* `wred_profile_id` [in]  -\nWRED profile ID for the private WRED context of the current node. Needs to\nbe either valid WRED profile ID or RTE_TM_WRED_PROFILE_ID_NONE, with the\nlatter disabling the private WRED context of the current node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_private_n_max"]
    pub fn rte_tm_node_wred_context_update(
        port_id: u16,
        node_id: u32,
        wred_profile_id: u32,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node shared WRED context update\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid leaf node ID.\n* `shared_wred_context_id` [in]  -\nShared WRED context ID. Needs to be valid.\n* `add` [in]  -\nSet to non-zero value to add this shared WRED context to current node or\nto zero to delete this shared WRED context from current node.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::cman_wred_context_shared_n_max"]
    pub fn rte_tm_node_shared_wred_context_update(
        port_id: u16,
        node_id: u32,
        shared_wred_context_id: u32,
        add: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager node statistics counters read\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `node_id` [in]  -\nNode ID. Needs to be valid.\n* `stats` [out]  -\nWhen non-NULL, it contains the current value for the statistics counters\nenabled for the current node.\n* `stats_mask` [out]  -\nWhen non-NULL, it contains the mask of statistics counter types that are\ncurrently enabled for this node, indicating which of the counters\nretrieved with the *stats* structure are valid.\n* `clear` [in]  -\nWhen this parameter has a non-zero value, the statistics counters are\ncleared (i.e. set to zero) immediately after they have been read,\notherwise the statistics counters are left untouched.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`enum`] rte_tm_stats_type"]
    pub fn rte_tm_node_stats_read(
        port_id: u16,
        node_id: u32,
        stats: *mut rte_tm_node_stats,
        stats_mask: *mut u64,
        clear: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager packet marking - VLAN DEI (IEEE 802.1Q)\nIEEE 802.1p maps the traffic class to the VLAN Priority Code Point (PCP)\nfield (3 bits), while IEEE 802.1q maps the drop priority to the VLAN Drop\nEligible Indicator (DEI) field (1 bit), which was previously named Canonical\nFormat Indicator (CFI).\nAll VLAN frames of a given color get their DEI bit set if marking is enabled\nfor this color; otherwise, their DEI bit is left as is (either set or not).\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mark_green` [in]  -\nSet to non-zero value to enable marking of green packets and to zero to\ndisable it.\n* `mark_yellow` [in]  -\nSet to non-zero value to enable marking of yellow packets and to zero to\ndisable it.\n* `mark_red` [in]  -\nSet to non-zero value to enable marking of red packets and to zero to\ndisable it.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::mark_vlan_dei_supported"]
    pub fn rte_tm_mark_vlan_dei(
        port_id: u16,
        mark_green: ::core::ffi::c_int,
        mark_yellow: ::core::ffi::c_int,
        mark_red: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager packet marking - IPv4 / IPv6 ECN (IETF RFC 3168)\nIETF RFCs 2474 and 3168 reorganize the IPv4 Type of Service (TOS) field\n(8 bits) and the IPv6 Traffic Class (TC) field (8 bits) into Differentiated\nServices Codepoint (DSCP) field (6 bits) and Explicit Congestion\nNotification (ECN) field (2 bits). The DSCP field is typically used to\nencode the traffic class and/or drop priority (RFC 2597), while the ECN\nfield is used by RFC 3168 to implement a congestion notification mechanism\nto be leveraged by transport layer protocols such as TCP and SCTP that have\ncongestion control mechanisms.\nWhen congestion is experienced, as alternative to dropping the packet,\nrouters can change the ECN field of input packets from 2'b01 or 2'b10\n(values indicating that source endpoint is ECN-capable) to 2'b11 (meaning\nthat congestion is experienced). The destination endpoint can use the\nECN-Echo (ECE) TCP flag to relay the congestion indication back to the\nsource endpoint, which acknowledges it back to the destination endpoint with\nthe Congestion Window Reduced (CWR) TCP flag.\nAll IPv4/IPv6 packets of a given color with ECN set to 2b01 or 2b10\ncarrying TCP or SCTP have their ECN set to 2b11 if the marking feature is\nenabled for the current color, otherwise the ECN field is left as is.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mark_green` [in]  -\nSet to non-zero value to enable marking of green packets and to zero to\ndisable it.\n* `mark_yellow` [in]  -\nSet to non-zero value to enable marking of yellow packets and to zero to\ndisable it.\n* `mark_red` [in]  -\nSet to non-zero value to enable marking of red packets and to zero to\ndisable it.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::mark_ip_ecn_tcp_supported\n> [`struct`] rte_tm_capabilities::mark_ip_ecn_sctp_supported"]
    pub fn rte_tm_mark_ip_ecn(
        port_id: u16,
        mark_green: ::core::ffi::c_int,
        mark_yellow: ::core::ffi::c_int,
        mark_red: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Traffic manager packet marking - IPv4 / IPv6 DSCP (IETF RFC 2597)\nIETF RFC 2597 maps the traffic class and the drop priority to the IPv4/IPv6\nDifferentiated Services Codepoint (DSCP) field (6 bits). Here are the DSCP\nvalues proposed by this RFC:\n<pre>                   Class 1    Class 2    Class 3    Class 4   </pre>\n<pre>                 +----------+----------+----------+----------+</pre>\n<pre>Low Drop Prec    |  001010  |  010010  |  011010  |  100010  |</pre>\n<pre>Medium Drop Prec |  001100  |  010100  |  011100  |  100100  |</pre>\n<pre>High Drop Prec   |  001110  |  010110  |  011110  |  100110  |</pre>\n<pre>                 +----------+----------+----------+----------+</pre>\nThere are 4 traffic classes (classes 1 .. 4) encoded by DSCP bits 1 and 2,\nas well as 3 drop priorities (low/medium/high) encoded by DSCP bits 3 and 4.\nAll IPv4/IPv6 packets have their color marked into DSCP bits 3 and 4 as\nfollows: green mapped to Low Drop Precedence (2b01), yellow to Medium\n(2b10) and red to High (2b11). Marking needs to be explicitly enabled\nfor each color; when not enabled for a given color, the DSCP field of all\npackets with that color is left as is.\n\n# Arguments\n\n* `port_id` [in]  -\nThe port identifier of the Ethernet device.\n* `mark_green` [in]  -\nSet to non-zero value to enable marking of green packets and to zero to\ndisable it.\n* `mark_yellow` [in]  -\nSet to non-zero value to enable marking of yellow packets and to zero to\ndisable it.\n* `mark_red` [in]  -\nSet to non-zero value to enable marking of red packets and to zero to\ndisable it.\n* `error` [out]  -\nError details. Filled in only on error, when not NULL.\n\n# Returns\n\n0 on success, non-zero error code otherwise.\n\n# See also\n\n> [`struct`] rte_tm_capabilities::mark_ip_dscp_supported"]
    pub fn rte_tm_mark_ip_dscp(
        port_id: u16,
        mark_green: ::core::ffi::c_int,
        mark_yellow: ::core::ffi::c_int,
        mark_red: ::core::ffi::c_int,
        error: *mut rte_tm_error,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK version prefix string"]
    pub fn rte_version_prefix() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK version year"]
    pub fn rte_version_year() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK version month"]
    pub fn rte_version_month() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK minor version number"]
    pub fn rte_version_minor() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK version suffix for any release candidates"]
    pub fn rte_version_suffix() -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    #[doc = "Function to return DPDK version release candidate value"]
    pub fn rte_version_release() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    #[doc = "Function returning version string\n\n# Returns\n\nDPDK version string"]
    pub fn rte_version() -> *const ::core::ffi::c_char;
}
pub type __u32 = ::core::ffi::c_uint;
#[doc = "VFIO_DEVICE_GET_INFO - _IOR(VFIO_TYPE, VFIO_BASE + 7,\nstruct vfio_device_info)\nRetrieve information about the device.  Fills in provided\nstruct vfio_device_info.  Caller sets argsz.\nReturn: 0 on success, -errno on failure."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct vfio_device_info {
    pub argsz: __u32,
    pub flags: __u32,
    #[doc = "Max region index + 1"]
    pub num_regions: __u32,
    #[doc = "Max IRQ index + 1"]
    pub num_irqs: __u32,
    #[doc = "Offset within info struct of first cap"]
    pub cap_offset: __u32,
    pub pad: __u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of vfio_device_info"][::core::mem::size_of::<vfio_device_info>() - 24usize];
    ["Alignment of vfio_device_info"][::core::mem::align_of::<vfio_device_info>() - 4usize];
    ["Offset of field: vfio_device_info::argsz"]
        [::core::mem::offset_of!(vfio_device_info, argsz) - 0usize];
    ["Offset of field: vfio_device_info::flags"]
        [::core::mem::offset_of!(vfio_device_info, flags) - 4usize];
    ["Offset of field: vfio_device_info::num_regions"]
        [::core::mem::offset_of!(vfio_device_info, num_regions) - 8usize];
    ["Offset of field: vfio_device_info::num_irqs"]
        [::core::mem::offset_of!(vfio_device_info, num_irqs) - 12usize];
    ["Offset of field: vfio_device_info::cap_offset"]
        [::core::mem::offset_of!(vfio_device_info, cap_offset) - 16usize];
    ["Offset of field: vfio_device_info::pad"]
        [::core::mem::offset_of!(vfio_device_info, pad) - 20usize];
};
unsafe extern "C" {
    #[doc = "Setup vfio_cfg for the device identified by its address.\nIt discovers the configured I/O MMU groups or sets a new one for the device.\nIf a new groups is assigned, the DMA mapping is performed.\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `sysfs_base` -\nsysfs path prefix.\n* `dev_addr` -\ndevice location.\n* `vfio_dev_fd` -\nVFIO fd.\n* `device_info` -\nDevice information.\n\n# Returns\n\n0 on success.\n<0 on failure.\n>1 if the device cannot be managed this way."]
    pub fn rte_vfio_setup_device(
        sysfs_base: *const ::core::ffi::c_char,
        dev_addr: *const ::core::ffi::c_char,
        vfio_dev_fd: *mut ::core::ffi::c_int,
        device_info: *mut vfio_device_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Release a device mapped to a VFIO-managed I/O MMU group.\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `sysfs_base` -\nsysfs path prefix.\n* `dev_addr` -\ndevice location.\n* `fd` -\nVFIO fd.\n\n# Returns\n\n0 on success.\n<0 on failure."]
    pub fn rte_vfio_release_device(
        sysfs_base: *const ::core::ffi::c_char,
        dev_addr: *const ::core::ffi::c_char,
        fd: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Enable a VFIO-related kmod.\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `modname` -\nkernel module name.\n\n# Returns\n\n0 on success.\n<0 on failure."]
    pub fn rte_vfio_enable(modname: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Check whether a VFIO-related kmod is enabled.\nThis function is only relevant to Linux.\n\n# Arguments\n\n* `modname` -\nkernel module name.\n\n# Returns\n\n1 if true.\n0 otherwise."]
    pub fn rte_vfio_is_enabled(modname: *const ::core::ffi::c_char) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Whether VFIO NOIOMMU mode is enabled.\nThis function is only relevant to Linux.\n\n# Returns\n\n1 if true.\n0 if false.\n<0 for errors."]
    pub fn rte_vfio_noiommu_is_enabled() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Remove group fd from internal VFIO group fd array/\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `vfio_group_fd` -\nVFIO Group FD.\n\n# Returns\n\n0 on success.\n<0 on failure."]
    pub fn rte_vfio_clear_group(vfio_group_fd: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Parse IOMMU group number for a device\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `sysfs_base` -\nsysfs path prefix.\n* `dev_addr` -\ndevice location.\n* `iommu_group_num` -\niommu group number\n\n# Returns\n\n>0 on success\n0 for non-existent group or VFIO\n<0 for errors"]
    pub fn rte_vfio_get_group_num(
        sysfs_base: *const ::core::ffi::c_char,
        dev_addr: *const ::core::ffi::c_char,
        iommu_group_num: *mut ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Get device information\nThis function is only relevant to Linux and will return an error on BSD.\n\n# Arguments\n\n* `sysfs_base` -\nsysfs path prefix.\n* `dev_addr` -\ndevice location.\n* `vfio_dev_fd` -\nVFIO fd.\n* `device_info` -\nDevice information.\n\n# Returns\n\n0 on success.\n<0 on failure."]
    pub fn rte_vfio_get_device_info(
        sysfs_base: *const ::core::ffi::c_char,
        dev_addr: *const ::core::ffi::c_char,
        vfio_dev_fd: *mut ::core::ffi::c_int,
        device_info: *mut vfio_device_info,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Open a new VFIO container fd\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Returns\n\n> 0 container fd\n< 0 for errors"]
    pub fn rte_vfio_get_container_fd() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Open VFIO group fd or get an existing one\nThis function is only relevant to linux and will return\nan error on BSD.\n\n# Arguments\n\n* `iommu_group_num` -\niommu group number\n\n# Returns\n\n> 0 group fd\n< 0 for errors"]
    pub fn rte_vfio_get_group_fd(iommu_group_num: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Create a new container for device binding.\n> **Note** Any newly allocated DPDK memory will not be mapped into these\ncontainers by default, user needs to manage DMA mappings for\nany container created by this API.\n> **Note** When creating containers using this API, the container will only be\navailable in the process that has created it. Sharing containers and\ndevices between multiple processes is not supported.\n\n# Returns\n\nthe container fd if successful\n<0 if failed"]
    pub fn rte_vfio_container_create() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Destroy the container, unbind all vfio groups within it.\n\n# Arguments\n\n* `container_fd` -\nthe container fd to destroy\n\n# Returns\n\n0 if successful\n<0 if failed"]
    pub fn rte_vfio_container_destroy(container_fd: ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Bind a IOMMU group to a container.\n\n# Arguments\n\n* `container_fd` -\nthe container's fd\n* `iommu_group_num` -\nthe iommu group number to bind to container\n\n# Returns\n\ngroup fd if successful\n<0 if failed"]
    pub fn rte_vfio_container_group_bind(
        container_fd: ::core::ffi::c_int,
        iommu_group_num: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Unbind a IOMMU group from a container.\n\n# Arguments\n\n* `container_fd` -\nthe container fd of container\n* `iommu_group_num` -\nthe iommu group number to delete from container\n\n# Returns\n\n0 if successful\n<0 if failed"]
    pub fn rte_vfio_container_group_unbind(
        container_fd: ::core::ffi::c_int,
        iommu_group_num: ::core::ffi::c_int,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Perform DMA mapping for devices in a container.\n\n# Arguments\n\n* `container_fd` -\nthe specified container fd. Use RTE_VFIO_DEFAULT_CONTAINER_FD to\nuse the default container.\n* `vaddr` -\nStarting virtual address of memory to be mapped.\n* `iova` -\nStarting IOVA address of memory to be mapped.\n* `len` -\nLength of memory segment being mapped.\n\n# Returns\n\n0 if successful\n<0 if failed"]
    pub fn rte_vfio_container_dma_map(
        container_fd: ::core::ffi::c_int,
        vaddr: u64,
        iova: u64,
        len: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Perform DMA unmapping for devices in a container.\n\n# Arguments\n\n* `container_fd` -\nthe specified container fd. Use RTE_VFIO_DEFAULT_CONTAINER_FD to\nuse the default container.\n* `vaddr` -\nStarting virtual address of memory to be unmapped.\n* `iova` -\nStarting IOVA address of memory to be unmapped.\n* `len` -\nLength of memory segment being unmapped.\n\n# Returns\n\n0 if successful\n<0 if failed"]
    pub fn rte_vfio_container_dma_unmap(
        container_fd: ::core::ffi::c_int,
        vaddr: u64,
        iova: u64,
        len: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    #[doc = "Thin wrapper to expose `rte_errno`.\n\n# Returns\n\nThe last rte_errno value (thread local value)."]
    pub fn rte_errno_get() -> ::core::ffi::c_int;
}
pub mod rte_eth_tx_offload {
    #[doc = "TX offloads to be set in [`rte_eth_tx_mode.offloads`].\nThis is a bitfield.  Union these to enable multiple offloads.\nI wrapped these because the enum must be explicitly typed as 64 bit, but\nDPDK is not yet using the C23 standard (which would allow the inheritance\nnotation with `uint64_t` seen here.)."]
    pub type Type = u64;
    pub const TX_OFFLOAD_VLAN_INSERT: Type = 1;
    pub const TX_OFFLOAD_IPV4_CKSUM: Type = 2;
    pub const TX_OFFLOAD_UDP_CKSUM: Type = 4;
    pub const TX_OFFLOAD_TCP_CKSUM: Type = 8;
    pub const TX_OFFLOAD_SCTP_CKSUM: Type = 16;
    pub const TX_OFFLOAD_TCP_TSO: Type = 32;
    pub const TX_OFFLOAD_UDP_TSO: Type = 64;
    pub const TX_OFFLOAD_OUTER_IPV4_CKSUM: Type = 128;
    pub const TX_OFFLOAD_QINQ_INSERT: Type = 256;
    pub const TX_OFFLOAD_VXLAN_TNL_TSO: Type = 512;
    pub const TX_OFFLOAD_GRE_TNL_TSO: Type = 1024;
    pub const TX_OFFLOAD_IPIP_TNL_TSO: Type = 2048;
    pub const TX_OFFLOAD_GENEVE_TNL_TSO: Type = 4096;
    pub const TX_OFFLOAD_MACSEC_INSERT: Type = 8192;
    pub const TX_OFFLOAD_MT_LOCKFREE: Type = 16384;
    pub const TX_OFFLOAD_MULTI_SEGS: Type = 32768;
    pub const TX_OFFLOAD_MBUF_FAST_FREE: Type = 65536;
    pub const TX_OFFLOAD_SECURITY: Type = 131072;
    pub const TX_OFFLOAD_UDP_TNL_TSO: Type = 262144;
    pub const TX_OFFLOAD_IP_TNL_TSO: Type = 524288;
    pub const TX_OFFLOAD_OUTER_UDP_CKSUM: Type = 1048576;
    pub const TX_OFFLOAD_SEND_ON_TIMESTAMP: Type = 2097152;
}
pub mod wrte_eth_rx_offload {
    #[doc = "RX offloads to be set in [`rte_eth_rx_mode.offloads`].\nThis is a bitfield.  Union these to enable multiple offloads.\nI wrapped these because the enum must be explicitly typed as 64 bit, but\nDPDK is not yet using the C23 standard (which would allow the inheritance\nnotation with `uint64_t` seen here.)."]
    pub type Type = u64;
    pub const RX_OFFLOAD_VLAN_STRIP: Type = 1;
    pub const RX_OFFLOAD_IPV4_CKSUM: Type = 2;
    pub const RX_OFFLOAD_UDP_CKSUM: Type = 4;
    pub const RX_OFFLOAD_TCP_CKSUM: Type = 8;
    pub const RX_OFFLOAD_TCP_LRO: Type = 16;
    pub const RX_OFFLOAD_QINQ_STRIP: Type = 32;
    pub const RX_OFFLOAD_OUTER_IPV4_CKSUM: Type = 64;
    pub const RX_OFFLOAD_MACSEC_STRIP: Type = 128;
    pub const RX_OFFLOAD_VLAN_FILTER: Type = 512;
    pub const RX_OFFLOAD_VLAN_EXTEND: Type = 1024;
    pub const RX_OFFLOAD_SCATTER: Type = 8192;
    pub const RX_OFFLOAD_TIMESTAMP: Type = 16384;
    pub const RX_OFFLOAD_SECURITY: Type = 32768;
    pub const RX_OFFLOAD_KEEP_CRC: Type = 65536;
    pub const RX_OFFLOAD_SCTP_CKSUM: Type = 131072;
    pub const RX_OFFLOAD_OUTER_UDP_CKSUM: Type = 262144;
    pub const RX_OFFLOAD_RSS_HASH: Type = 524288;
    pub const RX_OFFLOAD_BUFFER_SPLIT: Type = 1048576;
}
unsafe extern "C" {
    #[doc = "Static wrappers"]
    pub fn rte_is_aligned_w(
        ptr: *const ::core::ffi::c_void,
        align: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_smp_mb_w();
}
unsafe extern "C" {
    pub fn rte_get_tsc_cycles_w() -> u64;
}
unsafe extern "C" {
    pub fn rte_get_timer_cycles_w() -> u64;
}
unsafe extern "C" {
    pub fn rte_get_timer_hz_w() -> u64;
}
unsafe extern "C" {
    pub fn rte_delay_ms_w(ms: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rdtsc_w() -> u64;
}
unsafe extern "C" {
    pub fn rte_rdtsc_precise_w() -> u64;
}
unsafe extern "C" {
    pub fn rte_strlcpy_w(
        dst: *mut ::core::ffi::c_char,
        src: *const ::core::ffi::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    pub fn rte_strlcat_w(
        dst: *mut ::core::ffi::c_char,
        src: *const ::core::ffi::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    pub fn rte_str_skip_leading_spaces_w(
        src: *const ::core::ffi::c_char,
    ) -> *const ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_uuid_copy_w(dst: *mut ::core::ffi::c_uchar, src: *const ::core::ffi::c_uchar);
}
unsafe extern "C" {
    pub fn rte_gettid_w() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_lcore_id_w() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_pause_w();
}
unsafe extern "C" {
    pub fn rte_wait_until_equal_16_w(addr: *mut u16, expected: u16, memorder: rte_memory_order);
}
unsafe extern "C" {
    pub fn rte_wait_until_equal_32_w(addr: *mut u32, expected: u32, memorder: rte_memory_order);
}
unsafe extern "C" {
    pub fn rte_wait_until_equal_64_w(addr: *mut u64, expected: u64, memorder: rte_memory_order);
}
unsafe extern "C" {
    pub fn rte_spinlock_init_w(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_lock_w(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_unlock_w(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_trylock_w(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_spinlock_is_locked_w(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_tm_supported_w() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_spinlock_lock_tm_w(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_unlock_tm_w(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_trylock_tm_w(sl: *mut rte_spinlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_init_w(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_lock_w(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_unlock_w(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_trylock_w(
        slr: *mut rte_spinlock_recursive_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_lock_tm_w(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_unlock_tm_w(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_spinlock_recursive_trylock_tm_w(
        slr: *mut rte_spinlock_recursive_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_xbegin_w() -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_xend_w();
}
unsafe extern "C" {
    pub fn rte_xtest_w() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_try_tm_w(lock: *mut ::core::ffi::c_int) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_get32_w(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_set32_w(nr: ::core::ffi::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_clear32_w(nr: ::core::ffi::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_test_and_set32_w(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_test_and_clear32_w(nr: ::core::ffi::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_get64_w(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_set64_w(nr: ::core::ffi::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_clear64_w(nr: ::core::ffi::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_test_and_set64_w(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_bit_relaxed_test_and_clear64_w(nr: ::core::ffi::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_clz32_w(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_clz64_w(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ctz32_w(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ctz64_w(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_popcount32_w(v: u32) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_popcount64_w(v: u64) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_combine32ms1b_w(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_combine64ms1b_w(v: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_bsf32_w(v: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_bsf32_safe_w(v: u32, pos: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_bsf64_w(v: u64) -> u32;
}
unsafe extern "C" {
    pub fn rte_bsf64_safe_w(v: u64, pos: *mut u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fls_u32_w(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_fls_u64_w(x: u64) -> u32;
}
unsafe extern "C" {
    pub fn rte_is_power_of_2_w(n: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_align32pow2_w(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_align32prevpow2_w(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_align64pow2_w(v: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_align64prevpow2_w(v: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_log2_u32_w(v: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_log2_u64_w(v: u64) -> u32;
}
unsafe extern "C" {
    pub fn rte_rwlock_init_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_read_lock_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_read_trylock_w(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_rwlock_read_unlock_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_write_trylock_w(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_rwlock_write_lock_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_write_unlock_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_write_is_locked_w(rwl: *mut rte_rwlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_rwlock_read_lock_tm_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_read_unlock_tm_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_write_lock_tm_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_rwlock_write_unlock_tm_w(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_hts_enqueue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_hts_dequeue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_hts_enqueue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_hts_dequeue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_hts_enqueue_bulk_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_hts_dequeue_bulk_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_hts_enqueue_burst_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_hts_dequeue_burst_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_rts_enqueue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_rts_dequeue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_rts_enqueue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_rts_dequeue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_rts_enqueue_bulk_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_rts_dequeue_bulk_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_rts_enqueue_burst_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_rts_dequeue_burst_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_get_prod_htd_max_w(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    pub fn rte_ring_set_prod_htd_max_w(r: *mut rte_ring, v: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_get_cons_htd_max_w(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    pub fn rte_ring_set_cons_htd_max_w(r: *mut rte_ring, v: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_elem_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_elem_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_elem_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_bulk_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_elem_w(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_elem_w(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_elem_w(
        r: *mut rte_ring,
        obj_p: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_burst_elem_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_bulk_elem_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_bulk_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_burst_elem_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_burst_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_elem_finish_w(
        r: *mut rte_ring,
        obj_table: *const ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_finish_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_bulk_elem_start_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_bulk_start_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_burst_elem_start_w(
        r: *mut rte_ring,
        obj_table: *mut ::core::ffi::c_void,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_burst_start_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_elem_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_bulk_elem_start_w(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_bulk_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_burst_elem_start_w(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_burst_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_elem_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_zc_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_bulk_elem_start_w(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_bulk_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_burst_elem_start_w(
        r: *mut rte_ring,
        esize: ::core::ffi::c_uint,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_burst_start_w(
        r: *mut rte_ring,
        n: ::core::ffi::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_elem_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_zc_finish_w(r: *mut rte_ring, n: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_bulk_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_bulk_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_bulk_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_w(
        r: *mut rte_ring,
        obj: *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_bulk_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_bulk_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_bulk_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_w(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_w(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_w(
        r: *mut rte_ring,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_count_w(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_free_count_w(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_full_w(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_empty_w(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_get_size_w(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_get_capacity_w(r: *const rte_ring) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_get_prod_sync_type_w(r: *const rte_ring) -> rte_ring_sync_type::Type;
}
unsafe extern "C" {
    pub fn rte_ring_is_prod_single_w(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_get_cons_sync_type_w(r: *const rte_ring) -> rte_ring_sync_type::Type;
}
unsafe extern "C" {
    pub fn rte_ring_is_cons_single_w(r: *const rte_ring) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ring_mp_enqueue_burst_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sp_enqueue_burst_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_enqueue_burst_w(
        r: *mut rte_ring,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        free_space: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_mc_dequeue_burst_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_sc_dequeue_burst_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_ring_dequeue_burst_w(
        r: *mut rte_ring,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        available: *mut ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_memcpy_w(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_mov15_or_less_w(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_mov16_w(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    pub fn rte_mov32_w(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    pub fn rte_mov64_w(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    pub fn rte_mov256_w(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    pub fn rte_memcpy_generic_w(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_memcpy_aligned_w(
        dst: *mut ::core::ffi::c_void,
        src: *const ::core::ffi::c_void,
        n: usize,
    ) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_mempool_get_header_w(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool_objhdr;
}
unsafe extern "C" {
    pub fn rte_mempool_from_obj_w(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool;
}
unsafe extern "C" {
    pub fn rte_mempool_get_trailer_w(obj: *mut ::core::ffi::c_void) -> *mut rte_mempool_objtlr;
}
unsafe extern "C" {
    pub fn rte_mempool_get_ops_w(ops_index: ::core::ffi::c_int) -> *mut rte_mempool_ops;
}
unsafe extern "C" {
    pub fn rte_mempool_ops_dequeue_bulk_w(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_ops_dequeue_contig_blocks_w(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_ops_enqueue_bulk_w(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_default_cache_w(
        mp: *mut rte_mempool,
        lcore_id: ::core::ffi::c_uint,
    ) -> *mut rte_mempool_cache;
}
unsafe extern "C" {
    pub fn rte_mempool_cache_flush_w(cache: *mut rte_mempool_cache, mp: *mut rte_mempool);
}
unsafe extern "C" {
    pub fn rte_mempool_do_generic_put_w(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    pub fn rte_mempool_generic_put_w(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    pub fn rte_mempool_put_bulk_w(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    );
}
unsafe extern "C" {
    pub fn rte_mempool_put_w(mp: *mut rte_mempool, obj: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_mempool_do_generic_get_w(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_generic_get_w(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_get_bulk_w(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_get_w(
        mp: *mut rte_mempool,
        obj_p: *mut *mut ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_get_contig_blocks_w(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_full_w(mp: *const rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_empty_w(mp: *const rte_mempool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mempool_virt2iova_w(elt: *const ::core::ffi::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    pub fn rte_mempool_get_priv_w(mp: *mut rte_mempool) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_prefetch0_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch1_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch2_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch_non_temporal_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch0_write_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch1_write_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_prefetch2_write_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_cldemote_w(p: *const ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_constant_bswap16_w(x: u16) -> u16;
}
unsafe extern "C" {
    pub fn rte_constant_bswap32_w(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_constant_bswap64_w(x: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_arch_bswap16_w(_x: u16) -> u16;
}
unsafe extern "C" {
    pub fn rte_arch_bswap32_w(_x: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_arch_bswap64_w(_x: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_mbuf_prefetch_part1_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_mbuf_prefetch_part2_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_priv_size_w(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    pub fn rte_mbuf_iova_get_w(m: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    pub fn rte_mbuf_iova_set_w(m: *mut rte_mbuf, iova: rte_iova_t);
}
unsafe extern "C" {
    pub fn rte_mbuf_data_iova_w(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    pub fn rte_mbuf_data_iova_default_w(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    pub fn rte_mbuf_from_indirect_w(mi: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    pub fn rte_mbuf_buf_addr_w(mb: *mut rte_mbuf, mp: *mut rte_mempool)
    -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_mbuf_data_addr_default_w(mb: *mut rte_mbuf) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_mbuf_to_baddr_w(md: *mut rte_mbuf) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_mbuf_to_priv_w(m: *mut rte_mbuf) -> *mut ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_priv_flags_w(mp: *mut rte_mempool) -> u32;
}
unsafe extern "C" {
    pub fn rte_mbuf_refcnt_read_w(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    pub fn rte_mbuf_refcnt_set_w(m: *mut rte_mbuf, new_value: u16);
}
unsafe extern "C" {
    pub fn rte_mbuf_refcnt_update_w(m: *mut rte_mbuf, value: i16) -> u16;
}
unsafe extern "C" {
    pub fn rte_mbuf_ext_refcnt_read_w(shinfo: *const rte_mbuf_ext_shared_info) -> u16;
}
unsafe extern "C" {
    pub fn rte_mbuf_ext_refcnt_set_w(shinfo: *mut rte_mbuf_ext_shared_info, new_value: u16);
}
unsafe extern "C" {
    pub fn rte_mbuf_ext_refcnt_update_w(shinfo: *mut rte_mbuf_ext_shared_info, value: i16) -> u16;
}
unsafe extern "C" {
    pub fn rte_mbuf_raw_alloc_w(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    pub fn rte_mbuf_raw_free_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_data_room_size_w(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_reset_headroom_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_reset_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_alloc_w(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_alloc_bulk_w(
        pool: *mut rte_mempool,
        mbufs: *mut *mut rte_mbuf,
        count: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_ext_shinfo_init_helper_w(
        buf_addr: *mut ::core::ffi::c_void,
        buf_len: *mut u16,
        free_cb: rte_mbuf_extbuf_free_callback_t,
        fcb_opaque: *mut ::core::ffi::c_void,
    ) -> *mut rte_mbuf_ext_shared_info;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_attach_extbuf_w(
        m: *mut rte_mbuf,
        buf_addr: *mut ::core::ffi::c_void,
        buf_iova: rte_iova_t,
        buf_len: u16,
        shinfo: *mut rte_mbuf_ext_shared_info,
    );
}
unsafe extern "C" {
    pub fn rte_mbuf_dynfield_copy_w(mdst: *mut rte_mbuf, msrc: *const rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_attach_w(mi: *mut rte_mbuf, m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_detach_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_prefree_seg_w(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_free_seg_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_free_w(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_refcnt_update_w(m: *mut rte_mbuf, v: i16);
}
unsafe extern "C" {
    pub fn rte_pktmbuf_headroom_w(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_tailroom_w(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_lastseg_w(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_prepend_w(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_append_w(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_adj_w(m: *mut rte_mbuf, len: u16) -> *mut ::core::ffi::c_char;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_trim_w(m: *mut rte_mbuf, len: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_is_contiguous_w(m: *const rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_read_w(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        buf: *mut ::core::ffi::c_void,
    ) -> *const ::core::ffi::c_void;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_chain_w(head: *mut rte_mbuf, tail: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mbuf_tx_offload_w(
        il2: u64,
        il3: u64,
        il4: u64,
        tso: u64,
        ol3: u64,
        ol2: u64,
        unused: u64,
    ) -> u64;
}
unsafe extern "C" {
    pub fn rte_validate_tx_offload_w(m: *const rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_pktmbuf_linearize_w(mbuf: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_queue_get_w(m: *const rte_mbuf) -> u32;
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_traffic_class_get_w(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_color_get_w(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_get_w(
        m: *const rte_mbuf,
        queue_id: *mut u32,
        traffic_class: *mut u8,
        color: *mut u8,
    );
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_queue_set_w(m: *mut rte_mbuf, queue_id: u32);
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_traffic_class_set_w(m: *mut rte_mbuf, traffic_class: u8);
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_color_set_w(m: *mut rte_mbuf, color: u8);
}
unsafe extern "C" {
    pub fn rte_mbuf_sched_set_w(m: *mut rte_mbuf, queue_id: u32, traffic_class: u8, color: u8);
}
unsafe extern "C" {
    pub fn rte_is_same_ether_addr_w(
        ea1: *const rte_ether_addr,
        ea2: *const rte_ether_addr,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_zero_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_unicast_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_multicast_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_broadcast_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_universal_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_local_admin_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_is_valid_assigned_ether_addr_w(ea: *const rte_ether_addr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ether_addr_copy_w(ea_from: *const rte_ether_addr, ea_to: *mut rte_ether_addr);
}
unsafe extern "C" {
    pub fn rte_vlan_strip_w(m: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_vlan_insert_w(m: *mut *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_bitmap_get_memory_footprint_w(n_bits: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_bitmap_init_w(n_bits: u32, mem: *mut u8, mem_size: u32) -> *mut rte_bitmap;
}
unsafe extern "C" {
    pub fn rte_bitmap_init_with_all_set_w(
        n_bits: u32,
        mem: *mut u8,
        mem_size: u32,
    ) -> *mut rte_bitmap;
}
unsafe extern "C" {
    pub fn rte_bitmap_free_w(bmp: *mut rte_bitmap) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_bitmap_reset_w(bmp: *mut rte_bitmap);
}
unsafe extern "C" {
    pub fn rte_bitmap_prefetch0_w(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    pub fn rte_bitmap_get_w(bmp: *mut rte_bitmap, pos: u32) -> u64;
}
unsafe extern "C" {
    pub fn rte_bitmap_set_w(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    pub fn rte_bitmap_set_slab_w(bmp: *mut rte_bitmap, pos: u32, slab: u64);
}
unsafe extern "C" {
    pub fn rte_bitmap_clear_w(bmp: *mut rte_bitmap, pos: u32);
}
unsafe extern "C" {
    pub fn rte_bitmap_scan_w(
        bmp: *mut rte_bitmap,
        pos: *mut u32,
        slab: *mut u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_raw_cksum_w(buf: *const ::core::ffi::c_void, len: usize) -> u16;
}
unsafe extern "C" {
    pub fn rte_raw_cksum_mbuf_w(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        cksum: *mut u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv4_hdr_len_w(ipv4_hdr: *const rte_ipv4_hdr) -> u8;
}
unsafe extern "C" {
    pub fn rte_ipv4_cksum_w(ipv4_hdr: *const rte_ipv4_hdr) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv4_cksum_simple_w(ipv4_hdr: *const rte_ipv4_hdr) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv4_phdr_cksum_w(ipv4_hdr: *const rte_ipv4_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv4_udptcp_cksum_w(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv4_udptcp_cksum_mbuf_w(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv4_udptcp_cksum_verify_w(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv4_udptcp_cksum_mbuf_verify_w(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_eq_w(a: *const rte_ipv6_addr, b: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_mask_w(ip: *mut rte_ipv6_addr, depth: u8);
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_eq_prefix_w(
        a: *const rte_ipv6_addr,
        b: *const rte_ipv6_addr,
        depth: u8,
    ) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_mask_depth_w(mask: *const rte_ipv6_addr) -> u8;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_unspec_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_loopback_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_linklocal_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_sitelocal_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_v4compat_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_v4mapped_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_addr_is_mcast_w(ip: *const rte_ipv6_addr) -> bool;
}
unsafe extern "C" {
    pub fn rte_ipv6_mc_scope_w(ip: *const rte_ipv6_addr) -> rte_ipv6_mc_scope::Type;
}
unsafe extern "C" {
    pub fn rte_ipv6_llocal_from_ethernet_w(ip: *mut rte_ipv6_addr, mac: *const rte_ether_addr);
}
unsafe extern "C" {
    pub fn rte_ipv6_solnode_from_addr_w(sol: *mut rte_ipv6_addr, ip: *const rte_ipv6_addr);
}
unsafe extern "C" {
    pub fn rte_ether_mcast_from_ipv6_w(mac: *mut rte_ether_addr, ip: *const rte_ipv6_addr);
}
unsafe extern "C" {
    pub fn rte_ipv6_check_version_w(ip: *const rte_ipv6_hdr) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv6_phdr_cksum_w(ipv6_hdr: *const rte_ipv6_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv6_udptcp_cksum_w(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv6_udptcp_cksum_mbuf_w(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_ipv6_udptcp_cksum_verify_w(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::core::ffi::c_void,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv6_udptcp_cksum_mbuf_verify_w(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ipv6_get_next_ext_w(
        p: *const u8,
        proto: ::core::ffi::c_int,
        ext_len: *mut usize,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_meter_srtcm_color_blind_check_w(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_meter_srtcm_color_aware_check_w(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_meter_trtcm_color_blind_check_w(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_meter_trtcm_color_aware_check_w(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_meter_trtcm_rfc4115_color_blind_check_w(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_meter_trtcm_rfc4115_color_aware_check_w(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color::Type,
    ) -> rte_color::Type;
}
unsafe extern "C" {
    pub fn rte_eth_rss_hf_refine_w(rss_hf: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_eth_rx_burst_w(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_rx_queue_count_w(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_eth_rx_descriptor_status_w(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_eth_tx_descriptor_status_w(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_eth_tx_burst_w(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_tx_prepare_w(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_tx_buffer_flush_w(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_tx_buffer_w(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
        tx_pkt: *mut rte_mbuf,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_recycle_mbufs_w(
        rx_port_id: u16,
        rx_queue_id: u16,
        tx_port_id: u16,
        tx_queue_id: u16,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> u16;
}
unsafe extern "C" {
    pub fn rte_eth_tx_queue_count_w(port_id: u16, queue_id: u16) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_flow_dynf_metadata_get_w(m: *mut rte_mbuf) -> u32;
}
unsafe extern "C" {
    pub fn rte_flow_dynf_metadata_set_w(m: *mut rte_mbuf, v: u32);
}
unsafe extern "C" {
    pub fn rte_flow_dynf_metadata_avail_w() -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_hash_crc_1byte_w(data: u8, init_val: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_hash_crc_2byte_w(data: u16, init_val: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_hash_crc_4byte_w(data: u32, init_val: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_hash_crc_8byte_w(data: u64, init_val: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_hash_crc_w(data: *const ::core::ffi::c_void, data_len: u32, init_val: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_jhash_2hashes_w(
        key: *const ::core::ffi::c_void,
        length: u32,
        pc: *mut u32,
        pb: *mut u32,
    );
}
unsafe extern "C" {
    pub fn rte_jhash_32b_2hashes_w(k: *const u32, length: u32, pc: *mut u32, pb: *mut u32);
}
unsafe extern "C" {
    pub fn rte_jhash_w(key: *const ::core::ffi::c_void, length: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_jhash_32b_w(k: *const u32, length: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_jhash_3words_w(a: u32, b: u32, c: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_jhash_2words_w(a: u32, b: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_jhash_1word_w(a: u32, initval: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_get_bucket_w(ht: *const rte_fbk_hash_table, key: u32) -> u32;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_add_key_with_bucket_w(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        value: u16,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_add_key_w(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        value: u16,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_delete_key_with_bucket_w(
        ht: *mut rte_fbk_hash_table,
        key: u32,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_delete_key_w(ht: *mut rte_fbk_hash_table, key: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_lookup_with_bucket_w(
        ht: *const rte_fbk_hash_table,
        key: u32,
        bucket: u32,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_lookup_w(ht: *const rte_fbk_hash_table, key: u32) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_fbk_hash_clear_all_w(ht: *mut rte_fbk_hash_table);
}
unsafe extern "C" {
    pub fn rte_fbk_hash_get_load_factor_w(ht: *mut rte_fbk_hash_table) -> f64;
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_thread_online_w(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_thread_offline_w(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_lock_w(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_unlock_w(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_start_w(v: *mut rte_rcu_qsbr) -> u64;
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_quiescent_w(v: *mut rte_rcu_qsbr, thread_id: ::core::ffi::c_uint);
}
unsafe extern "C" {
    pub fn rte_rcu_qsbr_check_w(v: *mut rte_rcu_qsbr, t: u64, wait: bool) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_read8_relaxed_w(addr: *const ::core::ffi::c_void) -> u8;
}
unsafe extern "C" {
    pub fn rte_read16_relaxed_w(addr: *const ::core::ffi::c_void) -> u16;
}
unsafe extern "C" {
    pub fn rte_read32_relaxed_w(addr: *const ::core::ffi::c_void) -> u32;
}
unsafe extern "C" {
    pub fn rte_read64_relaxed_w(addr: *const ::core::ffi::c_void) -> u64;
}
unsafe extern "C" {
    pub fn rte_write8_relaxed_w(value: u8, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write16_relaxed_w(value: u16, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write32_relaxed_w(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write64_relaxed_w(value: u64, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_read8_w(addr: *const ::core::ffi::c_void) -> u8;
}
unsafe extern "C" {
    pub fn rte_read16_w(addr: *const ::core::ffi::c_void) -> u16;
}
unsafe extern "C" {
    pub fn rte_read32_w(addr: *const ::core::ffi::c_void) -> u32;
}
unsafe extern "C" {
    pub fn rte_read64_w(addr: *const ::core::ffi::c_void) -> u64;
}
unsafe extern "C" {
    pub fn rte_write8_w(value: u8, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write16_w(value: u16, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write32_w(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write64_w(value: u64, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write32_wc_relaxed_w(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_write32_wc_w(value: u32, addr: *mut ::core::ffi::c_void);
}
unsafe extern "C" {
    pub fn rte_mcslock_lock_w(msl: *mut *mut rte_mcslock_t, me: *mut rte_mcslock_t);
}
unsafe extern "C" {
    pub fn rte_mcslock_unlock_w(msl: *mut *mut rte_mcslock_t, me: *mut rte_mcslock_t);
}
unsafe extern "C" {
    pub fn rte_mcslock_trylock_w(
        msl: *mut *mut rte_mcslock_t,
        me: *mut rte_mcslock_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_mcslock_is_locked_w(msl: *mut rte_mcslock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_net_intel_cksum_flags_prepare_w(
        m: *mut rte_mbuf,
        ol_flags: u64,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_net_intel_cksum_prepare_w(m: *mut rte_mbuf) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_pflock_init_w(pf: *mut rte_pflock);
}
unsafe extern "C" {
    pub fn rte_pflock_read_lock_w(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    pub fn rte_pflock_read_unlock_w(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    pub fn rte_pflock_write_lock_w(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    pub fn rte_pflock_write_unlock_w(pf: *mut rte_pflock_t);
}
unsafe extern "C" {
    pub fn rte_reciprocal_divide_w(a: u32, R: rte_reciprocal) -> u32;
}
unsafe extern "C" {
    pub fn rte_reciprocal_divide_u64_w(a: u64, R: *const rte_reciprocal_u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_seqcount_init_w(seqcount: *mut rte_seqcount_t);
}
unsafe extern "C" {
    pub fn rte_seqcount_read_begin_w(seqcount: *const rte_seqcount_t) -> u32;
}
unsafe extern "C" {
    pub fn rte_seqcount_read_retry_w(seqcount: *const rte_seqcount_t, begin_sn: u32) -> bool;
}
unsafe extern "C" {
    pub fn rte_seqcount_write_begin_w(seqcount: *mut rte_seqcount_t);
}
unsafe extern "C" {
    pub fn rte_seqcount_write_end_w(seqcount: *mut rte_seqcount_t);
}
unsafe extern "C" {
    pub fn rte_seqlock_init_w(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    pub fn rte_seqlock_read_begin_w(seqlock: *const rte_seqlock_t) -> u32;
}
unsafe extern "C" {
    pub fn rte_seqlock_read_retry_w(seqlock: *const rte_seqlock_t, begin_sn: u32) -> bool;
}
unsafe extern "C" {
    pub fn rte_seqlock_write_lock_w(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    pub fn rte_seqlock_write_unlock_w(seqlock: *mut rte_seqlock_t);
}
unsafe extern "C" {
    pub fn rte_stack_push_w(
        s: *mut rte_stack,
        obj_table: *const *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_stack_pop_w(
        s: *mut rte_stack,
        obj_table: *mut *mut ::core::ffi::c_void,
        n: ::core::ffi::c_uint,
    ) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_stack_count_w(s: *mut rte_stack) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_stack_free_count_w(s: *mut rte_stack) -> ::core::ffi::c_uint;
}
unsafe extern "C" {
    pub fn rte_softrss_w(input_tuple: *mut u32, input_len: u32, rss_key: *const u8) -> u32;
}
unsafe extern "C" {
    pub fn rte_softrss_be_w(input_tuple: *mut u32, input_len: u32, rss_key: *const u8) -> u32;
}
unsafe extern "C" {
    pub fn rte_ticketlock_init_w(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_lock_w(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_unlock_w(tl: *mut rte_ticketlock_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_trylock_w(tl: *mut rte_ticketlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ticketlock_is_locked_w(tl: *mut rte_ticketlock_t) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_ticketlock_recursive_init_w(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_recursive_lock_w(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_recursive_unlock_w(tlr: *mut rte_ticketlock_recursive_t);
}
unsafe extern "C" {
    pub fn rte_ticketlock_recursive_trylock_w(
        tlr: *mut rte_ticketlock_recursive_t,
    ) -> ::core::ffi::c_int;
}
unsafe extern "C" {
    pub fn rte_cyclecounter_cycles_to_ns_w(tc: *mut rte_timecounter, cycles: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_timecounter_update_w(tc: *mut rte_timecounter, cycle_now: u64) -> u64;
}
unsafe extern "C" {
    pub fn rte_timespec_to_ns_w(ts: *const timespec) -> u64;
}
unsafe extern "C" {
    pub fn rte_ns_to_timespec_w(nsec: u64) -> timespec;
}
unsafe extern "C" {
    pub fn rte_trace_feature_is_enabled_w() -> bool;
}
pub type __builtin_va_list = [__va_list_tag; 1usize];
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __va_list_tag {
    pub gp_offset: ::core::ffi::c_uint,
    pub fp_offset: ::core::ffi::c_uint,
    pub overflow_arg_area: *mut ::core::ffi::c_void,
    pub reg_save_area: *mut ::core::ffi::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __va_list_tag"][::core::mem::size_of::<__va_list_tag>() - 24usize];
    ["Alignment of __va_list_tag"][::core::mem::align_of::<__va_list_tag>() - 8usize];
    ["Offset of field: __va_list_tag::gp_offset"]
        [::core::mem::offset_of!(__va_list_tag, gp_offset) - 0usize];
    ["Offset of field: __va_list_tag::fp_offset"]
        [::core::mem::offset_of!(__va_list_tag, fp_offset) - 4usize];
    ["Offset of field: __va_list_tag::overflow_arg_area"]
        [::core::mem::offset_of!(__va_list_tag, overflow_arg_area) - 8usize];
    ["Offset of field: __va_list_tag::reg_save_area"]
        [::core::mem::offset_of!(__va_list_tag, reg_save_area) - 16usize];
};
impl Default for __va_list_tag {
    fn default() -> Self {
        let mut s = ::core::mem::MaybeUninit::<Self>::uninit();
        unsafe {
            ::core::ptr::write_bytes(s.as_mut_ptr(), 0, 1);
            s.assume_init()
        }
    }
}
#[doc = "< Opaque item handle."]
#[repr(C)]
#[derive(Debug, Default, Copy, Clone)]
pub struct rte_flow_item_flex_handle {
    pub _address: u8,
}
